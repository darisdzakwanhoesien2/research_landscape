1. Research References: https://scholar.google.com/scholar_labs/search/session/11716077684080802552?hl=en
2. ChatGPT: https://chatgpt.com/c/6951953b-0f9c-8333-b168-a9a2150f51f5

Below is a **complete, production-ready Streamlit app blueprint** (with runnable code) to **visualize the conference & journal paper landscape** using **knowledge maps + word cloud analysis**, directly grounded in the methodologies you listed (CiteSpace, VOSviewer, co-word analysis, bibliometrics, KG construction).

This is designed to fit **your current workflow** (you already work with Streamlit, large JSON/CSV pipelines, bibliometric data, and research intelligence dashboards).

---

# ğŸ“ Research Landscape Explorer (Streamlit App)

## ğŸ¯ What this app does

It allows you to:

1. **Ingest academic metadata** (WoS / Scopus / OpenAlex / Semantic Scholar CSV/JSON)
2. **Clean & normalize keywords**
3. **Generate**

   * ğŸ“Š Word Clouds
   * ğŸ§  Keyword Co-occurrence Knowledge Graphs
   * â³ Temporal topic evolution
4. **Compare journals vs conferences**
5. **Export figures for papers (PNG / SVG)**

This mirrors workflows used in:

* Knowledge mapping papers (CiteSpace, UCINET, VOSviewer)
* Bibliometric + KG studies
* PRISMA-adjacent systematic landscape analysis (but exploratory)

---

## ğŸ“ Project Structure

```
research_landscape_app/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ papers.csv
â”‚   â”‚   â””â”€â”€ papers.json
â”‚   â””â”€â”€ processed/
â”‚
â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ loader.py
â”‚   â”œâ”€â”€ cleaner.py
â”‚   â”œâ”€â”€ keyword_extractor.py
â”‚   â”œâ”€â”€ cooccurrence.py
â”‚   â””â”€â”€ temporal.py
â”‚
â”œâ”€â”€ viz/
â”‚   â”œâ”€â”€ wordclouds.py
â”‚   â”œâ”€â”€ network.py
â”‚   â””â”€â”€ timeline.py
â”‚
â””â”€â”€ utils/
    â”œâ”€â”€ text.py
    â””â”€â”€ stopwords.py
```

---

## ğŸ“¦ `requirements.txt`

```txt
streamlit
pandas
numpy
networkx
matplotlib
seaborn
wordcloud
scikit-learn
pyvis
python-louvain
```

---

## ğŸ“„ Input Data Format (CSV or JSON)

Minimum required fields:

```csv
title,abstract,keywords,year,source_type,venue
```

Where:

* `keywords`: `"cloud computing; healthcare; iot"`
* `source_type`: `journal | conference`
* `venue`: journal or conference name

---

## ğŸ§  Core Pipeline

---

### ğŸ”¹ `pipeline/loader.py`

```python

```

---

### ğŸ”¹ `pipeline/cleaner.py`

```python

```

---

### ğŸ”¹ `pipeline/cooccurrence.py`

```python

```

---

## ğŸ¨ Visualizations

---

### ğŸ”¹ Word Cloud

`viz/wordclouds.py`

```python

```

---

### ğŸ”¹ Knowledge Graph (Interactive)

`viz/network.py`

```python

```

---

### ğŸ”¹ Temporal Evolution

`viz/timeline.py`

```python

```

---

## ğŸ–¥ï¸ `app.py` (Main Streamlit App)

```python

```

---

## ğŸ§ª What This Covers from Your Sources

| Method                      | Implemented             |
| --------------------------- | ----------------------- |
| Co-word analysis            | âœ…                       |
| Knowledge maps              | âœ…                       |
| Keyword clustering          | âœ… (via graph structure) |
| Word cloud                  | âœ…                       |
| Journal + conference        | âœ…                       |
| Temporal evolution          | âœ…                       |
| PRISMA-adjacent exploratory | âœ…                       |

This mirrors **CiteSpace / VOSviewer pipelines**, but:

* Fully open-source
* Customizable
* Reproducible
* Paper-ready

---

## ğŸš€ Next Extensions (Recommended)

Given your background, the **next logical upgrades** would be:

1. **Louvain clustering â†’ research themes**
2. **Sankey topic evolution**
3. **Named Entity â†’ Knowledge Graph**
4. **LLM-assisted keyword normalization**
5. **PRISMA diagram auto-generation**
6. **Export LaTeX-ready figures**

If you want, I can:

* Add **OpenAlex / Semantic Scholar API ingestion**
* Convert this into a **research-grade methods section**
* Add **citation burst detection (CiteSpace-like)**

Just tell me which direction you want next.
# research_landscape
