DOI,Title,Authors,Journal,Year,Abstract,LitmapsId,Cited By,References,PubMedId,Tags
10.18653/v1/2025.acl-long.505,Cracking Factual Knowledge: A Comprehensive Analysis of Degenerate Knowledge Neurons in Large Language Models,"Yuheng Chen, Pengfei Cao, Yubo Chen, Yining Wang, Shengping Liu, Kang Liu, Jun Zhao",Annual Meeting of the Association for Computational Linguistics,2024,"Large language models (LLMs) store extensive factual knowledge, but the underlying mechanisms remain unclear. Previous research suggests that factual knowledge is stored within multi-layer perceptron weights, and some storage units exhibit degeneracy, referred to as Degenerate Knowledge Neurons (DKNs). Despite the novelty and unique properties of this concept, it has not been rigorously defined or systematically studied. We first consider the connection weight patterns of MLP neurons and define DKNs from both structural and functional aspects. Based on this, we introduce the Neurological Topology Clustering method, which allows the formation of DKNs in any numbers and structures, leading to a more accurate DKN acquisition. Furthermore, inspired by cognitive science, we explore the relationship between DKNs and the robustness, evolvability, and complexity of LLMs. Our execution of 34 experiments under 6 settings demonstrates the connection between DKNs and these three properties. The code will be available soon.",274087012,3,34,,
10.48550/arxiv.2409.12737,MEXMA: Token-level objectives improve sentence representations,"Joao Maria Janeiro, Benjamin Piwowarski, P. Gallinari, Loic Barrault",arXiv.org,2024,"Current pre-trained cross-lingual sentence encoders approaches use sentence-level objectives only. This can lead to loss of information, especially for tokens, which then degrades the sentence representation. We propose MEXMA, a novel approach that integrates both sentence-level and token-level objectives. The sentence representation in one language is used to predict masked tokens in another language, with both the sentence representation and all tokens directly updating the encoder. We show that adding token-level objectives greatly improves the sentence representation quality across several tasks. Our approach outperforms current pre-trained cross-lingual sentence encoders on bi-text mining as well as several downstream tasks. We also analyse the information encoded in our tokens, and how the sentence representation is built from them.",277965403,3,41,,
10.18653/v1/2025.acl-long.244,Enhancing Unsupervised Sentence Embeddings via Knowledge-Driven Data Augmentation and Gaussian-Decayed Contrastive Learning,"Peichao Lai, Zhengfeng Zhang, Wentao Zhang, Fangcheng Fu, Bin Cui",Annual Meeting of the Association for Computational Linguistics,2024,"Recently, using large language models (LLMs) for data augmentation has led to considerable improvements in unsupervised sentence embedding models. However, existing methods encounter two primary challenges: limited data diversity and high data noise. Current approaches often neglect fine-grained knowledge, such as entities and quantities, leading to insufficient diversity. Besides, unsupervised data frequently lacks discriminative information, and the generated synthetic samples may introduce noise. In this paper, we propose a pipeline-based data augmentation method via LLMs and introduce the Gaussian-decayed gradient-assisted Contrastive Sentence Embedding (GCSE) model to enhance unsupervised sentence embeddings. To tackle the issue of low data diversity, our pipeline utilizes knowledge graphs (KGs) to extract entities and quantities, enabling LLMs to generate more diverse samples. To address high data noise, the GCSE model uses a Gaussian-decayed function to limit the impact of false hard negative samples, enhancing the model's discriminative capability. Experimental results show that our approach achieves state-of-the-art performance in semantic textual similarity (STS) tasks, using fewer data samples and smaller LLMs, demonstrating its efficiency and robustness across various models.",278553014,4,69,,
10.18653/v1/2025.acl-long.223,Auto-Arena: Automating LLM Evaluations with Agent Peer Battles and Committee Discussions,"Ruochen Zhao, Wenxuan Zhang, Yew Ken Chia, Deli Zhao, Lidong Bing",Annual Meeting of the Association for Computational Linguistics,2024,"As LLMs continuously evolve, there is an urgent need for a reliable evaluation method that delivers trustworthy results promptly. Currently, static benchmarks suffer from inflexibility and unreliability, leading users to prefer human voting platforms like Chatbot Arena. However, human evaluations require significant manual effort. To address this, we propose the Auto-Arena, an innovative framework that automates the entire evaluation process using LLM-powered agents. Firstly, an LLM examiner generates questions. Then, two LLM candidates engage in a multi-round peer battle based on individual questions, aiming at revealing their true performance differences. Finally, a committee of LLM judges collaboratively discusses and decides the winner, reducing bias and enhancing fairness. During the peer battles, we observe intriguing scenarios where the LLM candidates display competitive behaviors and even learn from the opponents. In our extensive experiments involving 15 recent LLMs, Auto-Arena shows a 92.14% correlation with human preferences, surpassing all previous expert-annotated benchmarks without any manual efforts. As a result, Auto-Arena offers a promising alternative to current human evaluation platforms for evaluating LLMs automatically.",279107490,18,47,,
10.18653/v1/2025.acl-long.1544,PKU-SafeRLHF: Towards Multi-Level Safety Alignment for LLMs with Human Preference,"Jiaming Ji, Donghai Hong, Borong Zhang, Boyuan Chen, Josef Dai, Boren Zheng, Tianyi Qiu, Boxun Li, Yaodong Yang",Annual Meeting of the Association for Computational Linguistics,2024,"In this study, we introduce the safety human preference dataset, PKU-SafeRLHF, designed to promote research on safety alignment in large language models (LLMs). As a sibling project to SafeRLHF and BeaverTails, we separate annotations of helpfulness and harmlessness for question-answering pairs, providing distinct perspectives on these coupled attributes. Overall, we provide 44.6k refined prompts and 265k question-answer pairs with safety meta-labels for 19 harm categories and three severity levels ranging from minor to severe, with answers generated by Llama-family models. Based on this, we collected 166.8k preference data, including dual-preference (helpfulness and harmlessness decoupled) and single-preference data (trade-off the helpfulness and harmlessness from scratch), respectively. Using the large-scale annotation data, we further train severity-sensitive moderation for the risk control of LLMs and safety-centric RLHF algorithms for the safety alignment of LLMs. We believe this dataset will be a valuable resource for the community, aiding in the safe deployment of LLMs. Data is available at https://huggingface.co/datasets/PKU-Alignment/PKU-SafeRLHF.",280084878,94,56,,
10.18653/v1/2025.acl-long.321,Can Graph Descriptive Order Affect Solving Graph Problems with LLMs?,"Yuyao Ge, Shenghua Liu, Baolong Bi, Yiwei Wang, Lingrui Mei, Wenjie Feng, Lizhe Chen, Xueqi Cheng",Annual Meeting of the Association for Computational Linguistics,2024,"Large language models (LLMs) have achieved significant success in reasoning tasks, including mathematical reasoning and logical deduction. Among these reasoning tasks, graph problems stand out due to their complexity and unique structural characteristics, attracting considerable attention from researchers. Previous studies have explored LLMs'graph reasoning abilities through various techniques, such as different encoding methods for graph structures and the use of carefully designed prompts. However, a critical factor has been mostly overlooked: the prompt sequential order in which graph descriptions are presented to the models. In this study, we present the first comprehensive analysis of how the order of graph descriptions impacts LLM performance. Specifically, we comprehensively evaluate four graph description orders across six graph problems using six mainstream LLMs. The results reveal that: (1) ordered graph descriptions significantly improve LLMs'comprehension of graph structures; (2) the robustness of LLMs to graph description order varies across different tasks; and (3) the impact of graph order on performance is closely related to the inherent characteristics of tasks. This study provides a critical advancement in the application of LLMs for solving graph-related problems, paving the way for future research to optimize model performance through strategic graph description ordering.",280104475,12,42,,
10.18653/v1/2025.acl-long.756,SkillAggregation: Reference-free LLM-Dependent Aggregation,"Guangzhi Sun, Anmol Kagrecha, Potsawee Manakul, Phil Woodland, Mark Gales",(missing journal),2024,"Large Language Models (LLMs) are increasingly used to assess NLP tasks due to their ability to generate human-like judgments. Single LLMs were used initially, however, recent work suggests using multiple LLMs as judges yields improved performance. An important step in exploiting multiple judgements is the combination stage, aggregation. Existing methods in NLP either assign equal weight to all LLM judgments or are designed for specific tasks such as hallucination detection. This work focuses on aggregating predictions from multiple systems where no reference labels are available. A new method called SkillAggregation is proposed, which learns to combine estimates from LLM judges without needing additional data or ground truth. It extends the Crowdlayer aggregation method, developed for image classification, to exploit the judge estimates during inference. The approach is compared to a range of standard aggregation methods on HaluEval-Dialogue, TruthfulQA and Chatbot Arena tasks. SkillAggregation outperforms Crowdlayer on all tasks, and yields the best performance over all approaches on the majority of tasks.",280113465,2,27,,
10.18653/v1/2025.acl-long.1488,Theoretical Analysis of Hierarchical Language Recognition and Generation by Transformers without Positional Encoding,"Daichi Hayakawa, Issei Sato",(missing journal),2024,"In this study, we provide constructive proof that Transformers can recognize and generate hierarchical language efficiently with respect to model size, even without the need for a specific positional encoding. Specifically, we show that causal masking and a starting token enable Transformers to compute positional information and depth within hierarchical structures. We demonstrate that Transformers without positional encoding can generate hierarchical languages. Furthermore, we suggest that explicit positional encoding might have a detrimental effect on generalization with respect to sequence length.",280118714,0,0,,
10.18653/v1/2025.acl-long.1421,Bypass Back-propagation: Optimization-based Structural Pruning for Large Language Models via Policy Gradient,"Yuan Gao, Zujing Liu, Weizhong Zhang, Bo Du, Gui-Song Xia",Annual Meeting of the Association for Computational Linguistics,2024,"Recent Large-Language Models (LLMs) pruning methods typically operate at the post-training phase without the expensive weight finetuning, however, their pruning criteria often rely on heuristically hand-crafted metrics, potentially leading to suboptimal performance. We instead propose a novel optimization-based structural pruning that learns the pruning masks in a probabilistic space directly by optimizing the loss of the pruned model. To preserve efficiency, our method eliminates the back-propagation through the LLM per se during optimization, requiring only the forward pass of the LLM. We achieve this by learning an underlying Bernoulli distribution to sample binary pruning masks, where we decouple the Bernoulli parameters from LLM loss, facilitating efficient optimization via policy gradient estimator without back-propagation. Thus, our method can 1) support global and heterogeneous pruning (i.e., automatically determine different redundancy for different layers), and 2) optionally initialize with a metric-based method (for our Bernoulli distributions). Extensive experiments conducted on LLaMA, LLaMA-2, LLaMA-3, Vicuna, and Mistral models using the C4 and WikiText2 datasets demonstrate the promising performance of our method in efficiency and effectiveness. Code is available at https://github.com/ethanygao/backprop-free_LLM_pruning.",280340867,3,79,,
10.18653/v1/2025.acl-long.449,The Male CEO and the Female Assistant: Evaluation and Mitigation of Gender Biases in Text-To-Image Generation of Dual Subjects,"Yixin Wan, Kai-Wei Chang",Annual Meeting of the Association for Computational Linguistics,2024,"Recent large-scale T2I models like DALLE-3 have made progress in reducing gender stereotypes when generating single-person images. However, significant biases remain when generating images with more than one person. To systematically evaluate this, we propose the Paired Stereotype Test (PST) framework, which queries T2I models to depict two individuals assigned with male-stereotyped and female-stereotyped social identities, respectively (e.g.""a CEO""and""an Assistant""). This contrastive setting often triggers T2I models to generate gender-stereotyped images. Using PST, we evaluate two aspects of gender biases -- the well-known bias in gendered occupation and a novel aspect: bias in organizational power. Experiments show that over 74\% images generated by DALLE-3 display gender-occupational biases. Additionally, compared to single-person settings, DALLE-3 is more likely to perpetuate male-associated stereotypes under PST. We further propose FairCritic, a novel and interpretable framework that leverages an LLM-based critic model to i) detect bias in generated images, and ii) adaptively provide feedback to T2I models for improving fairness. FairCritic achieves near-perfect fairness on PST, overcoming the limitations of previous prompt-based intervention approaches.",280348075,6,20,,
10.18653/v1/2025.acl-long.657,Code-Switching Red-Teaming: LLM Evaluation for Safety and Multilingual Understanding,"Haneul Yoo, Yongjin Yang, Hwaran Lee",Annual Meeting of the Association for Computational Linguistics,2024,"As large language models (LLMs) have advanced rapidly, concerns regarding their safety have become prominent. In this paper, we discover that code-switching in red-teaming queries can effectively elicit undesirable behaviors of LLMs, which are common practices in natural language. We introduce a simple yet effective framework, CSRT, to synthesize codeswitching red-teaming queries and investigate the safety and multilingual understanding of LLMs comprehensively. Through extensive experiments with ten state-of-the-art LLMs and code-switching queries combining up to 10 languages, we demonstrate that the CSRT significantly outperforms existing multilingual red-teaming techniques, achieving 46.7% more attacks than standard attacks in English and being effective in conventional safety domains. We also examine the multilingual ability of those LLMs to generate and understand codeswitching texts. Additionally, we validate the extensibility of the CSRT by generating codeswitching attack prompts with monolingual data. We finally conduct detailed ablation studies exploring code-switching and propound unintended correlation between resource availability of languages and safety alignment in existing multilingual LLMs.",281181716,14,49,,
10.18653/v1/2025.acl-long.56,BIPro: Zero-shot Chinese Poem Generation via Block Inverse Prompting Constrained Generation Framework,Xu Zou,arXiv.org,2024,"Recently, generative pre-trained models have made significant strides, particularly highlighted by the release of ChatGPT and GPT-4, which exhibit superior cross-domain capabilities. However, these models still face challenges on constrained writing tasks like poem generation under open-domain titles. In response to this challenge, we introduce Block Inverse Prompting (BIPro) constrained generation framework. BIPro leverages two block inverse prompting methods, revise and rewrite, that mimic the process of human text writing using block generative models. It significantly improves the zero-shot generation quality on the formidable constrained generation task of open-domain traditional-form Chinese poem generation. Based on a less powerful block generative model GLM-10B-Chinese, poems composed via BIPro without priming or additional training outperform both most advanced direct generative systems like GPT-4 or GLM-4 and best domain-specific systems such as Yusheng, Shisanbai, or Baidu Poetry Helper in human evaluation by proficient poets. Finally, BIPro considerably narrows the gap between AI-generated works and short-listed human literary arts in another human evaluation, unveiling the promising potential of block generative models in improving the quality of constrained generation.",281642277,0,0,,
10.18653/v1/2025.acl-long.1371,Opt-Out: Investigating Entity-Level Unlearning for Large Language Models via Optimal Transport,"Minseok Choi, Daniel Rim, Dohyun Lee, Jaegul Choo",Annual Meeting of the Association for Computational Linguistics,2024,"Instruction-following large language models (LLMs), such as ChatGPT, have become widely popular among everyday users. However, these models inadvertently disclose private, sensitive information to their users, underscoring the need for machine unlearning techniques to remove selective information from the models. While prior work has focused on forgetting small, random subsets of training data at the instance-level, we argue that real-world scenarios often require the removal of an entire user data, which may require a more careful maneuver. In this study, we explore entity-level unlearning, which aims to erase all knowledge related to a target entity while preserving the remaining model capabilities. To address this, we introduce Opt-Out, an optimal transport-based unlearning method that utilizes the Wasserstein distance from the model's initial parameters to achieve more effective and fine-grained unlearning. We also present the first Entity-Level Unlearning Dataset (ELUDe) designed to evaluate entity-level unlearning. Our empirical results demonstrate that Opt-Out surpasses existing methods, establishing a new standard for secure and adaptable LLMs that can accommodate user data removal requests without the need for full retraining.",282334363,6,62,,
10.18653/v1/2025.acl-long.452,DavIR: Data Selection via Implicit Reward for Large Language Models,"Haotian Zhou, Tingkai Liu, Qianli Ma, Yufeng Zhang, Jianbo Yuan, Pengfei Liu, Yang You, Hongxia Yang",Annual Meeting of the Association for Computational Linguistics,2023,"We introduce DavIR, a model-based data selection method for post-training Large Language Models. DavIR generalizes Reducible Holdout Loss to core-set selection problem of causal language modeling, and quantifies the learnability of a given datum with respect to a pre-trained LLM based on relative reduction in loss during fine-tuning, a metric we show to be closely related to the implicit reward model described in Direct Preference Optimization (DPO). We show that 6% of Alpaca dataset selected with DavIR can steer both the LLaMA and Gemma model family to produce superior performance compared to the same models trained on the full 52K dataset. We also show that Alpaca dataset compressed with DavIR can be combined with GSM8K dataset to effectively balance open-domain freeform QA and mathematical reasoning capabilities. Finally, we apply the DavIR objective to DPO and develop a normalized DavIR-DPO objective which improves alignment performance of Zephyr-7B-SFT model by 8% (relative) on AlpacaEval, compared against training on vanilla DPO objective.",282810442,7,47,,
10.18653/v1/2025.acl-long.283,P$^2$ Law: Scaling Law for Post-Training After Model Pruning,"Xiaodong Chen, Yuxuan Hu, Xiaokang Zhang, Yanling Wang, Cuiping Li, Hong Chen, Jing Zhang",(missing journal),2024,"Pruning has become a widely adopted technique for reducing the hardware requirements of large language models (LLMs). To recover model performance after pruning, post-training is commonly employed to mitigate the resulting performance degradation. While post-training benefits from larger datasets, once the dataset size is already substantial, increasing the training data provides only limited performance gains. To balance post-training cost and model performance, it is necessary to explore the optimal amount of post-training data.Through extensive experiments on the Llama-3 and Qwen-2.5 series models, pruned using various common pruning methods, we uncover the scaling \textbf{Law} for \textbf{P}ost-training after model \textbf{P}runing, referred to as the P$^2$ Law.This law identifies four key factors for predicting the pruned model's post-training loss: the model size before pruning, the number of post-training tokens, the pruning rate, and the model's loss before pruning. Moreover, P$^2$ Law can generalize to larger dataset sizes, larger model sizes, and higher pruning rates, offering valuable insights for the post-training of pruned LLMs.",282815755,1,13,,
10.18653/v1/2025.acl-long.752,DS$^2$-ABSA: Dual-Stream Data Synthesis with Label Refinement for Few-Shot Aspect-Based Sentiment Analysis,"Hongling Xu, Yice Zhang, Qianlong Wang, Ruifeng Xu",(missing journal),2024,"Recently developed large language models (LLMs) have presented promising new avenues to address data scarcity in low-resource scenarios. In few-shot aspect-based sentiment analysis (ABSA), previous efforts have explored data augmentation techniques, which prompt LLMs to generate new samples by modifying existing ones. However, these methods fail to produce adequately diverse data, impairing their effectiveness. Besides, some studies apply in-context learning for ABSA by using specific instructions and a few selected examples as prompts. Though promising, LLMs often yield labels that deviate from task requirements. To overcome these limitations, we propose DS$^2$-ABSA, a dual-stream data synthesis framework targeted for few-shot ABSA. It leverages LLMs to synthesize data from two complementary perspectives: \textit{key-point-driven} and \textit{instance-driven}, which effectively generate diverse and high-quality ABSA samples in low-resource settings. Furthermore, a \textit{label refinement} module is integrated to improve the synthetic labels. Extensive experiments demonstrate that DS$^2$-ABSA significantly outperforms previous few-shot ABSA solutions and other LLM-oriented data generation methods.",282817484,3,0,,
10.18653/v1/2025.acl-long.588,Quantifying Semantic Emergence in Language Models,"Hang Chen, Xinyu Yang, Jiaying Zhu, Wenya Wang",Annual Meeting of the Association for Computational Linguistics,2024,"Large language models (LLMs) are widely recognized for their exceptional capacity to capture semantics meaning. Yet, there remains no established metric to quantify this capability. In this work, we introduce a quantitative metric, Information Emergence (IE), designed to measure LLMs' ability to extract semantics from input tokens. We formalize ``semantics'' as the meaningful information abstracted from a sequence of tokens and quantify this by comparing the entropy reduction observed for a sequence of tokens (macro-level) and individual tokens (micro-level). To achieve this, we design a lightweight estimator to compute the mutual information at each transformer layer, which is agnostic to different tasks and language model architectures. We apply IE in both synthetic in-context learning (ICL) scenarios and natural sentence contexts. Experiments demonstrate informativeness and patterns about semantics. While some of these patterns confirm the conventional prior linguistic knowledge, the rest are relatively unexpected, which may provide new insights.",282817766,1,41,,
10.18653/v1/2025.acl-long.1141,Language Models Resist Alignment: Evidence From Data Compression,"Jiaming Ji, Kaile Wang, Tianyi Qiu, Boyuan Chen, Jiayi Zhou, Changye Li, Hantao Lou, Josef Dai, Yunhuai Liu, Yaodong Yang",Annual Meeting of the Association for Computational Linguistics,2024,"Large language models (LLMs) may exhibit unintended or undesirable behaviors. Recent works have concentrated on aligning LLMs to mitigate harmful outputs. Despite these efforts, some anomalies indicate that even a well-conducted alignment process can be easily circumvented, whether intentionally or accidentally. Does alignment fine-tuning yield have robust effects on models, or are its impacts merely superficial? In this work, we make the first exploration of this phenomenon from both theoretical and empirical perspectives. Empirically, we demonstrate the $\mathbf{elasticity}$ of post-alignment models, i.e., the tendency to revert to the behavior distribution formed during the pre-training phase upon further fine-tuning. Leveraging compression theory, we formally deduce that fine-tuning disproportionately undermines alignment relative to pre-training, potentially by orders of magnitude. We validate the presence of elasticity through experiments on models of varying types and scales. Specifically, we find that model performance declines rapidly before reverting to the pre-training distribution, after which the rate of decline drops significantly. Furthermore, we further reveal that elasticity positively correlates with the increased model size and the expansion of pre-training data. Our findings underscore the need to address the inherent elasticity of LLMs to mitigate their resistance to alignment. The model weight and code are available at pku-lm-resist-alignment.github.io.",282819519,12,69,,
(missing DOI),ConSim: Measuring Concept-Based Explanations’ Effectiveness with Automated Simulatability,"Antonin Poché, Alon Jacovi, Agustin Martin Picard, Victor Boutin, Fanny Jourdan",(missing journal),2024,(missing abstract),283180759,0,0,,
10.18653/v1/2025.acl-long.1500,FocusLLM: Precise Understanding of Long Context by Dynamic Condensing,"Zhenyu Li, Yike Zhang, Tengyu Pan, Yutao Sun, Zhichao Duan, Junjie Fang, Rong Han, Zixuan Wang, Jianyong Wang",(missing journal),2024,"Empowering LLMs with the ability to precisely understand long contexts is crucial for many downstream applications. However, handling long contexts with conventional transformer architecture requires substantial training and inference resources. Existing context condensing methods cannot accurately understand the full context, as there is a considerable amount of information loss in the condensing process. To address these issues, we present FocusLLM, a framework designed to extend the fixed context length of any decoder-only LLM, allowing the model to focus on relevant information from very long sequences. FocusLLM first divides long text input into chunks based on the model's original context length. It then employs the dynamic condensing process to distill crucial information from each chunk. Ultimately, through the novel parallel decoding mechanism, FocusLLM can integrate the extracted information into its local context. FocusLLM stands out for great training efficiency and versatility: trained with an 8K input length and with much less training cost than previous methods, FocusLLM exhibits superior performance across downstream tasks and maintains strong language modeling ability when handling extensive long texts, even up to 400K tokens. Our code is available at https://github.com/leezythu/FocusLLM.",283236296,5,21,,
10.18653/v1/2025.acl-long.303,Beyond Position: the emergence of wavelet-like properties in Transformers,"Valeria Ruscio, Fabrizio Silvestri",Annual Meeting of the Association for Computational Linguistics,2024,"This paper studies how Transformer models with Rotary Position Embeddings (RoPE) develop emergent, wavelet-like properties that compensate for the positional encoding's theoretical limitations. Through an analysis spanning model scales, architectures, and training checkpoints, we show that attention heads evolve to implement multi-resolution processing analogous to wavelet transforms. We demonstrate that this scale-invariant behavior is unique to RoPE, emerges through distinct evolutionary phases during training, and statistically adheres to the fundamental uncertainty principle. Our findings suggest that the effectiveness of modern Transformers stems from their remarkable ability to spontaneously develop optimal, multi-resolution decompositions to address inherent architectural constraints.",283975486,1,13,,
10.18653/v1/2025.acl-long.415,Unanswerability Evaluation for Retrieval Augmented Generation,"Xiangyu Peng, Prafulla Kumar Choubey, Caiming Xiong, Chien-Sheng Wu",Annual Meeting of the Association for Computational Linguistics,2024,"Existing evaluation frameworks for retrieval-augmented generation (RAG) systems focus on answerable queries, but they overlook the importance of appropriately rejecting unanswerable requests. In this paper, we introduce UAEval4RAG, a framework designed to evaluate whether RAG systems can handle unanswerable queries effectively. We define a taxonomy with six unanswerable categories, and UAEval4RAG automatically synthesizes diverse and challenging queries for any given knowledge base with unanswered ratio and acceptable ratio metrics. We conduct experiments with various RAG components, including retrieval models, rewriting methods, rerankers, language models, and prompting strategies, and reveal hidden trade-offs in performance of RAG systems. Our findings highlight the critical role of component selection and prompt design in optimizing RAG systems to balance the accuracy of answerable queries with high rejection rates of unanswerable ones. UAEval4RAG provides valuable insights and tools for developing more robust and reliable RAG systems.",284283101,1,37,,
10.18653/v1/2025.acl-long.351,M-MAD: Multidimensional Multi-Agent Debate for Advanced Machine Translation Evaluation,"Zhaopeng Feng, Jiayuan Su, Jiamei Zheng, Jiahan Ren, Yan Zhang, Jian Wu, Hongwei Wang, Zuozhu Liu",Annual Meeting of the Association for Computational Linguistics,2024,"Recent advancements in large language models (LLMs) have given rise to the LLM-as-a-judge paradigm, showcasing their potential to deliver human-like judgments. However, in the field of machine translation (MT) evaluation, current LLM-as-a-judge methods fall short of learned automatic metrics. In this paper, we propose Multidimensional Multi-Agent Debate (M-MAD), a systematic LLM-based multi-agent framework for advanced LLM-as-a-judge MT evaluation. Our findings demonstrate that M-MAD achieves significant advancements by (1) decoupling heuristic MQM criteria into distinct evaluation dimensions for fine-grained assessments; (2) employing multi-agent debates to harness the collaborative reasoning capabilities of LLMs; (3) synthesizing dimension-specific results into a final evaluation judgment to ensure robust and reliable outcomes. Comprehensive experiments show that M-MAD not only outperforms all existing LLM-as-a-judge methods but also competes with state-of-the-art reference-based automatic metrics, even when powered by a suboptimal model like GPT-4o mini. Detailed ablations and analysis highlight the superiority of our framework design, offering a fresh perspective for LLM-as-a-judge paradigm. Our code and data are publicly available at https://github.com/SU-JIAYUAN/M-MAD.",284752448,2,37,,
10.18653/v1/2025.acl-long.739,LLaVA Steering: Visual Instruction Tuning with 500x Fewer Parameters through Modality Linear Representation-Steering,"Jinhe Bi, Yujun Wang, Haokun Chen, Xun Xiao, Artur Hecker, Volker Tresp, Yunpu Ma",(missing journal),2024,"Multimodal Large Language Models (MLLMs) have significantly advanced visual tasks by integrating visual representations into large language models (LLMs). The textual modality, inherited from LLMs, equips MLLMs with abilities like instruction following and in-context learning. In contrast, the visual modality enhances performance in downstream tasks by leveraging rich semantic content, spatial information, and grounding capabilities. These intrinsic modalities work synergistically across various visual tasks. Our research initially reveals a persistent imbalance between these modalities, with text often dominating output generation during visual instruction tuning. This imbalance occurs when using both full fine-tuning and parameter-efficient fine-tuning (PEFT) methods. We then found that re-balancing these modalities can significantly reduce the number of trainable parameters required, inspiring a direction for further optimizing visual instruction tuning. We introduce Modality Linear Representation-Steering (MoReS) to achieve the goal. MoReS effectively re-balances the intrinsic modalities throughout the model, where the key idea is to steer visual representations through linear transformations in the visual subspace across each model layer. To validate our solution, we composed LLaVA Steering, a suite of models integrated with the proposed MoReS method. Evaluation results show that the composed LLaVA Steering models require, on average, 500 times fewer trainable parameters than LoRA needs while still achieving comparable performance across three visual benchmarks and eight visual question-answering tasks. Last, we present the LLaVA Steering Factory, an in-house developed platform that enables researchers to quickly customize various MLLMs with component-based architecture for seamlessly integrating state-of-the-art models, and evaluate their intrinsic modality imbalance.",284752938,23,0,,
10.18653/v1/2025.acl-long.1540,Deliberate Reasoning in Language Models as Structure-Aware Planning with an Accurate World Model,"Siheng Xiong, Ali Payani, Yuan Yang, F. Fekri",Annual Meeting of the Association for Computational Linguistics,2024,"Enhancing the reasoning capabilities of language models (LMs) remains a key challenge, especially for tasks that require complex, multi-step decision-making where existing Chain-of-Thought (CoT) approaches struggle with consistency and verification. In this paper, we propose a novel reasoning framework, referred to as Structure-aware Planning with an Accurate World Model (SWAP), that integrates structured knowledge representation with learned planning. Unlike prior methods that rely purely on natural language reasoning, SWAP leverages entailment graphs to encode structured dependencies and enable symbolic verification of intermediate steps. To systematically construct and update the graph, SWAP employs a policy model to propose candidate expansions and a world model to predict structural updates. To improve accuracy, the world model generates multiple alternative updates, and a discriminator re-ranks them based on plausibility. To encourage diverse exploration, we introduce Diversity-based Modelling (DM), which samples candidates from the remaining probability mass after removing previously sampled candidates from the original policy distribution. Additionally, SWAP improves the discrimination accuracy through Contrastive Ranking (CR), which directly compares candidates within prompts and incorporates meta-knowledge to improve ranking quality. We evaluate SWAP across diverse reasoning-intensive benchmarks including math reasoning, logical reasoning, and coding tasks. Extensive experiments demonstrate that SWAP significantly improves upon the base models and consistently outperforms existing reasoning methods.",284760364,8,86,,
10.18653/v1/2025.acl-long.499,Exploring How Generative MLLMs Perceive More Than CLIP with the Same Vision Encoder,"Siting Li, Pang Wei Koh, Simon Shaolei Du",Annual Meeting of the Association for Computational Linguistics,2024,"Recent research has shown that CLIP models struggle with visual reasoning tasks that require grounding compositionality, understanding spatial relationships, or capturing fine-grained details. One natural hypothesis is that the CLIP vision encoder does not embed essential information for these tasks. However, we find that this is not always the case: The encoder gathers query-relevant visual information, while CLIP fails to extract it. In particular, we show that another branch of Vision-Language Models (VLMs), Generative Multimodal Large Language Models (MLLMs), achieve significantly higher accuracy than CLIP in many of these tasks using the same vision encoder and weights, indicating that these Generative MLLMs perceive more -- as they extract and utilize visual information more effectively. We conduct a series of controlled experiments and reveal that their success is attributed to multiple key design choices, including patch tokens, position embeddings, and prompt-based weighting. On the other hand, enhancing the training data alone or applying a stronger text encoder does not suffice to solve the task, and additional text tokens offer little benefit. Interestingly, we find that fine-grained visual reasoning is not exclusive to generative models trained by an autoregressive loss: When converted into CLIP-like encoders by contrastive finetuning, these MLLMs still outperform CLIP under the same cosine similarity-based evaluation protocol. Our study highlights the importance of VLM architectural choices and suggests directions for improving the performance of CLIP-like contrastive VLMs.",284763576,7,41,,
10.18653/v1/2025.acl-long.248,Quantification of Large Language Model Distillation,"Sunbowen Lee, Junting Zhou, Chang Ao, Kaige Li, Xinrun Du, Sirui He, Haihong Wu, Tianci Liu, Jiaheng Liu, Hamid Alinejad-Rokny, Min Yang, Yitao Liang, Zhoufutu Wen, Shiwen Ni",Annual Meeting of the Association for Computational Linguistics,2025,"Model distillation is a fundamental technique in building large language models (LLMs), transferring knowledge from a teacher model to a student model. However, distillation can lead to model homogenization, reducing diversity among models and impairing their ability to robustly handle complex or novel tasks. These limitations underscore the need to systematically quantify the distillation process and its impact. In this work, we propose a framework to evaluate and quantify model distillation. Our method addresses two key aspects: (1) Identifying identity cognition contradictions to assess discrepancies in how models perceive and represent identity-related information, and (2) Analyzing multi-granularity response similarities across models to measure the extent of homogenization. Experimental results demonstrate two key insights: (1) Well-known closed-source and open-source LLMs usually exhibit high distillation degrees, except for Claude, Doubao, and Gemini. (2) Base LLMs show higher distillation degrees compared to aligned LLMs. By offering a systematic approach to improve the transparency of LLM data distillation, we call for LLMs with more independent development and more transparent technical reports to improve LLMs' robustness and safety. The code and data are available under https://github.com/Aegis1863/LLMs-Distillation-Quantification.",284763611,9,26,,
10.18653/v1/2025.acl-long.342,MergePrint: Merge-Resistant Fingerprints for Robust Black-box Ownership Verification of Large Language Models,"Shojiro Yamabe, Futa Waseda, Koki Wataoka, Tsubasa Takahashi",Annual Meeting of the Association for Computational Linguistics,2024,"Protecting the intellectual property of Large Language Models (LLMs) has become increasingly critical due to the high cost of training. Model merging, which integrates multiple expert models into a single multi-task model, introduces a novel risk of unauthorized use of LLMs due to its efficient merging process. While fingerprinting techniques have been proposed for verifying model ownership, their resistance to model merging remains unexplored. To address this gap, we propose a novel fingerprinting method, MergePrint, which embeds robust fingerprints capable of surviving model merging. MergePrint enables black-box ownership verification, where owners only need to check if a model produces target outputs for specific fingerprint inputs, without accessing model weights or intermediate outputs. By optimizing against a pseudo-merged model that simulates merged behavior, MergePrint ensures fingerprints that remain detectable after merging. Additionally, to minimize performance degradation, we pre-optimize the fingerprint inputs. MergePrint pioneers a practical solution for black-box ownership verification, protecting LLMs from misappropriation via merging, while also excelling in resistance to broader model theft threats.",284765104,3,32,,
10.18653/v1/2025.acl-long.1368,Many Heads Are Better Than One: Improved Scientific Idea Generation by A LLM-Based Multi-Agent System,"Haoyang Su, Renqi Chen, Shixiang Tang, Zhenfei Yin, Xinzhe Zheng, Jinzhe Li, Biqing Qi, Qi Wu, Hui Li, Wanli Ouyang, Philip Torr, Bowen Zhou, Nanqing Dong",Annual Meeting of the Association for Computational Linguistics,2024,"The rapid advancement of scientific progress requires innovative tools that can accelerate knowledge discovery. Although recent AI methods, particularly large language models (LLMs), have shown promise in tasks such as hypothesis generation and experimental design, they fall short of replicating the collaborative nature of real-world scientific practices, where diverse experts work together in teams to tackle complex problems. To address the limitations, we propose an LLM-based multi-agent system, i.e., Virtual Scientists (VirSci), designed to mimic the teamwork inherent in scientific research. VirSci organizes a team of agents to collaboratively generate, evaluate, and refine research ideas. Through comprehensive experiments, we demonstrate that this multi-agent approach outperforms the state-of-the-art method in producing novel scientific ideas. We further investigate the collaboration mechanisms that contribute to its tendency to produce ideas with higher novelty, offering valuable insights to guide future research and illuminating pathways toward building a robust system for autonomous scientific discovery. The code is available at https://github.com/open-sciencelab/Virtual-Scientists.",284765849,18,80,,
10.18653/v1/2025.acl-long.1375,Value Residual Learning,"Zhanchao Zhou, Tianyi Wu, Zhiyun Jiang, Fares Obeid, Zhenzhong Lan",Annual Meeting of the Association for Computational Linguistics,2024,"While Transformer models have achieved remarkable success in various domains, the effectiveness of information propagation through deep networks remains a critical challenge. Standard hidden state residuals often fail to adequately preserve initial token-level information in deeper layers. This paper introduces ResFormer, a novel architecture that enhances information flow by incorporating value residual connections in addition to hidden state residuals. And a variant is SVFormer, where all layers share the first layer's value embedding. Comprehensive empirical evidence demonstrates ResFormer achieves equivalent validation loss with 16.11\% fewer model parameters and 20.3\% less training data compared to Transformer, while maintaining similar memory usage and computational cost. Besides, SVFormer reduces KV cache size by nearly half with only a small performance penalty and can be integrated with other KV-efficient methods, yielding further reductions in KV cache, with performance influenced by sequence length and cumulative learning rate.",284768080,3,52,,
10.18653/v1/2025.acl-long.568,SPHERE: Unveiling Spatial Blind Spots in Vision-Language Models Through Hierarchical Evaluation,"Wenyu Zhang, Wei En Ng, Lixin Ma, Yuwen Wang, Jungqi Zhao, Allison Koenecke, Boyang Li, Lu Wang",Annual Meeting of the Association for Computational Linguistics,2024,"Current vision-language models may grasp basic spatial cues and simple directions (e.g. left, right, front, back), but struggle with the multi-dimensional spatial reasoning necessary for human-like understanding and real-world applications. To address this gap, we develop SPHERE (Spatial Perception and Hierarchical Evaluation of REasoning), a hierarchical evaluation framework supported by a new human-annotated dataset. SPHERE systematically probes models across increasing levels of complexity, from fundamental skills to multi-skill integration and high-level reasoning that combines spatial, visual, and logical understanding. Benchmark evaluation of state-of-the-art models reveals significant deficiencies, especially in reasoning about distance and proximity, understanding both egocentric and allocentric perspectives, and applying spatial logic in physical contexts. These findings expose critical blind spots in existing models and underscore the need for more advanced spatial reasoning techniques, driving the development of vision-language models that align more closely with human spatial cognition. The SPHERE benchmark is available at https://github.com/zwenyu/SPHERE-VLM.",284769409,9,11,,
10.18653/v1/2025.acl-long.863,ChatSOP: An SOP-Guided MCTS Planning Framework for Controllable LLM Dialogue Agents,"Zhigen Li, Jianxiang Peng, Yanmeng Wang, Tianhao Shen, Minghui Zhang, Linxi Su, Shang Wu, Yihang Wu, Yuqian Wang, Ye Wang, Wei Hu, Jianfeng Li, Shaojun Wang, Jing Xiao, Deyi Xiong",Annual Meeting of the Association for Computational Linguistics,2024,"Dialogue agents powered by Large Language Models (LLMs) show superior performance in various tasks. Despite the better user understanding and human-like responses, their lack of controllability remains a key challenge, often leading to unfocused conversations or task failure. To address this, we introduce Standard Operating Procedure (SOP) to regulate dialogue flow. Specifically, we propose ChatSOP, a novel SOP-guided Monte Carlo Tree Search (MCTS) planning framework designed to enhance the controllability of LLM-driven dialogue agents. To enable this, we curate a dataset comprising SOP-annotated multi-scenario dialogues, generated using a semi-automated role-playing system with GPT-4o and validated through strict manual quality control. Additionally, we propose a novel method that integrates Chain of Thought reasoning with supervised fine-tuning for SOP prediction and utilizes SOP-guided Monte Carlo Tree Search for optimal action planning during dialogues. Experimental results demonstrate the effectiveness of our method, such as achieving a 27.95% improvement in action accuracy compared to baseline models based on GPT-3.5 and also showing notable gains for open-source models. Dataset and codes are publicly available.",284949794,2,43,,
10.18653/v1/2025.acl-long.1245,On Many-Shot In-Context Learning for Long-Context Evaluation,"Kaijian Zou, Muhammad Khalifa, Lu Wang",Annual Meeting of the Association for Computational Linguistics,2024,"Many-shot in-context learning (ICL) has emerged as a unique setup to both utilize and test the ability of large language models to handle long context. This paper delves into long-context language model (LCLM) evaluation through many-shot ICL. We first ask: what types of ICL tasks benefit from additional demonstrations, and how effective are they in evaluating LCLMs? We find that classification and summarization tasks show performance improvements with additional demonstrations, while translation and reasoning tasks do not exhibit clear trends. Next, we investigate the extent to which different tasks necessitate retrieval versus global context understanding. We develop metrics to categorize ICL tasks into two groups: (i) similar-sample learning (SSL): tasks where retrieval of the most similar examples is sufficient for good performance, and (ii) all-sample learning (ASL): tasks that necessitate a deeper comprehension of all examples in the prompt. Lastly, we introduce a new many-shot ICL benchmark, MANYICLBENCH, to characterize model's ability on both fronts and benchmark 12 LCLMs using MANYICLBENCH. We find that while state-of-the-art models demonstrate good performance up to 64k tokens in SSL tasks, many models experience significant performance drops at only 16k tokens in ASL tasks.",284954194,4,43,,
10.18653/v1/2025.acl-long.1342,CheXalign: Preference fine-tuning in chest X-ray interpretation models without human feedback,"Dennis Hein, Zhihong Chen, Sophie Ostmeier, Justin Xu, Maya Varma, E. Reis, Arne Edward Michalson, Christian Bluethgen, Hyun Joo Shin, Curtis P. Langlotz, Akshay Chaudhari",Annual Meeting of the Association for Computational Linguistics,2024,"Radiologists play a crucial role in translating medical images into actionable reports. However, the field faces staffing shortages and increasing workloads. While automated approaches using vision-language models (VLMs) show promise as assistants, they require exceptionally high accuracy. Most current VLMs in radiology rely solely on supervised fine-tuning. Meanwhile, additional preference fine-tuning in the post-training pipeline has become standard practice in the general domain. The challenge in radiology lies in the prohibitive cost of obtaining radiologist feedback at scale. To address this challenge, we propose an automated pipeline for preference feedback, focusing on chest X-ray radiology report generation (RRG). Specifically, our method leverages publicly available datasets containing pairs of images and radiologist-written reference reports with reference-based metrics, or Judges, eliminating the need for additional radiologist feedback. We investigate reward overoptimization via length exploitation in this setting and introduce a length-controlled version of the GREEN score. Our best-performing setup achieves state-of-the-art CheXbert scores on the MIMIC-CXR dataset for the RRG task while on average maintaining robust performance across six additional image perception and reasoning tasks.",284956523,1,61,,
10.18653/v1/2025.acl-long.276,Hallucination Detox: Sensitivity Dropout (SenD) for Large Language Model Training,"Shahrad Mohammadzadeh, Juan David Guerra, Marco Bonizzato, Reihaneh Rabbany, Golnoosh Farnadi",Annual Meeting of the Association for Computational Linguistics,2024,"As large language models (LLMs) become increasingly prevalent, concerns about their reliability, particularly due to hallucinations - factually inaccurate or irrelevant outputs - have grown. Our research investigates the relationship between the uncertainty in training dynamics and the emergence of hallucinations. Using models from the Pythia suite and several hallucination detection metrics, we analyze hallucination trends and identify significant variance during training. To address this, we propose Sensitivity Dropout (SenD), a novel training protocol designed to reduce hallucination variance during training by deterministically dropping embedding indices with significant variability. In addition, we develop an unsupervised hallucination detection metric, Efficient EigenScore (EES), which approximates the traditional EigenScore in 2x speed. This metric is integrated into our training protocol, allowing SenD to be both computationally scalable and effective at reducing hallucination variance. SenD improves test-time reliability of Pythia and Meta's Llama models by up to 17% and enhances factual accuracy in Wikipedia, Medical, Legal, and Coding domains without affecting downstream task performance.",285409196,0,30,,
10.18653/v1/2025.acl-long.1211,RefreshKV: Updating Small KV Cache During Long-form Generation,"Fangyuan Xu, Tanya Goyal, Eunsol Choi",Annual Meeting of the Association for Computational Linguistics,2024,"Generating long sequences of tokens given a long-context input is a very compute-intensive inference scenario for large language models (LLMs). One prominent inference speed-up approach is to construct a smaller key-value (KV) cache, relieving LLMs from computing attention over a long sequence of tokens. While such methods work well to generate short sequences, their performance degrades rapidly for long-form generation. Most KV compression happens once, prematurely removing tokens that can be useful later in the generation. We propose a new inference method, RefreshKV, that flexibly alternates between full context attention and attention over a subset of input tokens during generation. After each full attention step, we update the smaller KV cache based on the attention pattern over the entire input. Applying our method to off-the-shelf LLMs achieves comparable speedup to eviction-based methods while improving performance for various long-form generation tasks. Lastly, we show that continued pretraining with our inference setting brings further gains in performance.",285960391,4,0,,
10.18653/v1/2025.acl-long.326,Unsolvable Problem Detection: Robust Understanding Evaluation for Large Multimodal Models,"Atsuyuki Miyai, Jingkang Yang, Jingyang Zhang, Yifei Ming, Qing Yu, Go Irie, Yixuan Li, Hai Li, Ziwei Liu, Kiyoharu Aizawa",Annual Meeting of the Association for Computational Linguistics,2024,"This paper introduces a novel task to evaluate the robust understanding capability of Large Multimodal Models (LMMs), termed $\textbf{Unsolvable Problem Detection (UPD)}$. Multiple-choice question answering (MCQA) is widely used to assess the understanding capability of LMMs, but it does not guarantee that LMMs truly comprehend the answer. UPD assesses the LMM's ability to withhold answers when encountering unsolvable problems of MCQA, verifying whether the model truly understands the answer. UPD encompasses three problems: Absent Answer Detection (AAD), Incompatible Answer Set Detection (IASD), and Incompatible Visual Question Detection (IVQD), covering unsolvable cases like answer-lacking or incompatible choices and image-question mismatches. For the evaluation, we introduce the MM-UPD Bench, a benchmark for assessing performance across various ability dimensions. Our experiments reveal that even most LMMs, which demonstrate adequate performance on existing benchmarks, struggle significantly with MM-UPD, underscoring a novel aspect of trustworthiness that current benchmarks have overlooked. A detailed analysis shows that LMMs have different bottlenecks and chain-of-thought and self-reflection improved performance for LMMs with the bottleneck in their LLM capability. We hope our insights will enhance the broader understanding and development of more reliable LMMs. The code is available at https://github.com/AtsuMiyai/UPD.",286153206,3,75,,
10.18653/v1/2025.acl-long.998,"Can LLMs Help Uncover Insights about LLMs? A Large-Scale, Evolving Literature Analysis of Frontier LLMs","Jungsoo Park, Junmo Kang, Gabriel Stanovsky, Alan Ritter",Annual Meeting of the Association for Computational Linguistics,2025,"The surge of LLM studies makes synthesizing their findings challenging. Analysis of experimental results from literature can uncover important trends across studies, but the time-consuming nature of manual data extraction limits its use. Our study presents a semi-automated approach for literature analysis that accelerates data extraction using LLMs. It automatically identifies relevant arXiv papers, extracts experimental results and related attributes, and organizes them into a structured dataset, LLMEvalDB. We then conduct an automated literature analysis of frontier LLMs, reducing the effort of paper surveying and data extraction by more than 93% compared to manual approaches. We validate LLMEvalDB by showing that it reproduces key findings from a recent manual analysis of Chain-of-Thought (CoT) reasoning and also uncovers new insights that go beyond it, showing, for example, that in-context examples benefit coding&multimodal tasks but offer limited gains in math reasoning tasks compared to zero-shot CoT. Our automatically updatable dataset enables continuous tracking of target models by extracting evaluation studies as new data becomes available. Through LLMEvalDB and empirical analysis, we provide insights into LLMs while facilitating ongoing literature analyses of their behavior.",286163005,3,47,,
10.18653/v1/2025.acl-long.51,Model Extrapolation Expedites Alignment,"Chujie Zheng, Ziqi Wang, Heng Ji, Minlie Huang, Nanyun Peng",Annual Meeting of the Association for Computational Linguistics,2024,"Given the high computational cost of preference alignment training of large language models (LLMs), exploring efficient methods to reduce the training overhead remains an important and compelling research problem. Motivated by the observation that alignment training typically involves only small parameter changes without injecting new knowledge into models, we propose a straightforward method called ExPO (model extrapolation) to expedite LLMs' alignment with human preferences. Given a partially-trained model and its initial SFT checkpoint, ExPO improves the implicit optimization objective of alignment training by simply amplifying the parameter change based on a first-order approximation, without any additional training overhead. Through controlled experiments, we demonstrate that ExPO boosts a DPO model trained with only 20% steps to outperform the fully-trained one. Moreover, we show that ExPO notably improves existing open-source LLMs (ranging from 1.8B to 70B parameters) on the leading AlpacaEval 2.0 and MT-Bench benchmarks, which highlights ExPO's broader utility in efficiently enhancing LLM alignment.",286167951,38,75,,
10.18653/v1/2025.acl-long.540,Knowledge-Augmented Multimodal Clinical Rationale Generation for Disease Diagnosis with Small Language Models,"Shuai Niu, Jing Ma, Hongzhan Lin, Liang Bai, Zhihua Wang, Yida Xu, Yunya Song, Xian Yang",Annual Meeting of the Association for Computational Linguistics,2024,"Interpretation is critical for disease diagnosis, but existing models struggle to balance predictive accuracy with human-understandable rationales. While large language models (LLMs) offer strong reasoning abilities, their clinical use is limited by high computational costs and restricted multimodal reasoning ability. Small language models (SLMs) are efficient but lack advanced reasoning for integrating multimodal medical data. In addition, both LLMs and SLMs lack domain knowledge for trustworthy reasoning. Therefore, we propose ClinRaGen, enhancing SLMs by leveraging LLM-derived reasoning ability via rationale distillation and domain knowledge injection for trustworthy multimodal rationale generation. Key innovations include a sequential rationale distillation framework that equips SLMs with LLM-comparable multimodal reasoning abilities, and a knowledge-augmented attention mechanism that jointly unifies multimodal representation from time series and textual data in the same encoding space, enabling it to be naturally interpreted by SLMs while incorporating domain knowledge for reliable rationale generation. Experiments on real-world medical datasets show that ClinRaGen achieves state-of-the-art performance in disease diagnosis and rationale generation, demonstrating the effectiveness of combining LLM-driven reasoning with knowledge augmentation for improved interpretability.",286767723,3,32,,
10.18653/v1/2025.acl-long.623,Nudging: Inference-time Alignment of LLMs via Guided Decoding,"Yu Fei, Yasaman Razeghi, Sameer Singh",Annual Meeting of the Association for Computational Linguistics,2024,"Large language models (LLMs) require alignment to effectively and safely follow user instructions. This process necessitates training an aligned version for every base model, resulting in significant computational overhead. In this work, we propose NUDGING, a simple, training-free algorithm that aligns any base model at inference time using a small aligned model. NUDGING is motivated by recent findings that alignment primarily alters the model's behavior on a small subset of stylistic tokens (e.g., discourse markers). We find that base models are significantly more uncertain when generating these tokens. Building on this insight, NUDGING employs a small aligned model to generate nudging tokens to guide the base model's output during decoding when the base model's uncertainty is high, with only a minor additional inference overhead. We evaluate NUDGING across 3 model families on a diverse range of open-instruction tasks. Without any training, nudging a large base model with a 7x-14x smaller aligned model achieves zero-shot performance comparable to, and sometimes surpassing, that of large aligned models. By operating at the token level, NUDGING enables off-the-shelf collaboration between model families. For instance, nudging Gemma-2-27b with Llama-27b-chat outperforms Llama-2-70b-chat on various tasks. Overall, our work offers a modular and cost-efficient solution to LLM alignment. Our code and demo are available at: https://fywalter.github.io/nudging/ .",286768760,4,44,,
10.18653/v1/2025.acl-long.645,Extending Complex Logical Queries on Uncertain Knowledge Graphs,"WeiZhi Fei, Zihao Wang, Hang Yin, Yang Duan, Hanghang Tong, Yangqiu Song",Annual Meeting of the Association for Computational Linguistics,2024,"The study of machine learning-based logical query answering enables reasoning with large-scale and incomplete knowledge graphs. This paper advances this area of research by addressing the uncertainty inherent in knowledge. While the uncertain nature of knowledge is widely recognized in the real world, it does not align seamlessly with the first-order logic that underpins existing studies. To bridge this gap, we explore the soft queries on uncertain knowledge, inspired by the framework of soft constraint programming. We propose a neural symbolic approach that incorporates both forward inference and backward calibration to answer soft queries on large-scale, incomplete, and uncertain knowledge graphs. Theoretical discussions demonstrate that our method avoids catastrophic cascading errors in the forward inference while maintaining the same complexity as state-of-the-art symbolic methods for complex logical queries. Empirical results validate the superior performance of our backward calibration compared to extended query embedding methods and neural symbolic approaches.",287522011,4,53,,
10.18653/v1/2025.acl-long.1023,Structural Reasoning Improves Molecular Understanding of LLM,"Yunhui Jang, Jaehyung Kim, Sungsoo Ahn",Annual Meeting of the Association for Computational Linguistics,2024,"Recently, large language models (LLMs) have shown significant progress, approaching human perception levels. In this work, we demonstrate that despite these advances, LLMs still struggle to reason using molecular structural information. This gap is critical because many molecular properties, including functional groups, depend heavily on such structural details. To address this limitation, we propose an approach that sketches molecular structures for reasoning. Specifically, we introduce Molecular Structural Reasoning (MSR) framework to enhance the understanding of LLMs by explicitly incorporating the key structural features. We present two frameworks for scenarios where the target molecule is known or unknown. We verify that our MSR improves molecular understanding through extensive experiments.",287524896,3,48,,
10.18653/v1/2025.acl-long.381,AXIS: Efficient Human-Agent-Computer Interaction with API-First LLM-Based Agents,"Junting Lu, Zhiyang Zhang, Fangkai Yang, Jue Zhang, Lu Wang, Chao Du, Qingwei Lin, S. Rajmohan, Dongmei Zhang, Qi Zhang",Annual Meeting of the Association for Computational Linguistics,2024,"Multimodal large language models (MLLMs) have enabled LLM-based agents to directly interact with application user interfaces (UIs), enhancing agents' performance in complex tasks. However, these agents often suffer from high latency and low reliability due to the extensive sequential UI interactions. To address this issue, we propose AXIS, a novel LLM-based agents framework that prioritize actions through application programming interfaces (APIs) over UI actions. This framework also facilitates the creation and expansion of APIs through automated exploration of applications. Our experiments on Microsoft Word demonstrate that AXIS reduces task completion time by 65%-70% and cognitive workload by 38%-53%, while maintaining accuracy of 97%-98% compared to humans. Our work contributes to a new human-agent-computer interaction (HACI) framework and explores a fresh UI design principle for application providers to turn applications into agents in the era of LLMs, paving the way towards an agent-centric operating system (Agent OS).",287530391,5,54,,
10.18653/v1/2025.acl-long.625,SCAR: Data Selection via Style Consistency-Aware Response Ranking for Efficient Instruction-Tuning of Large Language Models,"Zhuang Li, Yuncheng Hua, Thuy-Trang Vu, Haolan Zhan, Lizhen Qu, Gholamreza Haffari",Annual Meeting of the Association for Computational Linguistics,2024,"Recent studies emphasize that manually ensuring a consistent response style and maintaining high data quality in training sets can significantly improve the performance of fine-tuned Large Language Models (LLMs) while reducing the number of training examples needed. However, the precise definition of style and the relationship between style, data quality, and LLM performance remains unclear. This research identifies two key stylistic elements in responses: linguistic form and instructional surprisal. We find that, among training data of comparable quality, higher consistency in these response elements leads to better LLM performance. Inspired by this, we introduce Style Consistency-Aware Response Ranking (SCAR), which automatically prioritizes instruction-response pairs in the training set based on their response stylistic consistency. By selecting the most style-consistent examples, using only 0.7% of the full dataset in the best case, the fine-tuned LLMs can match or even surpass the performance of models trained on the entire dataset in coding and open-ended question-answering benchmarks. Code and data are available at https://github.com/zhuang-li/SCAR .",287534588,1,82,,
10.18653/v1/2025.acl-long.712,CoT-ICL Lab: A Synthetic Framework for Studying Chain-of-Thought Learning from In-Context Demonstrations,"Vignesh Kothapalli, Hamed Firooz, Maziar Sanjabi",Annual Meeting of the Association for Computational Linguistics,2025,"We introduce CoT-ICL Lab, a framework and methodology to generate synthetic tokenized datasets and systematically study chain-of-thought (CoT) in-context learning (ICL) in language models. CoT-ICL Lab allows fine grained control over the complexity of in-context examples by decoupling (1) the causal structure involved in chain token generation from (2) the underlying token processing functions. We train decoder-only transformers (up to 700M parameters) on these datasets and show that CoT accelerates the accuracy transition to higher values across model sizes. In particular, we find that model depth is crucial for leveraging CoT with limited in-context examples, while more examples help shallow models match deeper model performance. Additionally, limiting the diversity of token processing functions throughout training improves causal structure learning via ICL. We also interpret these transitions by analyzing transformer embeddings and attention maps. Overall, CoT-ICL Lab serves as a simple yet powerful testbed for theoretical and empirical insights into ICL and CoT in language models.",287798116,0,41,,
10.18653/v1/2025.acl-long.1045,JailbreakRadar: Comprehensive Assessment of Jailbreak Attacks Against LLMs,"Junjie Chu, Yugeng Liu, Ziqing Yang, Xinyue Shen, Michael Backes, Yang Zhang",Annual Meeting of the Association for Computational Linguistics,2024,"Jailbreak attacks aim to bypass the LLMs' safeguards. While researchers have proposed different jailbreak attacks in depth, they have done so in isolation -- either with unaligned settings or comparing a limited range of methods. To fill this gap, we present a large-scale evaluation of various jailbreak attacks. We collect 17 representative jailbreak attacks, summarize their features, and establish a novel jailbreak attack taxonomy. Then we conduct comprehensive measurement and ablation studies across nine aligned LLMs on 160 forbidden questions from 16 violation categories. Also, we test jailbreak attacks under eight advanced defenses. Based on our taxonomy and experiments, we identify some important patterns, such as heuristic-based attacks could achieve high attack success rates but are easy to mitigate by defenses, causing low practicality. Our study offers valuable insights for future research on jailbreak attacks and defenses. We hope our work could help the community avoid incremental work and serve as an effective benchmark tool for practitioners.",287799533,82,70,,
10.18653/v1/2025.acl-long.1038,The Invisible Hand: Unveiling Provider Bias in Large Language Models for Code Generation,"Xiaoyu Zhang, Juan Zhai, Shiqing Ma, Qingshuang Bao, Weipeng Jiang, Qian Wang, Chao Shen, Yang Liu",Annual Meeting of the Association for Computational Linguistics,2025,"Large Language Models (LLMs) have emerged as the new recommendation engines, surpassing traditional methods in both capability and scope, particularly in code generation. In this paper, we reveal a novel provider bias in LLMs: without explicit directives, these models show systematic preferences for services from specific providers in their recommendations (e.g., favoring Google Cloud over Microsoft Azure). To systematically investigate this bias, we develop an automated pipeline to construct the dataset, incorporating 6 distinct coding task categories and 30 real-world application scenarios. Leveraging this dataset, we conduct the first comprehensive empirical study of provider bias in LLM code generation across seven state-of-the-art LLMs, utilizing approximately 500 million tokens (equivalent to $5,000+ in computational costs). Our findings reveal that LLMs exhibit significant provider preferences, predominantly favoring services from Google and Amazon, and can autonomously modify input code to incorporate their preferred providers without users'requests. Such a bias holds far-reaching implications for market dynamics and societal equilibrium, potentially contributing to digital monopolies. It may also deceive users and violate their expectations, leading to various consequences. We call on the academic community to recognize this emerging issue and develop effective evaluation and mitigation methods to uphold AI security and fairness.",287799591,3,41,,
10.18653/v1/2025.acl-long.290,Efficient Universal Goal Hijacking with Semantics-guided Prompt Organization,"Yihao Huang, Chong Wang, Xiaojun Jia, Qing Guo, Felix Juefei-Xu, Jian Zhang, G. Pu, Yang Liu",Annual Meeting of the Association for Computational Linguistics,2024,"Universal goal hijacking is a kind of prompt injection attack that forces LLMs to return a target malicious response for arbitrary normal user prompts. The previous methods achieve high attack performance while being too cumbersome and time-consuming. Also, they have concentrated solely on optimization algorithms, overlooking the crucial role of the prompt. To this end, we propose a method called POUGH that incorporates an efficient optimization algorithm and two semantics-guided prompt organization strategies. Specifically, our method starts with a sampling strategy to select representative prompts from a candidate pool, followed by a ranking strategy that prioritizes them. Given the sequentially ranked prompts, our method employs an iterative optimization algorithm to generate a fixed suffix that can concatenate to arbitrary user prompts for universal goal hijacking. Experiments conducted on four popular LLMs and ten types of target responses verified the effectiveness.",287801605,10,56,,
10.18653/v1/2025.acl-long.191,Fine-Tuning on Diverse Reasoning Chains Drives Within-Inference CoT Refinement in LLMs,"Haritz Puerto, Tilek Chubakov, Xiaodan Zhu, Harish Tayyar Madabushi, Iryna Gurevych",Annual Meeting of the Association for Computational Linguistics,2024,"Requiring a large language model (LLM) to generate intermediary reasoning steps, known as Chain of Thought (CoT), has been shown to be an effective way of boosting performance. Previous approaches have focused on generating multiple independent CoTs, combining them through ensembling or other post-hoc strategies to enhance reasoning. In this work, we introduce a novel approach where LLMs are fine-tuned to generate a sequence of Diverse Chains of Thought (DCoT) within a single inference step, which is fundamentally different from prior work that primarily operate on parallel CoT generations. DCoT allows LLMs to gain the ability to perform within-inference refinement of reasoning chains without requiring external feedback. Through a rigorous set of experiments spanning a wide range of tasks that require various reasoning types, we show that fine-tuning on DCoT improves performance over the CoT baseline across model families and scales (1.3B to 70B). These improvements are particularly impactful for tasks with a large result state space, such as those involving numeric answers. Our work is also significant because both quantitative analyses and manual evaluations reveal the observed gains stem from the models' ability to refine an initial reasoning chain by generating a second, improved chain within the same inference step, demonstrating previously elusive self-improvement. Our code and data are publicly available at https://github.com/UKPLab/acl2025-diverse-cot.",287804029,13,52,,
10.18653/v1/2025.acl-long.39,EscapeBench: Towards Advancing Creative Intelligence of Language Model Agents,"Cheng Qian, Peixuan Han, Qinyu Luo, Bingxiang He, Xiusi Chen, Yuji Zhang, Hongyi Du, Jiarui Yao, Xiaocheng Yang, Denghui Zhang, Yunzhu Li, Heng Ji",Annual Meeting of the Association for Computational Linguistics,2024,"Language model agents excel in long-session planning and reasoning, but existing benchmarks primarily focus on goal-oriented tasks with explicit objectives, neglecting creative adaptation in unfamiliar environments. To address this, we introduce EscapeBench, a benchmark suite of room escape game environments designed to challenge agents with creative reasoning, unconventional tool use, and iterative problem-solving to uncover implicit goals. Our results show that current LM models, despite employing working memory and Chain-of-Thought reasoning, achieve only 15% average progress without hints, highlighting their limitations in creativity. To bridge this gap, we propose EscapeAgent, a framework designed to enhance creative reasoning through Foresight (innovative tool use) and Reflection (identifying unsolved tasks). Experiments show that EscapeAgent can execute action chains over 1,000 steps while maintaining logical coherence. It navigates and completes games with up to 40% fewer steps and hints, performs robustly across difficulty levels, and achieves higher action success rates with more efficient and innovative puzzle-solving strategies.",287805695,1,75,,
10.18653/v1/2025.acl-long.235,Principled Understanding of Generalization for Generative Transformer Models in Arithmetic Reasoning Tasks,"Xingcheng Xu, Zibo Zhao, Haipeng Zhang, Yanqing Yang",Annual Meeting of the Association for Computational Linguistics,2024,"Transformer-based models excel in various tasks but their generalization capabilities, especially in arithmetic reasoning, remain incompletely understood. Arithmetic tasks provide a controlled framework to explore these capabilities, yet performance anomalies persist, such as inconsistent effectiveness in multiplication and erratic generalization in modular addition (e.g., modulo 100 vs. 101). This paper develops a unified theoretical framework for understanding the generalization behaviors of transformers in arithmetic tasks, focusing on length generalization. Through detailed analysis of addition, multiplication, and modular operations, we reveal that translation invariance in addition aligns with relative positional encoding for robust generalization, while base mismatch in modular operations disrupts this alignment. Experiments across GPT-family models validate our framework, confirming its ability to predict generalization behaviors. Our work highlights the importance of task structure and training data distribution for achieving data-efficient and structure-aware training, providing a systematic approach to understanding of length generalization in transformers.",287806822,0,20,,
10.18653/v1/2025.acl-long.1246,HelpSteer3: Human-Annotated Feedback and Edit Data to Empower Inference-Time Scaling in Open-Ended General-Domain Tasks,"Zhilin Wang, Jiaqi Zeng, Olivier Delalleau, Daniel Egert, Ellie Evans, Hoo-Chang Shin, Felipe Soares, Yi Dong, Oleksii Kuchaiev",Annual Meeting of the Association for Computational Linguistics,2025,"Inference-Time Scaling has been critical to the success of recent models such as OpenAI o1 and DeepSeek R1. However, many techniques used to train models for inference-time scaling require tasks to have answers that can be verified, limiting their application to domains such as math, coding and logical reasoning. We take inspiration from how humans make first attempts, ask for detailed feedback from others and make improvements based on such feedback across a wide spectrum of open-ended endeavors. To this end, we collect HelpSteer3 data to train dedicated Feedback and Edit Models that are capable of performing inference-time scaling for open-ended general-domain tasks. In our setup, one model generates an initial response, which are given feedback by a second model, that are then used by a third model to edit the response. We show that performance on Arena Hard, a benchmark strongly predictive of Chatbot Arena Elo can be boosted by scaling the number of initial response drafts, effective feedback and edited responses. When scaled optimally, our setup based on 70B models from the Llama 3 family can reach SoTA performance on Arena Hard at 92.7 as of 5 Mar 2025, surpassing OpenAI o1-preview-2024-09-12 with 90.4 and DeepSeek R1 with 92.3.",287806841,8,19,,
10.18653/v1/2025.acl-long.10,CLEME2.0: Towards Interpretable Evaluation by Disentangling Edits for Grammatical Error Correction,"Jingheng Ye, Zishan Xu, Yinghui Li, Linlin Song, Qingyu Zhou, Hai-Tao Zheng, Ying Shen, Wenhao Jiang, Hong-Gee Kim, Ruitong Liu, Xin Su, Zifei Shan",(missing journal),2024,"The paper focuses on the interpretability of Grammatical Error Correction (GEC) evaluation metrics, which received little attention in previous studies. To bridge the gap, we introduce **CLEME2.0**, a reference-based metric describing four fundamental aspects of GEC systems: hit-correction, wrong-correction, under-correction, and over-correction. They collectively contribute to exposing critical qualities and locating drawbacks of GEC systems. Evaluating systems by combining these aspects also leads to superior human consistency over other reference-based and reference-less metrics. Extensive experiments on two human judgment datasets and six reference datasets demonstrate the effectiveness and robustness of our method, achieving a new state-of-the-art result. Our codes are released at https://github.com/THUKElab/CLEME.",287808758,0,0,,
10.18653/v1/2025.acl-long.1207,LLMs know their vulnerabilities: Uncover Safety Gaps through Natural Distribution Shifts,"Qibing Ren, Hao Li, Dongrui Liu, Zhanxu Xie, Xiaoya Lu, Yu Qiao, Lei Sha, Junchi Yan, Lizhuang Ma, Jing Shao",Annual Meeting of the Association for Computational Linguistics,2024,"Safety concerns in large language models (LLMs) have gained significant attention due to their exposure to potentially harmful data during pre-training. In this paper, we identify a new safety vulnerability in LLMs: their susceptibility to \textit{natural distribution shifts} between attack prompts and original toxic prompts, where seemingly benign prompts, semantically related to harmful content, can bypass safety mechanisms. To explore this issue, we introduce a novel attack method, \textit{ActorBreaker}, which identifies actors related to toxic prompts within pre-training distribution to craft multi-turn prompts that gradually lead LLMs to reveal unsafe content. ActorBreaker is grounded in Latour's actor-network theory, encompassing both human and non-human actors to capture a broader range of vulnerabilities. Our experimental results demonstrate that ActorBreaker outperforms existing attack methods in terms of diversity, effectiveness, and efficiency across aligned LLMs. To address this vulnerability, we propose expanding safety training to cover a broader semantic space of toxic content. We thus construct a multi-turn safety dataset using ActorBreaker. Fine-tuning models on our dataset shows significant improvements in robustness, though with some trade-offs in utility. Code is available at https://github.com/AI45Lab/ActorAttack.",287808771,34,83,,
10.18653/v1/2025.acl-long.332,TheoremExplainAgent: Towards Video-based Multimodal Explanations for LLM Theorem Understanding,"Max W.F. Ku, Thomas Chong, Jonathan Leung, Krish Shah, Alvin Yu, Wenhu Chen",Annual Meeting of the Association for Computational Linguistics,2025,"Understanding domain-specific theorems often requires more than just text-based reasoning; effective communication through structured visual explanations is crucial for deeper comprehension. While large language models (LLMs) demonstrate strong performance in text-based theorem reasoning, their ability to generate coherent and pedagogically meaningful visual explanations remains an open challenge. In this work, we introduce TheoremExplainAgent, an agentic approach for generating long-form theorem explanation videos (over 5 minutes) using Manim animations. To systematically evaluate multimodal theorem explanations, we propose TheoremExplainBench, a benchmark covering 240 theorems across multiple STEM disciplines, along with 5 automated evaluation metrics. Our results reveal that agentic planning is essential for generating detailed long-form videos, and the o3-mini agent achieves a success rate of 93.8% and an overall score of 0.77. However, our quantitative and qualitative studies show that most of the videos produced exhibit minor issues with visual element layout. Furthermore, multimodal explanations expose deeper reasoning flaws that text-based explanations fail to reveal, highlighting the importance of multimodal explanations.",287808819,5,35,,
10.18653/v1/2025.acl-long.1506,Subtle Errors in Reasoning: Preference Learning via Error-injected Self-editing,"Kaishuai Xu, Tiezheng Yu, Wenjun Hou, Yi Cheng, Chak Tou Leong, Liangyou Li, Xin Jiang, Lifeng Shang, Qun Liu, Wenjie Li",Annual Meeting of the Association for Computational Linguistics,2024,"Large Language Models (LLMs) have exhibited strong mathematical reasoning prowess, tackling tasks ranging from basic arithmetic to advanced competition-level problems. However, frequently occurring subtle yet critical errors, such as miscalculations or incorrect substitutions, limit the LLMs' full potential. Existing studies to improve mathematical ability typically involve applying preference learning to step-wise solution pairs. Although these methods leverage samples of varying granularity to mitigate reasoning errors, they overlook critical subtle errors. In this work, we propose a novel preference learning framework called eRror-Injected Self-Editing (RISE), which injects predefined subtle errors into pivotal tokens in reasoning or computation steps to construct hard pairs for error mitigation. In detail, RISE uses the LLM itself to edit a small number of tokens in the solution, injecting designed subtle errors. Then, pairs composed of self-edited solutions and their corresponding correct ones, along with pairs of correct and incorrect solutions obtained through sampling, are used together for subtle error-aware DPO training. Compared with other preference learning methods, RISE further refines the training objective without requiring fine-grained sampling or preference annotation. Extensive experiments validate the effectiveness of RISE, with preference learning on Qwen2-7B-Instruct yielding notable improvements of 3.0% on GSM8K and 7.9% on MATH with only 4.5K training samples. Moreover, the effect of error mitigation extends from mathematical reasoning to logical reasoning and code generation.",287811095,0,35,,
10.18653/v1/2025.acl-long.2,GraphNarrator: Generating Textual Explanations for Graph Neural Networks,"Bo Pan, Zhen Xiong, Guanchen Wu, Zhengwu Zhang, Yifei Zhang, Liang Zhao",Annual Meeting of the Association for Computational Linguistics,2024,"Graph representation learning has garnered significant attention due to its broad applications in various domains, such as recommendation systems and social network analysis. Despite advancements in graph learning methods, challenges still remain in explainability when graphs are associated with semantic features. In this paper, we present GraphNarrator, the first method designed to generate natural language explanations for Graph Neural Networks. GraphNarrator employs a generative language model that maps input-output pairs to explanations reflecting the model's decision-making process. To address the lack of ground truth explanations to train the model, we propose first generating pseudo-labels that capture the model's decisions from saliency-based explanations, then using Expert Iteration to iteratively train the pseudo-label generator based on training objectives on explanation quality. The high-quality pseudo-labels are finally utilized to train an end-to-end explanation generator model. Extensive experiments are conducted to demonstrate the effectiveness of GraphNarrator in producing faithful, concise, and human-preferred natural language explanations.",287811857,3,51,,
10.18653/v1/2025.acl-long.658,Unleashing LLM Reasoning Capability via Scalable Question Synthesis from Scratch,"Yuyang Ding, Xinyu Shi, Xiaobo Liang, Juntao Li, Zhaopeng Tu, Qiaoming Zhu, Min Zhang",Annual Meeting of the Association for Computational Linguistics,2024,"Improving the mathematical reasoning capabilities of Large Language Models (LLMs) is critical for advancing artificial intelligence. However, access to extensive, diverse, and high-quality reasoning datasets remains a significant challenge, particularly for the open-source community. In this paper, we propose ScaleQuest, a novel, scalable, and cost-effective data synthesis method that enables the generation of large-scale mathematical reasoning datasets using lightweight 7B-scale models. ScaleQuest introduces a two-stage question-tuning process comprising Question Fine-Tuning (QFT) and Question Preference Optimization (QPO) to unlock the question generation capabilities of problem-solving models. By generating diverse questions from scratch -- without relying on powerful proprietary models or seed data -- we produce a dataset of 1 million problem-solution pairs. Our experiments demonstrate that models trained on our data outperform existing open-source datasets in both in-domain and out-of-domain evaluations. Furthermore, our approach shows continued performance improvement as the volume of training data increases, highlighting its potential for ongoing data scaling. The extensive improvements observed in code reasoning tasks demonstrate the generalization capabilities of our proposed method. Our work provides the open-source community with a practical solution to enhance the mathematical reasoning abilities of LLMs.",287812994,10,64,,
10.18653/v1/2025.acl-long.378,GAMEBoT: Transparent Assessment of LLM Reasoning in Games,"Wenye Lin, Jonathan Roberts, Yunhan Yang, Samuel Albanie, Zongqing Lu, Kai Han",Annual Meeting of the Association for Computational Linguistics,2024,"Large Language Models (LLMs) are increasingly deployed in real-world applications that demand complex reasoning. To track progress, robust benchmarks are required to evaluate their capabilities beyond superficial pattern recognition. However, current LLM reasoning benchmarks often face challenges such as insufficient interpretability, performance saturation or data contamination. To address these challenges, we introduce GAMEBoT, a gaming arena designed for rigorous and transparent assessment of LLM reasoning capabilities. GAMEBoT decomposes complex reasoning in games into predefined modular subproblems. This decomposition allows us to design a suite of Chain-of-Thought (CoT) prompts that leverage domain knowledge to guide LLMs in addressing these subproblems before action selection. Furthermore, we develop a suite of rule-based algorithms to generate ground truth for these subproblems, enabling rigorous validation of the LLMs' intermediate reasoning steps. This approach facilitates evaluation of both the quality of final actions and the accuracy of the underlying reasoning process. GAMEBoT also naturally alleviates the risk of data contamination through dynamic games and head-to-head LLM competitions. We benchmark 17 prominent LLMs across eight games, encompassing various strategic abilities and game characteristics. Our results suggest that GAMEBoT presents a significant challenge, even when LLMs are provided with detailed CoT prompts. Project page: https://visual-ai.github.io/gamebot",287842414,4,22,,
10.18653/v1/2025.acl-long.1220,Estimating Privacy Leakage of Augmented Contextual Knowledge in Language Models,"James Flemings, Bo Jiang, Wanrong Zhang, Zafar Takhirov, Murali Annavaram",Annual Meeting of the Association for Computational Linguistics,2024,"Language models (LMs) rely on their parametric knowledge augmented with relevant contextual knowledge for certain tasks, such as question answering. However, the contextual knowledge can contain private information that may be leaked when answering queries, and estimating this privacy leakage is not well understood. A straightforward approach of directly comparing an LM's output to the contexts can overestimate the privacy risk, since the LM's parametric knowledge might already contain the augmented contextual knowledge. To this end, we introduce $\emph{context influence}$, a metric that builds on differential privacy, a widely-adopted privacy notion, to estimate the privacy leakage of contextual knowledge during decoding. Our approach effectively measures how each subset of the context influences an LM's response while separating the specific parametric knowledge of the LM. Using our context influence metric, we demonstrate that context privacy leakage occurs when contextual knowledge is out of distribution with respect to parametric knowledge. Moreover, we experimentally demonstrate how context influence properly attributes the privacy leakage to augmented contexts, and we evaluate how factors-- such as model size, context size, generation position, etc.-- affect context privacy leakage. The practical implications of our results will inform practitioners of the privacy risk associated with augmented contextual knowledge.",287850048,5,83,,
10.18653/v1/2025.acl-long.346,ControlSpeech: Towards Simultaneous and Independent Zero-shot Speaker Cloning and Zero-shot Language Style Control,"Shengpeng Ji, Qian Chen, Wen Wang, Jialong Zuo, Minghui Fang, Ziyue Jiang, Hai Huang, Zehan Wang, Xize Cheng, Siqi Zheng, Zhou Zhao",Annual Meeting of the Association for Computational Linguistics,2024,"In this paper, we present ControlSpeech, a text-to-speech (TTS) system capable of fully cloning the speaker's voice and enabling arbitrary control and adjustment of speaking style. Prior zero-shot TTS models only mimic the speaker's voice without further control and adjustment capabilities while prior controllable TTS models cannot perform speaker-specific voice generation. Therefore, ControlSpeech focuses on a more challenging task: a TTS system with controllable timbre, content, and style at the same time. ControlSpeech takes speech prompts, content prompts, and style prompts as inputs and utilizes bidirectional attention and mask-based parallel decoding to capture codec representations corresponding to timbre, content, and style in a discrete decoupling codec space. Moreover, we analyze the many-to-many issue in textual style control and propose the Style Mixture Semantic Density (SMSD) module, which is based on Gaussian mixture density networks, to resolve this problem. To facilitate empirical validations, we make available a new style controllable dataset called VccmDataset. Our experimental results demonstrate that ControlSpeech exhibits comparable or state-of-the-art (SOTA) performance in terms of controllability, timbre similarity, audio quality, robustness, and generalizability. The relevant code and demo are available at https://github.com/jishengpeng/ControlSpeech .",287855483,5,46,,
10.18653/v1/2025.acl-long.1557,LETS-C: Leveraging Text Embedding for Time Series Classification,"Rachneet Kaur, Zhen Zeng, T. Balch, Manuela Veloso",Annual Meeting of the Association for Computational Linguistics,2024,"Recent advancements in language modeling have shown promising results when applied to time series data. In particular, fine-tuning pre-trained large language models (LLMs) for time series classification tasks has achieved state-of-the-art (SOTA) performance on standard benchmarks. However, these LLM-based models have a significant drawback due to the large model size, with the number of trainable parameters in the millions. In this paper, we propose an alternative approach to leveraging the success of language modeling in the time series domain. Instead of fine-tuning LLMs, we utilize a text embedding model to embed time series and then pair the embeddings with a simple classification head composed of convolutional neural networks (CNN) and multilayer perceptron (MLP). We conducted extensive experiments on a well-established time series classification benchmark. We demonstrated LETS-C not only outperforms the current SOTA in classification accuracy but also offers a lightweight solution, using only 14.5% of the trainable parameters on average compared to the SOTA model. Our findings suggest that leveraging text embedding models to encode time series data, combined with a simple yet effective classification head, offers a promising direction for achieving high-performance time series classification while maintaining a lightweight model architecture.",287856075,2,86,,
10.18653/v1/2025.acl-long.204,"Automating Legal Interpretation with LLMs: Retrieval, Generation, and Evaluation","Kangcheng Luo, Quzhe Huang, Cong Jiang, Yansong Feng",Annual Meeting of the Association for Computational Linguistics,2025,"Interpreting the law is always essential for the law to adapt to the ever-changing society. It is a critical and challenging task even for legal practitioners, as it requires meticulous and professional annotations and summarizations by legal experts, which are admittedly time-consuming and expensive to collect at scale. To alleviate the burden on legal experts, we propose a method for automated legal interpretation. Specifically, by emulating doctrinal legal research, we introduce a novel framework, ATRIE, to address Legal Concept Interpretation, a typical task in legal interpretation. ATRIE utilizes large language models (LLMs) to AuTomatically Retrieve concept-related information, Interpret legal concepts, and Evaluate generated interpretations, eliminating dependence on legal experts. ATRIE comprises a legal concept interpreter and a legal concept interpretation evaluator. The interpreter uses LLMs to retrieve relevant information from previous cases and interpret legal concepts. The evaluator uses performance changes on Legal Concept Entailment, a downstream task we propose, as a proxy of interpretation quality. Automated and multifaceted human evaluations indicate that the quality of our interpretations is comparable to those written by legal experts, with superior comprehensiveness and readability. Although there remains a slight gap in accuracy, it can already assist legal practitioners in improving the efficiency of legal interpretation.",287857588,3,30,,
10.18653/v1/2025.acl-long.639,Exploring Compositional Generalization of Multimodal LLMs for Medical Imaging,"Zhenyang Cai, Junying Chen, Rongsheng Wang, Weihong Wang, Yonglin Deng, Dingjie Song, Yize Chen, Zixu Zhang, Benyou Wang",Annual Meeting of the Association for Computational Linguistics,2024,"Medical imaging provides essential visual insights for diagnosis, and multimodal large language models (MLLMs) are increasingly utilized for its analysis due to their strong generalization capabilities; however, the underlying factors driving this generalization remain unclear. Current research suggests that multi-task training outperforms single-task as different tasks can benefit each other, but they often overlook the internal relationships within these tasks. To analyze this phenomenon, we attempted to employ compositional generalization (CG), which refers to the models' ability to understand novel combinations by recombining learned elements, as a guiding framework. Since medical images can be precisely defined by Modality, Anatomical area, and Task, naturally providing an environment for exploring CG, we assembled 106 medical datasets to create Med-MAT for comprehensive experiments. The experiments confirmed that MLLMs can use CG to understand unseen medical images and identified CG as one of the main drivers of the generalization observed in multi-task training. Additionally, further studies demonstrated that CG effectively supports datasets with limited data and confirmed that MLLMs can achieve CG across classification and detection tasks, underscoring its broader generalization potential. Med-MAT is available at https://github.com/FreedomIntelligence/Med-MAT.",287859087,0,76,,
10.18653/v1/2025.acl-long.636,Improving Medical Large Vision-Language Models with Abnormal-Aware Feedback,"Yucheng Zhou, Lingran Song, Jianbing Shen",Annual Meeting of the Association for Computational Linguistics,2025,"Existing Medical Large Vision-Language Models (Med-LVLMs), encapsulating extensive medical knowledge, demonstrate excellent capabilities in understanding medical images. However, there remain challenges in visual localization in medical images, which is crucial for abnormality detection and interpretation. To address these issues, we propose a novel UMed-LVLM designed to unveil medical abnormalities. Specifically, we collect a Medical Abnormalities Unveiling (MAU) dataset and propose a two-stage training method for UMed-LVLM training. To collect MAU dataset, we propose a prompt method utilizing the GPT-4V to generate diagnoses based on identified abnormal areas in medical images. Moreover, the two-stage training method includes Abnormal-Aware Instruction Tuning and Abnormal-Aware Rewarding, comprising Relevance Reward, Abnormal Localization Reward and Vision Relevance Reward. Experimental results demonstrate that our UMed-LVLM significantly outperforms existing Med-LVLMs in identifying and understanding medical abnormalities, achieving a 58% improvement over the baseline. In addition, this work shows that enhancing the abnormality detection capabilities of Med-LVLMs significantly improves their understanding of medical images and generalization capability.",287859088,33,55,,
10.18653/v1/2025.acl-long.20,LLM-Powered Test Case Generation for Detecting Bugs in Plausible Programs,"Kaibo Liu, Zhenpeng Chen, Yiyang Liu, Jie M. Zhang, Mark Harman, Yudong Han, Yun Ma, Yihong Dong, Ge Li, Gang Huang",Annual Meeting of the Association for Computational Linguistics,2024,"Detecting tricky bugs in plausible programs, those that pass existing test suites yet still contain bugs, remains a significant challenge in software testing. To address this problem, we propose TrickCatcher, an LLM-powered approach to generating test cases for uncovering bugs in plausible programs. TrickCatcher operates in three stages: First, it uses an LLM to generate program variants based on the program under test (PUT) and its specification. Second, it employs an LLM to construct an input generator from the specification for producing test inputs. Finally, these inputs are executed on both the PUT and its program variants to detect inconsistencies in their outputs. We evaluate TrickCatcher on two datasets, TrickyBugs and EvalPlus, which include 366 human-written and 151 AI-generated plausible programs with tricky bugs. TrickCatcher achieves recall, precision, and F1 scores that are 1.80x, 2.65x, and 1.66x those of the state-of-the-art baselines, respectively. Code and data used are available at https://github.com/RinCloud/TrickCatcher.",287860657,7,19,,
10.18653/v1/2025.acl-long.352,SongComposer: A Large Language Model for Lyric and Melody Generation in Song Composition,"Shuangrui Ding, Zihan Liu, Xiao-wen Dong, Pan Zhang, Rui Qian, Junhao Huang, Conghui He, Dahua Lin, Jiaqi Wang",Annual Meeting of the Association for Computational Linguistics,2024,"Creating lyrics and melodies for the vocal track in a symbolic format, known as song composition, demands expert musical knowledge of melody, an advanced understanding of lyrics, and precise alignment between them. Despite achievements in sub-tasks such as lyric generation, lyric-to-melody, and melody-to-lyric, etc, a unified model for song composition has not yet been achieved. In this paper, we introduce SongComposer, a pioneering step towards a unified song composition model that can readily create symbolic lyrics and melodies following instructions. SongComposer is a music-specialized large language model (LLM) that, for the first time, integrates the capability of simultaneously composing lyrics and melodies into LLMs by leveraging three key innovations: 1) a flexible tuple format for word-level alignment of lyrics and melodies, 2) an extended tokenizer vocabulary for song notes, with scalar initialization based on musical knowledge to capture rhythm, and 3) a multi-stage pipeline that captures musical structure, starting with motif-level melody patterns and progressing to phrase-level structure for improved coherence. Extensive experiments demonstrate that SongComposer outperforms advanced LLMs, including GPT-4, in tasks such as lyric-to-melody generation, melody-to-lyric generation, song continuation, and text-to-song creation. Moreover, we will release SongCompose, a large-scale dataset for training, containing paired lyrics and melodies in Chinese and English.",287872714,4,38,,
10.18653/v1/2025.acl-long.266,Pattern Recognition or Medical Knowledge? The Problem with Multiple-Choice Questions in Medicine,"Maxime Griot, Jean Vanderdonckt, Demet Yuksel, C. Hemptinne",Annual Meeting of the Association for Computational Linguistics,2024,"Large Language Models (LLMs) such as ChatGPT demonstrate significant potential in the medical domain and are often evaluated using multiple-choice questions (MCQs) modeled on exams like the USMLE. However, such benchmarks may overestimate true clinical understanding by rewarding pattern recognition and test-taking heuristics. To investigate this, we created a fictional medical benchmark centered on an imaginary organ, the Glianorex, allowing us to separate memorized knowledge from reasoning ability. We generated textbooks and MCQs in English and French using leading LLMs, then evaluated proprietary, open-source, and domain-specific models in a zero-shot setting. Despite the fictional content, models achieved an average score of 64%, while physicians scored only 27%. Fine-tuned medical models outperformed base models in English but not in French. Ablation and interpretability analyses revealed that models frequently relied on shallow cues, test-taking strategies, and hallucinated reasoning to identify the correct choice. These results suggest that standard MCQ-based evaluations may not effectively measure clinical reasoning and highlight the need for more robust, clinically meaningful assessment methods for LLMs.",287874130,8,41,,
10.18653/v1/2025.acl-long.1590,Comparison-based Active Preference Learning for Multi-dimensional Personalization,"Minhyeon Oh, Seungjoon Lee, Jungseul Ok",Annual Meeting of the Association for Computational Linguistics,2024,"Large language models (LLMs) have shown remarkable success, but aligning them with human preferences remains a core challenge. As individuals have their own, multi-dimensional preferences, recent studies have explored multi-dimensional personalization, which aims to enable models to generate responses personalized to explicit preferences. However, human preferences are often implicit and thus difficult to articulate, limiting the direct application of this approach. To bridge this gap, we propose Active Multi-dimensional Preference Learning (AMPLe), designed to capture implicit user preferences from interactively collected comparative feedback. Building on Bayesian inference, our work introduces a modified posterior update procedure to mitigate estimation bias and potential noise in comparisons. Also, inspired by generalized binary search, we employ an active query selection strategy to minimize the number of required comparisons by a user. Through theoretical analysis and experiments on language generation tasks, we demonstrate feedback efficiency and effectiveness of our framework in personalizing model responses. Our code is publicly available at https://github.com/ml-postech/AMPLe .",287875644,0,41,,
10.18653/v1/2025.acl-long.1582,Towards Building Large Scale Datasets and State-of-the-Art Automatic Speech Translation Systems for 14 Indian Languages,"Sparsh Jain, Ashwin Sankar, Devilal Choudhary, Dhairya Suman, Nikhil Narasimhan, Mohammed Safi Ur Rahman Khan, Anoop Kunchukuttan, Mitesh M. Khapra, Raj Dabre",(missing journal),2024,"Speech translation for Indian languages remains a challenging task due to the scarcity of large-scale, publicly available datasets that capture the linguistic diversity and domain coverage essential for real-world applications. Existing datasets cover a fraction of Indian languages and lack the breadth needed to train robust models that generalize beyond curated benchmarks. To bridge this gap, we introduce BhasaAnuvaad, the largest speech translation dataset for Indian languages, spanning over 44 thousand hours of audio and 17 million aligned text segments across 14 Indian languages and English. Our dataset is built through a threefold methodology: (a) aggregating high-quality existing sources, (b) large-scale web crawling to ensure linguistic and domain diversity, and (c) creating synthetic data to model real-world speech disfluencies. Leveraging BhasaAnuvaad, we train IndicSeamless, a state-of-the-art speech translation model for Indian languages that performs better than existing models. Our experiments demonstrate improvements in the translation quality, setting a new standard for Indian language speech translation. We will release all the code, data and model weights in the open-source, with permissive licenses to promote accessibility and collaboration.",287880173,4,55,,
10.18653/v1/2025.acl-long.1562,Why Prompt Design Matters and Works: A Complexity Analysis of Prompt Search Space in LLMs,"Xiang Zhang, Juntai Cao, Jiaqi Wei, Chenyu You, Dujian Ding",Annual Meeting of the Association for Computational Linguistics,2025,"Despite the remarkable successes of large language models (LLMs), the underlying Transformer architecture has inherent limitations in handling complex reasoning tasks. Chain-of-thought (CoT) prompting has emerged as a practical workaround, but most CoT-based methods rely on a single, generic prompt such as""think step by step"", with no task-specific adaptation. These approaches expect the model to discover an effective reasoning path on its own, forcing it to search through a vast prompt space. In contrast, several studies have explored task-specific prompt designs to boost performance. However, these designs are typically developed through trial and error, lacking theoretical grounding. As a result, prompt engineering remains largely ad hoc and unguided. In this paper, we provide a theoretical framework that explains why some prompts succeed while others fail. We show that prompts function as selectors, extracting task-relevant information from the model's full hidden state during CoT reasoning. Each prompt defines a unique trajectory through the answer space, and the choice of trajectory is crucial for task performance and future navigation within the space. We analyze the complexity of finding optimal prompts and characterize the size of the prompt space for a given task. Our theory reveals principles behind effective prompt design and shows that naive CoT-using self-guided prompts like""think step by step""-can severely hinder performance. Through experiments, we show that optimal prompt search can lead to more than a 50% improvement on reasoning tasks, providing a theoretical foundation for prompt engineering.",287886214,13,38,,
10.18653/v1/2025.acl-long.654,Language-Codec: Bridging Discrete Codec Representations and Speech Language Models,"Shengpeng Ji, Minghui Fang, Jialong Zuo, Ziyue Jiang, Dingdong Wang, Hanting Wang, Hai Huang, Zhou Zhao",Annual Meeting of the Association for Computational Linguistics,2024,"In recent years, large language models have achieved significant success in generative tasks related to speech, audio, music, and other signal domains. A crucial element of these models is the discrete acoustic codecs, which serve as an intermediate representation replacing the mel-spectrogram. However, there exist several gaps between discrete codecs and downstream speech language models. Specifically, 1) Due to the reconstruction paradigm of the Codec model and the structure of residual vector quantization, the initial channel of the codebooks contains excessive information, making it challenging to directly generate acoustic tokens from weakly supervised signals such as text in downstream tasks. 2) numerous codebooks increases the burden on downstream speech language models. Consequently, leveraging the characteristics of speech language models, we propose Language-Codec. In the Language-Codec, we introduce a Masked Channel Residual Vector Quantization (MCRVQ) mechanism along with improved fourier transform structures and attention blocks, refined discriminator design to address the aforementioned gaps. We compare our method with competing audio compression algorithms and observe significant outperformance across extensive evaluations. Furthermore, we also validate the efficiency of the Language-Codec on downstream speech language models. The source code and pre-trained models can be accessed at https://github.com/jishengpeng/languagecodec .",287892975,0,24,,
10.18653/v1/2025.acl-long.590,The Tug of War Within: Mitigating the Fairness-Privacy Conflicts in Large Language Models,"Chen Qian, Dongrui Liu, Jie Zhang, Yong Liu, Jing Shao",Annual Meeting of the Association for Computational Linguistics,2024,"Ensuring awareness of fairness and privacy in Large Language Models (LLMs) is critical. Interestingly, we discover a counter-intuitive trade-off phenomenon that enhancing an LLM's privacy awareness through Supervised Fine-Tuning (SFT) methods significantly decreases its fairness awareness with thousands of samples. To address this issue, inspired by the information theory, we introduce a training-free method to \textbf{S}uppress the \textbf{P}rivacy and fa\textbf{I}rness coupled \textbf{N}eurons (\textbf{SPIN}), which theoretically and empirically decrease the mutual information between fairness and privacy awareness. Extensive experimental results demonstrate that SPIN eliminates the trade-off phenomenon and significantly improves LLMs' fairness and privacy awareness simultaneously without compromising general capabilities, \eg improving Qwen-2-7B-Instruct's fairness awareness by 12.2\% and privacy awareness by 14.0\%. More crucially, SPIN remains robust and effective with limited annotated data or even when only malicious fine-tuning data is available, whereas SFT methods may fail to perform properly in such scenarios. Furthermore, we show that SPIN could generalize to other potential trade-off dimensions. We hope this study provides valuable insights into concurrently addressing fairness and privacy concerns in LLMs and can be integrated into comprehensive frameworks to develop more ethical and responsible AI systems. Our code is available at https://github.com/ChnQ/SPIN.",287900940,1,110,,
10.18653/v1/2025.acl-long.1145,Marco-o1 v2: Towards Widening The Distillation Bottleneck for Reasoning Models,"Huifeng Yin, Yu Zhao, Minghao Wu, Xuanfan Ni, Bo Zeng, Hao Wang, Tianqi Shi, Liangying Shao, Chenyang Lyu, Longyue Wang, Weihua Luo, Kaifu Zhang",Annual Meeting of the Association for Computational Linguistics,2025,"Large Reasoning Models(LRMs) such as OpenAI o1 and DeepSeek-R1 have shown remarkable reasoning capabilities by scaling test-time compute and generating long Chain-of-Thought(CoT). Distillation--post-training on LRMs-generated data--is a straightforward yet effective method to enhance the reasoning abilities of smaller models, but faces a critical bottleneck: we found that distilled long CoT data poses learning difficulty for small models and leads to the inheritance of biases (i.e. over-thinking) when using Supervised Fine-tuning (SFT) and Reinforcement Learning (RL) methods. To alleviate this bottleneck, we propose constructing tree-based CoT data from scratch via Monte Carlo Tree Search(MCTS). We then exploit a set of CoT-aware approaches, including Thoughts Length Balance, Fine-grained DPO, and Joint Post-training Objective, to enhance SFT and RL on the constructed data. We conduct evaluation on various benchmarks such as math (GSM8K, MATH, AIME). instruction-following (Multi-IF) and planning (Blocksworld), results demonstrate our approaches substantially improve the reasoning performance of distilled models compared to standard distilled models via reducing the hallucinations in long-time thinking. The project homepage is https://github.com/AIDC-AI/Marco-o1.",287903903,10,27,,
10.18653/v1/2025.acl-long.445,"White Men Lead, Black Women Help? Benchmarking and Mitigating Language Agency Social Biases in LLMs","Yixin Wan, Kai-Wei Chang",(missing journal),2024,"Social biases can manifest in language agency. However, very limited research has investigated such biases in Large Language Model (LLM)-generated content. In addition, previous works often rely on string-matching techniques to identify agentic and communal words within texts, falling short of accurately classifying language agency. We introduce the Language Agency Bias Evaluation (LABE) benchmark, which comprehensively evaluates biases in LLMs by analyzing agency levels attributed to different demographic groups in model generations. LABE tests for gender, racial, and intersectional language agency biases in LLMs on 3 text generation tasks: biographies, professor reviews, and reference letters. Using LABE, we unveil language agency social biases in 3 recent LLMs: ChatGPT, Llama3, and Mistral. We observe that: (1) LLM generations tend to demonstrate greater gender bias than human-written texts; (2) Models demonstrate remarkably higher levels of intersectional bias than the other bias aspects. (3) Prompt-based mitigation is unstable and frequently leads to bias exacerbation. Based on our observations, we propose Mitigation via Selective Rewrite (MSR), a novel bias mitigation strategy that leverages an agency classifier to identify and selectively revise parts of generated texts that demonstrate communal traits. Empirical results prove MSR to be more effective and reliable than prompt-based mitigation method, showing a promising research direction.",287906850,0,38,,
10.18653/v1/2025.acl-long.1107,STRICTA: Structured Reasoning in Critical Text Assessment for Peer Review and Beyond,"Nils Dycke, M. Zecevic, Ilia Kuznetsov, Beatrix Suess, Kristian Kersting, Iryna Gurevych",Annual Meeting of the Association for Computational Linguistics,2024,"Critical text assessment is at the core of many expert activities, such as fact-checking, peer review, and essay grading. Yet, existing work treats critical text assessment as a black box problem, limiting interpretability and human-AI collaboration. To close this gap, we introduce Structured Reasoning In Critical Text Assessment (STRICTA), a novel specification framework to model text assessment as an explicit, step-wise reasoning process. STRICTA breaks down the assessment into a graph of interconnected reasoning steps drawing on causality theory (Pearl, 1995). This graph is populated based on expert interaction data and used to study the assessment process and facilitate human-AI collaboration. We formally define STRICTA and apply it in a study on biomedical paper assessment, resulting in a dataset of over 4000 reasoning steps from roughly 40 biomedical experts on more than 20 papers. We use this dataset to empirically study expert reasoning in critical text assessment, and investigate if LLMs are able to imitate and support experts within these workflows. The resulting tools and datasets pave the way for studying collaborative expert-AI reasoning in text assessment, in peer review and beyond.",287911117,1,82,,
10.18653/v1/2025.acl-long.1396,Length-Induced Embedding Collapse in PLM-based Models,"Yuqi Zhou, Sunhao Dai, Zhanshuo Cao, Xiao Zhang, Jun Xu",Annual Meeting of the Association for Computational Linguistics,2024,"Text embeddings from PLM-based models enable a wide range of applications, yet their performance often degrades on longer texts. In this paper, we introduce a phenomenon we call Length Collapse, where embeddings of longer texts tend to cluster together. This clustering results in a distributional inconsistency between the embeddings of short and long texts. We further investigate how these differences contribute to the performance decline observed with longer texts across various downstream tasks. Through a rigorous theoretical analysis of the self-attention mechanism, which acts as a low-pass filter in PLM-based models, we demonstrate that as text length increases, the strength of low-pass filtering intensifies, causing embeddings to retain more low-frequency components. As a result, input token features become more similar, leading to clustering and ultimately the collapse of embeddings for longer texts. To address this issue, we propose a simple method, TempScale, which mitigates the Length Collapse phenomenon. By narrowing the gap in low-pass filtering rates between long and short texts, TempScale ensures more consistent embeddings across different text lengths. This approach leads to performance improvements of 0.94% on MTEB and 1.10% on LongEmbed, which focuses specifically on long-context retrieval, providing strong evidence for the validity of our analysis. The source code is available at https://github.com/Yuqi-Zhou/Length_Collapse.",288152177,2,69,,
10.18653/v1/2025.acl-long.650,Inducing lexicons of in-group language with socio-temporal context,Christine de Kock,Annual Meeting of the Association for Computational Linguistics,2024,"In-group language is an important signifier of group dynamics. This paper proposes a novel method for inducing lexicons of in-group language, which incorporates its socio-temporal context. Existing methods for lexicon induction do not capture the evolving nature of in-group language, nor the social structure of the community. Using dynamic word and user embeddings trained on conversations from online anti-women communities, our approach outperforms prior methods for lexicon induction. We develop a test set for the task of lexicon induction and a new lexicon of manosphere language, validated by human experts, which quantifies the relevance of each term to a specific sub-community at a given point in time. Finally, we present novel insights on in-group language which illustrate the utility of this approach.",288156584,0,26,,
10.18653/v1/2025.acl-long.1011,Using Shapley interactions to understand how models use structure,"Divyansh Singhvi, Diganta Misra, Andrej Erkelens, Raghav Jain, Isabel Papadimitriou, Naomi Saphra",Annual Meeting of the Association for Computational Linguistics,2024,"Language is an intricately structured system, and a key goal of NLP interpretability is to provide methodological insights for understanding how language models represent this structure internally. In this paper, we use Shapley Taylor interaction indices (STII) in order to examine how language and speech models internally relate and structure their inputs. Pairwise Shapley interactions measure how much two inputs work together to influence model outputs beyond if we linearly added their independent influences, providing a view into how models encode structural interactions between inputs. We relate the interaction patterns in models to three underlying linguistic structures: syntactic structure, non-compositional semantics, and phonetic coarticulation. We find that autoregressive text models encode interactions that correlate with the syntactic proximity of inputs, and that both autoregressive and masked models encode nonlinear interactions in idiomatic phrases with non-compositional semantics. Our speech results show that inputs are more entangled for pairs where a neighboring consonant is likely to influence a vowel or approximant, showing that models encode the phonetic interaction needed for extracting discrete phonemic representations.",288180740,1,54,,
10.18653/v1/2025.acl-long.281,Uncovering Visual-Semantic Psycholinguistic Properties from the Distributional Structure of Text Embedding Space,"Si Wu, Sebastian Bruch",(missing journal),2025,"Imageability (potential of text to evoke a mental image) and concreteness (perceptibility of text) are two psycholinguistic properties that link visual and semantic spaces. It is little surprise that computational methods that estimate them do so using parallel visual and semantic spaces, such as collections of image-caption pairs or multi-modal models. In this paper, we work on the supposition that text itself in an image-caption dataset offers sufficient signals to accurately estimate these properties. We hypothesize, in particular, that the peakedness of the neighborhood of a word in the semantic embedding space reflects its degree of imageability and concreteness. We then propose an unsupervised, distribution-free measure, which we call Neighborhood Stability Measure (NSM), that quantifies the sharpness of peaks. Extensive experiments show that NSM correlates more strongly with ground-truth ratings than existing unsupervised methods, and is a strong predictor of these properties for classification. Our code and data are available on GitHub (https://github.com/Artificial-Memory-Lab/imageability).",288186551,0,29,,
10.18653/v1/2025.acl-long.317,Assessing Dialect Fairness and Robustness of Large Language Models in Reasoning Tasks,"Fangru Lin, Shaoguang Mao, Emanuele La Malfa, Valentin Hofmann, Adrian de Wynter, Jing Yao, Si-Qing Chen, Michael Wooldridge, Furu Wei",Annual Meeting of the Association for Computational Linguistics,2024,"Language is not monolithic. While benchmarks, including those designed for multiple languages, are often used as proxies to evaluate the performance of Large Language Models (LLMs), they tend to overlook the nuances of within-language variation and thus fail to model the experience of speakers of non-standard dialects. Focusing on African American Vernacular English (AAVE), we present the first study aimed at objectively assessing the fairness and robustness of LLMs in handling dialects across canonical reasoning tasks, including algorithm, math, logic, and integrated reasoning. We introduce ReDial (Reasoning with Dialect Queries), a benchmark containing 1.2K+ parallel query pairs in Standardized English and AAVE. We hire AAVE speakers, including experts with computer science backgrounds, to rewrite seven popular benchmarks, such as HumanEval and GSM8K. With ReDial, we evaluate widely used LLMs, including GPT, Claude, Llama, Mistral, and the Phi model families. Our findings reveal that almost all of these widely used models show significant brittleness and unfairness to queries in AAVE. Our work establishes a systematic and objective framework for analyzing LLM bias in dialectal queries. Moreover, it highlights how mainstream LLMs provide unfair service to dialect speakers in reasoning tasks, laying a critical foundation for future research.",288191299,5,89,,
10.18653/v1/2025.acl-long.466,Efficient Pretraining Data Selection for Language Models via Multi-Actor Collaboration,"Tianyi Bai, Ling Yang, Zhen Hao Wong, Fupeng Sun, Jiahui Peng, Xinlin Zhuang, Chi Zhang, Lijun Wu, Jiantao Qiu, Wentao Zhang, Binhang Yuan, Conghui He",Annual Meeting of the Association for Computational Linguistics,2024,"Efficient data selection is crucial to accelerate the pretraining of language model (LMs). While various methods have been proposed to enhance data efficiency, limited research has addressed the inherent conflicts between these approaches to achieve optimal data selection for LM pretraining. To tackle this problem, we propose a multi-actor collaborative data selection mechanism: each data selection method independently prioritizes data based on its criterion and updates its prioritization rules using the current state of the model, functioning as an independent actor for data selection; and a console is designed to adjust the impacts of different actors at various stages and dynamically integrate information from all actors throughout the LM pretraining process. We conduct extensive empirical studies to evaluate our multi-actor framework. The experimental results demonstrate that our approach significantly improves data efficiency, accelerates convergence in LM pretraining, and achieves an average relative performance gain up to $10.5\%$ across multiple language model benchmarks compared to the state-of-the-art methods.",288200977,10,52,,
10.18653/v1/2025.acl-long.1410,Diversity Explains Inference Scaling Laws: Through a Case Study of Minimum Bayes Risk Decoding,"Hidetaka Kamigaito, Hiroyuki Deguchi, Yusuke Sakai, Katsuhiko Hayashi, Taro Watanabe",Annual Meeting of the Association for Computational Linguistics,2024,"Inference methods play an important role in eliciting the performance of large language models (LLMs). Currently, LLMs use inference methods utilizing generated multiple samples, which can be derived from Minimum Bayes Risk (MBR) Decoding. Previous studies have conducted empirical analyses to clarify the improvements in generation performance achieved by MBR decoding and have reported various observations. However, the theoretical underpinnings of these findings remain uncertain. To address this, we offer a new theoretical interpretation of MBR decoding from the perspective of bias-diversity decomposition. In this interpretation, the error in the quality estimation of hypotheses by MBR decoding is decomposed into two main factors: bias, which considers the closeness between the utility function and human evaluation, and diversity, which represents the variability in the quality estimation of the utility function. The theoretical analysis reveals the difficulty of simultaneously improving bias and diversity, confirming the validity of enhancing MBR decoding performance by increasing diversity. Furthermore, we reveal that diversity can explain one aspect of inference scaling laws that describe performance improvement by increasing sample size. Moreover, experiments across multiple NLP tasks yielded results consistent with these theoretical characteristics. Our code is available at https://github.com/naist-nlp/mbr-bias-diversity.",288207589,3,76,,
10.18653/v1/2025.acl-long.1433,Synergizing Unsupervised Episode Detection with LLMs for Large-Scale News Events,"Priyanka Kargupta, Yunyi Zhang, Yizhu Jiao, Siru Ouyang, Jiawei Han",Annual Meeting of the Association for Computational Linguistics,2024,"State-of-the-art automatic event detection struggles with interpretability and adaptability to evolving large-scale key events -- unlike episodic structures, which excel in these areas. Often overlooked, episodes represent cohesive clusters of core entities performing actions at a specific time and location; a partially ordered sequence of episodes can represent a key event. This paper introduces a novel task, episode detection, which identifies episodes within a news corpus of key event articles. Detecting episodes poses unique challenges, as they lack explicit temporal or locational markers and cannot be merged using semantic similarity alone. While large language models (LLMs) can aid with these reasoning difficulties, they suffer with long contexts typical of news corpora. To address these challenges, we introduce EpiMine, an unsupervised framework that identifies a key event's candidate episodes by leveraging natural episodic partitions in articles, estimated through shifts in discriminative term combinations. These candidate episodes are more cohesive and representative of true episodes, synergizing with LLMs to better interpret and refine them into final episodes. We apply EpiMine to our three diverse, real-world event datasets annotated at the episode level, where it achieves a 59.2% average gain across all metrics compared to baselines.",288212337,1,53,,
10.18653/v1/2025.acl-long.845,Enhancing Open-Domain Task-Solving Capability of LLMs via Autonomous Tool Integration from GitHub,"Bohan Lyu, Xin Cong, Heyang Yu, Pan Yang, Yujia Qin, Yining Ye, Ya-Ting Lu, Zhong Zhang, Yukun Yan, Yankai Lin, Zhiyuan Liu, Maosong Sun",Annual Meeting of the Association for Computational Linguistics,2023,"Large Language Models (LLMs) excel in traditional natural language processing tasks but struggle with problems that require complex domain-specific calculations or simulations. While equipping LLMs with external tools to build LLM-based agents can enhance their capabilities, existing approaches lack the flexibility to address diverse and ever-evolving user queries in open domains. Currently, there is also no existing dataset that evaluates LLMs on open-domain knowledge that requires tools to solve. To this end, we introduce OpenAct benchmark to evaluate the open-domain task-solving capability, which is built on human expert consultation and repositories in GitHub. It comprises 339 questions spanning 7 diverse domains that need to be solved with domain-specific methods. In our experiments, even state-of-the-art LLMs and LLM-based agents demonstrate unsatisfactory success rates, underscoring the need for a novel approach. Furthermore, we present OpenAgent, a novel LLM-based agent system that can tackle evolving queries in open domains through autonomously integrating specialized tools from GitHub. OpenAgent employs 1) a hierarchical framework where specialized agents handle specific tasks and can assign tasks to inferior agents, 2) a bi-level experience learning mechanism to learn from both humans' and its own experiences to tackle tool flaws. Experiments demonstrate its superior effectiveness and efficiency, which significantly outperforms baselines. Our data and code are open-source at https://github.com/OpenBMB/OpenAct.",288236199,7,56,,
10.18653/v1/2025.acl-long.1323,Controllable and Reliable Knowledge-Intensive Task-Oriented Conversational Agents with Declarative Genie Worksheets,"Harshit Joshi, Shicheng Liu, James Chen, Robert Weigle, Monica S. Lam",Annual Meeting of the Association for Computational Linguistics,2024,"Large Language Models can carry out human-like conversations in diverse settings, responding to user requests for tasks and knowledge. However, existing conversational agents implemented with LLMs often struggle with hallucination, following instructions with conditional logic, and integrating knowledge from different sources. These shortcomings compromise the agents' effectiveness, rendering them unsuitable for deployment. To address these challenges, we introduce Genie, a programmable framework for creating knowledge-intensive task-oriented conversational agents. Genie can handle involved interactions and answer complex queries. Unlike LLMs, it delivers reliable, grounded responses through advanced dialogue state management and supports controllable agent policies via its declarative specification -- Genie Worksheet. This is achieved through an algorithmic runtime system that implements the developer-supplied policy, limiting LLMs to (1) parse user input using a succinct conversational history, and (2) generate responses according to supplied context. Agents built with Genie outperform SOTA methods on complex logic dialogue datasets. We conducted a user study with 62 participants on three real-life applications: restaurant reservations with Yelp, as well as ticket submission and course enrollment for university students. Genie agents with GPT-4 Turbo outperformed the GPT-4 Turbo agents with function calling, improving goal completion rates from 21.8% to 82.8% across three real-world tasks.",288269348,2,33,,
10.18653/v1/2025.acl-long.610,Making LLMs Better Many-to-Many Speech-to-Text Translators with Curriculum Learning,"Yexing Du, Ziyang Ma, Yifan Yang, Keqi Deng, Xie Chen, Bo Yang, Yang Xiang, Ming Liu, Bing Qin",Annual Meeting of the Association for Computational Linguistics,2024,"Multimodal Large Language Models (MLLMs) have achieved significant success in Speech-to-Text Translation (S2TT) tasks. While most existing research has focused on English-centric translation directions, the exploration of many-to-many translation is still limited by the scarcity of parallel data. To address this, we propose a three-stage curriculum learning strategy that leverages the machine translation capabilities of large language models and adapts them to S2TT tasks, enabling effective learning in low-resource settings. We trained MLLMs with varying parameter sizes (3B, 7B, and 32B) and evaluated the proposed strategy using the FLEURS and CoVoST-2 datasets. Experimental results show that the proposed strategy achieves state-of-the-art average performance in $15\times14$ language pairs, requiring fewer than 10 hours of speech data per language to achieve competitive results. The source code and models are released at https://github.com/yxduir/LLM-SRT.",288375595,13,48,,
10.18653/v1/2025.acl-long.1504,Efficient Safety Alignment of Large Language Models via Preference Re-ranking and Representation-based Reward Modeling,"Qiyuan Deng, Xuefeng Bai, Kehai Chen, Yaowei Wang, Liqiang Nie, Min Zhang",Annual Meeting of the Association for Computational Linguistics,2025,"Reinforcement Learning (RL) algorithms for safety alignment of Large Language Models (LLMs), such as Direct Preference Optimization (DPO), encounter the challenge of distribution shift. Current approaches typically address this issue through online sampling from the target policy, which requires significant computational resources. In this paper, we hypothesize that during off-policy training, while the ranking order of output generated by policy changes, their overall distribution remains relatively stable. This stability allows the conversion of the sampling process from the target policy into a computationally efficient re-ranking of preference data. Building on this hypothesis, we propose a new framework that leverages the model's intrinsic safety judgment capability to extract reward signals, which are then used to calculate label confidence for preference reordering. Extensive experiments and theoretical analysis demonstrate that the proposed method effectively addresses the distribution shift issue, remarkably enhancing the safety performance while avoiding about 300x computational overheads.",288398425,1,41,,
10.18653/v1/2025.acl-long.1454,A Theory of Response Sampling in LLMs: Part Descriptive and Part Prescriptive,"S. Sivaprasad, Pramod Kaushik, Sahar Abdelnabi, Mario Fritz",Annual Meeting of the Association for Computational Linguistics,2024,"Large Language Models (LLMs) are increasingly utilized in autonomous decision-making, where they sample options from vast action spaces. However, the heuristics that guide this sampling process remain under explored. We study this sampling behavior and show that this underlying heuristics resembles that of human decision-making: comprising a descriptive component (reflecting statistical norm) and a prescriptive component (implicit ideal encoded in the LLM) of a concept. We show that this deviation of a sample from the statistical norm towards a prescriptive component consistently appears in concepts across diverse real-world domains like public health, and economic trends. To further illustrate the theory, we demonstrate that concept prototypes in LLMs are affected by prescriptive norms, similar to the concept of normality in humans. Through case studies and comparison with human studies, we illustrate that in real-world applications, the shift of samples toward an ideal value in LLMs'outputs can result in significantly biased decision-making, raising ethical concerns.",289343122,3,50,,
10.18653/v1/2025.acl-long.87,Takin-VC: Expressive Zero-Shot Voice Conversion via Adaptive Hybrid Content Encoding and Enhanced Timbre Modeling,"Yuguang Yang, Yu Pan, Jixun Yao, Xiang Zhang, Jianhao Ye, Hongbin Zhou, Lei Xie, Lei Ma, Jianjun Zhao",Annual Meeting of the Association for Computational Linguistics,2024,"Expressive zero-shot voice conversion (VC) is a critical and challenging task that aims to transform the source timbre into an arbitrary unseen speaker while preserving the original content and expressive qualities. Despite recent progress in zero-shot VC, there remains considerable potential for improvements in speaker similarity and speech naturalness. Moreover, existing zero-shot VC systems struggle to fully reproduce paralinguistic information in highly expressive speech, such as breathing, crying, and emotional nuances, limiting their practical applicability. To address these issues, we propose Takin-VC, a novel expressive zero-shot VC framework via adaptive hybrid content encoding and memory-augmented context-aware timbre modeling. Specifically, we introduce an innovative hybrid content encoder that incorporates an adaptive fusion module, capable of effectively integrating quantized features of the pre-trained WavLM and HybridFormer in an implicit manner, so as to extract precise linguistic features while enriching paralinguistic elements. For timbre modeling, we propose advanced memory-augmented and context-aware modules to generate high-quality target timbre features and fused representations that seamlessly align source content with target timbre. To enhance real-time performance, we advocate a conditional flow matching model to reconstruct the Mel-spectrogram of the source speech. Experimental results show that our Takin-VC consistently surpasses state-of-the-art VC systems, achieving notable improvements in terms of speech naturalness, speech expressiveness, and speaker similarity, while offering enhanced inference speed.",289343184,2,72,,
10.18653/v1/2025.acl-long.1380,SpindleKV: A Novel KV Cache Reduction Method Balancing Both Shallow and Deep Layers,"Zicong Tang, Luohe Shi, Z. Li, Baoyuan Qi, Guoming Liu, Lefei Zhang, Ping Wang",Annual Meeting of the Association for Computational Linguistics,2025,"Large Language Models (LLMs) have achieved impressive accomplishments in recent years. However, the increasing memory consumption of KV cache has possessed a significant challenge to the inference system. Eviction methods have revealed the inherent redundancy within the KV cache, demonstrating its potential for reduction, particularly in deeper layers. However, KV cache reduction for shallower layers has been found to be insufficient. Based on our observation that, the KV cache exhibits a high degree of similarity. Based on this observation, we proposed a novel KV cache reduction method, SpindleKV, which balances both shallow and deep layers. For deep layers, we employ an attention weight based eviction method, while for shallow layers, we apply a codebook based replacement approach which is learnt by similarity and merging policy. Moreover, SpindleKV addressed the Grouped-Query Attention (GQA) dilemma faced by other attention based eviction methods. Experiments on two common benchmarks with three different LLMs shown that SpindleKV obtained better KV cache reduction effect compared to baseline methods, while preserving similar or even better model performance.",289343351,6,25,,
10.18653/v1/2025.acl-long.1208,WAFFLE: Fine-tuning Multi-Modal Model for Automated Front-End Development,"Shanchao Liang, Nan Jiang, Shangshu Qian, Lin Tan",Annual Meeting of the Association for Computational Linguistics,2024,"Web development involves turning UI designs into functional webpages, which can be difficult for both beginners and experienced developers due to the complexity of HTML's hierarchical structures and styles. While Large Language Models (LLMs) have shown promise in generating source code, two major challenges persist in UI-to-HTML code generation: (1) effectively representing HTML's hierarchical structure for LLMs, and (2) bridging the gap between the visual nature of UI designs and the text-based format of HTML code. To tackle these challenges, we introduce Waffle, a new fine-tuning strategy that uses a structure-aware attention mechanism to improve LLMs'understanding of HTML's structure and a contrastive fine-tuning approach to align LLMs'understanding of UI images and HTML code. Models fine-tuned with Waffle show up to 9.00 pp (percentage point) higher HTML match, 0.0982 higher CW-SSIM, 32.99 higher CLIP, and 27.12 pp higher LLEM on our new benchmark WebSight-Test and an existing benchmark Design2Code, outperforming current fine-tuning methods.",289347883,2,38,,
10.18653/v1/2025.acl-long.255,GradOT: Training-free Gradient-preserving Offsite-tuning for Large Language Models,"Kai Yao, Zhaorui Tan, Penglei Gao, Lichun Li, Kaixin Wu, Yinggui Wang, Yuan-yuan Zhao, Yixin Ji, Jianke Zhu, Wei Wang",Annual Meeting of the Association for Computational Linguistics,2025,"The rapid growth of large language models (LLMs) with traditional centralized fine-tuning emerges as a key technique for adapting these models to domain-specific challenges, yielding privacy risks for both model and data owners. One promising solution, called offsite-tuning (OT), is proposed to address these challenges, where a weaker emulator is compressed from the original model and further fine-tuned with adapter to enhance privacy. However, the existing OT-based methods require high computational costs and lack theoretical analysis. This paper introduces a novel OT approach based on gradient-preserving compression, named GradOT. By analyzing the OT problem through the lens of optimization, we propose a method that selectively applies compression techniques such as rank compression and channel pruning, preserving the gradients of fine-tuned adapters while ensuring privacy. Extensive experiments demonstrate that our approach surpasses existing OT methods, both in terms of privacy protection and model performance. Our method provides a theoretical foundation for OT and offers a practical, training-free solution for offsite-tuning of large-scale LLMs.",289348132,0,38,,
10.18653/v1/2025.acl-long.1576,EducationQ: Evaluating LLMs' Teaching Capabilities Through Multi-Agent Dialogue Framework,"Yao Shi, Rongkeng Liang, Yong Xu",Annual Meeting of the Association for Computational Linguistics,2025,"Large language models (LLMs) increasingly serve as educational tools, yet evaluating their teaching capabilities remains challenging due to the resource-intensive, context-dependent, and methodologically complex nature of teacher-student interactions. We introduce EducationQ, a multi-agent dialogue framework that efficiently assesses teaching capabilities through simulated dynamic educational scenarios, featuring specialized agents for teaching, learning, and evaluation. Testing 14 LLMs across major AI Organizations (OpenAI, Meta, Google, Anthropic, and others) on 1,498 questions spanning 13 disciplines and 10 difficulty levels reveals that teaching effectiveness does not correlate linearly with model scale or general reasoning capabilities - with some smaller open-source models outperforming larger commercial counterparts in teaching contexts. This finding highlights a critical gap in current evaluations that prioritize knowledge recall over interactive pedagogy. Our mixed-methods evaluation, combining quantitative metrics with qualitative analysis and expert case studies, identifies distinct pedagogical strengths employed by top-performing models (e.g., sophisticated questioning strategies, adaptive feedback mechanisms). Human expert evaluations show 78% agreement with our automated qualitative analysis of effective teaching behaviors, validating our methodology. EducationQ demonstrates that LLMs-as-teachers require specialized optimization beyond simple scaling, suggesting next-generation educational AI prioritize targeted enhancement of specific pedagogical effectiveness.",289349491,4,39,,
10.18653/v1/2025.acl-long.952,DAC: A Dynamic Attention-aware Approach for Task-Agnostic Prompt Compression,"Yi Zhao, Z. Li, Hai Zhao, Baoyuan Qi, Guoming Liu",Annual Meeting of the Association for Computational Linguistics,2025,"Task-agnostic prompt compression leverages the redundancy in natural language to reduce computational overhead and enhance information density within prompts, especially in long-context scenarios. Existing methods predominantly rely on information entropy as the metric to compress lexical units, aiming to achieve minimal information loss. However, these approaches overlook two critical aspects: (i) the importance of attention-critical tokens at the algorithmic level, and (ii) shifts in information entropy during the compression process. Motivated by these challenges, we propose a dynamic attention-aware approach for task-agnostic prompt compression (DAC). This approach effectively integrates entropy and attention information, dynamically sensing entropy shifts during compression to achieve fine-grained prompt compression. Extensive experiments across various domains, including LongBench, GSM8K, and BBH, show that DAC consistently yields robust and substantial improvements across a diverse range of tasks and LLMs, offering compelling evidence of its efficacy.",289351178,2,20,,
10.18653/v1/2025.acl-long.1402,Reviving Cultural Heritage: A Novel Approach for Comprehensive Historical Document Restoration,"Yuyi Zhang, Peirong Zhang, Zhenhua Yang, Pengyu Yan, Yongxin Shi, Pengwei Liu, Fengjun Guo, Lianwen Jin",Annual Meeting of the Association for Computational Linguistics,2025,"Historical documents represent an invaluable cultural heritage, yet have undergone significant degradation over time through tears, water erosion, and oxidation. Existing Historical Document Restoration (HDR) methods primarily focus on single modality or limited-size restoration, failing to meet practical needs. To fill this gap, we present a full-page HDR dataset (FPHDR) and a novel automated HDR solution (AutoHDR). Specifically, FPHDR comprises 1,633 real and 6,543 synthetic images with character-level and line-level locations, as well as character annotations in different damage grades. AutoHDR mimics historians'restoration workflows through a three-stage approach: OCR-assisted damage localization, vision-language context text prediction, and patch autoregressive appearance restoration. The modular architecture of AutoHDR enables seamless human-machine collaboration, allowing for flexible intervention and optimization at each restoration stage. Experiments demonstrate AutoHDR's remarkable performance in HDR. When processing severely damaged documents, our method improves OCR accuracy from 46.83% to 84.05%, with further enhancement to 94.25% through human-machine collaboration. We believe this work represents a significant advancement in automated historical document restoration and contributes substantially to cultural heritage preservation. The model and dataset are available at https://github.com/SCUT-DLVCLab/AutoHDR.",289352704,2,32,,
10.18653/v1/2025.acl-long.1326,Internal Value Alignment in Large Language Models through Controlled Value Vector Activation,"Haoran Jin, Meng Li, Xiting Wang, Zhihao Xu, Minlie Huang, Yantao Jia, Defu Lian",Annual Meeting of the Association for Computational Linguistics,2025,"Aligning Large Language Models (LLMs) with human values has attracted increasing attention since it provides clarity, transparency, and the ability to adapt to evolving scenarios. In this paper, we introduce a Controlled Value Vector Activation (ConVA) method that directly aligns the internal values of LLMs by interpreting how a value is encoded in their latent representations and modifies relevant activations to ensure consistent values in LLMs. To ensure an accurate and unbiased interpretation, we propose a context-controlled value vector identification method. To consistently control values without sacrificing model performance, we introduce a gated value vector activation method for effective and minimum degree of value control. Experiments show that our method achieves the highest control success rate across 10 basic values without hurting LLM performance and fluency, and ensures target values even with opposite and potentially malicious input prompts. Source code and data are available at~ https://github.com/hr-jin/ConVA.",289354250,0,41,,
10.18653/v1/2025.acl-long.344,UniConv: Unifying Retrieval and Response Generation for Large Language Models in Conversations,"Fengran Mo, Yifan Gao, Chuan Meng, Xin Liu, Zhuofeng Wu, Kelong Mao, Zhengyang Wang, Pei Chen, Zheng Li, Xian Li, Bing Yin, Meng Jiang",Annual Meeting of the Association for Computational Linguistics,2025,"The rapid advancement of conversational search systems revolutionizes how information is accessed by enabling the multi-turn interaction between the user and the system. Existing conversational search systems are usually built with two different models. This separation restricts the system from leveraging the intrinsic knowledge of the models simultaneously, which cannot ensure the effectiveness of retrieval benefiting the generation. The existing studies for developing unified models cannot fully address the aspects of understanding conversational context, managing retrieval independently, and generating responses. In this paper, we explore how to unify dense retrieval and response generation for large language models in conversation. We conduct joint fine-tuning with different objectives and design two mechanisms to reduce the inconsistency risks while mitigating data discrepancy. The evaluations on five conversational search datasets demonstrate that our unified model can mutually improve both tasks and outperform the existing baselines.",289355779,14,52,,
10.18653/v1/2025.acl-long.721,Continual Gradient Low-Rank Projection Fine-Tuning for LLMs,"Chenxu Wang, Yilin Lyu, Zicheng Sun, Liping Jing",Annual Meeting of the Association for Computational Linguistics,2025,"Continual fine-tuning of Large Language Models (LLMs) is hampered by the trade-off between efficiency and expressiveness. Low-Rank Adaptation (LoRA) offers efficiency but constrains the model's ability to learn new tasks and transfer knowledge due to its low-rank nature and reliance on explicit parameter constraints. We propose GORP (Gradient LOw Rank Projection) for Continual Learning, a novel training strategy that overcomes these limitations by synergistically combining full and low-rank parameters and jointly updating within a unified low-rank gradient subspace. GORP expands the optimization space while preserving efficiency and mitigating catastrophic forgetting. Extensive experiments on continual learning benchmarks demonstrate GORP's superior performance compared to existing state-of-the-art approaches. Code is available at https://github.com/Wcxwcxw/GORP.",289355859,2,43,,
10.18653/v1/2025.acl-long.424,SEUF: Is Unlearning One Expert Enough for Mixture-of-Experts LLMs?,"Haomin Zhuang, Yihua Zhang, Kehan Guo, Jinghan Jia, Gaowen Liu, Sijia Liu, Xiangliang Zhang",Annual Meeting of the Association for Computational Linguistics,2024,"Recent advancements in LLMs unlearning have shown remarkable success in removing unwanted data-model influences while preserving the model's utility for legitimate knowledge. Despite these strides, sparse Mixture-of-Experts (MoE) LLMs--a key subset of the LLM family--have remained unexplored in the context of unlearning. As MoE LLMs are celebrated for their exceptional performance, we ask:How can unlearning be performed effectively and efficiently on MoE LLMs? Our pilot study shows that the dynamic routing nature of MoE LLMs introduces unique challenges, leading to excessive forgetting, uncontrolled knowledge erasure and substantial utility drops when existing unlearning methods are applied. To address this, we propose a novel Selected-Expert Unlearning Framework (SEUF). Through expert attribution, unlearning is concentrated on the most actively engaged experts for the specified knowledge. Concurrently, an anchor loss is applied to the router to stabilize the active state of this targeted expert, ensuring focused and controlled unlearning. SEUF is compatible with various standard unlearning algorithms. Extensive experiments demonstrate that SEUF enhances both forget quality up to 5% and model utility by 35% on MoE LLMs across various benchmarks and LLM architectures (compared to standard unlearning algorithms), while only unlearning 0.06% of the model parameters.",289360244,6,45,,
10.18653/v1/2025.acl-long.1415,How LLMs Comprehend Temporal Meaning in Narratives: A Case Study in Cognitive Evaluation of LLMs,"Karin de Langis, Jong Inn Park, Andreas Schramm, Bin Hu, Khanh Chi Le, Dongyeop Kang",Annual Meeting of the Association for Computational Linguistics,2025,"Large language models (LLMs) exhibit increasingly sophisticated linguistic capabilities, yet the extent to which these behaviors reflect human-like cognition versus advanced pattern recognition remains an open question. In this study, we investigate how LLMs process the temporal meaning of linguistic aspect in narratives that were previously used in human studies. Using an Expert-in-the-Loop probing pipeline, we conduct a series of targeted experiments to assess whether LLMs construct semantic representations and pragmatic inferences in a human-like manner. Our findings show that LLMs over-rely on prototypicality, produce inconsistent aspectual judgments, and struggle with causal reasoning derived from aspect, raising concerns about their ability to fully comprehend narratives. These results suggest that LLMs process aspect fundamentally differently from humans and lack robust narrative understanding. Beyond these empirical findings, we develop a standardized experimental framework for the reliable assessment of LLMs'cognitive and linguistic capabilities.",289362821,0,43,,
10.18653/v1/2025.acl-long.772,ProxAnn: Use-Oriented Evaluations of Topic Models and Document Clustering,"Alexander Miserlis Hoyle, Lorena Calvo-Bartolomé, J. Boyd-Graber, Philip Resnik",Annual Meeting of the Association for Computational Linguistics,2025,"Topic model and document-clustering evaluations either use automated metrics that align poorly with human preferences or require expert labels that are intractable to scale. We design a scalable human evaluation protocol and a corresponding automated approximation that reflect practitioners'real-world usage of models. Annotators -- or an LLM-based proxy -- review text items assigned to a topic or cluster, infer a category for the group, then apply that category to other documents. Using this protocol, we collect extensive crowdworker annotations of outputs from a diverse set of topic models on two datasets. We then use these annotations to validate automated proxies, finding that the best LLM proxies are statistically indistinguishable from a human annotator and can therefore serve as a reasonable substitute in automated evaluations. Package, web interface, and data are at https://github.com/ahoho/proxann",289367943,0,53,,
10.18653/v1/2025.acl-long.1162,Ref-Long: Benchmarking the Long-context Referencing Capability of Long-context Language Models,"Junjie Wu, Gefei Gu, Yanan Zheng, Dit-Yan Yeung, Arman Cohan",Annual Meeting of the Association for Computational Linguistics,2025,"Long-context language models (LCLMs) have exhibited impressive capabilities in long-context understanding tasks. Among these, long-context referencing -- a crucial task that requires LCLMs to attribute items of interest to specific parts of long-context data -- remains underexplored. To bridge this gap, this paper proposes Referencing Evaluation for Long-context Language Models (Ref-Long), a novel benchmark designed to assess the long-context referencing capability of LCLMs. Specifically, Ref-Long requires LCLMs to identify the indexes of documents that reference a specific key, emphasizing contextual relationships between the key and the documents over simple retrieval. Based on the task design, we construct three subsets ranging from synthetic to realistic scenarios to form the Ref-Long benchmark. Experimental results of 13 LCLMs reveal significant shortcomings in long-context referencing, even among advanced models like GPT-4o. To further investigate these challenges, we conduct comprehensive analyses, including human evaluations, task format adjustments, fine-tuning experiments, and error analyses, leading to several key insights. Our data and code can be found in https://github. com/wujunjie1998/Ref-Long.",289367955,3,28,,
10.18653/v1/2025.acl-long.1464,"R2D2: Remembering, Replaying and Dynamic Decision Making with a Reflective Agentic Memory","Tenghao Huang, Kinjal Basu, Ibrahim Abdelaziz, P. Kapanipathi, Jonathan May, Muhao Chen",Annual Meeting of the Association for Computational Linguistics,2025,"The proliferation of web agents necessitates advanced navigation and interaction strategies within complex web environments. Current models often struggle with efficient navigation and action execution due to limited visibility and understanding of web structures. Our proposed R2D2 framework addresses these challenges by integrating two paradigms: Remember and Reflect. The Remember paradigm uses a replay buffer that aids agents in reconstructing the web environment dynamically, thus enabling the formulation of a detailed""map""of previously visited pages. This helps in reducing navigational errors and optimizing the decision-making process during web interactions. Conversely, the Reflect paradigm allows agents to learn from past mistakes by providing a mechanism for error analysis and strategy refinement, enhancing overall task performance. We evaluate R2D2 using the WebArena benchmark, demonstrating substantial improvements over existing methods, including a 50% reduction in navigation errors and a threefold increase in task completion rates. Our findings suggest that a combination of memory-enhanced navigation and reflective learning promisingly advances the capabilities of web agents, potentially benefiting various applications such as automated customer service and personal digital assistants.",289370922,2,37,,
10.18653/v1/2025.acl-long.1009,Can LLMs Identify Critical Limitations within Scientific Research? A Systematic Evaluation on AI Research Papers,"Zhijian Xu, Yilun Zhao, Manasi S. Patwardhan, L. Vig, Arman Cohan",Annual Meeting of the Association for Computational Linguistics,2025,"Peer review is fundamental to scientific research, but the growing volume of publications has intensified the challenges of this expertise-intensive process. While LLMs show promise in various scientific tasks, their potential to assist with peer review, particularly in identifying paper limitations, remains understudied. We first present a comprehensive taxonomy of limitation types in scientific research, with a focus on AI. Guided by this taxonomy, for studying limitations, we present LimitGen, the first comprehensive benchmark for evaluating LLMs'capability to support early-stage feedback and complement human peer review. Our benchmark consists of two subsets: LimitGen-Syn, a synthetic dataset carefully created through controlled perturbations of high-quality papers, and LimitGen-Human, a collection of real human-written limitations. To improve the ability of LLM systems to identify limitations, we augment them with literature retrieval, which is essential for grounding identifying limitations in prior scientific findings. Our approach enhances the capabilities of LLM systems to generate limitations in research papers, enabling them to provide more concrete and constructive feedback.",289371017,4,0,,
10.18653/v1/2025.acl-long.495,InvestAlign: Overcoming Data Scarcity in Aligning Large Language Models with Investor Decision-Making Processes Under Herd Behavior,"Huisheng Wang, Zhuoshi Pan, Hangjing Zhang, Mingxiao Liu, Hanqing Gao, † H.VickyZhao, Samuel A Assefa, Danial Dervovic, Mahmoud Mahfouz, Robert E Tillman, Prashant Reddy, Manuela Veloso. 2020, Christopher Avery, Peter Zemsky. 1998, Multidimensional, Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Samuel R Bowman, Jeeyoon Hyun, Ethan Perez, Edwin Chen, Craig Pettit, Scott Heiner, Kamil˙e Lukoši¯ut˙e, Hong-You Chen, Cheng-Hao Tu, Ziwei Li, Han-Wei Shen, Wei-Lun Chao, Team GLM, Aohan Zeng, Bin Xu, Bowen Wang, Chenhui Zhang, Da Yin, Diego Rojas, Guanyu Feng, Hanyu Lai, Hao Yu, Hongning Wang, Ji-adai Sun, Jiajie Zhang, Jiale Cheng, Jiayi Gui, Jie Tang, Jing Zhang, Juanzi Li, Lei Zhao, Lindong Wu, Lucen Zhong, Mingdao Liu, Minlie Huang, Peng Zhang, Qinkai Zheng, Rui Lu, Shuaiqi Duan, Shu-dan Zhang, Shulin Cao, Weng Shuxun Yang, Lam Tam, Wenyi Zhao, Xiao Liu, Xiao Xia, Xiaohan Zhang, Xiaotao Gu, Xin Lv, Xinghan Liu, Xinyi Liu, Xinyue Yang, Xixuan Song, Xunkai Zhang, Yifan An, Yifan Xu, Yilin Niu, Yuantao Yang, Yueyan Li, Yushi Bai, Yuxiao Dong, Zehan Qi, Zhaoyu Wang, Zhen Yang, Zhengxiao Du, Zhenyu Hou, Zihan Wang, Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Edward J Hu, Yelong Shen, Zeyuan Phillip Wallis, An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Chengpeng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Hao-ran Wei, Huan Lin, Jialong Tang, Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin Ma, Jin Xu, Jingren Zhou, Jinze Bai, Jinzheng He, Junyang Lin, Kai Dang, Keming Lu, Keqin Chen, Kexin Yang, Mei Li, Mingfeng Xue, Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji Lin, Shijie Wang, Shuai Bai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge, Xiaodong Deng, Shujuan Zhao, Lingfeng Qiao, Kangyang Luo, Qian-Wen Zhang, Junru Lu, Di Yin. 2024, SNFinLLM, Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang",Annual Meeting of the Association for Computational Linguistics,2025,"Aligning Large Language Models (LLMs) with investor decision-making processes under herd behavior is a critical challenge in behavioral finance, which grapples with a fundamental limitation: the scarcity of real-user data needed for Supervised Fine-Tuning (SFT). While SFT can bridge the gap between LLM outputs and human behavioral patterns, its reliance on massive authentic data imposes substantial collection costs and privacy risks. We propose InvestAlign, a novel framework that constructs high-quality SFT datasets by leveraging theoretical solutions to similar and simple optimal investment problems rather than complex scenarios. Our theoretical analysis demonstrates that training LLMs with InvestAlign-generated data achieves faster parameter convergence than using real-user data, suggesting superior learning efficiency. Furthermore, we develop InvestAgent, an LLM agent fine-tuned with InvestAlign, which demonstrates significantly closer alignment to real-user data than pre-SFT models in both simple and complex investment problems. This highlights our proposed InvestAlign as a promising approach with the potential to address complex optimal investment problems and align LLMs with investor decision-making processes under herd behavior. Our code is publicly available at https://github.com/thu-social-network-research-group/InvestAlign.",289371086,1,50,,
10.18653/v1/2025.acl-long.111,"LLäMmlein: Transparent, Compact and Competitive German-Only Language Models from Scratch","Jan Pfister, Julia Wunderle, Andreas Hotho, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, Anirudh Goyal, A. Hartshorn, Aobo Yang, Archi Mitra, A. Sravankumar, A. Korenev, Arthur Hinsvark, Arun Rao, Aston Zhang, Aurelien Rodriguez, Austen Gregerson, Ava Spataru, Baptiste Rozière, Bethany Biron, Binh Tang, Bobbie Chern, C. Caucheteux, Chaya Nayak, Chloe Bi, Chris Marra, Chris McConnell, Christian Keller, Christophe Touret, Chunyang Wu, Corinne Wong, Cris-tian Cantón Ferrer, Cyrus Nikolaidis, Damien Al-lonsius, Daniel Song, Danielle Pintz, Danny Livshits, David Esiobu, Dhruv Choudhary, Dhruv Mahajan, Diego Garcia-Olano, Diego Perino, Dieuwke Hupkes, Egor Lakomkin, Ehab A. AlBadawy, Elina Lobanova, Emily Dinan, Eric Michael Smith, Filip Radenovic, Frank Zhang, Gabriele Synnaeve, Gabrielle Lee, Georgia Lewis Anderson, Graeme Nail, Gregoire Mi-alon, Guan Pang, Guillem Cucurell, Hailey Nguyen, Han-nah Korevaar, Hu Xu, Hugo Touvron, Imanol Iliyan Zarov, Arrieta Ibarra, Is-abel Kloumann, Ishan Misra, Ivan Evtimov, Jade Copet, Jaewon Lee, Jan Geffert, Jana Vranes, Jason Park, Jay Mahadeokar, Jeet Shah, J. V. D. Linde, Jennifer Billock, Jenny Hong, Jenya Lee, J. Fu, Jianfeng Chi, Jianyu Huang, Jiawen Liu, Jie Wang, Jiecao Yu, Joanna Bitton, Joe Spisak, Jongsoo Park, Joseph Rocca, J. Johnstun, Joshua Saxe, Junteng Jia, Kalyan Vasuden Alwala, K. Upasani, Kate Plawiak, Keqian Li, K. Heafield, Kevin R. Stone, Khalid El-Arini, Krithika Iyer, Kshitiz Malik, Kuen-ley Chiu, Kunal Bhalla, Lauren Rantala-Yeary, Laurens van der Maaten, Lawrence Chen, Liang Tan, Liz Jenkins, Louis Martin, Lovish Madaan, Lubo Malo, Lukas Blecher, Lukas Landzaat, Luke de Oliveira, Madeline Muzzi, Mahesh Pasupuleti, Mannat Singh, Manohar Paluri, Marcin Kardas, Mathew Oldham, Mathieu Rita, Maya Pavlova, M. Kambadur, Mike Lewis, Mitesh Min Si, Kumar Singh, Mona Hassan, Naman Goyal, Narjes Torabi, Nikolay Bash-lykov, Nikolay Bogoychev, Niladri S. Chatterji, Olivier Duchenne, Onur Çelebi, Patrick Alrassy, Pengchuan Zhang, Pengwei Li, Petar Vasić, Peter Weng, Prajjwal Bhargava, P. Dubal, Praveen Krishnan Punit, S. Koura, Puxin Xu, Qing He, Qingxiao Dong, Ragavan Srinivasan, Raj Ganapathy, Ramon Calderer, Ricardo Silveira Cabral, Robert Stojnic, R. Raileanu, Rohit Girdhar, Rohit Patel, Ro-main Sauvestre, Ron-nie Polidoro, Roshan Sumbaly, Ross Taylor, Ruan Silva, Rui Hou, Rui Wang, S. Hosseini, Sa-hana Chennabasappa, Sanjay Singh, Seohyun Sean Bell, Sonia Kim, Sergey Edunov, Shaoliang Nie, Sharan Narang, S. Raparthy, Sheng Shen, Shengye Wan, Shruti Bhosale, Shun Zhang, Simon Vandenhende, Soumya Batra, Spencer Whitman, Sten Sootla, S. Collot, Suchin Gu-rurangan, S. Borodinsky, Tamar Herman, Tara Fowler, Tarek Sheasha, Thomas Georgiou, Thomas Scialom, Tobias Speckbacher, Todor Mihaylov, Tong Xiao, Ujjwal Karn, Vedanuj Goswami, Vibhor Gupta, Vignesh Ramanathan, Viktor Kerkez, Vincent Gonguet, Vir-ginie Do, Vish Vogeti, Vladan Petro-vic, Weiwei Chu, Wenhan Xiong, Wenyin Fu, Whit-ney Meers, Xavier Martinet, Xiaodong Wang, Ellen Tan, Xinfeng Xie, Xuchao Jia, Xuewei Wang, Yaelle Goldschlag, Yashesh Gaur, Yasmine Babaei, Yiwen Wen, Yiwen Song, Yuchen Zhang, Yue Li, Yuning Mao, Zacharie Delpierre Coudert, Zhengxu Yan, Zhengxing Chen, Zoe Papakipos, Aaditya K. Singh, Aaron Grattafiori, Abha Jain, Adam Kelsey, Adam Shajnfeld, Adi Gangidi, Adolfo Victoria, Ahuva Goldstand, A. Menon, Ajay Sharma, Alex Boesen-berg, Alex Vaughan, Alexei Baevski, Allie Feinstein, Amanda Kallet, Amit Sangani, Anam Yunus, An-drei Lupu, Andres Alvarado, A. Caples, Andrew Gu, Andrew Ho, Andrew Poulton, Andrew Ryan, Ankit Ramchandani, Annie Franco, Apara-jita Saraf, Arkabandhu Chowdhury, Ashley Gabriel, Ashwin Bharambe, Assaf Eisenman, Azadeh Yaz-dan, Beau James, Ben Maurer, B. Leonhardi, Bernie Huang, Beth Loyd, Beto de Paola, Bhargavi Paranjape, Bing Liu, Bo Wu, B. Ni, Braden Han-cock, Bram Wasti, Brandon Spence, Brani Stojkovic, Brian Gamido, Britt Montalvo, Carl Parker, Carly Burton, Catalina Mejia, Changhan Wang, Changkyu Kim, Chao Zhou, Chester Hu, Ching-Hsiang Chu, Chris Cai, Chris Tindal, Christoph Feichtenhofer, Damon Civin, Dana Beaty, Daniel Kreymer, Daniel Li, Gil Halpern, G. Thattai, Grant Herman, G. Sizov, Guangyi, Guna Zhang, Lakshminarayanan Hamid, Han Shojanazeri, Han Zou, Hanwen Wang, Haroun Zha, Harrison Habeeb, Helen Rudolph, Henry Suk, Hunter Aspegren, Ibrahim Goldman, Igor Damlaj, Igor Molybog, Irina-Elena Tufanov, Itai Veliche, Jake Gat, James Weissman, Geboski James, Japhet Kohli, Jean-Baptiste Asher, Gaya Jeff, Jeff Marcus, Jennifer Tang, Jenny Chan, Zhen Jeremy, J. Reizenstein, Jessica Teboul, Zhong Jian, Jingyi Jin, Joe Yang, Jon Cummings, Carvill Jon, Jon Shepard, J. McPhie, Torres Josh, Junjie Ginsburg, Kai Wang, Kam Wu, Hou Karan, Karthik Saxena, Kartikay Prasad, Katayoun Khan-delwal, Kathy Zand, Kaushik Matosich, Kelly Veeraraghavan, Keqian Michelena, Kun Li, Kunal Huang, Kushal Chawla, Kyle Lakhotia, Lailin Huang, Lakshya Chen, Lavender A Leandro Garg, Lee Silva, Lei Bell, Liangpeng Zhang, Licheng Guo, Liron Yu, L. Moshkovich, Madian Wehrstedt, Manav Khabsa, Manish Avalani, Maria Bhatt, Martynas Tsim-poukelli, Matan Mankus, Matthew Hasson, Matthias Lennie, M. Reso, Maxim Groshev, Maya Naumov, Meghan Lathi, Michael L Keneally, Michal Seltzer, M. Valko, Mihir Restrepo, Mik Patel, Mik Vyatskov, Mike Samvelyan, Mike Clark, Mike Macey, Miquel Wang, Jubert Mo, Mo Metanat, Mun-ish Rastegari, Nandhini Bansal, Natascha Santhanam, Parks Natasha, Navyata White, Nayan Bawa, Nick Singhal, Nicolas Egebo, Usunier, Nikolay Pavlovich, Laptev Ning, Ning Dong, Norman Zhang, Oleg Cheng, Olivia Chernoguz, Omkar Hart, Ozlem Salpekar, Parkin Kalinli, Parth Kent, Paul Parekh, Paul Saab, Pedro Balaji, Philip Rittner, Pierre Bontrager, Piotr Roux, Polina Dollár, P. Zvyagina, Pritish Yuvraj, Qian Liang, Rachad Alao, Rachel Rodriguez, Rafi Ayub, Raghotham Murthy, Raghu Nayani, Rahul Mitra, Raymond Li, Rebekkah Hogan, Robin Battey, Rocky Wang, Rohan Mah-eswari, Russ Howes, Ruty Rinott, Sai Jayesh, Bondu Samyak, Sara Datta, Sara Chugh, Sargun Hunt, Sasha Dhillon, Satadru Sidorov, Saurabh Pan, Verma Seiji, Sharadh Yamamoto, Shaun Ramaswamy, Shaun Lind-say, Sheng Lindsay, Sheng Feng, Lin Shengxin Cindy, Shiva Zha, Shuqiang Shankar, Shuqiang Zhang, Sinong Zhang, Sneha Wang, Soji Agar-wal, Soumith Sajuyigbe, Stephanie Chintala, Stephen Max, Steve Chen, Steve Kehoe, S. Sudarshan, S. Govindaprasad, Sungmin Gupta, Sunny Cho, Suraj Virk, Sy Subramanian, Choudhury Sydney, Tal Goldman, T. Remez, Tamara Glaser, Thilo Best, Thomas Kohler, Tianhe Robinson, Tianjun Li, Tim Zhang, Tim Matthews, Tzook Chou, Varun Shaked, Victoria Vontimitta, Victoria Ajayi, Vijai Montanez, Vinay Satish Mohan, Vishal Kumar, Vítor Mangla, Vlad Albiero, Vlad Ionescu, Poenaru Vlad Tiberiu, Vlad T. Mihailescu, Wei Ivanov, Li, Yilin Zhang, Ying Zhang, Yossi Adi, Youngjin Nam, Wang Yu, Yuchen Hao, Yundi Qian, Yuzi He, Zach Rait, Zachary DeVito, Zef Rosnbrick, Zhaoduo Wen",Annual Meeting of the Association for Computational Linguistics,2024,"We create two German-only decoder models, LL\""aMmlein 120M and 1B, transparently from scratch and publish them, along with the training data, for the German NLP research community to use. The model training involved several key steps, including extensive data preprocessing, the creation of a custom German tokenizer, the training itself, as well as the evaluation of the final models on various benchmarks. Throughout the training process, multiple checkpoints were saved and analyzed using the SuperGLEBer benchmark to monitor the models' learning dynamics. Compared to state-of-the-art models on the SuperGLEBer benchmark, both LL\""aMmlein models performed competitively, consistently matching or surpassing models with similar parameter sizes. The results show that the models' quality scales with size as expected, but performance improvements on some tasks plateaued early, offering valuable insights into resource allocation for future model development.",289372422,1,27,,
10.18653/v1/2025.acl-long.611,AbGen: Evaluating Large Language Models in Ablation Study Design and Evaluation for Scientific Research,"Yilun Zhao, Weiyuan Chen, Zhijian Xu, Manasi S. Patwardhan, Chengye Wang, Yixin Liu, L. Vig, Arman Cohan",Annual Meeting of the Association for Computational Linguistics,2025,"We introduce AbGen, the first benchmark designed to evaluate the capabilities of LLMs in designing ablation studies for scientific research. AbGen consists of 1,500 expert-annotated examples derived from 807 NLP papers. In this benchmark, LLMs are tasked with generating detailed ablation study designs for a specified module or process based on the given research context. Our evaluation of leading LLMs, such as DeepSeek-R1-0528 and o4-mini, highlights a significant performance gap between these models and human experts in terms of the importance, faithfulness, and soundness of the ablation study designs. Moreover, we demonstrate that current automated evaluation methods are not reliable for our task, as they show a significant discrepancy when compared to human assessment. To better investigate this, we develop AbGen-Eval, a meta-evaluation benchmark designed to assess the reliability of commonly used automated evaluation systems in measuring LLM performance on our task. We investigate various LLM-as-Judge systems on AbGen-Eval, providing insights for future research on developing more effective and reliable LLM-based evaluation systems for complex scientific tasks.",289377188,0,29,,
10.18653/v1/2025.acl-long.821,Disentangling the Roles of Representation and Selection in Data Pruning,"Yupei Du, Yingjin Song, Hugh Mee Wong, Daniil Ignatev, Albert Gatt, Dong Nguyen",Annual Meeting of the Association for Computational Linguistics,2025,"Data pruning, selecting small but impactful subsets, offers a promising way to efficiently scale NLP model training. However, existing methods often involve many different design choices, which have not been systematically studied. This limits future developments. In this work, we decompose data pruning into two key components: the data representation and the selection algorithm, and we systematically analyze their influence on the selection of instances. Our theoretical and empirical results highlight the crucial role of representations: better representations, e.g., training gradients, generally lead to a better selection of instances, regardless of the chosen selection algorithm. Furthermore, different selection algorithms excel in different settings, and none consistently outperforms the others. Moreover, the selection algorithms do not always align with their intended objectives: for example, algorithms designed for the same objective can select drastically different instances, highlighting the need for careful evaluation.",289378489,0,56,,
10.18653/v1/2025.acl-long.1391,Sticking to the Mean: Detecting Sticky Tokens in Text Embedding Models,"Kexin Chen, Dongxia Wang, Yi Liu, Haonan Zhang, Wenhai Wang",Annual Meeting of the Association for Computational Linguistics,2025,"Despite the widespread use of Transformer-based text embedding models in NLP tasks, surprising'sticky tokens'can undermine the reliability of embeddings. These tokens, when repeatedly inserted into sentences, pull sentence similarity toward a certain value, disrupting the normal distribution of embedding distances and degrading downstream performance. In this paper, we systematically investigate such anomalous tokens, formally defining them and introducing an efficient detection method, Sticky Token Detector (STD), based on sentence and token filtering. Applying STD to 40 checkpoints across 14 model families, we discover a total of 868 sticky tokens. Our analysis reveals that these tokens often originate from special or unused entries in the vocabulary, as well as fragmented subwords from multilingual corpora. Notably, their presence does not strictly correlate with model size or vocabulary size. We further evaluate how sticky tokens affect downstream tasks like clustering and retrieval, observing significant performance drops of up to 50%. Through attention-layer analysis, we show that sticky tokens disproportionately dominate the model's internal representations, raising concerns about tokenization robustness. Our findings show the need for better tokenization strategies and model design to mitigate the impact of sticky tokens in future text embedding applications.",289378607,1,0,,
10.18653/v1/2025.acl-long.779,Can External Validation Tools Improve Annotation Quality for LLM-as-a-Judge?,"Arduin Findeis, Floris Weers, Guoli Yin, Ke Ye, Ruoming Pang, Tom Gunter",Annual Meeting of the Association for Computational Linguistics,2025,"Pairwise preferences over model responses are widely collected to evaluate and provide feedback to large language models (LLMs). Given two alternative model responses to the same input, a human or AI annotator selects the""better""response. This approach can provide feedback for domains where other hard-coded metrics are difficult to obtain (e.g., chat response quality), thereby helping model evaluation or training. However, for some domains high-quality pairwise comparisons can be tricky to obtain - from AI and humans. For example, for responses with many factual statements, annotators may disproportionately weigh writing quality rather than underlying facts. In this work, we explore augmenting standard AI annotator systems with additional tools to improve performance on three challenging response domains: long-form factual, math and code tasks. We propose a tool-using agentic system to provide higher quality feedback on these domains. Our system uses web-search and code execution to ground itself based on external validation, independent of the LLM's internal knowledge and biases. We provide extensive experimental results evaluating our method across the three targeted response domains as well as general annotation tasks, using RewardBench (incl. AlpacaEval and LLMBar), RewardMath, as well as three new datasets for domains with saturated pre-existing datasets. Our results indicate that external tools can indeed improve performance in many, but not all, cases. More generally, our experiments highlight the sensitivity of performance to simple parameters (e.g., prompt) and the need for improved (non-saturated) annotator benchmarks. We share our code at https://github.com/apple/ml-agent-evaluator.",289383052,2,27,,
10.18653/v1/2025.acl-long.735,CART: A Generative Cross-Modal Retrieval Framework With Coarse-To-Fine Semantic Modeling,"Minghui Fang, Shengpeng Ji, Jialong Zuo, Hai Huang, Yan Xia, Jieming Zhu, Xize Cheng, Xiaoda Yang, Wenrui Liu, Gang Wang, Zhenhua Dong, Zhou Zhao",Annual Meeting of the Association for Computational Linguistics,2024,"Cross-modal retrieval aims to search for instances, which are semantically related to the query through the interaction of different modal data. Traditional solutions utilize a single-tower or dual-tower framework to explicitly compute the score between queries and candidates, which is challenged by training cost and inference latency with large-scale data. Inspired by the remarkable performance and efficiency of generative models, we propose a generative cross-modal retrieval framework (CART) based on coarse-to-fine semantic modeling, which assigns identifiers to each candidate and treats the generating identifier as the retrieval target. Specifically, we explore an effective coarse-to-fine scheme, combining K-Means and RQ-VAE to discretize multimodal data into token sequences that support autoregressive generation. Further, considering the lack of explicit interaction between queries and candidates, we propose a feature fusion strategy to align their semantics. Extensive experiments demonstrate the effectiveness of the strategies in the CART, achieving excellent results in both retrieval performance and efficiency.",289383566,0,51,,
10.18653/v1/2025.acl-long.212,Dynamic and Generalizable Process Reward Modeling,"Zhangyue Yin, Qiushi Sun, Zhiyuan Zeng, Qinyuan Cheng, Xipeng Qiu, Xuanjing Huang",Annual Meeting of the Association for Computational Linguistics,2025,"Process Reward Models (PRMs) are crucial for guiding Large Language Models (LLMs) in complex scenarios by providing dense reward signals. However, existing PRMs primarily rely on heuristic approaches, which struggle with cross-domain generalization. While LLM-as-judge has been proposed to provide generalized rewards, current research has focused mainly on feedback results, overlooking the meaningful guidance embedded within the text. Additionally, static and coarse-grained evaluation criteria struggle to adapt to complex process supervision. To tackle these challenges, we propose Dynamic and Generalizable Process Reward Modeling (DG-PRM), which features a reward tree to capture and store fine-grained, multi-dimensional reward criteria. DG-PRM dynamically selects reward signals for step-wise reward scoring. To handle multifaceted reward signals, we pioneeringly adopt Pareto dominance estimation to identify discriminative positive and negative pairs. Experimental results show that DG-PRM achieves stunning performance on prevailing benchmarks, significantly boosting model performance across tasks with dense rewards. Further analysis reveals that DG-PRM adapts well to out-of-distribution scenarios, demonstrating exceptional generalizability.",289387589,5,0,,
10.18653/v1/2025.acl-long.932,Beyond N-Grams: Rethinking Evaluation Metrics and Strategies for Multilingual Abstractive Summarization,"Itai Mondshine, Tzuf Paz-Argaman, Reut Tsarfaty",Annual Meeting of the Association for Computational Linguistics,2025,"Automatic n-gram based metrics such as ROUGE are widely used for evaluating generative tasks such as summarization. While these metrics are considered indicative (even if imperfect) of human evaluation for English, their suitability for other languages remains unclear. To address this, we systematically assess evaluation metrics for generation both n-gram-based and neural based to evaluate their effectiveness across languages and tasks. Specifically, we design a large-scale evaluation suite across eight languages from four typological families: agglutinative, isolating, low-fusional, and high-fusional, spanning both low- and high-resource settings, to analyze their correlation with human judgments. Our findings highlight the sensitivity of evaluation metrics to the language type. For example, in fusional languages, n-gram-based metrics show lower correlation with human assessments compared to isolating and agglutinative languages. We also demonstrate that proper tokenization can significantly mitigate this issue for morphologically rich fusional languages, sometimes even reversing negative trends. Additionally, we show that neural-based metrics specifically trained for evaluation, such as COMET, consistently outperform other neural metrics and better correlate with human judgments in low-resource languages. Overall, our analysis highlights the limitations of n-gram metrics for fusional languages and advocates for greater investment in neural-based metrics trained for evaluation tasks.",289387597,1,46,,
10.18653/v1/2025.acl-long.46,MIND: A Multi-agent Framework for Zero-shot Harmful Meme Detection,"Ziyan Liu, Chunxiao Fan, Haoran Lou, Yuexin Wu, Kaiwei Deng",Annual Meeting of the Association for Computational Linguistics,2025,"The rapid expansion of memes on social media has highlighted the urgent need for effective approaches to detect harmful content. However, traditional data-driven approaches struggle to detect new memes due to their evolving nature and the lack of up-to-date annotated data. To address this issue, we propose MIND, a multi-agent framework for zero-shot harmful meme detection that does not rely on annotated data. MIND implements three key strategies: 1) We retrieve similar memes from an unannotated reference set to provide contextual information. 2) We propose a bi-directional insight derivation mechanism to extract a comprehensive understanding of similar memes. 3) We then employ a multi-agent debate mechanism to ensure robust decision-making through reasoned arbitration. Extensive experiments on three meme datasets demonstrate that our proposed framework not only outperforms existing zero-shot approaches but also shows strong generalization across different model architectures and parameter scales, providing a scalable solution for harmful meme detection. The code is available at https://github.com/destroy-lonely/MIND.",289387656,1,51,,
10.18653/v1/2025.acl-long.606,Single-to-mix Modality Alignment with Multimodal Large Language Model for Document Image Machine Translation,"Yupu Liang, Yaping Zhang, Zhiyang Zhang, Yang Zhao, Lu Xiang, Chengqing Zong, Yu Zhou",Annual Meeting of the Association for Computational Linguistics,2025,"Document Image Machine Translation (DIMT) aims to translate text within document images, facing generalization challenges due to limited training data and the complex interplay between visual and textual information. To address these challenges, we introduce M4Doc, a novel single-to-mix modality alignment framework leveraging Multimodal Large Language Models (MLLMs). M4Doc aligns an image-only encoder with the multimodal representations of an MLLM, pre-trained on large-scale document image datasets. This alignment enables a lightweight DIMT model to learn crucial visual-textual correlations during training. During inference, M4Doc bypasses the MLLM, maintaining computational efficiency while benefiting from its multimodal knowledge. Comprehensive experiments demonstrate substantial improvements in translation quality, especially in cross-domain generalization and challenging document image scenarios.",289390544,2,29,,
10.18653/v1/2025.acl-long.1129,Enhancing Chain-of-Thought Reasoning with Critical Representation Fine-tuning,"Chenxi Huang, Shaotian Yan, Liang Xie, Binbin Lin, Sinan Fan, Yue Xin, Deng Cai, Chen Shen, Jieping Ye",Annual Meeting of the Association for Computational Linguistics,2025,"Representation Fine-tuning (ReFT), a recently proposed Parameter-Efficient Fine-Tuning (PEFT) method, has attracted widespread attention for significantly improving parameter efficiency by editing representation space alone. In this work, we investigate applying ReFT to complex reasoning tasks. However, directly using the native ReFT method, which modifies fixed representations at the beginning and end of each layer, yields suboptimal performance, as these fixed-position representations have uncertain impact on the outputs. We observe that, in complex reasoning tasks, there often exist certain critical representations. These representations either integrate significant information from preceding layers or regulate subsequent layer representations. Through layer-by-layer propagation, they exert a substantial influence on the final output. Naturally, fine-tuning these critical representations has the potential to greatly enhance reasoning performance. Building upon these insights, we propose Critical Representation Fine-Tuning (CRFT), a novel method that identifies and optimizes these critical representations through information flow analysis. CRFT operates within a supervised learning framework, dynamically optimizing critical representations in a low-rank linear subspace while freezing the base model. The effectiveness and efficiency of our method are validated across eight benchmarks for arithmetic and commonsense reasoning, using LLaMA and Mistral model families. Furthermore, our method also adapts effectively to few-shot settings, boosting one-shot accuracy by 16.4%. Our work highlights the untapped potential of representation-level optimization for CoT reasoning, offering a lightweight yet powerful alternative to traditional PEFT methods.",289390545,0,0,,
10.18653/v1/2025.acl-long.1383,Agentic Reasoning: A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools,"Junde Wu, Jiayuan Zhu, Yuyuan Liu, Min Xu, Yueming Jin",Annual Meeting of the Association for Computational Linguistics,2025,"We introduce Agentic Reasoning, a framework that enhances large language model (LLM) reasoning by integrating external tool-using agents. Agentic Reasoning dynamically leverages web search, code execution, and structured memory to address complex problems requiring deep research. A key innovation in our framework is the Mind-Map agent, which constructs a structured knowledge graph to store reasoning context and track logical relationships, ensuring coherence in long reasoning chains with extensive tool usage. Additionally, we conduct a comprehensive exploration of the Web-Search agent, leading to a highly effective search mechanism that surpasses all prior approaches. When deployed on DeepSeek-R1, our method achieves a new state-of-the-art (SOTA) among public models and delivers performance comparable to OpenAI Deep Research, the leading proprietary model in this domain. Extensive ablation studies validate the optimal selection of agentic tools and confirm the effectiveness of our Mind-Map and Web-Search agents in enhancing LLM reasoning. The code is at: https://github.com/theworldofagents/Agentic-Reasoning",289391873,47,15,,
10.18653/v1/2025.acl-long.1406,From Neurons to Semantics: Evaluating Cross-Linguistic Alignment Capabilities of Large Language Models via Neurons Alignment,"Chongxuan Huang, Yongshi Ye, Biao Fu, Qifeng Su, Xiaodong Shi",Annual Meeting of the Association for Computational Linguistics,2025,"Large language models (LLMs) have demonstrated remarkable multilingual capabilities, however, how to evaluate cross-lingual alignment remains underexplored. Existing alignment benchmarks primarily focus on sentence embeddings, but prior research has shown that neural models tend to induce a non-smooth representation space, which impact of semantic alignment evaluation on low-resource languages. Inspired by neuroscientific findings that similar information activates overlapping neuronal regions, we propose a novel Neuron State-Based Cross-Lingual Alignment (NeuronXA) to assess the cross-lingual a lignment capabilities of LLMs, which offers a more semantically grounded approach to assess cross-lingual alignment. We evaluate NeuronXA on several prominent multilingual LLMs (LLaMA, Qwen, Mistral, GLM, and OLMo) across two transfer tasks and three multilingual benchmarks. The results demonstrate that with only 100 parallel sentence pairs, NeuronXA achieves a Pearson correlation of 0.9556 with downstream tasks performance and 0.8514 with transferability. These findings demonstrate NeuronXA's effectiveness in assessing both cross-lingual alignment and transferability, even with a small dataset. This highlights its potential to advance cross-lingual alignment research and to improve the semantic understanding of multilingual LLMs.",289394986,1,51,,
10.18653/v1/2025.acl-long.1030,KatFishNet: Detecting LLM-Generated Korean Text through Linguistic Feature Analysis,"Shinwoo Park, Shubin Kim, Do-Kyung Kim, Yo-Sub Han",Annual Meeting of the Association for Computational Linguistics,2025,"The rapid advancement of large language models (LLMs) increases the difficulty of distinguishing between human-written and LLM-generated text. Detecting LLM-generated text is crucial for upholding academic integrity, preventing plagiarism, protecting copyrights, and ensuring ethical research practices. Most prior studies on detecting LLM-generated text focus primarily on English text. However, languages with distinct morphological and syntactic characteristics require specialized detection approaches. Their unique structures and usage patterns can hinder the direct application of methods primarily designed for English. Among such languages, we focus on Korean, which has relatively flexible spacing rules, a rich morphological system, and less frequent comma usage compared to English. We introduce KatFish, the first benchmark dataset for detecting LLM-generated Korean text. The dataset consists of text written by humans and generated by four LLMs across three genres. By examining spacing patterns, part-of-speech diversity, and comma usage, we illuminate the linguistic differences between human-written and LLM-generated Korean text. Building on these observations, we propose KatFishNet, a detection method specifically designed for the Korean language. KatFishNet achieves an average of 19.78% higher AUROC compared to the best-performing existing detection method. Our code and data are available at https://github.com/Shinwoo-Park/detecting_llm_generated_korean_text_through_linguistic_analysis.",289396358,4,6,,
10.18653/v1/2025.acl-long.880,ICR Probe: Tracking Hidden State Dynamics for Reliable Hallucination Detection in LLMs,"Zhenliang Zhang, Xinyu Hu, Huixuan Zhang, Junzhe Zhang, Xiaojun Wan",Annual Meeting of the Association for Computational Linguistics,2025,"Large language models (LLMs) excel at various natural language processing tasks, but their tendency to generate hallucinations undermines their reliability. Existing hallucination detection methods leveraging hidden states predominantly focus on static and isolated representations, overlooking their dynamic evolution across layers, which limits efficacy. To address this limitation, we shift the focus to the hidden state update process and introduce a novel metric, the ICR Score (Information Contribution to Residual Stream), which quantifies the contribution of modules to the hidden states'update. We empirically validate that the ICR Score is effective and reliable in distinguishing hallucinations. Building on these insights, we propose a hallucination detection method, the ICR Probe, which captures the cross-layer evolution of hidden states. Experimental results show that the ICR Probe achieves superior performance with significantly fewer parameters. Furthermore, ablation studies and case analyses offer deeper insights into the underlying mechanism of this method, improving its interpretability.",289397967,2,14,,
10.18653/v1/2025.acl-long.616,Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization,"Yuhao Wang, Keyan Ding, Kehua Feng, Zeyuan Wang, Ming Qin, Xiaotong Li, Qiang Zhang, Huajun Chen",Annual Meeting of the Association for Computational Linguistics,2025,"Protein language models have emerged as powerful tools for sequence generation, offering substantial advantages in functional optimization and denovo design. However, these models also present significant risks of generating harmful protein sequences, such as those that enhance viral transmissibility or evade immune responses. These concerns underscore critical biosafety and ethical challenges. To address these issues, we propose a Knowledge-guided Preference Optimization (KPO) framework that integrates prior knowledge via a Protein Safety Knowledge Graph. This framework utilizes an efficient graph pruning strategy to identify preferred sequences and employs reinforcement learning to minimize the risk of generating harmful proteins. Experimental results demonstrate that KPO effectively reduces the likelihood of producing hazardous sequences while maintaining high functionality, offering a robust safety assurance framework for applying generative models in biotechnology.",289397971,2,35,,
10.18653/v1/2025.acl-long.1234,ASPERA: A Simulated Environment to Evaluate Planning for Complex Action Execution,"Alexandru Coca, Mark Gaynor, Zhenxing Zhang, Jianpeng Cheng, Bo-Hsiang Tseng, Peter Boothroyd, Héctor Martínez Alonso, Diarmuid Ó Séaghdha, Anders Johannsen",Annual Meeting of the Association for Computational Linguistics,2025,"This work evaluates the potential of large language models (LLMs) to power digital assistants capable of complex action execution. These assistants rely on pre-trained programming knowledge to execute multi-step goals by composing objects and functions defined in assistant libraries into action execution programs. To achieve this, we develop ASPERA, a framework comprising an assistant library simulation and a human-assisted LLM data generation engine. Our engine allows developers to guide LLM generation of high-quality tasks consisting of complex user queries, simulation state and corresponding validation programs, tackling data availability and evaluation robustness challenges. Alongside the framework we release Asper-Bench, an evaluation dataset of 250 challenging tasks generated using ASPERA, which we use to show that program generation grounded in custom assistant libraries is a significant challenge to LLMs compared to dependency-free code generation.",289397986,0,45,,
10.18653/v1/2025.acl-long.419,A Survey on Patent Analysis: From NLP to Multimodal AI,"Homaira Huda Shomee, Zhu Wang, Sathya Ravi, Sourav Medya",Annual Meeting of the Association for Computational Linguistics,2024,"Recent advances in Pretrained Language Models (PLMs) and Large Language Models (LLMs) have demonstrated transformative capabilities across diverse domains. The field of patent analysis and innovation is not an exception, where natural language processing (NLP) techniques presents opportunities to streamline and enhance important tasks -- such as patent classification and patent retrieval -- in the patent cycle. This not only accelerates the efficiency of patent researchers and applicants, but also opens new avenues for technological innovation and discovery. Our survey provides a comprehensive summary of recent NLP-based methods -- including multimodal ones -- in patent analysis. We also introduce a novel taxonomy for categorization based on tasks in the patent life cycle, as well as the specifics of the methods. This interdisciplinary survey aims to serve as a comprehensive resource for researchers and practitioners who work at the intersection of NLP, Multimodal AI, and patent analysis, as well as patent offices to build efficient patent systems.",289399273,4,71,,
10.18653/v1/2025.acl-long.213,AdamMeme: Adaptively Probe the Reasoning Capacity of Multimodal Large Language Models on Harmfulness,"Zixin Chen, Hongzhan Lin, Kaixin Li, Ziyang Luo, Zhen Ye, Guang Chen, Zhiyong Huang, Jing Ma",Annual Meeting of the Association for Computational Linguistics,2025,"The proliferation of multimodal memes in the social media era demands that multimodal Large Language Models (mLLMs) effectively understand meme harmfulness. Existing benchmarks for assessing mLLMs on harmful meme understanding rely on accuracy-based, model-agnostic evaluations using static datasets. These benchmarks are limited in their ability to provide up-to-date and thorough assessments, as online memes evolve dynamically. To address this, we propose AdamMeme, a flexible, agent-based evaluation framework that adaptively probes the reasoning capabilities of mLLMs in deciphering meme harmfulness. Through multi-agent collaboration, AdamMeme provides comprehensive evaluations by iteratively updating the meme data with challenging samples, thereby exposing specific limitations in how mLLMs interpret harmfulness. Extensive experiments show that our framework systematically reveals the varying performance of different target mLLMs, offering in-depth, fine-grained analyses of model-specific weaknesses. Our code is available at https://github.com/Lbotirx/AdamMeme.",289399464,5,30,,
10.18653/v1/2025.acl-long.1252,Finding A Voice: Exploring the Potential of African American Dialect and Voice Generation for Chatbots,"Sarah E. Finch, Ellie S. Paek, Ikseon Choi, Jinho D. Choi",Annual Meeting of the Association for Computational Linguistics,2025,"As chatbots become integral to daily life, personalizing systems is key for fostering trust, engagement, and inclusivity. This study examines how linguistic similarity affects chatbot performance, focusing on integrating African American English (AAE) into virtual agents to better serve the African American community. We develop text-based and spoken chatbots using large language models and text-to-speech technology, then evaluate them with AAE speakers against standard English chatbots. Our results show that while text-based AAE chatbots often underperform, spoken chatbots benefit from an African American voice and AAE elements, improving performance and preference. These findings underscore the complexities of linguistic personalization and the dynamics between text and speech modalities, highlighting technological limitations that affect chatbots'AA speech generation and pointing to promising future research directions.",289399468,0,45,,
10.18653/v1/2025.acl-long.837,Can LLMs Evaluate Complex Attribution in QA? Automatic Benchmarking using Knowledge Graphs,"Nan Hu, Jiaoyan Chen, Yike Wu, Guilin Qi, Sheng Bi, Tongtong Wu, Jeff Z. Pan",Annual Meeting of the Association for Computational Linguistics,2024,"Attributed Question Answering (AQA) has attracted wide attention, but there are still several limitations in evaluating the attributions, including lacking fine-grained attribution categories, relying on manual annotations, and failing to compare attributions with only subtle differences. To bridge these gaps, we introduce Complex Attributed Question Answering (CAQA), a large-scale benchmark containing comprehensive attribution categories, automatically generated using Knowledge Graphs (KGs), and complex attribution scenarios. We have conducted extensive experiments to verify the effectiveness of CAQA, including the benchmarking of 25 automatic evaluators, their comparison with human evaluators, the testing of LLM evaluators fine-tuned by CAQA and so on. These experiments also lead to a series of important findings that can benefit the future research of AQA. All the codes and data are publicly accessible at https://github.com/HuuuNan/CAQA-Benchmark.",289402213,12,50,,
10.18653/v1/2025.acl-long.450,Mitigating Shortcut Learning with InterpoLated Learning,"Michalis Korakakis, Andreas Vlachos, Adrian Weller",Annual Meeting of the Association for Computational Linguistics,2025,"Empirical risk minimization (ERM) incentivizes models to exploit shortcuts, i.e., spurious correlations between input attributes and labels that are prevalent in the majority of the training data but unrelated to the task at hand. This reliance hinders generalization on minority examples, where such correlations do not hold. Existing shortcut mitigation approaches are model-specific, difficult to tune, computationally expensive, and fail to improve learned representations. To address these issues, we propose InterpoLated Learning (InterpoLL) which interpolates the representations of majority examples to include features from intra-class minority examples with shortcut-mitigating patterns. This weakens shortcut influence, enabling models to acquire features predictive across both minority and majority examples. Experimental results on multiple natural language understanding tasks demonstrate that InterpoLL improves minority generalization over both ERM and state-of-the-art shortcut mitigation methods, without compromising accuracy on majority examples. Notably, these gains persist across encoder, encoder-decoder, and decoder-only architectures, demonstrating the method's broad applicability.",289402439,0,68,,
10.18653/v1/2025.acl-long.665,ChainEdit: Propagating Ripple Effects in LLM Knowledge Editing through Logical Rule-Guided Chains,"Zilu Dong, Xiangqing Shen, Zinong Yang, Rui Xia",Annual Meeting of the Association for Computational Linguistics,2025,"Current knowledge editing methods for large language models (LLMs) struggle to maintain logical consistency when propagating ripple effects to associated facts. We propose ChainEdit, a framework that synergizes knowledge graph-derived logical rules with LLM logical reasoning capabilities to enable systematic chain updates. By automatically extracting logical patterns from structured knowledge bases and aligning them with LLMs'internal logics, ChainEdit dynamically generates and edits logically connected knowledge clusters. Experiments demonstrate an improvement of more than 30% in logical generalization over baselines while preserving editing reliability and specificity. We further address evaluation biases in existing benchmarks through knowledge-aware protocols that disentangle external dependencies. This work establishes new state-of-the-art performance on ripple effect while ensuring internal logical consistency after knowledge editing.",289402440,2,10,,
10.18653/v1/2025.acl-long.1197,BOOKCOREF: Coreference Resolution at Book Scale,"Giuliano Martinelli, Tommaso Bonomo, Pere-Lluís Huguet Cabot, Roberto Navigli",Annual Meeting of the Association for Computational Linguistics,2025,"Coreference Resolution systems are typically evaluated on benchmarks containing small- to medium-scale documents. When it comes to evaluating long texts, however, existing benchmarks, such as LitBank, remain limited in length and do not adequately assess system capabilities at the book scale, i.e., when co-referring mentions span hundreds of thousands of tokens. To fill this gap, we first put forward a novel automatic pipeline that produces high-quality Coreference Resolution annotations on full narrative texts. Then, we adopt this pipeline to create the first book-scale coreference benchmark, BOOKCOREF, with an average document length of more than 200,000 tokens. We carry out a series of experiments showing the robustness of our automatic procedure and demonstrating the value of our resource, which enables current long-document coreference systems to gain up to +20 CoNLL-F1 points when evaluated on full books. Moreover, we report on the new challenges introduced by this unprecedented book-scale setting, highlighting that current models fail to deliver the same performance they achieve on smaller documents. We release our data and code to encourage research and development of new book-scale Coreference Resolution systems at https://github.com/sapienzanlp/bookcoref.",289403867,2,31,,
10.18653/v1/2025.acl-long.539,PKAG-DDI: Pairwise Knowledge-Augmented Language Model for Drug-Drug Interaction Event Text Generation,"Ziyan Wang, Zhankun Xiong, Feng Huang, Wen Zhang",Annual Meeting of the Association for Computational Linguistics,2025,"Drug-drug interactions (DDIs) arise when multiple drugs are administered concurrently. Accurately predicting the specific mechanisms underlying DDIs (named DDI events or DDIEs) is critical for the safe clinical use of drugs. DDIEs are typically represented as textual descriptions. However, most computational methods focus more on predicting the DDIE class label over generating human-readable natural language increasing clinicians'interpretation costs. Furthermore, current methods overlook the fact that each drug assumes distinct biological functions in a DDI, which, when used as input context, can enhance the understanding of the DDIE process and benefit DDIE generation by the language model (LM). In this work, we propose a novel pairwise knowledge-augmented generative method (termed PKAG-DDI) for DDIE text generation. It consists of a pairwise knowledge selector efficiently injecting structural information between drugs bidirectionally and simultaneously to select pairwise biological functions from the knowledge set, and a pairwise knowledge integration strategy that matches and integrates the selected biological functions into the LM. Experiments on two professional datasets show that PKAG-DDI outperforms existing methods in DDIE text generation, especially in challenging inductive scenarios, indicating its practicality and generalization.",289403955,0,32,,
10.18653/v1/2025.acl-long.182,Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions,"Pu Jian, Donglei Yu, Wen Yang, Shuo Ren, Jiajun Zhang",Annual Meeting of the Association for Computational Linguistics,2025,"In visual question answering (VQA) context, users often pose ambiguous questions to visual language models (VLMs) due to varying expression habits. Existing research addresses such ambiguities primarily by rephrasing questions. These approaches neglect the inherently interactive nature of user interactions with VLMs, where ambiguities can be clarified through user feedback. However, research on interactive clarification faces two major challenges: (1) Benchmarks are absent to assess VLMs'capacity for resolving ambiguities through interaction; (2) VLMs are trained to prefer answering rather than asking, preventing them from seeking clarification. To overcome these challenges, we introduce \textbf{ClearVQA} benchmark, which targets three common categories of ambiguity in VQA context, and encompasses various VQA scenarios.",289406873,4,43,,
10.18653/v1/2025.acl-long.556,Locate-and-Focus: Enhancing Terminology Translation in Speech Language Models,"Suhang Wu, Jialong Tang, Chengyi Yang, Pei Zhang, Baosong Yang, Junhui Li, Junfeng Yao, Min Zhang, Jinsong Su",Annual Meeting of the Association for Computational Linguistics,2025,"Direct speech translation (ST) has garnered increasing attention nowadays, yet the accurate translation of terminology within utterances remains a great challenge. In this regard, current studies mainly concentrate on leveraging various translation knowledge into ST models. However, these methods often struggle with interference from irrelevant noise and can not fully utilize the translation knowledge. To address these issues, in this paper, we propose a novel Locate-and-Focus method for terminology translation. It first effectively locates the speech clips containing terminologies within the utterance to construct translation knowledge, minimizing irrelevant information for the ST model. Subsequently, it associates the translation knowledge with the utterance and hypothesis from both audio and textual modalities, allowing the ST model to better focus on translation knowledge during translation. Experimental results across various datasets demonstrate that our method effectively locates terminologies within utterances and enhances the success rate of terminology translation, while maintaining robust general translation performance.",289409787,1,37,,
10.18653/v1/2025.acl-long.861,Shifting from Ranking to Set Selection for Retrieval Augmented Generation,"Dahyun Lee, Yongrae Jo, Haeju Park, Moontae Lee",Annual Meeting of the Association for Computational Linguistics,2025,"Retrieval in Retrieval-Augmented Generation(RAG) must ensure that retrieved passages are not only individually relevant but also collectively form a comprehensive set. Existing approaches primarily rerank top-k passages based on their individual relevance, often failing to meet the information needs of complex queries in multi-hop question answering. In this work, we propose a set-wise passage selection approach and introduce SETR, which explicitly identifies the information requirements of a query through Chain-of-Thought reasoning and selects an optimal set of passages that collectively satisfy those requirements. Experiments on multi-hop RAG benchmarks show that SETR outperforms both proprietary LLM-based rerankers and open-source baselines in terms of answer correctness and retrieval quality, providing an effective and efficient alternative to traditional rerankers in RAG systems. The code is available at https://github.com/LGAI-Research/SetR",289412752,3,36,,
10.18653/v1/2025.acl-long.1241,Response Wide Shut? Surprising Observations in Basic Vision Language Model Capabilities,"Shivam Chandhok, Wan-Cyuan Fan, Vered Shwartz, Vineeth N. Balasubramanian, Leonid Sigal",Annual Meeting of the Association for Computational Linguistics,2025,"Vision-language Models (VLMs) have emerged as general-purpose tools for addressing a variety of complex computer vision problems. Such models have been shown to be highly capable, but, at the same time, lacking some basic visual understanding skills. In this paper, we set out to understand the limitations of SoTA VLMs on fundamental visual tasks by constructing a series of tests that probe which components of design, specifically, may be lacking. Importantly, we go significantly beyond the current benchmarks, which simply measure the final performance of VLM response, by also comparing and contrasting it to the performance of probes trained directly on features obtained from the visual encoder, intermediate vision-language projection and LLM-decoder output. In doing so, we uncover shortcomings in VLMs and make a number of important observations about their capabilities, robustness and how they process visual information. We hope our insights will guide progress in further improving VLMs.",289414289,0,31,,
10.18653/v1/2025.acl-long.1127,DRAE: Dynamic Retrieval-Augmented Expert Networks for Lifelong Learning and Task Adaptation in Robotics,"Yayu Long, Kewei Chen, Long Jin, Mingsheng Shang",Annual Meeting of the Association for Computational Linguistics,2025,"We introduce Dynamic Retrieval-Augmented Expert Networks (DRAE), a groundbreaking architecture that addresses the challenges of lifelong learning, catastrophic forgetting, and task adaptation by combining the dynamic routing capabilities of Mixture-of-Experts (MoE); leveraging the knowledge-enhancement power of Retrieval-Augmented Generation (RAG); incorporating a novel hierarchical reinforcement learning (RL) framework; and coordinating through ReflexNet-SchemaPlanner-HyperOptima (RSHO).DRAE dynamically routes expert models via a sparse MoE gating mechanism, enabling efficient resource allocation while leveraging external knowledge through parametric retrieval (P-RAG) to augment the learning process. We propose a new RL framework with ReflexNet for low-level task execution, SchemaPlanner for symbolic reasoning, and HyperOptima for long-term context modeling, ensuring continuous adaptation and memory retention. Experimental results show that DRAE significantly outperforms baseline approaches in long-term task retention and knowledge reuse, achieving an average task success rate of 82.5% across a set of dynamic robotic manipulation tasks, compared to 74.2% for traditional MoE models. Furthermore, DRAE maintains an extremely low forgetting rate, outperforming state-of-the-art methods in catastrophic forgetting mitigation. These results demonstrate the effectiveness of our approach in enabling flexible, scalable, and efficient lifelong learning for robotics.",289417155,4,44,,
10.18653/v1/2025.acl-long.218,Game Development as Human-LLM Interaction,"Jiale Hong, Hongqiu Wu, Hai Zhao",(missing journal),2025,(missing abstract),289426423,1,0,,
10.18653/v1/2025.acl-long.228,Sparse Latents Steer Retrieval-Augmented Generation,"Chunlei Xin, Shuheng Zhou, Huijia Zhu, Weiqiang Wang, Xuanang Chen, Xinyan Guan, Yaojie Lu, Hongyu Lin, Xianpei Han, Le Sun",(missing journal),2025,(missing abstract),289426425,0,0,,
10.18653/v1/2025.acl-long.192,Establishing Trustworthy LLM Evaluation via Shortcut Neuron Analysis,"Ke Zhu, Shangqing Tu, Zilong Jin, Lei Hou, Juanzi Li, Jun Zhao",(missing journal),2025,(missing abstract),289426427,0,0,,
10.18653/v1/2025.acl-long.206,Leveraging Dual Process Theory in Language Agent Framework for Real-time Simultaneous Human-AI Collaboration,"Zhang Shao, Xihuai Wang, Wenhao Zhang, Chaoran Li, Jing Song, Tingyu Li, Lin Qiu, Xuezhi Cao, Xunliang Cai, Wen Bin Yao, Weinan Zhang, Xinbing Wang, Ying Wen",(missing journal),2025,(missing abstract),289426429,1,0,,
10.18653/v1/2025.acl-long.222,Sharper and Faster mean Better: Towards More Efficient Vision-Language Model for Hour-scale Long Video Understanding,"Daoze Zhang, Yuze Zhao, Jintao Huang, Yingda Chen",(missing journal),2025,(missing abstract),289426431,0,0,,
10.18653/v1/2025.acl-long.210,Segment-Level Diffusion: A Framework for Controllable Long-Form Generation with Diffusion Language Models,"Xue‐Yi Zhu, Georgi Karadzhov, Chenxi Whitehouse, Andreas Vlachos",(missing journal),2025,(missing abstract),289426433,0,0,,
10.18653/v1/2025.acl-long.215,Large Margin Representation Learning for Robust Cross-lingual Named Entity Recognition,"G. Zhu, Ruixuan Xiao, Haobo Wang, Zhen Zhu, Gengyu Lyu, Junbo Zhao",(missing journal),2025,(missing abstract),289426435,0,0,,
10.18653/v1/2025.acl-long.167,Retrieve to Explain: Evidence-driven Predictions for Explainable Drug Target Identification,"Ravi Patel, Angus Brayne, Rogier Hintzen, Daniel Jaroslawicz, Georgiana Neculae, Dane Corneil",Annual Meeting of the Association for Computational Linguistics,2025,"Language models hold incredible promise for enabling scientific discovery by synthesizing massive research corpora. Many complex scientific research questions have multiple plausible answers, each supported by evidence of varying strength. However, existing language models lack the capability to quantitatively and faithfully compare answer plausibility in terms of supporting evidence. To address this, we introduce Retrieve to Explain (R2E), a retrieval-based model that scores and ranks all possible answers to a research question based on evidence retrieved from a document corpus. The architecture represents each answer only in terms of its supporting evidence, with the answer itself masked. This allows us to extend feature attribution methods such as Shapley values, to transparently attribute answer scores to supporting evidence at inference time. The architecture also allows incorporation of new evidence without retraining, including non-textual data modalities templated into natural language. We developed R2E for the challenging scientific discovery task of drug target identification, a human-in-the-loop process where failures are extremely costly and explainability paramount. When predicting whether drug targets will subsequently be confirmed as efficacious in clinical trials, R2E not only matches non-explainable literature-based models but also surpasses a genetics-based target identification approach used throughout the pharmaceutical industry.",289426437,1,41,,
10.18653/v1/2025.acl-long.196,Interpret and Improve In-Context Learning via the Lens of Input-Label Mappings,"Chenghao Sun, Zhen Huang, Yonggang Zhang, Le Lü, Houqiang Li, Xinmei Tian, Xu Shen, Jieping Ye",(missing journal),2025,(missing abstract),289426439,0,0,,
10.18653/v1/2025.acl-long.216,An Efficient and Precise Training Data Construction Framework for Process-supervised Reward Model in Mathematical Reasoning,"Wei Sun, Qianlong Du, Fuwei Cui, Jiajun Zhang",(missing journal),2025,(missing abstract),289426441,0,0,,
10.18653/v1/2025.acl-long.104,Beyond Demographics: Fine-tuning Large Language Models to Predict Individuals’ Subjective Text Perceptions,"Matthias Orlikowski, Jiaxin Pei, Paul Röttger, Philipp Cimiano, David Jurgens, Dirk Hovy",(missing journal),2025,(missing abstract),289426443,0,0,,
10.18653/v1/2025.acl-long.94,UnSeenTimeQA: Time-Sensitive Question-Answering Beyond LLMs’ Memorization,"Md Nayem Uddin, Amir Saeidi, Divij Handa, Agastya Seth, Tran Cao Son, Eduardo Blanco, Steven R. Corman, Chitta Baral",(missing journal),2025,(missing abstract),289426445,0,0,,
10.18653/v1/2025.acl-long.151,Mixture of insighTful Experts (MoTE): The Synergy of Reasoning Chains and Expert Mixtures in Self-Alignment,"Zhili Liu, Yunhao Gou, Chaoyu Chen, Lanqing Hong, Jiahui Gao, Fei Mi, Yu Zhang, Zhenguo Li, Xin Jiang, Qun Liu, James Kwok",Annual Meeting of the Association for Computational Linguistics,2025,"As the capabilities of large language models (LLMs) continue to expand, aligning these models with human values remains a significant challenge. Recent studies show that reasoning abilities contribute significantly to model safety, while integrating Mixture-of-Experts (MoE) architectures can further enhance alignment. In this work, we address a fundamental question: How to effectively incorporate reasoning abilities and MoE architectures into self-alignment process in LLMs? We propose Mixture of insighTful Experts (MoTE), a novel framework that synergistically combines reasoning chains and expert mixtures to improve self-alignments. From a data perspective, MoTE employs a structured reasoning chain comprising four key stages: Question Analysis, Answer Guidance, Safe Answer, and Safety Checking. This approach enhances safety through multi-step reasoning and proves effective even for smaller and less powerful LLMs (e.g., 7B models). From an architectural perspective, MoTE adopts a multi-LoRA framework with step-level routing, where each expert is dedicated to a specific reasoning step. This design eliminates the need for balance losses, ensures stable training, and supports adaptive inference lengths. Experimental results demonstrate that MoTE significantly improves model safety, jailbreak resistance, and over-refusal capabilities, achieving performance comparable to OpenAI's state-of-the-art o1 model.",289426447,12,60,,
10.18653/v1/2025.acl-long.123,Nemotron-CC: Transforming Common Crawl into a Refined Long-Horizon Pretraining Dataset,"Dan Su, Kezhi Kong, Ying Lin, Joseph Jennings, Brandon Norick, Markus Kliegl, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro",(missing journal),2025,(missing abstract),289426449,0,0,,
10.18653/v1/2025.acl-long.163,Towards Reward Fairness in RLHF: From a Resource Allocation Perspective,"Sheng Ouyang, Yulan Hu, G. Chen, Qingyang Li, Fuzheng Zhang, Yong Liu",Annual Meeting of the Association for Computational Linguistics,2025,"Rewards serve as proxies for human preferences and play a crucial role in Reinforcement Learning from Human Feedback (RLHF). However, if these rewards are inherently imperfect, exhibiting various biases, they can adversely affect the alignment of large language models (LLMs). In this paper, we collectively define the various biases present in rewards as the problem of reward unfairness. We propose a bias-agnostic method to address the issue of reward fairness from a resource allocation perspective, without specifically designing for each type of bias, yet effectively mitigating them. Specifically, we model preference learning as a resource allocation problem, treating rewards as resources to be allocated while considering the trade-off between utility and fairness in their distribution. We propose two methods, Fairness Regularization and Fairness Coefficient, to achieve fairness in rewards. We apply our methods in both verification and reinforcement learning scenarios to obtain a fairness reward model and a policy model, respectively. Experiments conducted in these scenarios demonstrate that our approach aligns LLMs with human preferences in a more fair manner.",289426451,1,34,,
10.18653/v1/2025.acl-long.93,Binary Classifier Optimization for Large Language Model Alignment,"Seungjae Jung, Gunsoo Han, Daniel Wontae Nam, Kyoung-Woon On",(missing journal),2025,(missing abstract),289426453,2,0,,
10.18653/v1/2025.acl-long.101,What Really Matters in Many-Shot Attacks? An Empirical Study of Long-Context Vulnerabilities in LLMs,"Sangyeop Kim, Yo Han Lee, Yun‐Heub Song, Kimin Lee",(missing journal),2025,(missing abstract),289426455,0,0,,
10.18653/v1/2025.acl-long.125,Contrastive Perplexity for Controlled Generation: An Application in Detoxifying Large Language Models,"Tassilo Klein, Moin Nabi",(missing journal),2025,(missing abstract),289426457,0,0,,
10.18653/v1/2025.acl-long.4,ELABORATION: A Comprehensive Benchmark on Human-LLM Competitive Programming,"Xinwei Yang, Zhaofeng Liu, Chen Huang, Jiashuai Zhang, Tong Zhang, Yifan Zhang, Wenqiang Lei",(missing journal),2025,(missing abstract),289426459,0,0,,
10.18653/v1/2025.acl-long.23,Enhancing Hyperbole and Metaphor Detection with Their Bidirectional Dynamic Interaction and Emotion Knowledge,"Li Zheng, S. M. Wang, Hao Fei, Zuquan Peng, Fei Li, Jianming Fu, Chong Teng, Donghong Ji",(missing journal),2025,(missing abstract),289426461,0,0,,
10.18653/v1/2025.acl-long.1568,Squeezed Attention: Accelerating Long Context Length LLM Inference,"Coleman Hooper, Sehoon Kim, Hiva Mohammadzadeh, Muthucumaru Maheswaran, Siyuan Zhao, Joonki Paik, Michael W. Mahoney, Kurt Keutzer, Amir Gholami",(missing journal),2025,(missing abstract),289426753,0,0,,
10.18653/v1/2025.acl-long.1532,Unintended Harms of Value-Aligned LLMs: Psychological and Empirical Insights,"Subin Choi, J. M. Lee, Xiaoyuan Yi, Jing Yao, Xing Xie, JinYeong Bak",(missing journal),2025,(missing abstract),289426755,0,0,,
10.18653/v1/2025.acl-long.1549,RePanda: Pandas-powered Tabular Verification and Reasoning,"Atoosa Chegini, Keivan Rezaei, Hamid Eghbal-zadeh, Soheil Feizi",(missing journal),2025,(missing abstract),289426759,1,0,,
10.18653/v1/2025.acl-long.1554,A Multi-Agent Framework for Mitigating Dialect Biases in Privacy Policy Question-Answering Systems,"Đorđe Klisura, Astrid R Bernaga Torres, Anna Karen Gárate-Escamilla, Rajesh Roshan Biswal, Ke Yang, Hilal Pataci, Anthony Rios",(missing journal),2025,(missing abstract),289426761,0,0,,
10.18653/v1/2025.acl-long.1533,Maximal Matching Matters: Preventing Representation Collapse for Robust Cross-Modal Retrieval,"Hani Al-Omari, Anushka Sivakumar, Andrew Zhang, Christopher Thomas",(missing journal),2025,(missing abstract),289426763,0,0,,
10.18653/v1/2025.acl-long.1579,Palm: A Culturally Inclusive and Linguistically Diverse Dataset for Arabic LLMs,"Fakhraddin Alwajih, Abdellah El Mekki, Samar Mohamed Magdy, AbdelRahim Elmadany, Omer Nacar, El Moatez Billah Nagoudi, Reem Abdel‐Salam, Hanin Atwany, Youssef Nafea, Azmi Yahya, Rahaf Alhamouri, Hamzah A. Alsayadi, Hiba Zayed, Sara Shatnawi, Serry Sibaee, Yasir Ech-chammakhy, Walid Al-Dhabyani, M. A. B. Md Ali, Imen Jarraya, Ahmed Oumar El-Shangiti, Aisha Alraeesi, Mohammed Anwar AL-Ghrawi, Abdulrahman S. Al-Batati, Elgizouli Mohamed, Noha Taha Elgindi, Muhammed Saeed, Houdaifa Atou, Issam Ait Yahia, Abdelhak Bouayad, Mohammed Machrouh, Amal Makouar, Dania Alkawi, Mukhtar Mohamed, Safaa Taher Abdelfadil, Amine Ziad Ounnoughene, Anfel Rouabhia, Rwaa Assi, Ahmed Sorkatti, Mohamedou Cheikh Tourad, Anis Koubâa, Ismaïl Berrada, Mustafa Jarrar, Shady Shehata, Muhammad Abdul-Mageed",(missing journal),2025,(missing abstract),289426767,0,0,,
10.18653/v1/2025.acl-long.1439,GETReason: Enhancing Image Context Extraction through Hierarchical Multi-Agent Reasoning,"Shikhhar Siingh, Abhinav Rawat, Chitta Baral, Vivek Gupta",(missing journal),2025,(missing abstract),289426769,0,0,,
10.18653/v1/2025.acl-long.1476,Astute RAG: Overcoming Imperfect Retrieval Augmentation and Knowledge Conflicts for Large Language Models,"Fei Wang, Xingchen Wan, Ruoxi Sun, Jiefeng Chen, Sercan Ö. Arık",(missing journal),2025,(missing abstract),289426771,5,0,,
10.18653/v1/2025.acl-long.1452,METAL: A Multi-Agent Framework for Chart Generation with Test-Time Scaling,"Bowen Li, Yiwei Wang, Jiuxiang Gu, Kai-Wei Chang, Nanyun Peng",(missing journal),2025,(missing abstract),289426773,0,0,,
10.18653/v1/2025.acl-long.1373,DISC: Plug-and-Play Decoding Intervention with Similarity of Characters for Chinese Spelling Check,"Zhijiao Qiao, Houquan Zhou, Yumeng Liu, Zhenghua Li, Min Zhang, Bo Zhang, Chen Li, Ji Zhang, Fei Huang",(missing journal),2025,(missing abstract),289426775,0,0,,
10.18653/v1/2025.acl-long.1408,Towards Better Value Principles for Large Language Model Alignment: A Systematic Evaluation and Enhancement,"Bingbing Xu, Jing Yao, Xiaoyuan Yi, Aishan Maoliniyazi, Xing Xie, Xiaofeng Meng",(missing journal),2025,(missing abstract),289426777,0,0,,
10.18653/v1/2025.acl-long.1374,Causal Estimation of Tokenisation Bias,"Pietro Lesci, Clara Meister, Thomas Hofmann, Andreas Vlachos, Tiago Pimentel",(missing journal),2025,(missing abstract),289426779,0,0,,
10.18653/v1/2025.acl-long.1329,Data-Constrained Synthesis of Training Data for De-Identification,"Thomas Vakili, Aron Henriksson, Hercules Dalianis",(missing journal),2025,(missing abstract),289426781,0,0,,
10.18653/v1/2025.acl-long.1358,Learning to Reason Over Time: Timeline Self-Reflection for Improved Temporal Reasoning in Language Models,"Adrián Bazaga, Rexhina Blloshmi, Bill Byrne, Adrià de Gispert",(missing journal),2025,(missing abstract),289426783,0,0,,
10.18653/v1/2025.acl-long.1338,Sightation Counts: Leveraging Sighted User Feedback in Building a BLV-aligned Dataset of Diagram Descriptions,"Wan Ju Kang, Eunki Kim, Na An, Sangryul Kim, Hyon K. Choi, Kyungwon Kwak, James H. Thorne",(missing journal),2025,(missing abstract),289426785,0,0,,
10.18653/v1/2025.acl-long.1388,Multi-Facet Blending for Faceted Query-by-Example Retrieval,"Heejin Do, Sangwon Ryu, Jaegil Kim, Gary Lee",(missing journal),2025,(missing abstract),289426787,0,0,,
10.18653/v1/2025.acl-long.1318,SudoLM: Learning Access Control of Parametric Knowledge with Authorization Alignment,"Qin Liu, Fei Wang, Chaowei Xiao, Muhao Chen",(missing journal),2025,(missing abstract),289426789,0,0,,
10.18653/v1/2025.acl-long.1228,Watching the Watchers: Exposing Gender Disparities in Machine Translation Quality Estimation,"Emmanouil Zaranis, Giuseppe Attanasio, Sweta Agrawal, André F. T. Martins",(missing journal),2025,(missing abstract),289426791,0,0,,
10.18653/v1/2025.acl-long.1270,LogicPro: Improving Complex Logical Reasoning via Program-Guided Learning,"Jin Jiang, Yuchen Yan, Yang Liu, Jianing Wang, Shuai Peng, Xunliang Cai, Yixin Cao, Mengdi Zhang, Liangcai Gao",Annual Meeting of the Association for Computational Linguistics,2025,"In this paper, we propose a new data synthesis method called \textbf{LogicPro}, which leverages LeetCode-style algorithm \underline{Pro}blems and their corresponding \underline{Pro}gram solutions to synthesize Complex \underline{Logic}al Reasoning data in text format. First, we synthesize complex reasoning problems through source algorithm problems and test cases. Then, standard answers and intermediate variable outputs are obtained for each problem based on standard python solutions and test cases. Finally, with the guidance of code intermediate variables, we synthesize the text reasoning process for each reasoning problems. Through this method, we can synthesize data that is difficult, scalable, effective, and comes with golden standard answers and high-quality reasoning processes. As a result, with our 540K synthesized dataset constructed solely from 2,360 algorithm problems, our approach \footnote{Code and data are publicly available at https://github.com/jiangjin1999/LogicPro} achieves significant improvements in multiple models for the datasets \textit{BBH$^{27}$}, \textit{LogicBench}, \textit{DROP}, \textit{AR-LSAT}, and \textit{GSM8K}, etc. outperforming a wide range of existing reasoning datasets.",289426793,9,59,,
10.18653/v1/2025.acl-long.1298,Exploring Multimodal Relation Extraction of Hierarchical Tabular Data with Multi-task Learning,"Xinyu Zhang, Aibo Song, Jingyi Qiu, Jiahui Jin, Tianbo Zhang, Xiaolin Fang",(missing journal),2025,(missing abstract),289426795,0,0,,
10.18653/v1/2025.acl-long.1262,ChatBench: From Static Benchmarks to Human-AI Evaluation,"Shanshan Chang, Ashton Anderson, Jake M. Hofman",Annual Meeting of the Association for Computational Linguistics,2025,"With the rapid adoption of LLM-based chatbots, there is a pressing need to evaluate what humans and LLMs can achieve together. However, standard benchmarks, such as MMLU, measure LLM capabilities in isolation (i.e.,""AI-alone""). Here, we design and conduct a user study to convert MMLU questions into user-AI conversations, by seeding the user with the question and having them carry out a conversation with the LLM to answer their question. We release ChatBench, a new dataset with AI-alone, user-alone, and user-AI data for 396 questions and two LLMs, including 144K answers and 7,336 user-AI conversations. We find that AI-alone accuracy fails to predict user-AI accuracy, with significant differences across multiple subjects (math, physics, and moral reasoning), and we analyze the user-AI conversations to provide insight into how they diverge from AI-alone benchmarks. Finally, we show that fine-tuning a user simulator on a subset of ChatBench improves its ability to estimate user-AI accuracies, increasing correlation on held-out questions by more than 20 points, creating possibilities for scaling interactive evaluation.",289426797,10,31,,
10.18653/v1/2025.acl-long.1222,Mapping the Podcast Ecosystem with the Structured Podcast Research Corpus,"Benjamin Roger Litterer, David Jurgens, Dallas Card",(missing journal),2025,(missing abstract),289426799,0,0,,
10.18653/v1/2025.acl-long.1250,Writing Like the Best: Exemplar-Based Expository Text Generation,"Yuxiang Liu, Kevin Chang",(missing journal),2025,(missing abstract),289426801,0,0,,
10.18653/v1/2025.acl-long.1094,ChartLens: Fine-grained Visual Attribution in Charts,"Manan Suri, Puneet Mathur, Nedim Lipka, Franck Dernoncourt, Ryan A. Rossi, Dinesh Manocha",(missing journal),2025,(missing abstract),289430373,0,0,,
10.18653/v1/2025.acl-long.1088,"Automatic Evaluation for Text-to-image Generation: Task-decomposed Framework, Distilled Training, and Meta-evaluation Benchmark","Rong-Cheng Tu, Zi-Ao Ma, Tian Lan, Yi Zhao, Heyan Huang, Xian-Ling Mao",(missing journal),2025,(missing abstract),289430375,1,0,,
10.18653/v1/2025.acl-long.1149,MPO: Multilingual Safety Alignment via Reward Gap Optimization,"Wenjie Zhao, Yunfei Hu, Yang Deng, Tongtong Wu, Wenhao Zhang, Jingheng Guo, An Zhang, Yanyan Zhao, Bing Qin, Tat‐Seng Chua, Zhiyuan Liu",(missing journal),2025,(missing abstract),289430377,0,0,,
10.18653/v1/2025.acl-long.1097,Towards the Law of Capacity Gap in Distilling Language Models,"Chen Zhang, Qiuchi Li, Dawei Song, Zheyu Ye, Yan Gao, Yao Hu",(missing journal),2025,(missing abstract),289430379,0,0,,
10.18653/v1/2025.acl-long.1170,AgentDropout: Dynamic Agent Elimination for Token-Efficient and High-Performance LLM-Based Multi-Agent Collaboration,"Zhexuan Wang, Yutong Wang, Xuebo Liu, Liang Ding, Miao Zhang, Jie Liu, Min Zhang",(missing journal),2025,(missing abstract),289430381,1,0,,
10.18653/v1/2025.acl-long.1124,One QuantLLM for ALL: Fine-tuning Quantized LLMs Once for Efficient Deployments,"Ke Yi, Yuhui Xu, Heng Chang, Meng Yuan, Tong Zhang, Jia Li",(missing journal),2025,(missing abstract),289430383,0,0,,
10.18653/v1/2025.acl-long.1150,QualiSpeech: A Speech Quality Assessment Dataset with Natural Language Reasoning and Descriptions,"Siyin Wang, Wenyi Yu, Xianzhao Chen, Xiaohai Tian, Jun Zhang, Lu Lu, Yu Tsao, Junichi Yamagishi, Yuxuan Wang, Chao Zhang",(missing journal),2025,(missing abstract),289430385,2,0,,
10.18653/v1/2025.acl-long.916,"Crowdsource, Crawl, or Generate? Creating SEA-VL, a Multicultural Vision-Language Dataset for Southeast Asia","Samuel Cahyawijaya, Holy Lovenia, Joel Ruben Antony Moniz, Tiffany Wong, Mohammad Rifqi Farhansyah, Tin Maung Maung, Frederikus Hudi, David Anugraha, Muhammad Ravi Shulthan Habibi, Muhammad Reza Qorib, Amit Agarwal, Joseph Marvin Imperial, Hitesh Laxmichand Patel, Vicky Feliren, Bahrul Ilmi Nasution, Manuel Rufino, Genta Indra Winata, Rian Adam Rajagede, Carlos Rafael Catalan, Mohamed A. Imam, Priyaranjan Pattnayak, Salsabila Zahirah Pranida, Kevin Pratama, Yeshil Bangera, Adisai Na-Thalang, Patricia Nicole Monderin, Yueqi Song, Christian Simon, Lynnette Hui Xian Ng, Richardy Lobo Sapan, Taki Hasan Rafi, B.-H Wang, Supryadi, Kanyakorn Veerakanjana, Piyalitt Ittichaiwong, Matthew Theodore Roque, Karissa Vincentio, Takdanai Kreangphet, Phakphum Artkaew, Kadek Hendrawan Palgunadi, Yang Yu, Rochana Prih Hastuti, William Nixon, Mithil Bangera, Andy K.H. Lim, Aye Hninn Khine, Hanif Muhammad Zhafran, Teddy Ferdinan, Audra Aurora Izzani, Ankush Singh, Evan Evan, Jauza Akbar Krito, Michael Anugraha, Fenal Ashokbhai Ilasariya, Haochen Li, John Amadeo Daniswara, Filbert Aurelian Tjiaranata, Eryawan Presma Yulianrifat, Can Udomcharoenchaikit, Fadil Risdian Ansori, Mahardika Krisna Ihsani, Giang Nguyen, Anab Maulana Barik, Dan John Velasco, Rifo Ahmad Genadi, Subrata Saha, Cong Wei, Isaiah Edri W. Flores, Keli Han, Adrián Santos, Boon Leong Lim, Kaung Si Phyo, Tim Santos, Meisyarah Dwiastuti, Jun Luo, Jan Christian Blaise Cruz, Ming Shan Hee, Ikhlasul Akmal Hanif, M Hakim, Muhammad Rizky Sya’ban, Kun Kerdthaisong, Lester James V. Miranda, Fajri Koto, Tirana Noor Fatyanosa, Alham Fikri Aji, Jostin Jerico Rosal, Jeremy Kevin, Reynard Wiratama Wijaya, Onno P. Kampman, Ruochen Zhang, Börje F. Karlsson, Peerat Limkonchotiwat",(missing journal),2025,(missing abstract),289430387,1,0,,
10.18653/v1/2025.acl-long.942,"PVP: An Image Dataset for Personalized Visual Persuasion with Persuasion Strategies, Viewer Characteristics, and Persuasiveness Ratings","Jeongmin Kim, Jong-Wook Han, Dongmin Choi, Ji Won Yoon, Eun‐Ju Lee, You Hwan Jo",(missing journal),2025,(missing abstract),289430389,0,0,,
10.18653/v1/2025.acl-long.999,BIG5-CHAT: Shaping LLM Personalities Through Training on Human-Grounded Data,"Wenkai Li, Jiarui Liu, Andy Liu, Xuhui Zhou, Mona Diab, Maarten Sap",(missing journal),2025,(missing abstract),289430391,1,0,,
10.18653/v1/2025.acl-long.925,CULEMO: Cultural Lenses on Emotion - Benchmarking LLMs for Cross-Cultural Emotion Understanding,"Tadesse Destaw Belay, Ahmed Haj Ahmed, Alvin Grissom, Iqra Ameer, Grigori Sidorov, Olga Kolesnikova, Seid Muhie Yimam",(missing journal),2025,(missing abstract),289430393,0,0,,
10.18653/v1/2025.acl-long.954,IPO: Your Language Model is Secretly a Preference Classifier,"Shivank Garg, Ayush Singh, Shweta Singh, Prem Chopra",(missing journal),2025,(missing abstract),289430395,0,0,,
10.18653/v1/2025.acl-long.891,Identifying Open Challenges in Language Identification,Rob van der Goot,(missing journal),2025,(missing abstract),289430397,0,0,,
10.18653/v1/2025.acl-long.868,Revealing the Deceptiveness of Knowledge Editing: A Mechanistic Analysis of Superficial Editing,"Jinqiao Xie, Cao Peng-fei, Yubo Chen, Kang Liu, Jun Zhao",(missing journal),2025,(missing abstract),289430399,0,0,,
10.18653/v1/2025.acl-long.848,Which Demographics do LLMs Default to During Annotation?,"Johannes Schäfer, Aidan Combs, Christopher Bagdon, Jiahui Li, Nadine Probol, Lynn Greschner, Sean Papay, Yarik Menchaca Resendiz, Aswathy Velutharambath, Amelie Wuehrl, Sabine Weber, Roman Klinger",(missing journal),2025,(missing abstract),289430401,0,0,,
10.18653/v1/2025.acl-long.785,Com2 : A Causal-Guided Benchmark for Exploring Complex Commonsense Reasoning in Large Language Models,"Kai Xiong, Xiao Ding, Yixin Cao, Yuanliang Yan, Li Du, Yufei Zhang, Jinglong Gao, J. Y. Liu, Bing Qin, Ting Liu",(missing journal),2025,(missing abstract),289430403,0,0,,
10.18653/v1/2025.acl-long.857,"Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents","Tianyi Men, Zhuoran Jin, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao",(missing journal),2025,(missing abstract),289430405,0,0,,
10.18653/v1/2025.acl-long.858,It’s Not Bragging If You Can Back It Up: Can LLMs Understand Braggings?,"Jianhao Zeng, hongping Li, Liang Huai Yang, Yuanyuan Sun, Hongfei Lin",(missing journal),2025,(missing abstract),289430407,0,0,,
10.18653/v1/2025.acl-long.828,On Synthesizing Data for Context Attribution in Question Answering,"Gorjan Radevski, Kiril Gashteovski, Shahbaz Syed, Christopher Malon, Sébastien Nicolas, Chia-Chien Hung, Timo Sztyler, Verena Heußer, Wiem Ben Rim, Masafumi Enomoto, Kunihiro Takeoka, Masafumi Oyamada, Goran Glavaš, Carolin Lawrence",(missing journal),2025,(missing abstract),289430409,0,0,,
10.18653/v1/2025.acl-long.1188,Fairness Beyond Performance: Revealing Reliability Disparities Across Groups in Legal NLP,"Santosh T.y.s.s, Irtiza Chowdhury",(missing journal),2025,(missing abstract),289430411,0,0,,
10.18653/v1/2025.acl-long.1186,Decoding on Graphs: Faithful and Sound Reasoning on Knowledge Graphs through Generation of Well-Formed Chains,"Kun Li, Tianhua Zhang, Xixin Wu, Hongyin Luo, James Glass, Helen Meng",(missing journal),2025,(missing abstract),289430413,1,0,,
10.18653/v1/2025.acl-long.770,Removal of Hallucination on Hallucination: Debate-Augmented RAG,"Wei Hu, Wengyu Zhang, Yiyang Jiang, Chen Zhang, Xiaoyong Wei, Qing Li",(missing journal),2025,(missing abstract),289430415,0,0,,
10.18653/v1/2025.acl-long.736,MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding Benchmark,"Xiang Yue, Tianyu Zheng, Yuansheng Ni, Yubo Wang, Kai Zhang, Shengbang Tong, Yuxuan Sun, Botao Yu, Ge ZHANG, Huan Sun, Yu Su, Wenhu Chen, Graham Neubig",(missing journal),2025,(missing abstract),289430417,1,0,,
10.18653/v1/2025.acl-long.672,Mimicking the Familiar: Dynamic Command Generation for Information Theft Attacks in LLM Tool-Learning System,"Ziyou Jiang, Mingyang Li, Guowei Yang, Junjie Wang, Yue-Kai Huang, Z. Chang, Qing Wang",(missing journal),2025,(missing abstract),289430419,0,0,,
10.18653/v1/2025.acl-long.713,Flexora: Flexible Low-Rank Adaptation for Large Language Models,"C.-H. Wei, Yao Shu, Yong He, Fei Fei Yu",(missing journal),2025,(missing abstract),289430421,0,0,,
10.18653/v1/2025.acl-long.597,HomeBench: Evaluating LLMs in Smart Homes with Valid and Invalid Instructions Across Single and Multiple Devices,"Silin Li, Y. Jay Guo, JingTao Yao, Zeming Liu, Haifeng Wang",(missing journal),2025,(missing abstract),289430423,0,0,,
10.18653/v1/2025.acl-long.778,Middle-Layer Representation Alignment for Cross-Lingual Transfer in Fine-Tuned LLMs,"Danni Liu, Jan Niehues",(missing journal),2025,(missing abstract),289430425,2,0,,
10.18653/v1/2025.acl-long.595,SAM Decoding: Speculative Decoding via Suffix Automaton,"Yuxuan Hu, Ke Wang, Xiaokang Zhang, Fanjin Zhang, Cuiping Li, Hong Chen, Jing Zhang",(missing journal),2025,(missing abstract),289430427,0,0,,
10.18653/v1/2025.acl-long.769,Program Synthesis Benchmark for Visual Programming in XLogoOnline Environment,"Chao Wen, Jacqueline Staub, Adish Singla",(missing journal),2025,(missing abstract),289430429,0,0,,
10.18653/v1/2025.acl-long.622,Can Knowledge Graphs Make Large Language Models More Trustworthy? An Empirical Study Over Open-ended Question Answering,"Yuan Sui, Yufei He, Zifeng Ding, Bryan Hooi",(missing journal),2025,(missing abstract),289430431,1,0,,
10.18653/v1/2025.acl-long.583,GODBench: A Benchmark for Multimodal Large Language Models in Video Comment Art,"Yiming Lei, Chenkai Zhang, Zeming Liu, Haitao Leng, Shaoguo Liu, Tingting Gao, Qingjie Liu, Yunhong Wang",(missing journal),2025,(missing abstract),289430433,0,0,,
10.18653/v1/2025.acl-long.573,Less Mature is More Adaptable for Sentence-level Language Modeling,"Abhilasha Sancheti, David C. Dale, Artyom Kozhevnikov, Maha Elbayad",(missing journal),2025,(missing abstract),289430435,0,0,,
10.18653/v1/2025.acl-long.551,Pre3: Enabling Deterministic Pushdown Automata for Faster Structured LLM Generation,"Junyi Chen, Shihao Bai, Zaijun Wang, Siyu Wu, Chuheng Du, Hai-Long Yang, Ruihao Gong, Shengzhong Liu, Fan Wu, Guihai Chen",Annual Meeting of the Association for Computational Linguistics,2025,"Extensive LLM applications demand efficient structured generations, particularly for LR(1) grammars, to produce outputs in specified formats (e.g., JSON). Existing methods primarily parse LR(1) grammars into a pushdown automaton (PDA), leading to runtime execution overhead for context-dependent token processing, especially inefficient under large inference batches. To address these issues, we propose Pre$^3$ that exploits deterministic pushdown automata (DPDA) to optimize the constrained LLM decoding efficiency. First, by precomputing prefix-conditioned edges during the preprocessing, Pre$^3$ enables ahead-of-time edge analysis and thus makes parallel transition processing possible. Second, by leveraging the prefix-conditioned edges, Pre$^3$ introduces a novel approach that transforms LR(1) transition graphs into DPDA, eliminating the need for runtime path exploration and achieving edge transitions with minimal overhead. Pre$^3$ can be seamlessly integrated into standard LLM inference frameworks, reducing time per output token (TPOT) by up to 40% and increasing throughput by up to 36% in our experiments. Our code is available at https://github.com/ModelTC/lightllm.",289430437,3,33,,
10.18653/v1/2025.acl-long.544,Beware of Your Po! Measuring and Mitigating AI Safety Risks in Role-Play Fine-Tuning of LLMs,"Weixiang Zhao, Yulin Hu, Yang Deng, Jiahe Guo, Xin Sui, Xinyang Han, An Zhang, Yanyan Zhao, Bing Qin, Tat‐Seng Chua, Ting Liu",(missing journal),2025,(missing abstract),289430439,0,0,,
10.18653/v1/2025.acl-long.448,SelfElicit: Your Language Model Secretly Knows Where is the Relevant Evidence,"Zhining Liu, Rana Ali Amjad, Ravinarayana Adkathimar, Tingting Wei, Hanghang Tong",(missing journal),2025,(missing abstract),289430441,0,0,,
10.18653/v1/2025.acl-long.492,Polishing Every Facet of the GEM: Testing Linguistic Competence of LLMs and Humans in Korean,"SungHo Kim, N.I. Kim, Taehee Jeon, SangKeun Lee",(missing journal),2025,(missing abstract),289430443,0,0,,
10.18653/v1/2025.acl-long.468,KG-Agent: An Efficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph,"Jinhao Jiang, Kun Zhou, Wayne Xin Zhao, Yang Song, Chen Zhu, Hengshu Zhu, Ji-Rong Wen",(missing journal),2025,(missing abstract),289430445,3,0,,
10.18653/v1/2025.acl-long.493,SpeechFake: A Large-Scale Multilingual Speech Deepfake Dataset Incorporating Cutting-Edge Generation Methods,"Wen Huang, Ying-Qiu Gu, Zhiming Wang, Huijia Zhu, Yanmin Qian",Annual Meeting of the Association for Computational Linguistics,2025,"As speech generation technology advances, the risk of misuse through deepfake audio has become a pressing concern, which underscores the critical need for robust detection systems. However, many existing speech deepfake datasets are limited in scale and diversity, making it challenging to train models that can generalize well to unseen deepfakes. To address these gaps, we introduce SpeechFake, a large-scale dataset designed specifically for speech deepfake detection. SpeechFake includes over 3 million deepfake samples, totaling more than 3,000 hours of audio, generated using 40 different speech synthesis tools. The dataset encompasses a wide range of generation techniques, including text-to-speech, voice conversion, and neural vocoder, incorporating the latest cutting-edge methods. It also provides multilingual support, spanning 46 languages. In this paper, we offer a detailed overview of the dataset's creation, composition, and statistics. We also present baseline results by training detection models on SpeechFake, demonstrating strong performance on both its own test sets and various unseen test sets. Additionally, we conduct experiments to rigorously explore how generation methods, language diversity, and speaker variation affect detection performance. We believe SpeechFake will be a valuable resource for advancing speech deepfake detection and developing more robust models for evolving generation techniques.",289430447,2,57,,
10.18653/v1/2025.acl-long.413,In Prospect and Retrospect: Reflective Memory Management for Long-term Personalized Dialogue Agents,"Tan Zhen, Jun Yan, I-Hung Hsu, R.J. Han, Zifeng Wang, Duc Long Le, Yong Sang Song, Yanfei Chen, Hamid Palangi, George Lee, Aarti Iyer, Tianlong Chen, Huan Liu, Chen-Yu Lee, Tomas Pfister",(missing journal),2025,(missing abstract),289430449,1,0,,
10.18653/v1/2025.acl-long.319,Adaptive Retrieval Without Self-Knowledge? Bringing Uncertainty Back Home,"Viktor Moskvoretskii, Maria Marina, Mikhail Salnikov, Nikolay Ivanov, Sergey Pletenev, Daria Galimzianova, Nikita Krayko, Vasily Konovalov, Irina Nikishinа, Alexander Panchenko",(missing journal),2025,(missing abstract),289430451,0,0,,
10.18653/v1/2025.acl-long.364,The Cross-linguistic Role of Animacy in Grammar Structures,"Nina Gregorio, Michel Gay, Sharon Goldwater, Edoardo Maria Ponti",(missing journal),2025,(missing abstract),289430453,0,0,,
10.18653/v1/2025.acl-long.456,Culture Matters in Toxic Language Detection in Persian,"Zahra Bokaei, Walid Magdy, Bonnie Webber",(missing journal),2025,(missing abstract),289430455,0,0,,
10.18653/v1/2025.acl-long.407,Data Laundering: Artificially Boosting Benchmark Results through Knowledge Distillation,"Jonibek Mansurov, Akhmed Sakip, Alham Fikri Aji",(missing journal),2025,(missing abstract),289430457,0,0,,
10.18653/v1/2025.acl-long.372,VLM2-Bench: A Closer Look at How Well VLMs Implicitly Link Explicit Matching Visual Cues,"Jianshu Zhang, Dongyu Yao, Renjie Pi, Paul Pu Liang, Yi R. Fung",(missing journal),2025,(missing abstract),289430459,0,0,,
10.18653/v1/2025.acl-long.370,Data Quality Issues in Multilingual Speech Datasets: The Need for Sociolinguistic Awareness and Proactive Language Planning,"Monica Laura Lau, Qian Chen, Yeming Fang, Tingting Xu, Tongzhou Chen, Pavel Golik",(missing journal),2025,(missing abstract),289430461,0,0,,
10.18653/v1/2025.acl-long.324,GIFT-SW: Gaussian noise Injected Fine-Tuning of Salient Weights for LLMs,"Maxim Zhelnin, Viktor Moskvoretskii, Egor Shvetsov, Maria Krylova, Venediktov Egor, Zuev Aleksandr, Evgeny Burnaev",(missing journal),2025,(missing abstract),289430463,0,0,,
10.18653/v1/2025.acl-long.365,LexGen: Domain-aware Multilingual Lexicon Generation,"Ayush Maheshwari, Atul Kumar Singh, N J Karthika, Krishnakant Bhatt, Preethi Jyothi, Ganesh Ramakrishnan",(missing journal),2025,(missing abstract),289430465,0,0,,
10.18653/v1/2025.acl-long.311,NeuSym-RAG: Hybrid Neural Symbolic Retrieval with Multiview Structuring for PDF Question Answering,"Ruisheng Cao, Hanchong Zhang, Tiancheng Huang, Zhangyi Kang, Yuan‐Ting Zhang, Liangtai Sun, Hanqi Li, Y.Z. Miao, Shuai Fan, Lu Chen, Kai Yu",Annual Meeting of the Association for Computational Linguistics,2025,"The increasing number of academic papers poses significant challenges for researchers to efficiently acquire key details. While retrieval augmented generation (RAG) shows great promise in large language model (LLM) based automated question answering, previous works often isolate neural and symbolic retrieval despite their complementary strengths. Moreover, conventional single-view chunking neglects the rich structure and layout of PDFs, e.g., sections and tables. In this work, we propose NeuSym-RAG, a hybrid neural symbolic retrieval framework which combines both paradigms in an interactive process. By leveraging multi-view chunking and schema-based parsing, NeuSym-RAG organizes semi-structured PDF content into both the relational database and vectorstore, enabling LLM agents to iteratively gather context until sufficient to generate answers. Experiments on three full PDF-based QA datasets, including a self-annotated one AIRQA-REAL, show that NeuSym-RAG stably defeats both the vector-based RAG and various structured baselines, highlighting its capacity to unify both retrieval schemes and utilize multiple views. Code and data are publicly available at https://github.com/X-LANCE/NeuSym-RAG.",289430467,1,30,,
10.18653/v1/2025.acl-long.411,Attacking Vision-Language Computer Agents via Pop-ups,"Yanzhe Zhang, Tao Yu, Diyi Yang",(missing journal),2025,(missing abstract),289430469,0,0,,
10.18653/v1/2025.acl-long.262,Learning to Reason from Feedback at Test-Time,"Ye Li, Michael R. Lyu, Liwei Wang",(missing journal),2025,(missing abstract),289430471,0,0,,
10.18653/v1/2025.acl-long.267,People who frequently use ChatGPT for writing tasks are accurate and robust detectors of AI-generated text,"J. Russell, Marzena Karpinska, Mohit Iyyer",(missing journal),2025,(missing abstract),289430473,2,0,,
10.18653/v1/2025.acl-long.266,Pattern Recognition or Medical Knowledge? The Problem with Multiple-Choice Questions in Medicine,"Maxime Griot, Jean Vanderdonckt, Demet Yüksel, Coralie Hemptinne",Annual Meeting of the Association for Computational Linguistics,2025,"Large Language Models (LLMs) such as ChatGPT demonstrate significant potential in the medical domain and are often evaluated using multiple-choice questions (MCQs) modeled on exams like the USMLE. However, such benchmarks may overestimate true clinical understanding by rewarding pattern recognition and test-taking heuristics. To investigate this, we created a fictional medical benchmark centered on an imaginary organ, the Glianorex, allowing us to separate memorized knowledge from reasoning ability. We generated textbooks and MCQs in English and French using leading LLMs, then evaluated proprietary, open-source, and domain-specific models in a zero-shot setting. Despite the fictional content, models achieved an average score of 64%, while physicians scored only 27%. Fine-tuned medical models outperformed base models in English but not in French. Ablation and interpretability analyses revealed that models frequently relied on shallow cues, test-taking strategies, and hallucinated reasoning to identify the correct choice. These results suggest that standard MCQ-based evaluations may not effectively measure clinical reasoning and highlight the need for more robust, clinically meaningful assessment methods for LLMs.",289430477,10,41,,
10.18653/v1/2025.acl-long.224,How Humans and LLMs Organize Conceptual Knowledge: Exploring Subordinate Categories in Italian,"Andrea Pedrotti, Giulia Rambelli, Caterina Villani, Marianna Bolognesi",(missing journal),2025,(missing abstract),289442439,0,0,,
10.18653/v1/2025.acl-long.184,Battling against Tough Resister: Strategy Planning with Adversarial Game for Non-collaborative Dialogues,"Haiyang Wang, Zhiliang Tian, Yuchen Pan, Xin Song, Xin Niu, Minlie Huang, Bin Zhou",(missing journal),2025,(missing abstract),289442441,0,0,,
10.18653/v1/2025.acl-long.238,from Benign import Toxic: Jailbreaking the Language Model via Adversarial Metaphors,"Yu Yan, Sheng Sun, Zhaoyun Duan, Tongze Liu, Min Liu, Zhiyi Yin, LeiJingyu LeiJingyu, Qi Li",Annual Meeting of the Association for Computational Linguistics,2025,"Current studies have exposed the risk of Large Language Models (LLMs) generating harmful content by jailbreak attacks. However, they overlook that the direct generation of harmful content from scratch is more difficult than inducing LLM to calibrate benign content into harmful forms. In our study, we introduce a novel attack framework that exploits AdVersArial meTAphoR (AVATAR) to induce the LLM to calibrate malicious metaphors for jailbreaking. Specifically, to answer harmful queries, AVATAR adaptively identifies a set of benign but logically related metaphors as the initial seed. Then, driven by these metaphors, the target LLM is induced to reason and calibrate about the metaphorical content, thus jailbroken by either directly outputting harmful responses or calibrating residuals between metaphorical and professional harmful content. Experimental results demonstrate that AVATAR can effectively and transferable jailbreak LLMs and achieve a state-of-the-art attack success rate across multiple advanced LLMs.",289442443,6,0,,
10.18653/v1/2025.acl-long.173,Taming Language Models for Text-attributed Graph Learning with Decoupled Aggregation,"Chuang Zhou, Zhu Wang, Shengyuan Chen, Jiahe Du, Qiyuan Zheng, Zhaozhuo Xu, Xiao Huang",(missing journal),2025,(missing abstract),289442445,0,0,,
10.18653/v1/2025.acl-long.120,Behind Closed Words: Creating and Investigating the forePLay Annotated Dataset for Polish Erotic Discourse,"Anna Kołos, Katarzyna Lorenc, Emilia Wiśnios, Agnieszka Karlińska",(missing journal),2025,(missing abstract),289442447,0,0,,
10.18653/v1/2025.acl-long.114,When Backdoors Speak: Understanding LLM Backdoor Attacks Through Model-Generated Explanations,"Huaizhi Ge, Yiming Li, Qifan Wang, Yongfeng Zhang, Ruixiang Tang",(missing journal),2025,(missing abstract),289442449,0,0,,
10.18653/v1/2025.acl-long.126,INVESTORBENCH: A Benchmark for Financial Decision-Making Tasks with LLM-based Agent,"Haohang Li, Yupeng Cao, Yangyang Yu, Shashidhar Reddy Javaji, Zhiyang Deng, Yueru He, Yuechen Jiang, Zining Zhu, K. P. Subbalakshmi, Jimin Huang, Lingfei Qian, Xueqing Peng, Jordan W. Suchow, Qianqian Xie",(missing journal),2025,(missing abstract),289442451,1,0,,
10.18653/v1/2025.acl-long.61,Modeling Uncertainty in Composed Image Retrieval via Probabilistic Embeddings,"Haomiao Tang, Jinpeng Wang, Yuang Peng, Guanghao Meng, Ruisheng Luo, Bin Chen, Long Chen, Yaowei Wang, Shu–Tao Xia",(missing journal),2025,(missing abstract),289442453,0,0,,
10.18653/v1/2025.acl-long.1,EcomScriptBench: A Multi-task Benchmark for E-commerce Script Planning via Step-wise Intention-Driven Product Association,"Weiqi Wang, Limeng Cui, Xin Liu, Sreyashi Nag, Wenju Xu, Chen Luo, Sheikh Muhammad Sarwar, Yang Li, Hansu Gu, Liu Hui, Changlong Yu, Jiaxin Bai, Yifan Gao, Haiyang Zhang, Qiang He, Shuiwang Ji, Yangqiu Song",(missing journal),2025,(missing abstract),289442457,0,0,,
10.18653/v1/2025.acl-long.48,Rethinking Repetition Problems of LLMs in Code Generation,"Yihong Dong, Yuchen Liu, Xue Jiang, Bin Gu, Zhi Jin, Ge Li",(missing journal),2025,(missing abstract),289442461,0,0,,
10.18653/v1/2025.acl-long.33,TrimLLM: Progressive Layer Dropping for Domain-Specific LLMs,"Lanxiang Hu, Tajana Rosing, Hao Zhang",(missing journal),2025,(missing abstract),289442465,0,0,,
10.18653/v1/2025.acl-long.50,ProcessBench: Identifying Process Errors in Mathematical Reasoning,"Chujie Zheng, Zhirenyong Zhang, Beichen Zhang, Runji Lin, Keming Lu, B. X. Yu, Dayiheng Liu, Jingren Zhou, Junyang Lin",(missing journal),2025,(missing abstract),289442467,0,0,,
10.18653/v1/2025.acl-long.1559,"HELIOS: Harmonizing Early Fusion, Late Fusion, and LLM Reasoning for Multi-Granular Table-Text Retrieval","Sungho Park, Joohyung Yun, Jongwuk Lee, Wook-Shin Han",(missing journal),2025,(missing abstract),289442689,0,0,,
10.18653/v1/2025.acl-long.1598,TETRIS: Optimal Draft Token Selection for Batch Speculative Decoding,"Zhaoxuan Wu, Zijian Zhou, Arun Kumar Verma, Alok Prakash, Daniela Rus, Bryan Kian Hsiang Low",(missing journal),2025,(missing abstract),289442691,0,0,,
10.18653/v1/2025.acl-long.1522,Theory of Mind in Large Language Models: Assessment and Enhancement,"Ruirui Chen, Weifeng Jiang, Chengwei Qin, Cheston Tan",(missing journal),2025,(missing abstract),289442693,0,0,,
10.18653/v1/2025.acl-long.1514,A Parameter-Efficient and Fine-Grained Prompt Learning for Vision-Language Models,"Yongbin Guo, Shuzhen Li, Zhulin Liu, Tong Zhang, C. L. Philip Chen",(missing journal),2025,(missing abstract),289442695,0,0,,
10.18653/v1/2025.acl-long.1592,LlamaDuo: LLMOps Pipeline for Seamless Migration from Service LLMs to Small-Scale Local LLMs,"Chansung Park, Juyong Jiang, Fan Wang, Sayak Paul, Jing Tang",(missing journal),2025,(missing abstract),289442697,0,0,,
10.18653/v1/2025.acl-long.1561,La Leaderboard: A Large Language Model Leaderboard for Spanish Varieties and Languages of Spain and Latin America,"María Grandury, Javier Aula-Blasco, Júlia Falcão, Clémentine Fourrier, M. Saiz, Gonzalo Martínez, Graciela Gómez, Rodrigo Agerri, Nuria Aldama García, Luis Chiruzzo, Javier Conde, Helena Gómez Adorno, Marta Guerrero Nieto, Guido Ivetta, Natalia Fuertes, Flor Miriam Plaza-del-Arco, María Teresa Martín Valdivia, Helena Montoro Zamorano, Cecilia Verónica Sanz, Pedro Reviriego, L Plaza, Alejandro Vaca Serrano, Estrella Vallecillo-Rodríguez, Jorge Vallego, Irune Zubiaga",Annual Meeting of the Association for Computational Linguistics,2025,"Leaderboards showcase the current capabilities and limitations of Large Language Models (LLMs). To motivate the development of LLMs that represent the linguistic and cultural diversity of the Spanish-speaking community, we present La Leaderboard, the first open-source leaderboard to evaluate generative LLMs in languages and language varieties of Spain and Latin America. La Leaderboard is a community-driven project that aims to establish an evaluation standard for everyone interested in developing LLMs for the Spanish-speaking community. This initial version combines 66 datasets in Basque, Catalan, Galician, and different Spanish varieties, showcasing the evaluation results of 50 models. To encourage community-driven development of leaderboards in other languages, we explain our methodology, including guidance on selecting the most suitable evaluation setup for each downstream task. In particular, we provide a rationale for using fewer few-shot examples than typically found in the literature, aiming to reduce environmental impact and facilitate access to reproducible results for a broader research community.",289442699,0,74,,
10.18653/v1/2025.acl-long.1585,ConsistencyChecker: Tree-based Evaluation of LLM Generalization Capabilities,"Zhaochen Hong, Haofei Yu, Jiaxuan You",(missing journal),2025,(missing abstract),289442701,0,0,,
10.18653/v1/2025.acl-long.1602,Just Go Parallel: Improving the Multilingual Capabilities of Large Language Models,"Muhammad Reza Qorib, Junyi Li, Hwee Tou Ng",(missing journal),2025,(missing abstract),289442703,0,0,,
10.18653/v1/2025.acl-long.1416,Data Caricatures: On the Representation of African American Language in Pretraining Corpora,"Nicholas Deas, Blake Vente, Amith Ananthram, Jessica A. Grieser, Desmond U. Patton, Shana Kleiner, J A Shepard, Kathleen McKeown",(missing journal),2025,(missing abstract),289442705,0,0,,
10.18653/v1/2025.acl-long.1445,Principled Content Selection to Generate Diverse and Personalized Multi-Document Summaries,"Vishakh Padmakumar, Zichao Wang, David Arbour, Jennifer Healey",(missing journal),2025,(missing abstract),289442707,0,0,,
10.18653/v1/2025.acl-long.1455,MEraser: An Effective Fingerprint Erasure Approach for Large Language Models,"Jingxuan Zhang, Zhenhua Xu, Rui Hu, Wenpeng Xing, Xuhong Zhang, Meng Han",(missing journal),2025,(missing abstract),289442709,0,0,,
10.18653/v1/2025.acl-long.1490,Benchmarking LLMs and LLM-based Agents in Practical Vulnerability Detection for Code Repositories,"Alperen Yildiz, Sin G. Teo, Yiling Lou, Yebo Feng, Chong Wang, Dinil Mon Divakaran",(missing journal),2025,(missing abstract),289442711,1,0,,
10.18653/v1/2025.acl-long.1497,Hidden in Plain Sight: Evaluation of the Deception Detection Capabilities of LLMs in Multimodal Settings,"Md Messal Monem Miah, Adrita Anika, Xi Shi, Ruihong Huang",(missing journal),2025,(missing abstract),289442713,0,0,,
10.18653/v1/2025.acl-long.1449,Measuring the Effect of Transcription Noise on Downstream Language Understanding Tasks,"Ori Shapira, Shlomo E. Chazan, Amir Cohen",(missing journal),2025,(missing abstract),289442715,0,0,,
10.18653/v1/2025.acl-long.1503,Diffusion Models Through a Global Lens: Are They Culturally Inclusive?,"Zahra Bayramli, Ayhan Suleymanzade, Na An, H. Ahmad, Eun‐Su Kim, Jun‐Hyoung Park, James H. Thorne, Alice Oh",(missing journal),2025,(missing abstract),289442717,0,0,,
10.18653/v1/2025.acl-long.1496,SocialEval: Evaluating Social Intelligence of Large Language Models,"Jinfeng Zhou, Yuxuan Chen, Yan Shi, Xuanming Zhang, Lei Lv, Yi Feng, Zexuan Xiong, Yan Miao, Xunzhi Wang, Yaru Cao, Jianing Yin, Shuai Wang, Quanyu Dai, Zhenhua Dong, Hongning Wang, Minlie Huang",(missing journal),2025,(missing abstract),289442719,0,0,,
10.18653/v1/2025.acl-long.1502,GPT-4 as a Homework Tutor Can Improve Student Engagement and Learning Outcomes,"Alessandro Vanzo, Sankalan Pal Chowdhury, Mrinmaya Sachan",(missing journal),2025,(missing abstract),289442721,3,0,,
10.18653/v1/2025.acl-long.1420,DeepReview: Improving LLM-based Paper Review with Human-like Deep Thinking Process,"Min Zhu, Yixuan Weng, Linyi Yang, Yue Zhang",(missing journal),2025,(missing abstract),289442723,2,0,,
10.18653/v1/2025.acl-long.1448,Theorem Prover as a Judge for Synthetic Data Generation,"Joshua Ong Jun Leang, Giwon Hong, Wenda Li, Shay B. Cohen",Annual Meeting of the Association for Computational Linguistics,2025,"The demand for synthetic data in mathematical reasoning has increased due to its potential to enhance the mathematical capabilities of large language models (LLMs). However, ensuring the validity of intermediate reasoning steps remains a significant challenge, affecting data quality. While formal verification via theorem provers effectively validates LLM reasoning, the autoformalisation of mathematical proofs remains error-prone. In response, we introduce iterative autoformalisation, an approach that iteratively refines theorem prover formalisation to mitigate errors, thereby increasing the execution rate on the Lean prover from 60% to 87%. Building upon that, we introduce Theorem Prover as a Judge (TP-as-a-Judge), a method that employs theorem prover formalisation to rigorously assess LLM intermediate reasoning, effectively integrating autoformalisation with synthetic data generation. Finally, we present Reinforcement Learning from Theorem Prover Feedback (RLTPF), a framework that replaces human annotation with theorem prover feedback in Reinforcement Learning from Human Feedback (RLHF). Across multiple LLMs, applying TP-as-a-Judge and RLTPF improves benchmarks with only 3,508 samples, achieving 5.56% accuracy gain on Mistral-7B for MultiArith, 6.00% on Llama-2-7B for SVAMP, and 3.55% on Llama-3.1-8B for AQUA.",289442725,7,46,,
10.18653/v1/2025.acl-long.1341,LLM×MapReduce: Simplified Long-Sequence Processing using Large Language Models,"Zihan Zhou, Chong Li, Xinyi Chen, Shuo Wang, Chao Yu, Zhili Li, Haoyu Wang, Qi Shi, Zhixing Tan, Xu Han, Xiaodong Shi, Zhiyuan Liu, Maosong Sun",Annual Meeting of the Association for Computational Linguistics,2025,"Enlarging the context window of large language models (LLMs) has become a crucial research area, particularly for applications involving extremely long texts. In this work, we propose a novel training-free framework for processing long texts, utilizing a divide-and-conquer strategy to achieve comprehensive document understanding. The proposed LLM$\times$MapReduce framework splits the entire document into several chunks for LLMs to read and then aggregates the intermediate answers to produce the final output. The main challenge for divide-and-conquer long text processing frameworks lies in the risk of losing essential long-range information when splitting the document, which can lead the model to produce incomplete or incorrect answers based on the segmented texts. Disrupted long-range information can be classified into two categories: inter-chunk dependency and inter-chunk conflict. We design a structured information protocol to better cope with inter-chunk dependency and an in-context confidence calibration mechanism to resolve inter-chunk conflicts. Experimental results demonstrate that LLM$\times$MapReduce can outperform representative open-source and commercial long-context LLMs, and is applicable to several different models.",289442727,4,17,,
10.18653/v1/2025.acl-long.1411,Performance Gap in Entity Knowledge Extraction Across Modalities in Vision Language Models,"I. Bernard Cohen, Daniela Gottesman, Mor Geva, Raja Giryes",(missing journal),2025,(missing abstract),289442729,0,0,,
10.18653/v1/2025.acl-long.1279,RADAR: Enhancing Radiology Report Generation with Supplementary Knowledge Injection,"Wenjun Hou, Cheng Yi, Kaishuai Xu, Heng Li, Yan Hu, Wenjie Li, Jiang Liu",(missing journal),2025,(missing abstract),289442731,0,0,,
10.18653/v1/2025.acl-long.1290,Advancing SMoE for Continuous Domain Adaptation of MLLMs: Adaptive Router and Domain-Specific Loss,"Liang Zhang, Ziyao Lu, Fandong Meng, Hui Li, Jie Zhou, Jinsong Su",(missing journal),2025,(missing abstract),289442733,0,0,,
10.18653/v1/2025.acl-long.1296,Do Language Models Understand Honorific Systems in Javanese?,"Mohammad Rifqi Farhansyah, I Dewa Made Bayu Atmaja Darmawan, Adryan Kusumawardhana, Genta Indra Winata, Alham Fikri Aji, Derry Wijaya",(missing journal),2025,(missing abstract),289442735,0,0,,
10.18653/v1/2025.acl-long.1311,CoAM: Corpus of All-Type Multiword Expressions,"Yusuke Ide, Joshua Tanner, Adam Nohejl, J. M. HOFFMAN, Justin Vasselli, Hidetaka Kamigaito, Taro Watanabe",(missing journal),2025,(missing abstract),289442737,0,0,,
10.18653/v1/2025.acl-long.1278,Balancing Diversity and Risk in LLM Sampling: How to Select Your Method and Parameter for Open-Ended Text Generation,"Yuxuan Zhou, Margret Keuper, Mario Fritz",(missing journal),2025,(missing abstract),289442739,1,0,,
10.18653/v1/2025.acl-long.1277,Mixtures of In-Context Learners,"Giwon Hong, Emile van Krieken, Edoardo Maria Ponti, Nikolay Malkin, Pasquale Minervini",(missing journal),2025,(missing abstract),289442741,0,0,,
10.18653/v1/2025.acl-long.1256,Culture is Not Trivia: Sociocultural Theory for Cultural NLP,"Naitian Zhou, David Bamman, Isaac L. Bleaman",(missing journal),2025,(missing abstract),289442743,1,0,,
10.18653/v1/2025.acl-long.1251,Temporal Relation Extraction in Clinical Texts: A Span-based Graph Transformer Approach,"Rochana Chaturvedi, Peyman Baghershahi, Sourav Medya, Barbara Di Eugenio",(missing journal),2025,(missing abstract),289442745,0,0,,
10.18653/v1/2025.acl-long.1231,Efficient Ensemble for Fine-tuning Language Models on Multiple Datasets,"Dongyue Li, Ziniu Zhang, Lu Wang, Hongyang R. Zhang",(missing journal),2025,(missing abstract),289442747,0,0,,
10.18653/v1/2025.acl-long.1072,CoIR: A Comprehensive Benchmark for Code Information Retrieval Models,"Xiangyang Li, Kuicai Dong, Yi Quan Lee, Xia Wei, Hao Zhang, Xinyi Dai, Yasheng Wang, Ruiming Tang",(missing journal),2025,(missing abstract),289446305,0,0,,
10.18653/v1/2025.acl-long.1128,MT-RAIG: Novel Benchmark and Evaluation Framework for Retrieval-Augmented Insight Generation over Multiple Tables,"Kwangwook Seo, Deukwoo Kwon, Dongha Lee",(missing journal),2025,(missing abstract),289446307,0,0,,
10.18653/v1/2025.acl-long.1165,Enhancing Machine Translation with Self-Supervised Preference Data,"Haoxiang Sun, Ruize Gao, Pei Zhang, Baosong Yang, Rui Wang",(missing journal),2025,(missing abstract),289446309,0,0,,
10.18653/v1/2025.acl-long.1140,MobiLoRA: Accelerating LoRA-based LLM Inference on Mobile Devices via Context-aware KV Cache Optimization,"Borui Li, Yitao Wang, Haoran Ma, Ligeng Chen, Jun Xiao, Shuai Wang",(missing journal),2025,(missing abstract),289446311,0,0,,
10.18653/v1/2025.acl-long.1169,Uncertainty-Aware Iterative Preference Optimization for Enhanced LLM Reasoning,"Lei Li, Hehuan Liu, Yu Zhou, Zhiguo Gui, Xudong Weng, Yi Yuan, Zheng Wei, Zang Li",(missing journal),2025,(missing abstract),289446313,0,0,,
10.18653/v1/2025.acl-long.1043,OZSpeech: One-step Zero-shot Speech Synthesis with Learned-Prior-Conditioned Flow Matching,"Nguyen Quang Hieu, Son Nguyen, Ha Dang, Thieu Vo, Truong Son Hy, Van‐Dinh Nguyen",(missing journal),2025,(missing abstract),289446315,0,0,,
10.18653/v1/2025.acl-long.1073,Enhancing Multimodal Retrieval via Complementary Information Extraction and Alignment,"Delong Zeng, Yuexiang Xie, Yunfei Li, Ying Shen",(missing journal),2025,(missing abstract),289446317,0,0,,
10.18653/v1/2025.acl-long.992,Error-driven Data-efficient Large Multimodal Model Tuning,"Barry Menglong Yao, Qifan Wang, Lifu Huang",(missing journal),2025,(missing abstract),289446319,1,0,,
10.18653/v1/2025.acl-long.981,Beyond Prompting: An Efficient Embedding Framework for Open-Domain Question Answering,"Zhanghao Hu, Hanqi Yan, Qinglin Zhu, Zhenyi Shen, Yulan He, Lin Gui",(missing journal),2025,(missing abstract),289446321,0,0,,
10.18653/v1/2025.acl-long.1070,IndicSynth: A Large-Scale Multilingual Synthetic Speech Dataset for Low-Resource Indian Languages,"Divya Sharma, Vijval Ekbote, Anubha Gupta",(missing journal),2025,(missing abstract),289446323,0,0,,
10.18653/v1/2025.acl-long.1065,GUICourse: From General Vision Language Model to Versatile GUI Agent,"Wentong Chen, Junbo Cui, Jinyi Hu, Yujia Qin, Junjie Fang, Yue Zhao, Chongyi Wang, Jun Liu, Guirong Chen, Yupeng Huo, Yuan Yao, Yankai Lin, Zhiyuan Liu, Maosong Sun",(missing journal),2025,(missing abstract),289446325,0,0,,
10.18653/v1/2025.acl-long.889,RUBY: An Effective Framework for Multi-Constraint Multi-Hop Question Generation,"Wenlu Zhao, Shuangyin Li",(missing journal),2025,(missing abstract),289446327,0,0,,
10.18653/v1/2025.acl-long.900,Exploring Persona Sentiment Sensitivity in Personalized Dialogue Generation,"Yonghyun Jun, Hwanhee Lee",(missing journal),2025,(missing abstract),289446329,0,0,,
10.18653/v1/2025.acl-long.895,CodeTool: Enhancing Programmatic Tool Invocation of LLMs via Process Supervision,"YifeiLu YifeiLu, Fanghua Ye, Jian Li, Qiang Gao, Cheng Liu, Haibo Luo, Nan Du, Xiaolong Li, Feiliang Ren",(missing journal),2025,(missing abstract),289446331,0,0,,
10.18653/v1/2025.acl-long.946,From Outcomes to Processes: Guiding PRM Learning from ORM for Inference-Time Alignment,"Bin Xie, Bingbing Xu, Yige Yuan, S. Zhu, Huawei Shen",(missing journal),2025,(missing abstract),289446333,0,0,,
10.18653/v1/2025.acl-long.934,SConU: Selective Conformal Uncertainty in Large Language Models,"Zhiyuan Wang, Qingni Wang, Yue Zhang, Tianlong Chen, Xiaofeng Zhu, Xiaoshuang Shi, Kaidi Xu",(missing journal),2025,(missing abstract),289446335,0,0,,
10.18653/v1/2025.acl-long.1017,Substance over Style: Evaluating Proactive Conversational Coaching Agents,"Vidya Srinivas, Xuhai Xu, Xin Liu, Kumar Ayush, Isaac R. Galatzer‐Levy, Shwetak Patel, Daniel McDuff, Tim Althoff",(missing journal),2025,(missing abstract),289446337,0,0,,
10.18653/v1/2025.acl-long.969,CU-MAM: Coherence-Driven Unified Macro-Structures for Argument Mining,"Debela Gemechu, Chris Reed",(missing journal),2025,(missing abstract),289446339,0,0,,
10.18653/v1/2025.acl-long.1012,Adversarial Tokenization,"Renato Geh, Zilei Shao, Guy Van den Broeck",(missing journal),2025,(missing abstract),289446341,0,0,,
10.18653/v1/2025.acl-long.788,EvolveBench: A Comprehensive Benchmark for Assessing Temporal Awareness in LLMs on Evolving Knowledge,"Zhiyuan Zhu, Yusheng Liao, Zhe Chen, Yuhao Wang, Yudong Guan, Yanfeng Wang, Yu Wang",(missing journal),2025,(missing abstract),289446343,0,0,,
10.18653/v1/2025.acl-long.869,Masking in Multi-hop QA: An Analysis of How Language Models Perform with Context Permutation,"Wenyu Huang, Pavlos Vougiouklis, Mirella Lapata, Jeff Z. Pan",(missing journal),2025,(missing abstract),289446347,0,0,,
10.18653/v1/2025.acl-long.784,How to Mitigate Overfitting in Weak-to-strong Generalization?,"Junhao Shi, Qinyuan Cheng, Zhaoye Fei, Yining Zheng, Qipeng Guo, Xipeng Qiu",(missing journal),2025,(missing abstract),289446349,0,0,,
10.18653/v1/2025.acl-long.835,DualGuard: A Parameter Space Transformation Approach for Bidirectional Defense in Split-Based LLM Fine-Tuning,"Zihan Liu, Yizhen Wang, Rui Wang, Sai Wu",(missing journal),2025,(missing abstract),289446351,0,0,,
10.18653/v1/2025.acl-long.876,From Isolates to Families: Using Neural Networks for Automated Language Affiliation,"Frederic Blum, Steffen Herbold, Johann‐Mattis List",(missing journal),2025,(missing abstract),289446353,0,0,,
10.18653/v1/2025.acl-long.1200,Retrospective Learning from Interactions,"Zizhao Chen, Mustafa Omer Gul, Yiwei Chen, Gloria Geng, Anqi Wu, Yoav Artzi",(missing journal),2025,(missing abstract),289446355,0,0,,
10.18653/v1/2025.acl-long.1198,OMGM: Orchestrate Multiple Granularities and Modalities for Efficient Multimodal Retrieval,"Wei Yang, Jingjing Fu, Rui Wang, Jinyu Wang, Lei Song, 将尚 渡辺",(missing journal),2025,(missing abstract),289446357,0,0,,
10.18653/v1/2025.acl-long.1172,Marco-Bench-MIF: On Multilingual Instruction-Following Capability of Large Language,"Bo Zeng, Chenyang Lyu, Sinuo Liu, Mingyan Zeng, Minghao Wu, Xuanfan Ni, Tianqi Shi, Yu Zhao, Yefeng Liu, Chenyu Zhu, Ruizhe Li, Jiahui Geng, Li Q, Tong Yu, Longyue Wang, Weihua Luo, Kaifu Zhang",(missing journal),2025,(missing abstract),289446361,0,0,,
10.18653/v1/2025.acl-long.1203,SOTOPIA-: Dynamic Strategy Injection Learning and Social Instruction Following Evaluation for Social Agents,"W. Zhang, Tianyun Liu, Mengxiao Song, Xiaodong Li, Tingwen Liu",(missing journal),2025,(missing abstract),289446363,0,0,,
10.18653/v1/2025.acl-long.742,Towards Omni-RAG: Comprehensive Retrieval-Augmented Generation for Large Language Models in Medical Applications,"Zhe Chen, Yusheng Liao, Shuyang Jiang, Pingjie Wang, Y. P. Guo, Yanfeng Wang, Yu Wang",(missing journal),2025,(missing abstract),289446365,2,0,,
10.18653/v1/2025.acl-long.767,Controllable Style Arithmetic with Language Models,"Weiqi Wang, Wengang Zhou, Zijing Zhang, Jietang Zhao, Houqiang Li",(missing journal),2025,(missing abstract),289446367,0,0,,
10.18653/v1/2025.acl-long.734,Cross-Lingual Optimization for Language Transfer in Large Language Models,"Jungseob Lee, Seongtae Hong, Hyeonseok Moon, Heuiseok Lim",(missing journal),2025,(missing abstract),289446369,0,0,,
10.18653/v1/2025.acl-long.748,DCG-SQL: Enhancing In-Context Learning for Text-to-SQL with Deep Contextual Schema Link Graph,"Jihyung Lee, Jin-Seop Lee, Jaehoon Lee, YunSeok Choi, Jee-Hyong Lee",(missing journal),2025,(missing abstract),289446371,0,0,,
10.18653/v1/2025.acl-long.675,YESciEval: Robust LLM-as-a-Judge for Scientific Question Answering,"Jennifer D’Souza, Hamed Babaei Giglou, Quentin Münch",(missing journal),2025,(missing abstract),289446373,0,0,,
10.18653/v1/2025.acl-long.624,Unveiling Attractor Cycles in Large Language Models: A Dynamical Systems View of Successive Paraphrasing,"Zhilin Wang, Yafu Li, Jianhao Yan, Yu Cheng, Yue Zhang",(missing journal),2025,(missing abstract),289446375,0,0,,
10.18653/v1/2025.acl-long.640,CLAIM: Mitigating Multilingual Object Hallucination in Large Vision-Language Models with Cross-Lingual Attention Intervention,"Zekai Ye, Qiming Li, Xiaocheng Feng, L. Q. Qin, Yichong Huang, Baohang Li, Kui Jiang, Yang Xiang, Zhirui Zhang, Yunfei Lu, Duyu Tang, Dandan Tu, Bing Qin",(missing journal),2025,(missing abstract),289446377,1,0,,
10.18653/v1/2025.acl-long.663,ReflecTool: Towards Reflection-Aware Tool-Augmented Clinical Agents,"Yusheng Liao, Shuyang Jiang, Yanfeng Wang, Yu Wang",(missing journal),2025,(missing abstract),289446379,1,0,,
10.18653/v1/2025.acl-long.685,SPECTRA: Faster Large Language Model Inference with Optimized Internal and External Speculation,"Nguyen-Khang Le, Dinh Quang Truong, Le-Minh Nguyen",(missing journal),2025,(missing abstract),289446381,0,0,,
10.18653/v1/2025.acl-long.627,Beyond Surface Simplicity: Revealing Hidden Reasoning Attributes for Precise Commonsense Diagnosis,"Huijun Lian, Z. T. Sun, Keqi Chen, Yingming Gao, Ya Li",(missing journal),2025,(missing abstract),289446383,0,0,,
10.18653/v1/2025.acl-long.696,"Towards Comprehensive Argument Analysis in Education: Dataset, Tasks, and Method","Yupei Ren, Xinyi Zhou, Ning Zhang, Shangqing Zhao, Mingjun Lan, Xiaopeng Bai",(missing journal),2025,(missing abstract),289446385,0,0,,
10.18653/v1/2025.acl-long.693,UniRAG: Unified Query Understanding Method for Retrieval Augmented Generation,"Rui Li, Liyang He, Qi Liu, Zheng Zhang, Heng Yu, Yuyang Ye, Linbo Zhu, Yu Su",(missing journal),2025,(missing abstract),289446387,0,0,,
10.18653/v1/2025.acl-long.673,FlashAudio: Rectified Flow for Fast and High-Fidelity Text-to-Audio Generation,"Huadai Liu, Jialei Wang, Rongjie Huang, Yan Liu, Heng Lu, Zhou Zhao, Weiwei Xue",(missing journal),2025,(missing abstract),289446389,0,0,,
10.18653/v1/2025.acl-long.602,RSCF: Relation-Semantics Consistent Filter for Entity Embedding of Knowledge Graph,"Jun-Sik Kim, Jinwook Park, Kangil Kim",(missing journal),2025,(missing abstract),289446391,0,0,,
10.18653/v1/2025.acl-long.637,Upcycling Instruction Tuning from Dense to Mixture-of-Experts via Parameter Merging,"Tingfeng Hui, Zhenyu Zhang, Shuohuan Wang, Yu Sun, Hua Wu, Sen Su",(missing journal),2025,(missing abstract),289446393,0,0,,
10.18653/v1/2025.acl-long.532,PrivacyRestore: Privacy-Preserving Inference in Large Language Models via Privacy Removal and Restoration,"Ziqian Zeng, J.H. Wang, Jingjing Yang, Zhengdong Lu, Haoran Li, Huiping Zhuang, Cen Chen",(missing journal),2025,(missing abstract),289446395,1,0,,
10.18653/v1/2025.acl-long.554,Large Language and Protein Assistant for Protein-Protein Interactions Prediction,"Peng Zhou, Pengsen Ma, Jianmin Wang, Xin Cai, Hsiao‐Wen Huang, Wei Liu, Lu Wang, Lai Hou Tim, Xiangxiang Zeng",(missing journal),2025,(missing abstract),289446397,0,0,,
10.18653/v1/2025.acl-long.559,SoRFT: Issue Resolving with Subtask-oriented Reinforced Fine-Tuning,"Zexiong Ma, Chao Peng, Pengfei Gao, Xiangxin Meng, Yanzhen Zou, Bing Xie",(missing journal),2025,(missing abstract),289446399,0,0,,
10.18653/v1/2025.acl-long.548,Improving Factuality with Explicit Working Memory,"Mingda Chen, Li Yang, Karthik K. Padthe, Rulin Shao, Alicia Sun, Luke Zettlemoyer, Gargi Ghosh, Wen-tau Yih",(missing journal),2025,(missing abstract),289446401,0,0,,
10.18653/v1/2025.acl-long.560,MiniLongBench: The Low-cost Long Context Understanding Benchmark for Large Language Models,"Zhongzhan Huang, Guoming Ling, Shanshan Zhong, Hefeng Wu, Liang Lin",(missing journal),2025,(missing abstract),289446403,0,0,,
10.18653/v1/2025.acl-long.516,The Knowledge Microscope: Features as Better Analytical Lenses than Neurons,"Yuheng Chen, Pengfei Cao, Kang Liu, Jun Zhao",(missing journal),2025,(missing abstract),289446405,0,0,,
10.18653/v1/2025.acl-long.368,Mining Complex Patterns of Argumentative Reasoning in Natural Language Dialogue,"Ramon Ruiz-Dolz, Zlata Kikteva, John Lawrence",(missing journal),2025,(missing abstract),289446407,0,0,,
10.18653/v1/2025.acl-long.429,Understanding In-Context Machine Translation for Low-Resource Languages: A Case Study on Manchu,"Renhao Pei, Yihong Liu, Peiqin Lin, François Yvon, Hinrich Schuetze",(missing journal),2025,(missing abstract),289446409,0,0,,
10.18653/v1/2025.acl-long.336,Can Language Models Reason about Individualistic Human Values and Preferences?,"Liwei Jiang, Taylor Sorensen, Sydney Levine, Yejin Choi",(missing journal),2025,(missing abstract),289446411,1,0,,
10.18653/v1/2025.acl-long.433,Large Language and Reasoning Models are Shallow Disjunctive Reasoners,"Irtaza Khalid, Amir Masoud Nourollah, Steven Schockaert",Annual Meeting of the Association for Computational Linguistics,2025,"Large Language Models (LLMs) have been found to struggle with systematic reasoning. Even on tasks where they appear to perform well, their performance often depends on shortcuts, rather than on genuine reasoning abilities, leading them to collapse on out-of-distribution (OOD) examples. Post-training strategies based on reinforcement learning and chain-of-thought prompting have recently been hailed as a step change. However, little is known about the potential of the resulting ``Large Reasoning Models'' (LRMs) beyond maths and programming-based problem solving, where genuine OOD problems can be sparse. In this paper, we focus on tasks that require systematic relational composition for qualitative spatial and temporal reasoning. The setting allows fine control over problem difficulty to precisely measure OOD generalization. We find that, zero-shot LRMs generally outperform their LLM counterparts in single-path reasoning tasks but struggle in the multi-path setting. Whilst showing comparatively better results, fine-tuned LLMs are also not capable of multi-path generalization. We also provide evidence for the behavioral interpretation for this, i.e., that LRMs are shallow disjunctive reasoners.",289446413,2,45,,
10.18653/v1/2025.acl-long.330,That is Unacceptable: the Moral Foundations of Canceling,"Siu Hing Lo, Óscar Araque, Rajesh Sharma, Marco Antonio Stranisci",(missing journal),2025,(missing abstract),289446415,0,0,,
10.18653/v1/2025.acl-long.414,Revisiting Classical Chinese Event Extraction with Ancient Literature Information,"Xiaoyi Bao, Zhongqing Wang, Jinghang Gu, Chu‐Ren Huang",(missing journal),2025,(missing abstract),289446417,0,0,,
10.18653/v1/2025.acl-long.464,INJONGO: A Multicultural Intent Detection and Slot-filling Dataset for 16 African Languages,"Hao Yu, Jesujoba Oluwadara Alabi, Andiswa Bukula, Jian Yun Zhuang, En-Shiun Annie Lee, Tadesse Kebede Guge, Israel Abebe Azime, Happy Buzaaba, Blessing Sibanda, Godson Koffi Kalipe, Jonathan Mukiibi, Salomon Kabongo Kabenamualu, Mmasibidi Setaka, Lolwethu Ndolela, Nkiruka Odu, Rooweither Mabuya, Shamsuddeen Hassan Muhammad, Salomey Osei, Sokhar Samb, Dietrich Klakow, David Ifeoluwa Adelani",(missing journal),2025,(missing abstract),289446419,0,0,,
10.18653/v1/2025.acl-long.261,RPO: Retrieval Preference Optimization for Robust Retrieval-Augmented Generation,"Shi-Qi Yan, Quan Liu, Zhen-Hua Ling",(missing journal),2025,(missing abstract),289446423,1,0,,
10.18653/v1/2025.acl-long.208,AdaEdit: Advancing Continuous Knowledge Editing For Large Language Models,"Qi Li, Xiaowen Chu",(missing journal),2025,(missing abstract),289458191,0,0,,
10.18653/v1/2025.acl-long.181,Pre-training Distillation for Large Language Models: A Design Space Exploration,"Hao Peng, Xin Lv, Yushi Bai, Zijun Yao, Jiajie Zhang, Lei Hou, Juanzi Li",(missing journal),2025,(missing abstract),289458193,0,0,,
10.18653/v1/2025.acl-long.220,DeepSolution: Boosting Complex Engineering Solution Design via Tree-based Exploration and Bi-point Thinking,"Zhuoqun Li, Haiyang Yu, Xuanang Chen, Hongyu Lin, Yaojie Lu, Fei Huang, Xianpei Han, Yongbin Li, Le Sun",(missing journal),2025,(missing abstract),289458195,1,0,,
10.18653/v1/2025.acl-long.211,BELLE: A Bi-Level Multi-Agent Reasoning Framework for Multi-Hop Question Answering,"Taolin Zhang, Dongyang Li, Qizhou Chen, Chengyu Wang, Xiaofeng He",(missing journal),2025,(missing abstract),289458197,0,0,,
10.18653/v1/2025.acl-long.116,LegalAgentBench: Evaluating LLM Agents in Legal Domain,"Haitao Li, Junjie Chen, Jingli Yang, Qingyao Ai, Jia Wei, Youfeng Liu, Kai‐Hsin Lin, Yueyue Wu, Guozhi Yuan, Yiran Hu, Wuyue Wang, Yiqun Liu, Minlie Huang",(missing journal),2025,(missing abstract),289458199,2,0,,
10.18653/v1/2025.acl-long.108,Modular Sentence Encoders: Separating Language Specialization from Cross-Lingual Alignment,"Yongxin Huang, Kexin Wang, Goran Glavaš, Iryna Gurevych",(missing journal),2025,(missing abstract),289458201,0,0,,
10.18653/v1/2025.acl-long.91,TUNA: Comprehensive Fine-grained Temporal Understanding Evaluation on Dense Dynamic Videos,"Fanyu Kong, Jingyuan Zhang, Hongzhi Zhang, Feng Shi, Daling Wang, Linhao Yu, Xingguang Ji, Yu Tian, V. W., Fuzheng Zhang",(missing journal),2025,(missing abstract),289458203,0,0,,
10.18653/v1/2025.acl-long.160,"No Questions are Stupid, but some are Poorly Posed: Understanding Poorly-Posed Information-Seeking Questions","Neha Srikanth, Rachel Rudinger, Jordan Lee Boyd-Graber",(missing journal),2025,(missing abstract),289458205,0,0,,
10.18653/v1/2025.acl-long.121,Assessment and manipulation of latent constructs in pre-trained language models using psychometric scales,"Maor Reuben, Ortal Slobodin, Idan-Chaim Cohen, Aviad Elyashar, Orna Braun‐Lewensohn, Odeya Cohen, Rami Puzis",(missing journal),2025,(missing abstract),289458207,0,0,,
10.18653/v1/2025.acl-long.100,Second Language (Arabic) Acquisition of LLMs via Progressive Vocabulary Expansion,"Jianqing Zhu, Huang Huang, Lin Zhan, Juhao Liang, Zhengyang Tang, Khalid Almubarak, Mosen Alharthi, Bang An, Juncai He, Xiangbo Wu, Fei Yu, Junying Chen, Ma Zhuoheng, Yuhao Du, He Zhang, Saied Alshahrani, Emad A. Alghamdi, Lian Zhang, Ruoyu Sun, Haizhou Li, Benyou Wang, Jinchao Xu",(missing journal),2025,(missing abstract),289458209,0,0,,
10.18653/v1/2025.acl-long.59,Interlocking-free Selective Rationalization Through Genetic-based Learning,"Federico Ruggeri, Gaetano Signorelli",(missing journal),2025,(missing abstract),289458211,0,0,,
10.18653/v1/2025.acl-long.44,Re-ranking Using Large Language Models for Mitigating Exposure to Harmful Content on Social Media Platforms,"Rajvardhan Oak, Muhammad Haroon, Claire Wonjeong Jo, Magdalena Wojcieszak, Anshuman Chhabra",(missing journal),2025,(missing abstract),289458215,0,0,,
10.18653/v1/2025.acl-long.19,Towards Robust and Efficient Federated Low-Rank Adaptation with Heterogeneous Clients,"Junemo Koo, Minwoo Jang, Jungseul Ok",(missing journal),2025,(missing abstract),289458219,0,0,,
10.18653/v1/2025.acl-long.13,GAPO: Learning Preferential Prompt through Generative Adversarial Policy Optimization,"Zhouhong Gu, Xingzhou Chen, Xiaoran Shi, Tao Wang, Suhang Zheng, Tianyu Li, Hongwei Feng, Yanghua Xiao",(missing journal),2025,(missing abstract),289458223,0,0,,
10.18653/v1/2025.acl-long.0,Front Matter,"Wanxiang Che, Joyce Nabende, Ekaterina Shutova, Mohammad Taher Pilehvar",(missing journal),2025,(missing abstract),289458227,0,0,,
10.18653/v1/2025.acl-long.21,Capture the Key in Reasoning to Enhance CoT Distillation Generalization,"Chengwei Dai, Ke Li, Wei Zhou, Songlin Hu",(missing journal),2025,(missing abstract),289458231,0,0,,
10.18653/v1/2025.acl-long.11,StrucText-Eval: Evaluating Large Language Model’s Reasoning Ability in Structure-Rich Text,"Zhouhong Gu, Haoning Ye, Xingzhou Chen, Zeyang Zhou, Hongwei Feng, Yanghua Xiao",(missing journal),2025,(missing abstract),289458239,0,0,,
10.18653/v1/2025.acl-long.1518,Re3Syn: A Dependency-Based Data Synthesis Framework for Long-Context Post-training,"Zhiyang Zhang, Ziqiang Liu, Huiming Wang, Renliang Shan, Li Kuang, Lu Wang, De Wen Soh",(missing journal),2025,(missing abstract),289458481,0,0,,
10.18653/v1/2025.acl-long.1566,Magnet: Multi-turn Tool-use Data Synthesis and Distillation via Graph Translation,"Fan Yin, Zifeng Wang, I-Hung Hsu, Jun Yan, Ke Jiang, Yanfei Chen, Jindong Gu, Long Tan Le, Kai-Wei Chang, Chen-Yu Lee, Hamid Palangi, Tomas Pfister",(missing journal),2025,(missing abstract),289458483,0,0,,
10.18653/v1/2025.acl-long.1594,SocialCC: Interactive Evaluation for Cultural Competence in Language Agents,"Jincenzi Wu, Jianxun Lian, Dingdong Wang, Helen Meng",(missing journal),2025,(missing abstract),289458485,0,0,,
10.18653/v1/2025.acl-long.1536,Separating Tongue from Thought: Activation Patching Reveals Language-Agnostic Concept Representations in Transformers,"Chair Julie Dumas, Chris Wendler, Veniamin Veselovsky, Giovanni Monea, Robert West",(missing journal),2025,(missing abstract),289458487,0,0,,
10.18653/v1/2025.acl-long.1581,CFBench: A Comprehensive Constraints-Following Benchmark for LLMs,"Tao Zhang, Chenqi Zhu, Yanjun Shen, Wenjing Luo, Yan Zhang, Hao Liang, Tao Zhang, Fan Yang, Mingan Lin, Yujing Qiao, Weipeng Chen, Bin Cui, Wentao Zhang, Zenan Zhou",(missing journal),2025,(missing abstract),289458489,0,0,,
10.18653/v1/2025.acl-long.1586,Robust Estimation of Population-Level Effects in Repeated-Measures NLP Experimental Designs,"Alejandro Benito-Santos, Adrián Ghajari, Víctor Fresno",(missing journal),2025,(missing abstract),289458491,0,0,,
10.18653/v1/2025.acl-long.1597,Towards Economical Inference: Enabling DeepSeek’s Multi-Head Latent Attention in Any Transformer-based LLMs,"Tao Ji, Bin Guo, Yuanbin Wu, Qipeng Guo, Shenlixing Shenlixing, Chenzhan Chenzhan, Xipeng Qiu, Qi Zhang, Tao Gui",(missing journal),2025,(missing abstract),289458493,3,0,,
10.18653/v1/2025.acl-long.1580,NewsInterview: a Dataset and a Playground to Evaluate LLMs’ Grounding Gap via Informational Interviews,"Alexander Spangher, Michael C. Lu, Sriya Kalyan, Hyundong Justin Cho, Tenghao Huang, Weiyan Shi, Jonathan May",(missing journal),2025,(missing abstract),289458495,0,0,,
10.18653/v1/2025.acl-long.1540,Deliberate Reasoning in Language Models as Structure-Aware Planning with an Accurate World Model,"Siheng Xiong, Ali Payani, Yuan Yang, Faramarz Fekri",Annual Meeting of the Association for Computational Linguistics,2025,"Enhancing the reasoning capabilities of language models (LMs) remains a key challenge, especially for tasks that require complex, multi-step decision-making where existing Chain-of-Thought (CoT) approaches struggle with consistency and verification. In this paper, we propose a novel reasoning framework, referred to as Structure-aware Planning with an Accurate World Model (SWAP), that integrates structured knowledge representation with learned planning. Unlike prior methods that rely purely on natural language reasoning, SWAP leverages entailment graphs to encode structured dependencies and enable symbolic verification of intermediate steps. To systematically construct and update the graph, SWAP employs a policy model to propose candidate expansions and a world model to predict structural updates. To improve accuracy, the world model generates multiple alternative updates, and a discriminator re-ranks them based on plausibility. To encourage diverse exploration, we introduce Diversity-based Modelling (DM), which samples candidates from the remaining probability mass after removing previously sampled candidates from the original policy distribution. Additionally, SWAP improves the discrimination accuracy through Contrastive Ranking (CR), which directly compares candidates within prompts and incorporates meta-knowledge to improve ranking quality. We evaluate SWAP across diverse reasoning-intensive benchmarks including math reasoning, logical reasoning, and coding tasks. Extensive experiments demonstrate that SWAP significantly improves upon the base models and consistently outperforms existing reasoning methods.",289458497,8,86,,
10.18653/v1/2025.acl-long.1509,Batayan: A Filipino NLP benchmark for evaluating Large Language Models,"Jann Railey Montalan, Jimson Paulo Layacan, David Demitri Africa, R. Flores, Manuel López López, Theresa Denise Magsajo, Anjanette Cayabyab, William Chandra Tjhi",(missing journal),2025,(missing abstract),289458499,1,0,,
10.18653/v1/2025.acl-long.1513,"PolyNarrative: A Multilingual, Multilabel, Multi-domain Dataset for Narrative Extraction from News Articles","Nikos Nikolaidis, Nicolas Stefanovitch, Purificação Silvano, Dimitar Dimitrov, Roman Yangarber, Nuno Guimar�ães, Elisa Sartori, Ion Androutsopoulos, Preslav Nakov, Giovanni Da San Martino, Jakub Piskorski",(missing journal),2025,(missing abstract),289458501,0,0,,
10.18653/v1/2025.acl-long.1483,ISR: Self-Refining Referring Expressions for Entity Grounding,"Zhizhi Yu, Bin Zhao, Yifan Song, Sujian Li, Zhonghui He",(missing journal),2025,(missing abstract),289458503,0,0,,
10.18653/v1/2025.acl-long.1456,VISA: Retrieval Augmented Generation with Visual Source Attribution,"Xueguang Ma, Shengyao Zhuang, Bevan Koopman, Guido Zuccon, Wenhu Chen, Jimmy Lin",(missing journal),2025,(missing abstract),289458505,1,0,,
10.18653/v1/2025.acl-long.1467,Predicting Implicit Arguments in Procedural Video Instructions,"Anil Batra, Laura Sevilla-Lara, Marcus Rohrbach, Frank Keller",(missing journal),2025,(missing abstract),289458507,0,0,,
10.18653/v1/2025.acl-long.1505,English-based acoustic models perform well in the forced alignment of two English-based Pacific Creoles,"Sam Passmore, Lila San Roque, Kirsty Gillespie, Sanghamitra Nath, Kira Davey, Kerry Mullan, Tim Cawley, Jennifer Biggs, Rosey Billington, Bethwyn Evans, Nick Thieberger, Danielle Barth",(missing journal),2025,(missing abstract),289458509,0,0,,
10.18653/v1/2025.acl-long.1432,Programming by Example meets Historical Linguistics: A Large Language Model Based Approach to Sound Law Induction,"Atharva Naik, D. C. Agrawal, Hong Sng, Clayton Marr, Kexun Zhang, Nathaniel Romney Robinson, Kalvin Chang, Rebecca Byrnes, Aravind Mysore, Carolyn Penstein Rosé, David R. Mortensen",(missing journal),2025,(missing abstract),289458511,0,0,,
10.18653/v1/2025.acl-long.1348,Online Iterative Self-Alignment for Radiology Report Generation,"Ting Xiao, Lei Shi, Y.S. Zhang, Huabin Yang, Zhe Wang, Chenjia Bai",(missing journal),2025,(missing abstract),289458513,0,0,,
10.18653/v1/2025.acl-long.1364,Persistent Homology of Topic Networks for the Prediction of Reader Curiosity,"Marie-T Hopp, Vincent Labatut, Arthur Amalvy, Richard Dufour, Hannah Stone, Hayley Jach, Kou Murayama",Annual Meeting of the Association for Computational Linguistics,2025,"Reader curiosity, the drive to seek information, is crucial for textual engagement, yet remains relatively underexplored in NLP. Building on Loewenstein's Information Gap Theory, we introduce a framework that models reader curiosity by quantifying semantic information gaps within a text's semantic structure. Our approach leverages BERTopic-inspired topic modeling and persistent homology to analyze the evolving topology (connected components, cycles, voids) of a dynamic semantic network derived from text segments, treating these features as proxies for information gaps. To empirically evaluate this pipeline, we collect reader curiosity ratings from participants (n = 49) as they read S. Collins's''The Hunger Games''novel. We then use the topological features from our pipeline as independent variables to predict these ratings, and experimentally show that they significantly improve curiosity prediction compared to a baseline model (73% vs. 30% explained deviance), validating our approach. This pipeline offers a new computational method for analyzing text structure and its relation to reader engagement.",289458515,0,41,,
10.18653/v1/2025.acl-long.1344,PRISM: A Framework for Producing Interpretable Political Bias Embeddings with Political-Aware Cross-Encoder,"Yiqun Sun, Qiang Huang, Anthony K. H. Tung, Jun Yu",(missing journal),2025,(missing abstract),289458517,0,0,,
10.18653/v1/2025.acl-long.1247,"CulturalBench: A Robust, Diverse and Challenging Benchmark for Measuring LMs’ Cultural Knowledge Through Human-AI Red-Teaming","Yu Ying Chiu, Liwei Jiang, Bill Yuchen Lin, Chan Young Park, Shuyue Stella Li, Sahithya Ravi, Mehar Bhatia, Maria Antoniak, Yulia Tsvetkov, Vered Shwartz, Yejin Choi",(missing journal),2025,(missing abstract),289458519,0,0,,
10.18653/v1/2025.acl-long.1315,"VideoVista-CulturalLingo: 360° Horizons-Bridging Cultures, Languages, and Domains in Video Comprehension","Xinyu Chen, Yunxin Li, Haoyuan Shi, Baotian Hu, Wenhan Luo, Yaowei Wang, Min Zhang",(missing journal),2025,(missing abstract),289458521,0,0,,
10.18653/v1/2025.acl-long.1152,Finding Needles in Images: Can Multi-modal LLMs Locate Fine Details?,"Parth Thakkar, Ankush Agarwal, Prasad Kasu, Pulkit Bansal, Chaitanya Devaguptapu",Annual Meeting of the Association for Computational Linguistics,2025,"While Multi-modal Large Language Models (MLLMs) have shown impressive capabilities in document understanding tasks, their ability to locate and reason about fine-grained details within complex documents remains understudied. Consider searching a restaurant menu for a specific nutritional detail or identifying a disclaimer in a lengthy newspaper article tasks that demand careful attention to small but significant details within a broader narrative, akin to Finding Needles in Images (NiM). To address this gap, we introduce NiM, a carefully curated benchmark spanning diverse real-world documents including newspapers, menus, and lecture images, specifically designed to evaluate MLLMs'capability in these intricate tasks. Building on this, we further propose Spot-IT, a simple yet effective approach that enhances MLLMs capability through intelligent patch selection and Gaussian attention, motivated from how humans zoom and focus when searching documents. Our extensive experiments reveal both the capabilities and limitations of current MLLMs in handling fine-grained document understanding tasks, while demonstrating the effectiveness of our approach. Spot-IT achieves significant improvements over baseline methods, particularly in scenarios requiring precise detail extraction from complex layouts.",289462325,0,32,,
10.18653/v1/2025.acl-long.1090,TableLoRA: Low-rank Adaptation on Table Structure Understanding for Large Language Models,"Xinyi He, Yihao Liu, Mengyu Zhou, Yeye He, Haoyu Dong, Han Shi, Zejian Yuan, Dongmei Zhang",(missing journal),2025,(missing abstract),289462327,0,0,,
10.18653/v1/2025.acl-long.1109,"CENTAUR: Bridging the Impossible Trinity of Privacy, Efficiency, and Performance in Privacy-Preserving Transformer Inference","Jinglong Luo, Guanzhong Chen, Yehong Zhang, Shiyu Liu, Hui Wang, Yue Yu, Xun Zhou, Qi Yuan, Zenglin Xu",(missing journal),2025,(missing abstract),289462329,1,0,,
10.18653/v1/2025.acl-long.1069,HACo-Det: A Study Towards Fine-Grained Machine-Generated Text Detection under Human-AI Coauthoring,"Zhonghua Su, Yichen Wang, Herun Wan, Zhaohan Zhang, Minnan Luo",(missing journal),2025,(missing abstract),289462331,0,0,,
10.18653/v1/2025.acl-long.1095,LESA: Learnable LLM Layer Scaling-Up,"Yifei Yang, Zouying Cao, Xiaofei Ma, Yao Yao, Zhi Chen, Libo Qin, Hai Zhao",(missing journal),2025,(missing abstract),289462333,0,0,,
10.18653/v1/2025.acl-long.1156,Prediction Hubs are Context-Informed Frequent Tokens in LLMs,"Brenda Nielsen, Iuri Macocco, Marco Baroni",Annual Meeting of the Association for Computational Linguistics,2025,"Hubness, the tendency for a few points to be among the nearest neighbours of a disproportionate number of other points, commonly arises when applying standard distance measures to high-dimensional data, often negatively impacting distance-based analysis. As autoregressive large language models (LLMs) operate on high-dimensional representations, we ask whether they are also affected by hubness. We first prove that the only large-scale representation comparison operation performed by LLMs, namely that between context and unembedding vectors to determine continuation probabilities, is not characterized by the concentration of distances phenomenon that typically causes the appearance of nuisance hubness. We then empirically show that this comparison still leads to a high degree of hubness, but the hubs in this case do not constitute a disturbance. They are rather the result of context-modulated frequent tokens often appearing in the pool of likely candidates for next token prediction. However, when other distances are used to compare LLM representations, we do not have the same theoretical guarantees, and, indeed, we see nuisance hubs appear. There are two main takeaways. First, hubness, while omnipresent in high-dimensional spaces, is not a negative property that needs to be mitigated when LLMs are being used for next token prediction. Second, when comparing representations from LLMs using Euclidean or cosine distance, there is a high risk of nuisance hubs and practitioners should use mitigation techniques if relevant.",289462335,1,33,,
10.18653/v1/2025.acl-long.1115,Around the World in 24 Hours: Probing LLM Knowledge of Time and Place,"Carolin Holtermann, Paul Röttger, Anne Lauscher",(missing journal),2025,(missing abstract),289462337,0,0,,
10.18653/v1/2025.acl-long.1061,ECLM: Entity Level Language Model for Spoken Language Understanding with Chain of Intent,"Shangjian Yin, Peijie Huang, Jiatian Chen, Haojing Huang, Yuhong Xu",Annual Meeting of the Association for Computational Linguistics,2025,"Large Language Models (LLMs) have demonstrated impressive capabilities in language generation and general task performance. However, their application to spoken language understanding (SLU) remains challenging, particularly for token-level tasks, where the autoregressive nature of LLMs often leads to misalignment issues. They also struggle to capture nuanced interrelations in semantic-level tasks through direct fine-tuning alone. To address these challenges, we propose the Entity-level Language Model (ECLM) framework, which reformulates slot-filling as an entity recognition task and introduces a novel concept, \textit{Chain of Intent}, to enable step-by-step multi-intent recognition. Experimental results show that ECLM significantly outperforms strong baselines such as Uni-MIS, achieving gains of 3.7\% on MixATIS and 3.1\% on MixSNIPS. Compared to standard supervised fine-tuning of LLMs, ECLM further achieves improvements of 8.5\% and 21.2\% on these datasets, respectively. Our code is available at https://github.com/SJY8460/ECLM.",289462339,9,26,,
10.18653/v1/2025.acl-long.1042,Can Third Parties Read Our Emotions?,"Jiayi Li, Yingfan Zhou, Pranav Narayanan Venkit, Halima Binte Islam, Sachin Arya, Shomir Wilson, Sarah Rajtmajer",(missing journal),2025,(missing abstract),289462341,1,0,,
10.18653/v1/2025.acl-long.881,Revisit Self-Debugging with Self-Generated Tests for Code Generation,"Xiaodong Chen, Zhengwei Tao, Kechi Zhang, Chunhua Zhou, Xinyu Zhang, Wei Gu, Yuanpeng He, Mengdi Zhang, Xunliang Cai, Haiyan Zhao, Zhi Jin",(missing journal),2025,(missing abstract),289462343,1,0,,
10.18653/v1/2025.acl-long.1035,Optimal Transport-Based Token Weighting scheme for Enhanced Preference Optimization,"Meng Li, Guangda Huzhang, Haibo Zhang, X L Wang, Anxiang Zeng",(missing journal),2025,(missing abstract),289462345,0,0,,
10.18653/v1/2025.acl-long.983,We-Math: Does Your Large Multimodal Model Achieve Human-like Mathematical Reasoning?,"Runqi Qiao, Qiuna Tan, Guanting Dong, MinhuiWu MinhuiWu, Chong Sun, Xiaoshuai Song, Jiapeng Wang, Zhuoma GongQue, Shanglin Lei, Yifan Zhang, Zhe Wei, Miaoxuan Zhang, Runfeng Qiao, Xiao Zong, Yida Xu, Peiqing Yang, Zhimin Bao, Muxi Diao, Li Chen, Honggang Zhang",(missing journal),2025,(missing abstract),289462347,0,0,,
10.18653/v1/2025.acl-long.912,LLaMA-Omni 2: LLM-based Real-time Spoken Chatbot with Autoregressive Streaming Speech Synthesis,"Qingkai Fang, Zhou Yan, Shoutao Guo, Shaolei Zhang, Yang Feng",(missing journal),2025,(missing abstract),289462349,0,0,,
10.18653/v1/2025.acl-long.940,Controlled Low-Rank Adaptation with Subspace Regularization for Continued Training on Large Language Models,"Yuheng Lu, Buyue Qian, Caixia Yuan, Huixing Jiang, Xiaojie Wang",(missing journal),2025,(missing abstract),289462351,0,0,,
10.18653/v1/2025.acl-long.913,Error Comparison Optimization for Large Language Models on Aspect-Based Sentiment Analysis,"Qianlong Wang, Keyang Ding, H. Gao, H. Wang, Ruifeng Xu",(missing journal),2025,(missing abstract),289462353,0,0,,
10.18653/v1/2025.acl-long.976,If Eleanor Rigby Had Met ChatGPT: A Study on Loneliness in a Post-LLM World,Adrian de Wynter,(missing journal),2025,(missing abstract),289462355,0,0,,
10.18653/v1/2025.acl-long.973,DARS: Dynamic Action Re-Sampling to Enhance Coding Agent Performance by Adaptive Tree Traversal,"Vijay Aggarwal, Ojasv Kamal, Abhinav Japesh, Zhijing Jin, Bernhard Schölkopf",(missing journal),2025,(missing abstract),289462357,0,0,,
10.18653/v1/2025.acl-long.980,Generalized Attention Flow: Feature Attribution for Transformer Models via Maximum Flow,"Behrooz Azarkhalili, Maxwell W. Libbrecht",(missing journal),2025,(missing abstract),289462359,0,0,,
10.18653/v1/2025.acl-long.818,VoxEval: Benchmarking the Knowledge Understanding Capabilities of End-to-End Spoken Language Models,"Wenqian Cui, Xiaoqi Jiao, Ziqiao Meng, Irwin King",(missing journal),2025,(missing abstract),289462361,0,0,,
10.18653/v1/2025.acl-long.854,An Expanded Massive Multilingual Dataset for High-Performance Language Technologies (HPLT),"Laurie Burchell, Ona De Gibert Bonet, Nikolay Arefyev, Mikko Aulamo, Marta Bañón, Pinzhen Chen, Mariіa Fedorova, Liane Guillou, Barry Haddow, Jan Hajič, Jindřich Helcl, Erik Henriksson, Mateusz Klimaszewski, Ville Komulainen, Andrey Kutuzov, Joona Kytöniemi, Veronika Laippala, Petter Mæhlum, Bhavitvya Malik, Farrokh Mehryary, Vladislav Mikhailov, Nikita Moghe, Amanda Myntti, David M. O'Brien, Stephan Oepen, Proyag Pal, Jousia Piha, Sampo Pyysalo, Gema Ramírez-Sánchez, David Samuel, Pavel Stepachev, Jörg Tiedemann, Dušan Variš, Tereza Vojtěchová, Jaume Zaragoza-Bernabeu",(missing journal),2025,(missing abstract),289462363,0,0,,
10.18653/v1/2025.acl-long.787,My Words Imply Your Opinion: Reader Agent-Based Propagation Enhancement for Personalized Implicit Emotion Analysis,"Jian Liao, Yu Feng, Yujin Zheng, Jun Zhao, Suge Wang, Jianxing Zheng",Annual Meeting of the Association for Computational Linguistics,2025,"The subtlety of emotional expressions makes implicit emotion analysis (IEA) particularly sensitive to user-specific characteristics. Current studies personalize emotion analysis by focusing on the author but neglect the impact of the intended reader on implicit emotional feedback. In this paper, we introduce Personalized IEA (PIEA) and present the RAPPIE model, which addresses subjective variability by incorporating reader feedback. In particular, (1) we create reader agents based on large language models to simulate reader feedback, overcoming the issue of ``spiral of silence effect'' and data incompleteness of real reader reaction. (2) We develop a role-aware multi-view graph learning to model the emotion interactive propagation process in scenarios with sparse reader information. (3) We construct two new PIEA datasets covering English and Chinese social media with detailed user metadata, addressing the text-centric limitation of existing datasets. Extensive experiments show that RAPPIE significantly outperforms state-of-the-art baselines, demonstrating the value of incorporating reader feedback in PIEA.",289462365,0,26,,
10.18653/v1/2025.acl-long.867,Faithful and Robust LLM-Driven Theorem Proving for NLI Explanations,"信之 和泉, Marco Valentino, Louise A. Dennis, André Freitas",(missing journal),2025,(missing abstract),289462367,0,0,,
10.18653/v1/2025.acl-long.792,CritiQ: Mining Data Quality Criteria from Human Preferences,"Honglin Guo, Kai Lv, Qipeng Guo, Tao Liang, Zhiheng Xi, Demin Song, Qiuyinzhe Zhang, Yufeng Sun, Chaoyu Chen, Xipeng Qiu, Tao Gui",(missing journal),2025,(missing abstract),289462369,0,0,,
10.18653/v1/2025.acl-long.844,Information Extraction from Visually Rich Documents using LLM-based Organization of Documents into Independent Textual Segments,"Asok Bhattacharyya, Anurag Tripathi, Ujjal Das, Anwesa Karmakar, Amit Kumar Pathak, Manish Gupta",(missing journal),2025,(missing abstract),289462371,0,0,,
10.18653/v1/2025.acl-long.1180,GRaMPa: Subword Regularisation by Skewing Uniform Segmentation Distributions with an Efficient Path-counting Markov Model,"Thomas Bauwens, David Kaczér, Miryam de Lhoneux",(missing journal),2025,(missing abstract),289462373,0,0,,
10.18653/v1/2025.acl-long.1176,HalluLens: LLM Hallucination Benchmark,"Yejin Bang, Ziwei Ji, Alan Schelten, Anthony S. Hartshorn, T.K. Fowler, Cheng Zhang, Nicola Cancedda, Pascale Fung",(missing journal),2025,(missing abstract),289462375,4,0,,
10.18653/v1/2025.acl-long.1201,Personalized Generation In Large Model Era: A Survey,"Yuehang Xu, Jinghao Zhang, Alireza Salemi, Xinting Hu, Wenjie Wang, Fuli Feng, Hamed Zamani, Xiangnan He, Tat‐Seng Chua",(missing journal),2025,(missing abstract),289462377,1,0,,
10.18653/v1/2025.acl-long.763,M2RC-EVAL: Massively Multilingual Repository-level Code Completion Evaluation,"Jiaheng Liu, Ken Deng, Congnan Liu, Jian Yang, Shukai Liu, He Zhu, Peng Zhao, Linzheng Chai, Yanan Wu, JinKe JinKe, Ge Zhang, Zekun Moore Wang, Guoan Zhang, Yingshui Tan, Bangyu Xiang, Zhaoxiang Zhang, Wenbo Su, Bo Zheng",(missing journal),2025,(missing abstract),289462379,0,0,,
10.18653/v1/2025.acl-long.601,Reliably Bounding False Positives: A Zero-Shot Machine-Generated Text Detection Framework via Multiscaled Conformal Prediction,"Xiaowei Zhu, Yubing Ren, Yanan Cao, Xixun Lin, Fang Fang, Yangxi Li",(missing journal),2025,(missing abstract),289462381,0,0,,
10.18653/v1/2025.acl-long.691,Learning First-Order Logic Rules for Argumentation Mining,"Yang Sun, Guanrong Chen, Hamid Alinejad‐Rokny, Jianzhu Bao, Yuqi Huang, Bin Liang, Kam‐Fai Wong, Min Yang, Ruifeng Xu",(missing journal),2025,(missing abstract),289462383,0,0,,
10.18653/v1/2025.acl-long.593,A Multi-persona Framework for Argument Quality Assessment,"Bojun Jin, Jianzhu Bao, Yufang Hou, Yang Sun, Yice Zhang, Hua‐Jie Wang, Bin Liang, Ruifeng Xu",(missing journal),2025,(missing abstract),289462385,0,0,,
10.18653/v1/2025.acl-long.591,GraphInsight: Unlocking Insights in Large Language Models for Graph Structure Understanding,"Yukun Cao, Shuo Han, Zhiqiang Gao, Zezhong Ding, Xike Xie, S Kevin Zhou",(missing journal),2025,(missing abstract),289462387,2,0,,
10.18653/v1/2025.acl-long.566,A Strategic Coordination Framework of Small LMs Matches Large LMs in Data Synthesis,"Xin Gao, Qizhi Pei, Zinan Tang, Yu Li, H. Lin, Jiang Wu, Lijun Wu, Conghui He",(missing journal),2025,(missing abstract),289462389,0,0,,
10.18653/v1/2025.acl-long.533,Meta-rater: A Multi-dimensional Data Selection Method for Pre-training Language Models,"Xinlin Zhuang, Jiahui Peng, Ren Ma, Yinfan Wang, Tianyi Bai, Xingjian Wei, Qiu Jiantao, Chi Zhang, Ying Qian, Conghui He",(missing journal),2025,(missing abstract),289462391,0,0,,
10.18653/v1/2025.acl-long.541,TWIST: Text-encoder Weight-editing for Inserting Secret Trojans in Text-to-Image Models,"Xiuwen Li, Zhe Liu, Tong Zhang, Jiahao Chen, Qingming Li, Jinbao Li, Shouling Ji",(missing journal),2025,(missing abstract),289462393,0,0,,
10.18653/v1/2025.acl-long.530,Mitigating Non-Representative Prototypes and Representation Bias in Few-Shot Continual Relation Extraction,"Thanh Duc Pham, Nam Le Hai, Linh Ngo Van, Nguyen Thi Ngoc Diep, Dinh Viet Sang, Thien Huu Nguyen",(missing journal),2025,(missing abstract),289462395,0,0,,
10.18653/v1/2025.acl-long.524,LongReD: Mitigating Short-Text Degradation of Long-Context Large Language Models via Restoration Distillation,"Zican Dong, Xia Li, Jinhao Jiang, Mingyu Xu, Wayne Xin Zhao, Bingning Wang, Weipeng Chen",(missing journal),2025,(missing abstract),289462397,0,0,,
10.18653/v1/2025.acl-long.453,Byte Latent Transformer: Patches Scale Better Than Tokens,"Artidoro Pagnoni, Ramakanth Pasunuru, Pedro Rodríguez, John Nguyen, Benjamin Müller, Margaret Li, Chunting Zhou, Lili Yu, Jason Weston, Luke Zettlemoyer, Gargi Ghosh, Michael Lewis, Ari Holtzman, Srini Iyer",(missing journal),2025,(missing abstract),289462399,1,0,,
10.18653/v1/2025.acl-long.430,"CKnowEdit: A New Chinese Knowledge Editing Dataset for Linguistics, Facts, and Logic Error Correction in LLMs","J. Fang, Tianhe Lu, Yunzhi Yao, Ziyan Jiang, Xin Xu, Huajun Chen, Ningyu Zhang",Annual Meeting of the Association for Computational Linguistics,2025,"Chinese, as a linguistic system rich in depth and complexity, is characterized by distinctive elements such as ancient poetry, proverbs, idioms, and other cultural constructs. However, current Large Language Models (LLMs) face limitations in these specialized domains, highlighting the need for the development of comprehensive datasets that can assess, continuously update, and progressively improve these culturally-grounded linguistic competencies through targeted training optimizations. To address this gap, we introduce CKnowEdit, the first-ever Chinese knowledge editing dataset designed to correct linguistic, factual, and logical errors in LLMs. We collect seven types of knowledge from a wide range of sources, including classical texts, idioms, and content from Baidu Tieba Ruozhiba, taking into account the unique polyphony, antithesis, and logical structures inherent in the Chinese language. By analyzing this dataset, we highlight the challenges current LLMs face in mastering Chinese. Furthermore, our evaluation of state-of-the-art knowledge editing techniques reveals opportunities to advance the correction of Chinese knowledge. Code and dataset are available at https://github.com/zjunlp/EasyEdit.",289462401,0,34,,
10.18653/v1/2025.acl-long.490,Think&amp;Cite: Improving Attributed Text Generation with Self-Guided Tree Search and Progress Reward Modeling,"Junyi Li, Hwee Tou Ng",(missing journal),2025,(missing abstract),289462403,0,0,,
10.18653/v1/2025.acl-long.367,MathFusion: Enhancing Mathematical Problem-solving of LLM through Instruction Fusion,"Qizhi Pei, Lijun Wu, Zhuoshi Pan, Yu Li, Honglin Lin, Chenlin Ming, Xin Gao, Cong He, Rui Yan",(missing journal),2025,(missing abstract),289462405,0,0,,
10.18653/v1/2025.acl-long.369,"OS Agents: A Survey on MLLM-based Agents for Computer, Phone and Browser Use","Xueyu Hu, Xiong Tao, Biao Yi, Zishu Wei, Ruixuan Xiao, YangQuan Chen, Jiasheng Ye, Meiling Tao, Xiangxin Zhou, Ziyu Zhao, Yuhuai Li, Shaohua Xu, Shenzhi Wang, Xinchen Xu, Shuofei Qiao, Zhaokai Wang, Kun Kuang, Tieyong Zeng, Liang Wang, Jia‐Hao Li, Yuchen Eleanor Jiang, Wangchunshu Zhou, Guoyin Wang, Keting Yin, Zhou Zhao, Hongxia Yang, Fan Wu, Shengyu Zhang, Fei Wu",(missing journal),2025,(missing abstract),289462407,1,0,,
10.18653/v1/2025.acl-long.375,Large Language Models Struggle to Describe the Haystack without Human Help: A Social Science-Inspired Evaluation of Topic Models,"Zongxia Li, Lorena Calvo-Bartolomé, Alexander Hoyle, Paiheng Xu, Daniel J. Stephens, Juan F. Fung, Alden Dima, Jordan Lee Boyd-Graber",(missing journal),2025,(missing abstract),289462409,1,0,,
10.18653/v1/2025.acl-long.353,Personalized Text Generation with Contrastive Activation Steering,"Jinghao Zhang, Yuting Liu, Wenjie Wang, Qiang Liu, Shu Wu, Liang Wang, Tat‐Seng Chua",(missing journal),2025,(missing abstract),289462411,2,0,,
10.18653/v1/2025.acl-long.362,Rolling the DICE on Idiomaticity: How LLMs Fail to Grasp Context,"Maggie Mi, Aline Villavicencio, Nafise Sadat Moosavi",(missing journal),2025,(missing abstract),289462413,1,0,,
10.18653/v1/2025.acl-long.350,A Systematic Study of Compositional Syntactic Transformer Language Models,"Yida Zhao, Hao Xve, Xiang Hu, Kewei Tu",(missing journal),2025,(missing abstract),289462415,0,0,,
10.18653/v1/2025.acl-long.306,LLaMAs Have Feelings Too: Unveiling Sentiment and Emotion Representations in LLaMA Models Through Probing,"Dario Di Palma, Alessandro Bellis, Giovanni Servedio, Vito Walter Anelli, Fedelucio Narducci, Tommaso Di Noia",(missing journal),2025,(missing abstract),289462417,0,0,,
10.18653/v1/2025.acl-long.265,Geometric Signatures of Compositionality Across a Language Model’s Lifetime,"Jin Hwa Lee, Thomas Jiralerspong, Lei Yu, Yoshua Bengio, Emily Cheng",(missing journal),2025,(missing abstract),289462419,0,0,,
10.18653/v1/2025.acl-long.302,Uncertainty Propagation on LLM Agent,"Q. C. Zhao, Dong Li, Yanchi Liu, Wei Cheng, Yiyou Sun, Mika Oishi, Takao Osaki, Katsushi Matsuda, Huaxiu Yao, Zhao Chen, Haifeng Chen, Xujiang Zhao",(missing journal),2025,(missing abstract),289462421,0,0,,
10.18653/v1/2025.acl-long.217,QAEncoder: Towards Aligned Representation Learning in Question Answering Systems,"Zhengren Wang, Qinhan Yu, Shida Wei, Zhiyu Li, Feiyu Xiong, Xiaoxing Wang, Simin Niu, Hao Liang, Wentao Zhang",(missing journal),2025,(missing abstract),289472683,0,0,,
10.18653/v1/2025.acl-long.214,Towards Text-Image Interleaved Retrieval,"Xin Zhang, Ziqi Dai, Yongqi Li, Yanzhao Zhang, Dingkun Long, Pengjun Xie, Meishan Zhang, Jun Yu, Wenjie Li, Min Zhang",(missing journal),2025,(missing abstract),289472684,0,0,,
10.18653/v1/2025.acl-long.250,Pandora’s Box or Aladdin’s Lamp: A Comprehensive Analysis Revealing the Role of RAG Noise in Large Language Models,"Jinyang Wu, Shuai Zhang, Feihu Che, Min Feng, Pengpeng Shao, Jianhua Tao",(missing journal),2025,(missing abstract),289472685,1,0,,
10.18653/v1/2025.acl-long.241,A Silver Bullet or a Compromise for Full Attention? A Comprehensive Study of Gist Token-based Context Compression,"Chenlong Deng, Zhisong Zhang, Kelong Mao, Shuaiyi Li, Xinting Huang, Dong Yu, Zhicheng Dou",(missing journal),2025,(missing abstract),289472686,0,0,,
10.18653/v1/2025.acl-long.229,Unveiling Language-Specific Features in Large Language Models via Sparse Autoencoders,"Bo Deng, Yu Wan, Baosong Yang, Yidan Zhang, Fuli Feng",(missing journal),2025,(missing abstract),289472687,0,0,,
10.18653/v1/2025.acl-long.207,TokAlign: Efficient Vocabulary Adaptation via Token Alignment,"C.‐J. LI, Jiajun Zhang, Chengqing Zong",(missing journal),2025,(missing abstract),289472688,0,0,,
10.18653/v1/2025.acl-long.177,Comparing Moral Values in Western English-speaking societies and LLMs with Word Associations,"Chaoyi Xiang, Chunhua Liu, Simon De Deyne, Lea Frermann",(missing journal),2025,(missing abstract),289472689,0,0,,
10.18653/v1/2025.acl-long.161,Understanding Common Ground Misalignment in Goal-Oriented Dialog: A Case-Study with Ubuntu Chat Logs,"Rupak Sarkar, Neha Srikanth, Taylor Pellegrin, Rachel Rudinger, Claire Bonial, Philip Resnik",(missing journal),2025,(missing abstract),289472690,0,0,,
10.18653/v1/2025.acl-long.102,ECERC: Evidence-Cause Attention Network for Multi-Modal Emotion Recognition in Conversation,"Tao Zhang, Zhenhua Tan",(missing journal),2025,(missing abstract),289472691,1,0,,
10.18653/v1/2025.acl-long.134,uMedSum: A Unified Framework for Clinical Abstractive Summarization,"Aishik Nagar, Yutong Liu, Andy T. Liu, Viktor Schlegel, Vijay Prakash Dwivedi, Arun-Kumar Kaliya-Perumal, Guna Pratheep Kalanchiam, Yili Tang, Robby T. Tan",(missing journal),2025,(missing abstract),289472692,0,0,,
10.18653/v1/2025.acl-long.74,Jailbreak Large Vision-Language Models Through Multi-Modal Linkage,"Yu Wang, Xiaofei Zhou, Yichen Wang, Geyuan Zhang, Tianxing He",(missing journal),2025,(missing abstract),289472693,0,0,,
10.18653/v1/2025.acl-long.79,MARS: Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset,"Weiqi Wang, Yangqiu Song",(missing journal),2025,(missing abstract),289472694,0,0,,
10.18653/v1/2025.acl-long.65,Autoregressive Speech Synthesis without Vector Quantization,"Lingwei Meng, Long Zhou, Shujie Liu, Sanyuan Chen, Bing Han, Shujie Hu, Yanqing Liu, Jinyu Li, Sheng Zhao, Xixin Wu, Helen Meng, Furu Wei",(missing journal),2025,(missing abstract),289472695,1,0,,
10.18653/v1/2025.acl-long.9,The Impact of Auxiliary Patient Data on Automated Chest X-Ray Report Generation and How to Incorporate It,"Aaron Nicolson, Shengyao Zhuang, Jason Dowling, Bevan Koopman",(missing journal),2025,(missing abstract),289472696,0,0,,
10.18653/v1/2025.acl-long.29,Semantic Exploration with Adaptive Gating for Efficient Problem Solving with Language Models,"Sungjae Lee, Hyejin Park, Jae-Chang Kim, Jungseul Ok",(missing journal),2025,(missing abstract),289472699,1,0,,
10.18653/v1/2025.acl-long.40,BPP-Search: Enhancing Tree of Thought Reasoning for Mathematical Modeling Problem Solving,"Teng Wang, Wing-Yin Yu, Zhe He, Zehua Liu, HaileiGong HaileiGong, Han Wu, Xiongwei Han, Wei Shi, Ruifeng She, Fangzhou Zhu, Tao Zhong",(missing journal),2025,(missing abstract),289472701,0,0,,
10.18653/v1/2025.acl-long.12,Literature Meets Data: A Synergistic Approach to Hypothesis Generation,"Haokun Liu, Yang Zhou, Mingxuan Li, Chun Yuan, Chenhao Tan",(missing journal),2025,(missing abstract),289472702,0,0,,
10.18653/v1/2025.acl-long.3,M-RewardBench: Evaluating Reward Models in Multilingual Settings,"Srishti Gureja, Lester James V. Miranda, Shafiqul Islam, Rishabh Maheshwary, Dinkar Sharma, Gusti Triandi Winata, Nathan Lambert, Sebastian Ruder, Sara Hooker, Marzieh Fadaee",(missing journal),2025,(missing abstract),289472703,0,0,,
10.18653/v1/2025.acl-long.32,S3 - Semantic Signal Separation,"Márton Kardos, Jan Kostkan, Kenneth Enevoldsen, Arnault‐Quentin Vermillet, Kristoffer Laigaard Nielbo, Roberta Rocca",(missing journal),2025,(missing abstract),289472704,1,0,,
10.18653/v1/2025.acl-long.1576,EducationQ: Evaluating LLMs’ Teaching Capabilities Through Multi-Agent Dialogue Framework,"Yao Shi, Rongkeng Liang, Yong Xu",(missing journal),2025,(missing abstract),289472816,0,0,,
10.18653/v1/2025.acl-long.1552,Entailed Between the Lines: Incorporating Implication into NLI,"Shreya Havaldar, Hamidreza Alvari, John Palowitch, Mohammad Javad Hosseini, Senaka Buthpitiya, Alex Fabrikant",(missing journal),2025,(missing abstract),289472817,0,0,,
10.18653/v1/2025.acl-long.1538,Dynamic Chunking and Selection for Reading Comprehension of Ultra-Long Context in Large Language Models,"Baohan Sheng, Jiacheng Yao, Ming Zhang, Guoxiu He",(missing journal),2025,(missing abstract),289472818,1,0,,
10.18653/v1/2025.acl-long.1520,Multimodal Coreference Resolution for Chinese Social Media Dialogues: Dataset and Benchmark Approach,"Xingyu Li, Gong Chen, Guohong Fu",(missing journal),2025,(missing abstract),289472819,0,0,,
10.18653/v1/2025.acl-long.1575,HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model,"Mengkang Hu, Tianxing Chen, Qiguang Chen, Yi Mu, Wenqi Shao, Ping Luo",(missing journal),2025,(missing abstract),289472820,3,0,,
10.18653/v1/2025.acl-long.1596,GRAM: Generative Recommendation via Semantic-aware Multi-granular Late Fusion,"Sukhyang Lee, Minjin Choi, Eunseong Choi, H. J. Kim, Jongwuk Lee",(missing journal),2025,(missing abstract),289472821,0,0,,
10.18653/v1/2025.acl-long.1493,A Survey on Efficient Large Language Model Training: From Data-centric Perspectives,"Junyu Luo, Bohan Wu, Xiao Luo, Zhiping Xiao, Yue Jin, Rong-Cheng Tu, Nan Yin, Yifan Wang, Jingyang Yuan, Wei Ju, Ming Zhang",Annual Meeting of the Association for Computational Linguistics,2025,"Post-training of Large Language Models (LLMs) is crucial for unlocking their task generalization potential and domain-specific capabilities. However, the current LLM post-training paradigm faces significant data challenges, including the high costs of manual annotation and diminishing marginal returns on data scales. Therefore, achieving data-efficient post-training has become a key research question. In this paper, we present the first systematic survey of data-efficient LLM post-training from a data-centric perspective. We propose a taxonomy of data-efficient LLM post-training methods, covering data selection, data quality enhancement, synthetic data generation, data distillation and compression, and self-evolving data ecosystems. We summarize representative approaches in each category and outline future research directions. By examining the challenges in data-efficient LLM post-training, we highlight open problems and propose potential research avenues. We hope our work inspires further exploration into maximizing the potential of data utilization in large-scale model training. Paper List: https://github.com/luo-junyu/Awesome-Data-Efficient-LLM",289472822,2,80,,
10.18653/v1/2025.acl-long.1508,Revisiting Compositional Generalization Capability of Large Language Models Considering Instruction Following Ability,"Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe",(missing journal),2025,(missing abstract),289472823,0,0,,
10.18653/v1/2025.acl-long.1458,Stochastic Chameleons: Irrelevant Context Hallucinations Reveal Class-Based (Mis)Generalization in LLMs,"Ziling Cheng, Meng Cao, Marc-Antoine Rondeau, Jonah Cheung",(missing journal),2025,(missing abstract),289472824,0,0,,
10.18653/v1/2025.acl-long.1377,NusaAksara: A Multimodal and Multilingual Benchmark for Preserving Indonesian Indigenous Scripts,"Muhammad Farid Adilazuarda, Musa Izzanardi Wijanarko, Lucky Susanto, Khumaisa Nur’aini, Derry Wijaya, Alham Fikri Aji",Annual Meeting of the Association for Computational Linguistics,2025,"Indonesia is rich in languages and scripts. However, most NLP progress has been made using romanized text. In this paper, we present NusaAksara, a novel public benchmark for Indonesian languages that includes their original scripts. Our benchmark covers both text and image modalities and encompasses diverse tasks such as image segmentation, OCR, transliteration, translation, and language identification. Our data is constructed by human experts through rigorous steps. NusaAksara covers 8 scripts across 7 languages, including low-resource languages not commonly seen in NLP benchmarks. Although unsupported by Unicode, the Lampung script is included in this dataset. We benchmark our data across several models, from LLMs and VLMs such as GPT-4o, Llama 3.2, and Aya 23 to task-specific systems such as PP-OCR and LangID, and show that most NLP technologies cannot handle Indonesia's local scripts, with many achieving near-zero performance.",289472825,2,51,,
10.18653/v1/2025.acl-long.1328,Recurrent Knowledge Identification and Fusion for Language Model Continual Learning,"Yujie Feng, Xujia Wang, Zexin Lu, Shenghong Fu, Guangyuan Shi, Yongxin Xu, Yasha Wang, Philip S. Yu, Xu Chu, Xiao-Ming Wu",(missing journal),2025,(missing abstract),289472826,0,0,,
10.18653/v1/2025.acl-long.1379,Hierarchical-Task-Aware Multi-modal Mixture of Incremental LoRA Experts for Embodied Continual Learning,"Ziqi Jia, An-Feng Wang, Xiaoyang Qu, Xiaowen Yang, Jianzong Wang",(missing journal),2025,(missing abstract),289472827,1,0,,
10.18653/v1/2025.acl-long.1343,Knowledge Tracing in Programming Education Integrating Students’ Questions,"Doyoun Kim, Su‐In Kim, Yohan Jo",(missing journal),2025,(missing abstract),289472828,0,0,,
10.18653/v1/2025.acl-long.1400,"LLMs Trust Humans More, That’s a Problem! Unveiling and Mitigating the Authority Bias in Retrieval-Augmented Generation","Yuxuan Li, Xinwei Guo, Jiashi Gao, Guanhua Chen, Xiangyu Zhao, Jiaxin Zhang, Quanying Liu, Haiyan Wu, Xin Yao, Xuetao Wei",(missing journal),2025,(missing abstract),289472829,0,0,,
10.18653/v1/2025.acl-long.1395,Dialogue Systems for Emotional Support via Value Reinforcement,"Ju‐Hee Kim, Che Ling Michelle Mok, Jeesun Lee, Hyang Sook Kim, Yohan Jo",(missing journal),2025,(missing abstract),289472830,2,0,,
10.18653/v1/2025.acl-long.1365,Tokenisation is NP-Complete,"Philip A. Whittington, Gregor Bachmann, Tiago Pimentel",(missing journal),2025,(missing abstract),289472831,0,0,,
10.18653/v1/2025.acl-long.1295,Exploring the Impact of Instruction-Tuning on LLM’s Susceptibility to Misinformation,"Kyubeen Han, Jong Hyun Jang, H.C. Kim, Geunyeong Jeong, Harksoo Kim",(missing journal),2025,(missing abstract),289472832,0,0,,
10.18653/v1/2025.acl-long.1230,PRMBench: A Fine-grained and Challenging Benchmark for Process-Level Reward Models,"Mingyang Song, Zhaochen Su, Xiaoye Qu, Jiawei Zhou, Cheng Yu",(missing journal),2025,(missing abstract),289472833,0,0,,
10.18653/v1/2025.acl-long.1229,Language Constrained Multimodal Hyper Adapter For Many-to-Many Multimodal Summarization,"Nayu Liu, Fanglong Yao, Haoran Luo, Yong Yang, Chen Tang, Bo Lv",(missing journal),2025,(missing abstract),289472834,0,0,,
10.18653/v1/2025.acl-long.1244,Can We Further Elicit Reasoning in LLMs? Critic-Guided Planning with Retrieval-Augmentation for Solving Challenging Tasks,"Xingxuan Li, Weiwen Xu, Ruochen Zhao, Fangkai Jiao, Shafiq Joty, Lidong Bing",(missing journal),2025,(missing abstract),289472835,1,0,,
10.18653/v1/2025.acl-long.1213,Chain-of-Reasoning: Towards Unified Mathematical Reasoning in Large Language Models via a Multi-Paradigm Perspective,"Yu Yang, Yuxiang Zhang, Dongdong Zhang, Xiao Liang, Hengyuan Zhang, Xingxing Zhang, Mahmoud Khademi, Hany Hassan Awadalla, Junjie Wang, Yujiu Yang, Furu Wei",(missing journal),2025,(missing abstract),289472836,2,0,,
10.18653/v1/2025.acl-long.1159,Graph of Records: Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs,"Haozhen Zhang, Feng Tao, Jiaxuan You",(missing journal),2025,(missing abstract),289474621,0,0,,
10.18653/v1/2025.acl-long.1111,EdiText: Controllable Coarse-to-Fine Text Editing with Diffusion Language Models,"Che Hyun Lee, Heeseung Kim, Jiheum Yeom, Sungroh Yoon",(missing journal),2025,(missing abstract),289474622,0,0,,
10.18653/v1/2025.acl-long.1151,"On the Relation Between Fine-Tuning, Topological Properties, and Task Performance in Sense-Enhanced Embeddings","Deniz Ekin Yavas, Timothée Bernard, Benoît Crabbé, Laura Kallmeyer",(missing journal),2025,(missing abstract),289474623,0,0,,
10.18653/v1/2025.acl-long.1078,Aligned but Blind: Alignment Increases Implicit Bias by Reducing Awareness of Race,"Liling Sun, Chengzhi Mao, Valentin Hofmann, Xuechunzi Bai",(missing journal),2025,(missing abstract),289474624,0,0,,
10.18653/v1/2025.acl-long.1126,Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention,"Jingyang Yuan, Huazuo Gao, Damai Dai, Junyu Luo, Liang Zhao, Zhengyan Zhang, Zhenda Xie, Yuxing Wei, Lean Wang, Zhiping Xiao, Yuqing Wang, Chong Ruan, Ming Zhang, Wenfeng Liang, Wangding Zeng",(missing journal),2025,(missing abstract),289474625,8,0,,
10.18653/v1/2025.acl-long.1063,Knowledge Image Matters: Improving Knowledge-Based Visual Reasoning with Multi-Image Large Language Models,"Guanghui Ye, Huan Zhao, Zhixue Zhao, Xupeng Zha, Yang Liu, Zhihua Jiang",(missing journal),2025,(missing abstract),289474626,0,0,,
10.18653/v1/2025.acl-long.993,Planning with Diffusion Models for Target-Oriented Dialogue Systems,"Hanwen Du, Bo Peng, Xia Ning",(missing journal),2025,(missing abstract),289474627,0,0,,
10.18653/v1/2025.acl-long.949,Bi-Tuning with Collaborative Information for Controllable LLM-based Sequential Recommendation,"Xinyu Zhang, Linmei Hu, Luhao Zhang, Wentao Cheng, Yashen Wang, Ge Shi, Chong Feng, Liqiang Nie",(missing journal),2025,(missing abstract),289474628,0,0,,
10.18653/v1/2025.acl-long.931,CoCoLex: Confidence-guided Copy-based Decoding for Grounded Legal Text Generation,"Santosh T.y.s.s, Youssef Tarek Elkhayat, Oana Ichim, Pranav Shetty, Dongsheng Wang, Zhiqiang Ma, Armineh Nourbakhsh, Xiaomo Liu",Annual Meeting of the Association for Computational Linguistics,2025,"Due to their ability to process long and complex contexts, LLMs can offer key benefits to the Legal domain, but their adoption has been hindered by their tendency to generate unfaithful, ungrounded, or hallucinatory outputs. While Retrieval-Augmented Generation offers a promising solution by grounding generations in external knowledge, it offers no guarantee that the provided context will be effectively integrated. To address this, context-aware decoding strategies have been proposed to amplify the influence of relevant context, but they usually do not explicitly enforce faithfulness to the context. In this work, we introduce Confidence-guided Copy-based Decoding for Legal Text Generation (CoCoLex)-a decoding strategy that dynamically interpolates the model produced vocabulary distribution with a distribution derived based on copying from the context. CoCoLex encourages direct copying based on the model's confidence, ensuring greater fidelity to the source. Experimental results on five legal benchmarks demonstrate that CoCoLex outperforms existing context-aware decoding methods, particularly in long-form generation tasks.",289474629,1,59,,
10.18653/v1/2025.acl-long.943,Any Information Is Just Worth One Single Screenshot: Unifying Search With Visualized Information Retrieval,"Zheng Liu, Zehuan Liu, Zhengyang Liang, Junjie Zhou, Shitao Xiao, Chao Gao, Chen Zhang, Defu Lian",(missing journal),2025,(missing abstract),289474630,0,0,,
10.18653/v1/2025.acl-long.1015,QQSUM: A Novel Task and Model of Quantitative Query-Focused Summarization for Review-based Product Question Answering,"An Quang Tang, Xiuzhen Zhang, Minh Ngoc Dinh, Zhuang Li",(missing journal),2025,(missing abstract),289474631,0,0,,
10.18653/v1/2025.acl-long.948,Cramming 1568 Tokens into a Single Vector and Back Again: Exploring the Limits of Embedding Space Capacity,"Yuri Kuratov, М. В. Архипов, Aydar Bulatov, Mikhail Burtsev",(missing journal),2025,(missing abstract),289474632,0,0,,
10.18653/v1/2025.acl-long.907,Tree-KG: An Expandable Knowledge Graph Construction Framework for Knowledge-intensive Domains,"Songjie Niu, Kaisen Yang, Rui Zhao, Yichao Liu, Zonglin Li, Hongning Wang, Wenguang Chen",(missing journal),2025,(missing abstract),289474633,0,0,,
10.18653/v1/2025.acl-long.902,LLM-Guided Semantic-Aware Clustering for Topic Modeling,"Jianghan Liu, Ziyu Shang, Wenjun Ke, Peng Wang, Zhizhao Luo, Jiajun Liu, Guozheng Li, Yining Li",(missing journal),2025,(missing abstract),289474634,0,0,,
10.18653/v1/2025.acl-long.893,Multilingual Encoder Knows more than You Realize: Shared Weights Pretraining for Extremely Low-Resource Languages,"Zeli Su, Ziyin Zhang, Guixian Xu, Jianing Liu, Xu Han, Ting Zhang, Yi Dong",(missing journal),2025,(missing abstract),289474635,0,0,,
10.18653/v1/2025.acl-long.1016,Navigating Rifts in Human-LLM Grounding: Study and Benchmark,"Omar Shaikh, Hussein Mozannar, Gagan Bansal, Adam Fourney, Eric Horvitz",(missing journal),2025,(missing abstract),289474636,1,0,,
10.18653/v1/2025.acl-long.798,BMIKE-53: Investigating Cross-Lingual Knowledge Editing with In-Context Learning,"Ercong Nie, Bo Shao, Mingyang Wang, Zifeng Ding, Helmut Schmid, Hinrich Schuetze",(missing journal),2025,(missing abstract),289474637,0,0,,
10.18653/v1/2025.acl-long.790,Rhythm Controllable and Efficient Zero-Shot Voice Conversion via Shortcut Flow Matching,"Jialong Zuo, Shengpeng Ji, Minghui Fang, Mingze Li, Ziyue Karen Jiang, Xize Cheng, Xiaoda Yang, Feiyang Chen, Xinyu Duan, Zhou Zhao",(missing journal),2025,(missing abstract),289474638,0,0,,
10.18653/v1/2025.acl-long.824,Logical forms complement probability in understanding language model (and human) performance,"Yixuan Wang, Freda Shi",(missing journal),2025,(missing abstract),289474639,0,0,,
10.18653/v1/2025.acl-long.862,Understanding Large Language Model Vulnerabilities to Social Bias Attacks,"Jiaxu Zhao, Meng Fang, Fanghua Ye, Ke Xu, Qin Zhang, Jia Zhou, Mykola Pechenizkiy",(missing journal),2025,(missing abstract),289474640,0,0,,
10.18653/v1/2025.acl-long.871,Optimizing Question Semantic Space for Dynamic Retrieval-Augmented Multi-hop Question Answering,"L.X. Ye, Lang Yu, Zhikai Lei, Qin Chen, Jie Zhou, Liang He",(missing journal),2025,(missing abstract),289474641,0,0,,
10.18653/v1/2025.acl-long.1192,"Using Information Theory to Characterize Prosodic Typology: The Case of Tone, Pitch-Accent and Stress-Accent","Ethan Wilcox, Cui Ding, Giovanni Acampa, Tiago Pimentel, Alex Warstadt, Tamar I. Regev",(missing journal),2025,(missing abstract),289474642,0,0,,
10.18653/v1/2025.acl-long.741,Ontology-Guided Reverse Thinking Makes Large Language Models Stronger on Knowledge Graph Question Answering,"Runxuan Liu, Luobei Luobei, J. Jenny Li, Baoxin Wang, Ming Liu, Dayong Wu, Shijin Wang, Bing Qin",(missing journal),2025,(missing abstract),289474644,0,0,,
10.18653/v1/2025.acl-long.612,Redundancy Principles for MLLMs Benchmarks,"Zicheng Zhang, Xiangyu Zhao, Xinyu Fang, Chunyi Li, Xiaohong Liu, Xiongkuo Min, Haodong Duan, Chaoyu Chen, Guangtao Zhai",(missing journal),2025,(missing abstract),289474645,2,0,,
10.18653/v1/2025.acl-long.780,One for All: Update Parameterized Knowledge Across Multiple Models with Once Edit,"Weitao Ma, Xiaocong Du, Xiaocheng Feng, Lei Huang, Yudong Huang, Huiyi Zhang, Xiaoliang Yang, Baohang Li, Xiachong Feng, Ting Liu, Bing Qin",(missing journal),2025,(missing abstract),289474646,0,0,,
10.18653/v1/2025.acl-long.608,KokoroChat: A Japanese Psychological Counseling Dialogue Dataset Collected via Role-Playing by Trained Counselors,"Zhiyang Qi, Takumasa Kaneko, Keiko Takamizo, Mariko Ukiyo, Michimasa Inaba",(missing journal),2025,(missing abstract),289474647,0,0,,
10.18653/v1/2025.acl-long.604,TreeRL: LLM Reinforcement Learning with On-Policy Tree Search,"Zhenyu Hou, Ziniu Hu, Yujiang Li, Rui Lu, Jie Tang, Yuxiao Dong",(missing journal),2025,(missing abstract),289474648,0,0,,
10.18653/v1/2025.acl-long.631,Accurate KV Cache Quantization with Outlier Tokens Tracing,"Yi Su, Yuechi Zhou, Qianqian Qiu, Juntao Li, Qingrong Xia, Ping Li, Xinyu Duan, Zhefeng Wang, Min Zhang",(missing journal),2025,(missing abstract),289474649,1,0,,
10.18653/v1/2025.acl-long.671,STUN: Structured-Then-Unstructured Pruning for Scalable MoE Pruning,"Jaeseong Lee, Seung-won Hwang, Aurick Qiao, Daniel Campos, Zhewei Yao, Yuxiong He",(missing journal),2025,(missing abstract),289474650,0,0,,
10.18653/v1/2025.acl-long.718,Demystifying Small Language Models for Edge Deployment,"Zhichun Lu, Xiang Li, Dongqi Cai, Rongjie Yi, Fangming Liu, Wei Liu, Jian Luan, Xiwen Zhang, Nicholas D. Lane, Mengwei Xu",(missing journal),2025,(missing abstract),289474651,1,0,,
10.18653/v1/2025.acl-long.633,EAC-MoE: Expert-Selection Aware Compressor for Mixture-of-Experts Large Language Models,"Y C Chen, Yuantian Shao, Peisong Wang, Jian Cheng",Annual Meeting of the Association for Computational Linguistics,2025,"Mixture-of-Experts (MoE) has demonstrated promising potential in scaling LLMs. However, it is hindered by two critical challenges: (1) substantial GPU memory consumption to load all experts; (2) low activated parameters cannot be equivalently translated into inference acceleration effects. In this work, we propose EAC-MoE, an Expert-Selection Aware Compressor for MoE-LLMs, which deeply aligns with the characteristics of MoE from the perspectives of quantization and pruning, and introduces two modules to address these two challenges respectively: (1) The expert selection bias caused by low-bit quantization is a major factor contributing to the performance degradation in MoE-LLMs. Based on this, we propose Quantization with Expert-Selection Calibration (QESC), which mitigates the expert selection bias by calibrating the routers within the MoE; (2) There are always certain experts that are not crucial for the corresponding tasks, yet causing inference latency. Therefore, we propose Pruning based on Expert-Selection Frequency (PESF), which significantly improves inference speed by pruning less frequently used experts for current task. Extensive experiments demonstrate that our approach significantly reduces memory usage and improves inference speed with minimal performance degradation.",289474652,2,54,,
10.18653/v1/2025.acl-long.600,Enhancing Interpretable Image Classification Through LLM Agents and Conditional Concept Bottleneck Models,"Yiwen Jiang, Deval Mehta, Wei Feng, Zongyuan Ge",(missing journal),2025,(missing abstract),289474653,0,0,,
10.18653/v1/2025.acl-long.703,ClusterAttn: KV Cache Compression under Intrinsic Attention Clustering,"M. Zhang, Haifeng Sun, Jingyu Wang, Shisong Li, Wanyi Ning, Qi Qi, Zirui Zhuang, Jianxin Liao",(missing journal),2025,(missing abstract),289474654,0,0,,
10.18653/v1/2025.acl-long.511,Introducing Graph Context into Language Models through Parameter-Efficient Fine-Tuning for Lexical Relation Mining,"Jingwen Sun, Zhiyi Tian, Yu He, Jingwei Sun, Guangzhong Sun",(missing journal),2025,(missing abstract),289474655,0,0,,
10.18653/v1/2025.acl-long.528,Top-n𝜎: Eliminating Noise in Logit Space for Robust Token Sampling of LLM,"C. J. Tang, Jianchun Liu, Hongli Xu, Liusheng Huang",(missing journal),2025,(missing abstract),289474656,0,0,,
10.18653/v1/2025.acl-long.483,"If Attention Serves as a Cognitive Model of Human Memory Retrieval, What is the Plausible Memory Representation?","Ryo Yoshida, Shinnosuke Isono, Kohei Kajikawa, Taiga Someya, Yushi Sugimoto, Yohei Oseki",Annual Meeting of the Association for Computational Linguistics,2025,"Recent work in computational psycholinguistics has revealed intriguing parallels between attention mechanisms and human memory retrieval, focusing primarily on vanilla Transformers that operate on token-level representations. However, computational psycholinguistic research has also established that syntactic structures provide compelling explanations for human sentence processing that token-level factors cannot fully account for. In this paper, we investigate whether the attention mechanism of Transformer Grammar (TG), which uniquely operates on syntactic structures as representational units, can serve as a cognitive model of human memory retrieval, using Normalized Attention Entropy (NAE) as a linking hypothesis between models and humans. Our experiments demonstrate that TG's attention achieves superior predictive power for self-paced reading times compared to vanilla Transformer's, with further analyses revealing independent contributions from both models. These findings suggest that human sentence processing involves dual memory representations -- one based on syntactic structures and another on token sequences -- with attention serving as the general memory retrieval algorithm, while highlighting the importance of incorporating syntactic structures as representational units.",289474657,0,57,,
10.18653/v1/2025.acl-long.309,HD-NDEs: Neural Differential Equations for Hallucination Detection in LLMs,"Qing Li, Jiahui Geng, Zongxiong Chen, Derui Zhu, Yuxia Wang, Congbo Ma, Chenyang Lyu, Fakhri Karray",(missing journal),2025,(missing abstract),289474658,0,0,,
10.18653/v1/2025.acl-long.383,Conditional Dichotomy Quantification via Geometric Embedding,"Shaobo Cui, Wenqing Liu, Yiyang Feng, Jiawei Zhou, Boi Faltings",(missing journal),2025,(missing abstract),289474659,0,0,,
10.18653/v1/2025.acl-long.345,Tracking Life’s Ups and Downs: Mining Life Events from Social Media Posts for Mental Health Analysis,"Minghao Lv, Siyuan Chen, Haoan Jin, Minghao Yuan, Qianqian Ju, Yujia Peng, Kenny Q. Zhu, Mengyue Wu",(missing journal),2025,(missing abstract),289474660,0,0,,
10.18653/v1/2025.acl-long.327,AlignMMBench: Evaluating Chinese Multimodal Alignment in Large Vision-Language Models,"Yuhang Wu, Wenmeng Yu, Yean Cheng, Yan Wang, Xiaohan Zhang, Jiazheng Xu, Ming Ding, Yuxiao Dong",(missing journal),2025,(missing abstract),289474661,1,0,,
10.18653/v1/2025.acl-long.363,ChartCoder: Advancing Multimodal Large Language Model for Chart-to-Code Generation,"Xuanle Zhao, Xianzhen Luo, Qi Shi, Chi Chen, Shuo Wang, Zhiyuan Liu, Maosong Sun",(missing journal),2025,(missing abstract),289474662,1,0,,
10.18653/v1/2025.acl-long.416,SCALE: Towards Collaborative Content Analysis in Social Science with Large Language Model Agents and Human Intervention,"Chunhua Zhao, Zhen Tan, Chau-Wai Wong, Xinyan Zhao, Tianlong Chen, Huan Liu",(missing journal),2025,(missing abstract),289474663,0,0,,
10.18653/v1/2025.acl-long.305,Disentangling Biased Knowledge from Reasoning in Large Language Models via Machine Unlearning,"Zheyuan Liu, Suraj Maharjan, Fanyou Wu, Rahil Parikh, Belhassen Bayar, Srinivasan H. Sengamedu, Meng Jiang",(missing journal),2025,(missing abstract),289474665,0,0,,
10.18653/v1/2025.acl-long.296,NGQA: A Nutritional Graph Question Answering Benchmark for Personalized Health-aware Nutritional Reasoning,"Zheyuan Zhang, Yiyang Li, Nhi Ha Lan Le, Zehong Wang, Tianyi Ma, Vincent Galassi, Keerthiram Murugesan, Nuno Moniz, Philipp Geyer, Nitesh V. Chawla, Chuxu Zhang, Yanfang Ye",(missing journal),2025,(missing abstract),289474666,2,0,,
10.18653/v1/2025.acl-long.295,Modality-Aware Neuron Pruning for Unlearning in Multimodal Large Language Models,"Zheyuan Liu, Guangyao Dou, Xiangchi Yuan, Chunhui Zhang, Zhaoxuan Tan, Meng Jiang",(missing journal),2025,(missing abstract),289474667,0,0,,
10.18653/v1/2025.acl-long.287,Enhancing Multimodal Continual Instruction Tuning with BranchLoRA,"Duzhen Zhang, Yong Ren, Zhongzhi Li, Yahan Yu, Jiahua Dong, Chenxing Li, Zhuoyu Ji, J. Z. Bai",(missing journal),2025,(missing abstract),289474668,0,0,,
10.18653/v1/2025.acl-long.272,"What is Stigma Attributed to? A Theory-Grounded, Expert-Annotated Interview Corpus for Demystifying Mental-Health Stigma","Han Meng, Yongqian Chen, Yunan Li, Yitian Yang, Jungup Lee, Renwen Zhang, Yi‐Chieh Lee",(missing journal),2025,(missing abstract),289474669,0,0,,
10.18653/v1/2025.acl-long.271,Plug-in and Fine-tuning: Bridging the Gap between Small Language Models and Large Language Models,"Kyuhee Kim, Jinhee Jang, Juhwan Choi, Yoonji Lee, Kyohoon Jin, Youngbin Kim",(missing journal),2025,(missing abstract),289474670,0,0,,
10.18653/v1/2025.acl-long.232,Revisiting the Test-Time Scaling of o1-like Models: Do they Truly Possess Test-Time Scaling Capabilities?,"Zhiyuan Zeng, Qinyuan Cheng, Zhangyue Yin, Yunhua Zhou, Xipeng Qiu",(missing journal),2025,(missing abstract),289480689,1,0,,
10.18653/v1/2025.acl-long.203,Confidence v.s. Critique: A Decomposition of Self-Correction Capability for LLMs,"Zhe Yang, Yuhan Zhang, Yudong Wang, Zhao Xu, Junyang Lin, Zhifang Sui",(missing journal),2025,(missing abstract),289480690,0,0,,
10.18653/v1/2025.acl-long.186,FoldMoE: Efficient Long Sequence MoE Training via Attention-MoE Pipelining,"Guo-Yu Zhu, Lei Liang, Yuhao Qing, Yichao Fu, Fanxin Li, Dong Huang, Zekai Sun, Heming Cui",(missing journal),2025,(missing abstract),289480691,0,0,,
10.18653/v1/2025.acl-long.195,Conformity in Large Language Models,"Xue‐Yi Zhu, Caiqi Zhang, Tom Stafford, Nigel Collier, Andreas Vlachos",(missing journal),2025,(missing abstract),289480692,0,0,,
10.18653/v1/2025.acl-long.253,Lost in Multilinguality: Dissecting Cross-lingual Factual Inconsistency in Transformer Language Models,"Mingyang Wang, Heike Adel, Lukas Lange, Yihong Liu, Ercong Nie, Jannik Strötgen, Hinrich Schuetze",(missing journal),2025,(missing abstract),289480693,2,0,,
10.18653/v1/2025.acl-long.164,Taming LLMs with Gradient Grouping,"Siyuan Li, Jie Tian, Zedong Wang, Xin Jin, Zichen Liu, Wentao Zhang, Dan Xu",(missing journal),2025,(missing abstract),289480694,0,0,,
10.18653/v1/2025.acl-long.138,AndroidGen: Building an Android Language Agent under Data Scarcity,"Hanyu Lai, Junjie Gao, Xiao Liu, Yifan Xu, Shudan Zhang, Yuxiao Dong, Junwang Tang",(missing journal),2025,(missing abstract),289480695,0,0,,
10.18653/v1/2025.acl-long.124,Hierarchical Level-Wise News Article Clustering via Multilingual Matryoshka Embeddings,"Hans W. A. Hanley, Zakir Durumeric",(missing journal),2025,(missing abstract),289480696,0,0,,
10.18653/v1/2025.acl-long.119,Digital Gatekeepers: Google’s Role in Curating Hashtags and Subreddits,"Amrit Poudel, Yifan Ding, Tim Weninger, Jürgen Pfeffer",(missing journal),2025,(missing abstract),289480697,0,0,,
10.18653/v1/2025.acl-long.154,LADM: Long-context Training Data Selection with Attention-based Dependency Measurement for LLMs,"Jianghao Chen, Junhong Wu, Yangyifan Xu, Jiajun Zhang",(missing journal),2025,(missing abstract),289480698,0,0,,
10.18653/v1/2025.acl-long.53,MPVStance: Mitigating Hallucinations in Stance Detection with Multi-Perspective Verification,"Zeyu Zhang, Zhao Zhang, Jin Zhang, Hui Xu, Xueqi Cheng",(missing journal),2025,(missing abstract),289480699,0,0,,
10.18653/v1/2025.acl-long.28,Extending LLM Context Window with Adaptive Grouped Positional Encoding: A Training-Free Method,"Xinhao Xu, Jiaxin Li, Hui Chen, Zijia Lin, Jungong Han, Guiguang Ding",(missing journal),2025,(missing abstract),289480700,0,0,,
10.18653/v1/2025.acl-long.62,Untie the Knots: An Efficient Data Augmentation Strategy for Long-Context Pre-Training in Language Models,"Junfeng Tian, Da Zheng, Yang Chen, Rui Wang, Colin Zhang, Debing Zhang",(missing journal),2025,(missing abstract),289480702,0,0,,
10.18653/v1/2025.acl-long.37,Efficient and Accurate Prompt Optimization: the Benefit of Memory in Exemplar-Guided Reflection,"Yan Cui, Jingyun Wang, Lin Zhang, Run Zhao, X.J. Wu, Kai Xiong, Qing-song Liu, Guoliang Kang, Young Ae Kang",(missing journal),2025,(missing abstract),289480706,0,0,,
10.18653/v1/2025.acl-long.35,Generating Diverse Training Samples for Relation Extraction with Large Language Models,"Zexuan Li, Hongliang Dai, Piji Li",(missing journal),2025,(missing abstract),289480709,0,0,,
10.18653/v1/2025.acl-long.38,Evaluation of LLM Vulnerabilities to Being Misused for Personalized Disinformation Generation,"Aneta Žugecová, Dominik Macko, Ivan Srba, Róbert Móro, Jakub Kopál, Katarína Marcinčinová, Matúš Mesarčík",(missing journal),2025,(missing abstract),289480711,2,0,,
10.18653/v1/2025.acl-long.27,RuleArena: A Benchmark for Rule-Guided Reasoning with LLMs in Real-World Scenarios,"R. Zhou, Wenyue Hua, Liangming Pan, Sitao Cheng, Xiaobao Wu, En Yu, William Yang Wang",(missing journal),2025,(missing abstract),289480713,2,0,,
10.18653/v1/2025.acl-long.30,HotelMatch-LLM: Joint Multi-Task Training of Small and Large Language Models for Efficient Multimodal Hotel Retrieval,"Arian Askari, Emmanouil Stergiadis, Ilya Gusev, Moran Beladev",(missing journal),2025,(missing abstract),289480714,0,0,,
10.18653/v1/2025.acl-long.17,FACT-AUDIT: An Adaptive Multi-Agent Framework for Dynamic Fact-Checking Evaluation of Large Language Models,"Hongzhan Lin, Yang Deng, Yuxuan Gu, Wenxuan Zhang, Jing Ma, See-Kiong Ng, Tat‐Seng Chua",(missing journal),2025,(missing abstract),289480716,1,0,,
10.18653/v1/2025.acl-long.55,PsyDT: Using LLMs to Construct the Digital Twin of Psychological Counselor with Personalized Counseling Style for Psychological Counseling,"Hui Xie, Yirong Chen, Xiaofen Xing, Jingkai Lin, Xiangmin Xu",(missing journal),2025,(missing abstract),289480717,1,0,,
10.18653/v1/2025.acl-long.1507,Truth Knows No Language: Evaluating Truthfulness Beyond English,"Blanca Calvo Figueras, Eneko Sagarzazu, Julen Etxaniz, Jeremy Barnes, Pablo Gamallo, Iria de-Dios-Flores, Rodrigo Agerri",(missing journal),2025,(missing abstract),289480833,0,0,,
10.18653/v1/2025.acl-long.1494,IMOL: Incomplete-Modality-Tolerant Learning for Multi-Domain Fake News Video Detection,"Zhi Zeng, Jiaying Wu, Minnan Luo, Herun Wan, Xiangzheng Kong, Z. Ma, Guang Dai, Qinghua Zheng",(missing journal),2025,(missing abstract),289480834,2,0,,
10.18653/v1/2025.acl-long.1472,Basic Reading Distillation,"Zhidong Zhou, S. Y. Miao, Xiangyu Duan, Hao Yang, Min Zhang",Annual Meeting of the Association for Computational Linguistics,2025,"Large language models (LLMs) have demonstrated remarkable abilities in various natural language processing areas, but they demand high computation resources which limits their deployment in real-world. Distillation is one technique to solve this problem through either knowledge distillation or task distillation. Both distillation approaches train small models to imitate specific features of LLMs, but they all neglect basic reading education for small models on generic texts that are \emph{unrelated} to downstream tasks. In this paper, we propose basic reading distillation (BRD) which educates a small model to imitate LLMs basic reading behaviors, such as named entity recognition, question raising and answering, on each sentence. After such basic education, we apply the small model on various tasks including language inference benchmarks and BIG-bench tasks. It shows that the small model can outperform or perform comparable to over 20x bigger LLMs. Analysis reveals that BRD effectively influences the probability distribution of the small model, and has orthogonality to either knowledge distillation or task distillation.",289480835,0,32,,
10.18653/v1/2025.acl-long.1475,More is not always better? Enhancing Many-Shot In-Context Learning with Differentiated and Reweighting Objectives,"Xiaoqing Zhang, Ang Lv, Yuhan Liu, Flood Sung, Wei Liu, Jian Luan, Shuo Shang, Xiuying Chen, Rui Ting Yan",(missing journal),2025,(missing abstract),289480836,0,0,,
10.18653/v1/2025.acl-long.1451,PARME: Parallel Corpora for Low-Resourced Middle Eastern Languages,"Sina Ahmadi, Rico Sennrich, Ebrahim Karami, Ako Marani, Parviz Fekrazad, Gholamreza Akbarzadeh Baghban, Harem Mahdi Hadi, Safanaz Heidari, Midrabi Doğan, Parisa Asadi, Dashne Bashir, Masoud Ghodrati, Kourosh Amini, Zeynab Ashourinezhad, Mana Baladi, Farshid Ezzati, Alireza Ghasemifar, Daryoush Hosseinpour, Behrooz Abbaszadeh, Amin Hassanpour, Bahaddin Jalal Hamaamin, S. Hama, Alireza Mousavi, Sherif E. Hussein, Isar Nejadgholi, Mehmet Ölmez, Horam Osmanpour, Rashid Roshan Ramezani, Ahmed Abdel Aziz, Ali Salehi, Mohammad Yadegari, Kewyar Yadegari, Sedighe Zamani Roodsari",(missing journal),2025,(missing abstract),289480837,0,0,,
10.18653/v1/2025.acl-long.1384,Probing Relative Interaction and Dynamic Calibration in Multi-modal Entity Alignment,"C. Li, Jingwei Cheng, Qiang Tong, Fu Zhang, Changle Wang",(missing journal),2025,(missing abstract),289480838,1,0,,
10.18653/v1/2025.acl-long.1330,Just a Scratch: Enhancing LLM Capabilities for Self-harm Detection through Intent Differentiation and Emoji Interpretation,"Soumitra Ghosh, Gopendra Vikram Singh, Shambhavi Shambhavi, Suborna Roy Choudhury, Asif Ekbal",(missing journal),2025,(missing abstract),289480839,0,0,,
10.18653/v1/2025.acl-long.1325,MAGNET: Augmenting Generative Decoders with Representation Learning and Infilling Capabilities,"Savya Khosla, Aditi Tiwari, Kushal Kafle, Simon Jenni, Handong Zhao, John Collomosse, Jing Shi",(missing journal),2025,(missing abstract),289480840,0,0,,
10.18653/v1/2025.acl-long.1320,Odysseus Navigates the Sirens’ Song: Dynamic Focus Decoding for Factual and Diverse Open-Ended Text Generation,"Wen Luo, Feifan Song, Ranran Liu, Guangyue Peng, Sun Wei, Houfeng Wang",(missing journal),2025,(missing abstract),289480841,0,0,,
10.18653/v1/2025.acl-long.1309,Colloquial Singaporean English Style Transfer with Fine-Grained Explainable Control,"Jinggui Liang, Dũng Trung Võ, Ying Xian, Hai Leong Chieu, Kian Ming A. Chai, Jing Jiang, Lizi Liao",(missing journal),2025,(missing abstract),289480842,0,0,,
10.18653/v1/2025.acl-long.1226,Follow-up Question Generation For Enhanced Patient-Provider Conversations,"Joseph Gatto, Parker Seegmiller, Timothy E. Burdick, Inas S. Khayal, Sarah DeLozier, Sarah Masud Preum",(missing journal),2025,(missing abstract),289480843,2,0,,
10.18653/v1/2025.acl-long.1258,Do Language Models Have Semantics? On the Five Standard Positions,Anders Søgaard,(missing journal),2025,(missing abstract),289480844,0,0,,
10.18653/v1/2025.acl-long.1254,Help Me Write a Story: Evaluating LLMs’ Ability to Generate Writing Feedback,"Hannah Rashkin, Elizabeth Clark, Fantine Huot, Mirella Lapata",(missing journal),2025,(missing abstract),289480845,0,0,,
10.18653/v1/2025.acl-long.1104,S2R: Teaching LLMs to Self-verify and Self-correct via Reinforcement Learning,"Ruijuan Ma, P.F. Wang, Cheng Liu, Xingyan Liu, Jiaqi Chen, Bang Zhang, Xin Zhou, Nan Du, Jia Li",(missing journal),2025,(missing abstract),289482728,0,0,,
10.18653/v1/2025.acl-long.1075,Proxy-Driven Robust Multimodal Sentiment Analysis with Incomplete Data,"Aoqiang Zhu, Min Hu, Xiaohua Wang, Jiaoyun Yang, Yiming Tang, Ning An",(missing journal),2025,(missing abstract),289482729,0,0,,
10.18653/v1/2025.acl-long.1044,World Modeling Makes a Better Planner: Dual Preference Optimization for Embodied Task Planning,"Siyin Wang, Zhaoye Fei, Qinyuan Cheng, Shiduo Zhang, Panpan Cai, Jinlan Fu, Xipeng Qiu",(missing journal),2025,(missing abstract),289482730,0,0,,
10.18653/v1/2025.acl-long.1051,Exclusion of Thought: Mitigating Cognitive Load in Large Language Models for Enhanced Reasoning in Multiple-Choice Tasks,"Qing Fu, Yongbin Qin, Ringo Huang, Yanping Chen, Yulin Zhou, Lili Long",(missing journal),2025,(missing abstract),289482731,0,0,,
10.18653/v1/2025.acl-long.937,UniCodec: Unified Audio Codec with Single Domain-Adaptive Codebook,"Yidi Jiang, Qian Chen, Shengpeng Ji, Xi Yu, Wen Wang, Chong Zhang, Xianghu Yue, Shiliang Zhang, Haizhou Li",(missing journal),2025,(missing abstract),289482732,0,0,,
10.18653/v1/2025.acl-long.1059,Typology-Guided Adaptation in Multilingual Models,Ndapa Nakashole,(missing journal),2025,(missing abstract),289482733,0,0,,
10.18653/v1/2025.acl-long.956,Déjà Vu? Decoding Repeated Reading from Eye Movements,"Yoav Meiri, Omer Shubi, Cfir Avraham Hadar, Ariel Kreisberg Nitzav, Yevgeni Berzak",(missing journal),2025,(missing abstract),289482734,0,0,,
10.18653/v1/2025.acl-long.1008,AdaptAgent: Adapting Multimodal Web Agents with Few-Shot Learning from Human Demonstrations,"Gaurav Verma, Rachneet Kaur, Nishan Srishankar, Zhen Zeng, Tucker Balch, Manuela Veloso",(missing journal),2025,(missing abstract),289482735,0,0,,
10.18653/v1/2025.acl-long.1024,CAMI: A Counselor Agent Supporting Motivational Interviewing through State Inference and Topic Exploration,"Yizhe Yang, Palakorn Achananuparp, Heyan Huang, Jing Jiang, Phey Ling Kit, Nicholas K. Lim, Cameron Tan Shi Ern, Ee‐Peng Lim",(missing journal),2025,(missing abstract),289482736,0,0,,
10.18653/v1/2025.acl-long.1062,FaithfulRAG: Fact-Level Conflict Modeling for Context-Faithful Retrieval-Augmented Generation,"Qinggang Zhang, Zhiyi Xiang, Yilin Xiao, Le Wang, Lei Zhu, Xinrun Wang, Jinsong Su",(missing journal),2025,(missing abstract),289482737,1,0,,
10.18653/v1/2025.acl-long.936,When GPT Spills the Tea: Comprehensive Assessment of Knowledge File Leakage in GPTs,"Xinyue Shen, Yun Shen, Michael Backes, Yang Zhang",(missing journal),2025,(missing abstract),289482738,0,0,,
10.18653/v1/2025.acl-long.920,Improving Dialogue Discourse Parsing through Discourse-aware Utterance Clarification,"Yaxin Fan, Peifeng Li, Qiaoming Zhu",(missing journal),2025,(missing abstract),289482739,0,0,,
10.18653/v1/2025.acl-long.928,LoGU: Long-form Generation with Uncertainty Expressions,"Ruihan Yang, Caiqi Zhang, Zhisong Zhang, Xinting Huang, Shucai Yang, Nigel Collier, Donghong Yu, Deqing Yang",(missing journal),2025,(missing abstract),289482740,0,0,,
10.18653/v1/2025.acl-long.971,Text-to-ES Bench: A Comprehensive Benchmark for Converting Natural Language to Elasticsearch Query,"Danna Xue, Zhili Pu, Zhiqiang Xia, Hongli Sun, Ruihui Hou, Guoxing Yu, Yan Lin, Yongqi Fan, Jingping Liu, Tong Ruan",(missing journal),2025,(missing abstract),289482741,0,0,,
10.18653/v1/2025.acl-long.804,Aligning Large Language Models to Follow Instructions and Hallucinate Less via Effective Data Filtering,"Shuzheng Si, Haozhe Zhao, Gang Chen, Cheng Gao, Yuzhuo Bai, Zhitong Wang, Kaikai An, Kangyang Luo, Qian Chen, Fanchao Qi, Baobao Chang, Maosong Sun",(missing journal),2025,(missing abstract),289482742,0,0,,
10.18653/v1/2025.acl-long.827,Global Eye: Breaking the “Fixed Thinking Pattern” during the Instruction Expansion Process,"Wenxuan Lu, Yunguo Liu, Jian Luan, Bin Wang, Shu Jiang, Tianning Zang",(missing journal),2025,(missing abstract),289482743,0,0,,
10.18653/v1/2025.acl-long.799,What Matters in Evaluating Book-Length Stories? A Systematic Study of Long Story Evaluation,"Dingyi Yang, Qin Jin",(missing journal),2025,(missing abstract),289482744,0,0,,
10.18653/v1/2025.acl-long.786,Dynamic Head Selection for Neural Lexicalized Constituency Parsing,"Yang Hou, Zhenghua Li",(missing journal),2025,(missing abstract),289482745,0,0,,
10.18653/v1/2025.acl-long.810,Private Memorization Editing: Turning Memorization into a Defense to Strengthen Data Privacy in Large Language Models,"Elena Sofia Ruzzetti, Giancarlo A. Xompero, Davide Venditti, Fabio Massimo Zanzotto",Annual Meeting of the Association for Computational Linguistics,2025,"Large Language Models (LLMs) memorize, and thus, among huge amounts of uncontrolled data, may memorize Personally Identifiable Information (PII), which should not be stored and, consequently, not leaked. In this paper, we introduce Private Memorization Editing (PME), an approach for preventing private data leakage that turns an apparent limitation, that is, the LLMs'memorization ability, into a powerful privacy defense strategy. While attacks against LLMs have been performed exploiting previous knowledge regarding their training data, our approach aims to exploit the same kind of knowledge in order to make a model more robust. We detect a memorized PII and then mitigate the memorization of PII by editing a model knowledge of its training data. We verify that our procedure does not affect the underlying language model while making it more robust against privacy Training Data Extraction attacks. We demonstrate that PME can effectively reduce the number of leaked PII in a number of configurations, in some cases even reducing the accuracy of the privacy attacks to zero.",289482746,1,27,,
10.18653/v1/2025.acl-long.1177,DEEPER Insight into Your User: Directed Persona Refinement for Dynamic Persona Modeling,"Aili Chen, Chengyu Du, Jiangjie Chen, Jinghan Xu, Yikai Zhang, Siyu Yuan, Zulong Chen, Liangyue Li, Yanghua Xiao",(missing journal),2025,(missing abstract),289482747,0,0,,
10.18653/v1/2025.acl-long.628,From Objectives to Questions: A Planning-based Framework for Educational Mathematical Question Generation,"Cheng Cheng, Zhenya Huang, GuanHao Zhao, Y. Guo, Xin Lin, Jinze Wu, Xin Li, Shijin Wang",(missing journal),2025,(missing abstract),289482748,0,0,,
10.18653/v1/2025.acl-long.698,MaXIFE: Multilingual and Cross-lingual Instruction Following Evaluation,"Yile Liu, Ziwei Ma, Xiu Jiang, Jinglu Hu, ChangJing ChangJing, Liang Li",(missing journal),2025,(missing abstract),289482749,0,0,,
10.18653/v1/2025.acl-long.733,TRIDENT: Enhancing Large Language Model Safety with Tri-Dimensional Diversified Red-Teaming Data Synthesis,"Xiaorui Wu, Xiaofeng Mao, Fei Li, Xin Zhang, Xiaoming Li, Chong Teng, D.D. Ji, Zhuang Li",(missing journal),2025,(missing abstract),289482750,0,0,,
10.18653/v1/2025.acl-long.714,QDTSynth: Quality-Driven Formal Theorem Synthesis for Enhancing Proving Performance of LLMs,"Lei Wang, Ruobing Zuo, Guangyuan He, Jianlin Wang, Zhaohui Yang",(missing journal),2025,(missing abstract),289482751,0,0,,
10.18653/v1/2025.acl-long.682,Recent Advances in Speech Language Models: A Survey,"Wenqian Cui, Dianzhi Yu, Xiaoqi Jiao, Ziqiao Meng, Guangyan Zhang, Qichao Wang, Shesen Guo, Irwin King",(missing journal),2025,(missing abstract),289482752,3,0,,
10.18653/v1/2025.acl-long.609,"SURVEYFORGE : On the Outline Heuristics, Memory-Driven Generation, and Multi-dimensional Evaluation for Automated Survey Writing","Xiangchao Yan, Shiyang Feng, Jiakang Yuan, Renqiu Xia, Bin Wang, Lei Bai, Bo Zhang",(missing journal),2025,(missing abstract),289482753,1,0,,
10.18653/v1/2025.acl-long.638,MapNav: A Novel Memory Representation via Annotated Semantic Maps for VLM-based Vision-and-Language Navigation,"Lingfeng Zhang, Xiaoshuai Hao, Qinwen Xu, Qiang Zhang, Xinyao Zhang, Pengwei Wang, Jing Zhang, Zhongyuan Wang, Shanghang Zhang, Renjing Xu",(missing journal),2025,(missing abstract),289482754,0,0,,
10.18653/v1/2025.acl-long.694,Contextual Experience Replay for Self-Improvement of Language Agents,"Yitao Liu, Chenglei Si, Karthik Narasimhan, Shunyu Yao",(missing journal),2025,(missing abstract),289482755,0,0,,
10.18653/v1/2025.acl-long.699,Linguistic Generalizability of Test-Time Scaling in Mathematical Reasoning,"Guijin Son, Jiwoo Hong, Hyunwoo Ko, James Thorne",(missing journal),2025,(missing abstract),289482756,0,0,,
10.18653/v1/2025.acl-long.765,How to Compare Things Properly? A Study of Argument Relevance in Comparative Question Answering,"Irina Nikishina, Saba Anwar, Nikolay Dolgov, Maria Manina, Daria Ignatenko, Artem Shelmanov, Chris Biemann",(missing journal),2025,(missing abstract),289482757,0,0,,
10.18653/v1/2025.acl-long.643,Cultivating Gaming Sense for Yourself: Making VLMs Gaming Experts,"Weixu Lu, Jian He, Zhanqiu Zhang, Shengli Guo, Tianning Zang",(missing journal),2025,(missing abstract),289482758,0,0,,
10.18653/v1/2025.acl-long.542,Frictional Agent Alignment Framework: Slow Down and Don’t Break Things,"Abhijnan Nath, Carine Graff, Andrei Bachinin, Nikhil Krishnaswamy",(missing journal),2025,(missing abstract),289482759,0,0,,
10.18653/v1/2025.acl-long.576,"Agri-CM3: A Chinese Massive Multi-modal, Multi-level Benchmark for Agricultural Understanding and Reasoning","Haotian Wang, Yi Guan, Fanchao Meng, Chao Zhao, Lian Yan, Yang Yang, Jingchi Jiang",(missing journal),2025,(missing abstract),289482760,0,0,,
10.18653/v1/2025.acl-long.558,TC–RAG: Turing–Complete RAG’s Case study on Medical LLM Systems,"Xinke Jiang, Yue Fang, Rihong Qiu, Haoyu Zhang, Yongxin Xu, Hao Chen, Wentao Zhang, R.Q. Zhang, Yuchen Fang, Xin Ma, Xu Chu, Zhao Jun-feng, Yasha Wang",(missing journal),2025,(missing abstract),289482761,3,0,,
10.18653/v1/2025.acl-long.547,Disambiguating Reference in Visually Grounded Dialogues through Joint Modeling of Textual and Multimodal Semantic Structures,"Shun Inadumi, Nobuhiro Ueda, Koichiro Yoshino",(missing journal),2025,(missing abstract),289482762,0,0,,
10.18653/v1/2025.acl-long.520,ExpeTrans: LLMs Are Experiential Transfer Learners,"Jinglong Gao, Xiao Ding, Longhao Zou, Bibo Cai, Bing Qin, Ting Liu",(missing journal),2025,(missing abstract),289482763,0,0,,
10.18653/v1/2025.acl-long.517,From Real to Synthetic: Synthesizing Millions of Diversified and Complicated User Instructions with Attributed Grounding,"Chiwei Zhu, Benfeng Xu, Xiaorui Wang, Zhendong Mao",(missing journal),2025,(missing abstract),289482764,0,0,,
10.18653/v1/2025.acl-long.534,GuessArena: Guess Who I Am? A Self-Adaptive Framework for Evaluating LLMs in Domain-Specific Knowledge and Reasoning,"Qingchen Yu, Zifan Zheng, Chen Ding, Simin Niu, Bo Tang, Feiyu Xiong, Zhiyu Li",(missing journal),2025,(missing abstract),289482765,0,0,,
10.18653/v1/2025.acl-long.473,TeRDy: Temporal Relation Dynamics through Frequency Decomposition for Temporal Knowledge Graph Completion,"Ziyang Liu, Chaokun Wang",(missing journal),2025,(missing abstract),289482766,0,0,,
10.18653/v1/2025.acl-long.401,Building a Long Text Privacy Policy Corpus with Multi-Class Labels,"Florencia Marotta‐Wurgler, David Stein",(missing journal),2025,(missing abstract),289482767,0,0,,
10.18653/v1/2025.acl-long.316,Efficiently Identifying Watermarked Segments in Mixed-Source Texts,"Xuandong Zhao, Chenwen Liao, Yu-Xiang Wang, Lei Li",(missing journal),2025,(missing abstract),289482768,0,0,,
10.18653/v1/2025.acl-long.423,LLMs can Perform Multi-Dimensional Analytic Writing Assessments: A Case Study of L2 Graduate-Level Academic English Writing,"Zhengxiang Wang, Veronika Makarova, Zhi Li, Jordan Kodner, Owen Rambow",(missing journal),2025,(missing abstract),289482769,0,0,,
10.18653/v1/2025.acl-long.444,Improving Preference Extraction In LLMs By Identifying Latent Knowledge Through Classifying Probes,"Sharan Maiya, Yinhong Liu, Ramit Debnath, Anna Korhonen",(missing journal),2025,(missing abstract),289482770,0,0,,
10.18653/v1/2025.acl-long.274,Enhancing Transformers for Generalizable First-Order Logical Entailment,"Tianshi Zheng, Jiazheng Wang, Zihao Wang, Jiaxin Bai, Hang Yin, Zheye Deng, Yangqiu Song, Jianxin Li",(missing journal),2025,(missing abstract),289482771,0,0,,
10.18653/v1/2025.acl-long.288,Enhancing Automated Interpretability with Output-Centric Feature Descriptions,"Yoav Gur-Arieh, Roy Mayan, Chen Agassy, Atticus Geiger, Mor Geva",(missing journal),2025,(missing abstract),289482772,0,0,,
10.18653/v1/2025.acl-long.242,On the Limit of Language Models as Planning Formalizers,"Cassie Huang, Li Zhang",(missing journal),2025,(missing abstract),289488669,0,0,,
10.18653/v1/2025.acl-long.251,Stepwise Reasoning Disruption Attack of LLMs,"Jingyu Peng, Maolin Wang, Xiangyu Zhao, Kai Zhang, Wanyu Wang, Pengyue Jia, Qidong Liu, Ruocheng Guo, Qi Liu",(missing journal),2025,(missing abstract),289488670,0,0,,
10.18653/v1/2025.acl-long.236,Discourse Relation-Enhanced Neural Coherence Modeling,"Wei Liu, Michael Strube",(missing journal),2025,(missing abstract),289488671,0,0,,
10.18653/v1/2025.acl-long.209,The Impact of Token Granularity on the Predictive Power of Language Model Surprisal,"Byung-Doh Oh, William Schuler",(missing journal),2025,(missing abstract),289488672,0,0,,
10.18653/v1/2025.acl-long.200,Past Meets Present: Creating Historical Analogy with Large Language Models,"Nianqi Li, Siyu Yuan, Jiangjie Chen, Jiaqing Liang, Wei Feng, Zujie Liang, Deqing Yang, Yanghua Xiao",(missing journal),2025,(missing abstract),289488673,0,0,,
10.18653/v1/2025.acl-long.219,Can LLMs Simulate L2-English Dialogue? An Information-Theoretic Analysis of L1-Dependent Biases,"Rena Gao, Xuetong Wu, Tatsuki Kuribayashi, Mingrui Ye, Siya Qi, Carsten Roever, Ying Liu, Zheng Yuan, Jey Han Lau",(missing journal),2025,(missing abstract),289488674,0,0,,
10.18653/v1/2025.acl-long.143,Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model,"Gregor Geigle, Florian Schneider, Carolin Holtermann, Chris Biemann, Radu Timofte, Anne Lauscher, Goran Glavaš",(missing journal),2025,(missing abstract),289488675,0,0,,
10.18653/v1/2025.acl-long.110,Have We Designed Generalizable Structural Knowledge Promptings? Systematic Evaluation and Rethinking,"Yichi Zhang, Zhuo Chen, Lingbing Guo, Yajing Xu, S S Chen, Mengshu Sun, Binbin Hu, Zhiqiang Zhang, Lei Liang, Wen Zhang, Huajun Chen",(missing journal),2025,(missing abstract),289488676,0,0,,
10.18653/v1/2025.acl-long.132,Unraveling the Mechanics of Learning-Based Demonstration Selection for In-Context Learning,"Hui Liu, Wenya Wang, Hao Sun, Chris Xing Tian, Chenqi Kong, Xin Dong, Haoliang Li",(missing journal),2025,(missing abstract),289488677,0,0,,
10.18653/v1/2025.acl-long.115,HateDay: Insights from a Global Hate Speech Dataset Representative of a Day on Twitter,"Manuel Tonneau, Diyi Liu, Niyati Malhotra, Scott A. Hale, Samuel P. Fraiberger, Víctor Orozco-Olvera, Paul Röttger",(missing journal),2025,(missing abstract),289488678,0,0,,
10.18653/v1/2025.acl-long.152,MAPS: Motivation-Aware Personalized Search via LLM-Driven Consultation Alignment,"Weicong Qin, Yi Xu, Weijie Yu, Chenglei Shen, Mingguang He, Jianping Fan, Xiao Zhang, Jun Xu",(missing journal),2025,(missing abstract),289488679,0,0,,
10.18653/v1/2025.acl-long.58,ObfusLM: Privacy-preserving Language Model Service against Embedding Inversion Attacks,"Yu‐Pin Lin, Ruining Yang, Yunlong Mao, Qizhi Zhang, Jue Hong, Quanwei Cai, Ye Wu, Huiqi Liu, Zhiyu Chen, Bing Duan, Sheng Zhong",(missing journal),2025,(missing abstract),289488680,0,0,,
10.18653/v1/2025.acl-long.8,Sliding Windows Are Not the End: Exploring Full Ranking with Long-Context Large Language Models,"Wenhan Liu, Xinyu Ma, Yutao Zhu, Ziliang Zhao, Shuaiqiang Wang, Dawei Yin, Zhicheng Dou",(missing journal),2025,(missing abstract),289488687,1,0,,
10.18653/v1/2025.acl-long.1570,Neural Parameter Search for Slimmer Fine-Tuned Models and Better Transfer,"Guodong Du, Fangwei Zhang, Jing Li, Jianming Li, Rong Jiang, Shuyang Yu, Yifei Guo, Yida Chen, Sim Kuan Goh, Ho-Kin Tang, Daojing He, Honghai Liu, M. Zhang",(missing journal),2025,(missing abstract),289488831,0,0,,
10.18653/v1/2025.acl-long.1555,Low-Bit Quantization Favors Undertrained LLMs,"Xu Ouyang, Tao Ge, Thomas Hartvigsen, Zhisong Zhang, Haitao Mi, Yu Dong",(missing journal),2025,(missing abstract),289488832,0,0,,
10.18653/v1/2025.acl-long.1529,Only a Little to the Left: A Theory-grounded Measure of Political Bias in Large Language Models,"Mats Faulborn, Indira Sen, Max Pellert, Andreas Spitz, David García",(missing journal),2025,(missing abstract),289488833,0,0,,
10.18653/v1/2025.acl-long.1569,LangMark: A Multilingual Dataset for Automatic Post-Editing,"Diego Alejandro Velazquez, Mikaela Grace, Konstantinos Karageorgos, Lawrence Carin, Aaron Schliem, Dimitrios Zaikis, Roger Wechsler",Annual Meeting of the Association for Computational Linguistics,2025,"Automatic post-editing (APE) aims to correct errors in machine-translated text, enhancing translation quality, while reducing the need for human intervention. Despite advances in neural machine translation (NMT), the development of effective APE systems has been hindered by the lack of large-scale multilingual datasets specifically tailored to NMT outputs. To address this gap, we present and release LangMark, a new human-annotated multilingual APE dataset for English translation to seven languages: Brazilian Portuguese, French, German, Italian, Japanese, Russian, and Spanish. The dataset has 206,983 triplets, with each triplet consisting of a source segment, its NMT output, and a human post-edited translation. Annotated by expert human linguists, our dataset offers both linguistic diversity and scale. Leveraging this dataset, we empirically show that Large Language Models (LLMs) with few-shot prompting can effectively perform APE, improving upon leading commercial and even proprietary machine translation systems. We believe that this new resource will facilitate the future development and evaluation of APE systems.",289488834,0,36,,
10.18653/v1/2025.acl-long.1526,Teaching Text Agents to Learn Sequential Decision Making from Failure,"Canasai Kruengkrai, Koichiro Yoshino",(missing journal),2025,(missing abstract),289488835,0,0,,
10.18653/v1/2025.acl-long.1531,Exploiting Contextual Knowledge in LLMs through 𝒱-usable Information based Layer Enhancement,"Xiaowei Yuan, Zhao Yang, Ziyang Huang, Yongke Wang, Si Fan, Yonglin Ju, Jun Zhao, L. Kang",(missing journal),2025,(missing abstract),289488836,0,0,,
10.18653/v1/2025.acl-long.1510,HintsOfTruth: A Multimodal Checkworthiness Detection Dataset with Real and Synthetic Claims,"M. van der Meer, Pavel Korshunov, Sébastien Marcel, Lonneke van der Plas",(missing journal),2025,(missing abstract),289488837,0,0,,
10.18653/v1/2025.acl-long.1541,Refining Salience-Aware Sparse Fine-Tuning Strategies for Language Models,"Xinxin Liu, Aaron Thomas, Cheng Zhang, Jianyi Cheng, Yiren Zhao, Xitong Gao",(missing journal),2025,(missing abstract),289488838,0,0,,
10.18653/v1/2025.acl-long.1591,OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models,"Si-Ming Huang, Tsung‐Chieh Cheng, Jie Liu, Weidi Xu, Jingru Hao, Liuyihan Song, Yang Xu, Jian Yang, Jiaheng Liu, Chenchen Zhang, Linzheng Chai, Ruifeng Yuan, Xianzhen Luo, Qiufeng Wang, YuanTao Fan, Qingfu Zhu, Zhaoxiang Zhang, Yang Gao, Jie Fu, Qian Liu, Houyi Li, Ge Zhang, Qi Yuan, Xu Yinghui, Wei-Ta Chu, Zili Wang",(missing journal),2025,(missing abstract),289488839,3,0,,
10.18653/v1/2025.acl-long.1465,FairI Tales: Evaluation of Fairness in Indian Contexts with a Focus on Bias and Stereotypes,"Janki Nawale, Mohammed Safi Ur Rahman Khan, D Janani, Mansi Gupta, Danish Pruthi, Mitesh M. Khapra",(missing journal),2025,(missing abstract),289488840,0,0,,
10.18653/v1/2025.acl-long.1442,TaxoAdapt: Aligning LLM-Based Multidimensional Taxonomy Construction to Evolving Research Corpora,"Priyanka Kargupta, Nan Zhang, Yunyi Zhang, Rui Zhang, Prasenjit Mitra, Jiawei Han",(missing journal),2025,(missing abstract),289488841,1,0,,
10.18653/v1/2025.acl-long.1437,Time-MQA: Time Series Multi-Task Question Answering with Context Enhancement,"Yaxuan Kong, Yiyuan Yang, Yoontae Hwang, Wenjie Du, Stefan Zohren, Zhangyang Wang, Ming Jin, Qingsong Wen",(missing journal),2025,(missing abstract),289488842,0,0,,
10.18653/v1/2025.acl-long.1423,Hierarchical Memory Organization for Wikipedia Generation,"Eugene J. Yu, Dawei Zhu, Yifan Song, Xiangyu Wong, Jiebin Zhang, Wenxuan Shi, Xiaoguang Li, Qun Liu, Sujian Li",(missing journal),2025,(missing abstract),289488843,0,0,,
10.18653/v1/2025.acl-long.1468,PIGuard: Prompt Injection Guardrail via Mitigating Overdefense for Free,"Hao Li, Xiaogeng Liu, Ning Zhang, Chaowei Xiao",(missing journal),2025,(missing abstract),289488844,0,0,,
10.18653/v1/2025.acl-long.1389,PIPER: Benchmarking and Prompting Event Reasoning Boundary of LLMs via Debiasing-Distillation Enhanced Tuning,"Zhicong Lu, Changyuan Tian, PeiguangLi PeiguangLi, Li Jin, Sirui Wang, Jia Wei, Jianfa Shen, Guangluan Xu",(missing journal),2025,(missing abstract),289488845,0,0,,
10.18653/v1/2025.acl-long.1339,Personal Travel Solver: A Preference-Driven LLM-Solver System for Travel Planning,"Zhijing Shao, Jiancan Wu, Jiawei Chen, Xiang Wang",(missing journal),2025,(missing abstract),289488846,0,0,,
10.18653/v1/2025.acl-long.1310,From Informal to Formal – Incorporating and Evaluating LLMs on Natural Language Requirements to Verifiable Formal Proofs,"Jialun Cao, Yaojie Lu, Meiziniu Li, Haoyang Ma, Haokun Li, Mengda He, Cheng Wen, Le Sun, Hongyu Zhang, Shengchao Qin, Shing-Chi Cheung, Cong Tian",(missing journal),2025,(missing abstract),289488847,1,0,,
10.18653/v1/2025.acl-long.1275,Cultural Bias Matters: A Cross-Cultural Benchmark Dataset and Sentiment-Enriched Model for Understanding Multimodal Metaphors,"Senqi Yang, Dongyu Zhang, Jing Ren, Ziqi Xu, Xiuzhen Zhang, Yiliao Song, Hongfei Lin, Feng Xia",(missing journal),2025,(missing abstract),289488848,0,0,,
10.18653/v1/2025.acl-long.1316,What are the Essential Factors in Crafting Effective Long Context Multi-Hop Instruction Datasets? Insights and Best Practices,"Zhi Chen, Qiguang Chen, Libo Qin, Qipeng Guo, Haijun Lv, Yicheng Zou, Hang Yan, Kai Chen, Dahua Lin",(missing journal),2025,(missing abstract),289488849,0,0,,
10.18653/v1/2025.acl-long.1223,Unravelling the Logic: Investigating the Generalisation of Transformers in Numerical Satisfiability Problems,"Tharindu Madusanka, Marco Valentino, Iqra Zahid, Ian Pratt‐Hartmann, Riza Batista-Navarro",(missing journal),2025,(missing abstract),289488850,0,0,,
10.18653/v1/2025.acl-long.1304,“Give Me BF16 or Give Me Death”? Accuracy-Performance Trade-Offs in LLM Quantization,"Eldar Kurtic, Alexandre Carriconde Marques, Shubhra Pandit, Mark Kurtz, Dan Alistarh",(missing journal),2025,(missing abstract),289488851,1,0,,
10.18653/v1/2025.acl-long.1212,SEA: Low-Resource Safety Alignment for Multimodal Large Language Models via Synthetic Embeddings,"Weikai Lu, Hao Peng, Huiping Zhuang, Cen Chen, Ziqian Zeng",(missing journal),2025,(missing abstract),289488852,0,0,,
10.18653/v1/2025.acl-long.1136,Synthesizing Post-Training Data for LLMs through Multi-Agent Simulation,"Shuo Tang, Xinyue Pang, Zihang Liu, Bohan Tang, Rui Ye, Tian Jin, Xiaowen Dong, Yanfeng Wang, Siheng Chen",(missing journal),2025,(missing abstract),289490669,1,0,,
10.18653/v1/2025.acl-long.1105,Advancing Collaborative Debates with Role Differentiation through Multi-Agent Reinforcement Learning,"Haoran Li, Zhanhao Su, Yun Xue, Zhiliang Tian, Yiping Song, Minlie Huang",(missing journal),2025,(missing abstract),289490670,2,0,,
10.18653/v1/2025.acl-long.1093,Decoding Knowledge Attribution in Mixture-of-Experts: A Framework of Basic-Refinement Collaboration and Efficiency Analysis,"Junzhuo Li, Bo Wang, Xiuze Zhou, Peijie Jiang, Jia Liu, Xuming Hu",(missing journal),2025,(missing abstract),289490671,0,0,,
10.18653/v1/2025.acl-long.1081,Flipping Knowledge Distillation: Leveraging Small Models’ Expertise to Enhance LLMs in Text Matching,"M. Li, Jing Xiang, Qishen Zhang, Kai-Yang Wan, Xiuying Chen",(missing journal),2025,(missing abstract),289490672,0,0,,
10.18653/v1/2025.acl-long.1089,Mitigating Lost-in-Retrieval Problems in Retrieval Augmented Multi-Hop Question Answering,"Rong Zhu, Xiangyu Liu, Zequn Sun, Yiwei Wang, Wei Hu",(missing journal),2025,(missing abstract),289490673,0,0,,
10.18653/v1/2025.acl-long.1131,S2WTM: Spherical Sliced-Wasserstein Autoencoder for Topic Modeling,"Suman Adhya, Debarshi Kumar Sanyal",Annual Meeting of the Association for Computational Linguistics,2025,"Modeling latent representations in a hyperspherical space has proven effective for capturing directional similarities in high-dimensional text data, benefiting topic modeling. Variational autoencoder-based neural topic models (VAE-NTMs) commonly adopt the von Mises-Fisher prior to encode hyperspherical structure. However, VAE-NTMs often suffer from posterior collapse, where the KL divergence term in the objective function highly diminishes, leading to ineffective latent representations. To mitigate this issue while modeling hyperspherical structure in the latent space, we propose the Spherical Sliced Wasserstein Autoencoder for Topic Modeling (S2WTM). S2WTM employs a prior distribution supported on the unit hypersphere and leverages the Spherical Sliced-Wasserstein distance to align the aggregated posterior distribution with the prior. Experimental results demonstrate that S2WTM outperforms state-of-the-art topic models, generating more coherent and diverse topics while improving performance on downstream tasks.",289490674,0,43,,
10.18653/v1/2025.acl-long.1101,MEMERAG: A Multilingual End-to-End Meta-Evaluation Benchmark for Retrieval Augmented Generation,"María Andrea Cruz Blandón, Jayasimha Talur, Bruno Charron, Dong Liu, Saab Mansour, Marcello Federico",(missing journal),2025,(missing abstract),289490675,0,0,,
10.18653/v1/2025.acl-long.963,Dynamic Evaluation with Cognitive Reasoning for Multi-turn Safety of Large Language Models,"Li Zhang, Yanan Cao, Yuqiang Xie, Fang Fang, Yangxi Li",(missing journal),2025,(missing abstract),289490676,0,0,,
10.18653/v1/2025.acl-long.1020,SYNTHIA: Novel Concept Design with Affordance Composition,"H.N. Ha, Xiaomeng Jin, Jeonghwan Kim, Jiateng Liu, Zhenhailong Wang, Khanh Duy Nguyen, Ansel Blume, Nanyun Peng, Kai-Wei Chang, Heng Ji",(missing journal),2025,(missing abstract),289490677,0,0,,
10.18653/v1/2025.acl-long.1060,"Don’t Erase, Inform! Detecting and Contextualizing Harmful Language in Cultural Heritage Collections","Orfeas Menis Mastromichalakis, Jason Liartis, Kristina Rose, Antoine Isaac, Giorgos Stamou",(missing journal),2025,(missing abstract),289490678,0,0,,
10.18653/v1/2025.acl-long.964,From Tools to Teammates: Evaluating LLMs in Multi-Session Coding Interactions,"Nathanaël Carraz Rakotonirina, Mohammed Hamdy, Jon Ander Campos, Linda Weber, Alberto Testoni, Marzieh Fadaee, Sandro Pezzelle, Marco Del Tredici",(missing journal),2025,(missing abstract),289490679,0,0,,
10.18653/v1/2025.acl-long.984,Modeling the Evolution of English Noun Compounds with Feature-Rich Diachronic Compositionality Prediction,"Filip Miletić, Sabine Schulte im Walde",(missing journal),2025,(missing abstract),289490680,0,0,,
10.18653/v1/2025.acl-long.978,Vulnerability of LLMs to Vertically Aligned Text Manipulations,"Zhecheng Li, Yiwei Wang, Bryan Hooi, Yujun Cai, Zeng Xiong, Nanyun Peng, Kai-Wei Chang",(missing journal),2025,(missing abstract),289490681,0,0,,
10.18653/v1/2025.acl-long.1022,AUTALIC: A Dataset for Anti-AUTistic Ableist Language In Context,"Naba Rizvi, Hugh Edwin Strickland, Darren R. Gitelman, Alexis Morales Flores, Ted Cooper, Aekta Kallepalli, Akshat Alurkar, Haaset Owens, Saleha Ahmedi, Isha Khirwadkar, Imani N. S. Munyaka, Nedjma Ousidhoum",Annual Meeting of the Association for Computational Linguistics,2025,"As our understanding of autism and ableism continues to increase, so does our understanding of ableist language towards autistic people. Such language poses a significant challenge in NLP research due to its subtle and context-dependent nature. Yet, detecting anti-autistic ableist language remains underexplored, with existing NLP tools often failing to capture its nuanced expressions. We present AUTALIC, the first benchmark dataset dedicated to the detection of anti-autistic ableist language in context, addressing a significant gap in the field. The dataset comprises 2,400 autism-related sentences collected from Reddit, accompanied by surrounding context, and is annotated by trained experts with backgrounds in neurodiversity. Our comprehensive evaluation reveals that current language models, including state-of-the-art LLMs, struggle to reliably identify anti-autistic ableism and align with human judgments, underscoring their limitations in this domain. We publicly release AUTALIC along with the individual annotations which serve as a valuable resource to researchers working on ableism, neurodiversity, and also studying disagreements in annotation tasks. This dataset serves as a crucial step towards developing more inclusive and context-aware NLP systems that better reflect diverse perspectives.",289490682,3,68,,
10.18653/v1/2025.acl-long.901,AntiLeakBench: Preventing Data Contamination by Automatically Constructing Benchmarks with Updated Real-World Knowledge,"Xiaobao Wu, Liangming Pan, Y. Y. Xie, R. Zhou, Shuai Zhao, Yubo Ma, M.W. Du, Rui Mao, Anh Tuan Luu, William Yang Wang",(missing journal),2025,(missing abstract),289490683,1,0,,
10.18653/v1/2025.acl-long.1010,On the Acquisition of Shared Grammatical Representations in Bilingual Language Models,"Catherine Arnett, Tyler A. Chang, James A. Michaelov, Ben Bergen",(missing journal),2025,(missing abstract),289490684,0,0,,
10.18653/v1/2025.acl-long.977,"Integrating Audio, Visual, and Semantic Information for Enhanced Multimodal Speaker Diarization on Multi-party Conversation","Luyao Cheng, Hui Wang, Chong Deng, Siqi Zheng, Yafeng Chen, Rongjie Huang, Qinglin Zhang, Qian Chen, Xihao Li, Wen Wang",(missing journal),2025,(missing abstract),289490685,0,0,,
10.18653/v1/2025.acl-long.898,Acquisition and Application of Novel Knowledge in Large Language Models,"Ziyu Shang, Jianghan Liu, Zhizhao Luo, Peng Wang, Wenjun Ke, Jiajun Liu, Zijie Xu, Guozheng Li",(missing journal),2025,(missing abstract),289490686,0,0,,
10.18653/v1/2025.acl-long.905,Can Large Language Models Detect Errors in Long Chain-of-Thought Reasoning?,"Y He, Shilong Li, Jiaheng Liu, Weixun Wang, Xingyuan Bu, Ge Zhang, Zhongyuan Peng, Zhaoxiang Zhang, Zhicheng Zheng, Wenbo Su, B. Zheng",(missing journal),2025,(missing abstract),289490687,1,0,,
10.18653/v1/2025.acl-long.806,RAEmoLLM: Retrieval Augmented LLMs for Cross-Domain Misinformation Detection Using In-Context Learning Based on Emotional Information,"Zhiwei Liu, Kailai Yang, Qianqian Xie, Christine de Kock, Sophia Ananiadou, Eduard Hovy",Annual Meeting of the Association for Computational Linguistics,2025,"Misinformation is prevalent in various fields such as education, politics, health, etc., causing significant harm to society. However, current methods for cross-domain misinformation detection rely on effort- and resource-intensive fine-tuning and complex model structures. With the outstanding performance of LLMs, many studies have employed them for misinformation detection. Unfortunately, they focus on in-domain tasks and do not incorporate significant sentiment and emotion features (which we jointly call {\em affect}). In this paper, we propose RAEmoLLM, the first retrieval augmented (RAG) LLMs framework to address cross-domain misinformation detection using in-context learning based on affective information. RAEmoLLM includes three modules. (1) In the index construction module, we apply an emotional LLM to obtain affective embeddings from all domains to construct a retrieval database. (2) The retrieval module uses the database to recommend top K examples (text-label pairs) from source domain data for target domain contents. (3) These examples are adopted as few-shot demonstrations for the inference module to process the target domain content. The RAEmoLLM can effectively enhance the general performance of LLMs in cross-domain misinformation detection tasks through affect-based retrieval, without fine-tuning. We evaluate our framework on three misinformation benchmarks. Results show that RAEmoLLM achieves significant improvements compared to the other few-shot methods on three datasets, with the highest increases of 15.64%, 31.18%, and 15.73% respectively. This project is available at https://github.com/lzw108/RAEmoLLM.",289490688,10,31,,
10.18653/v1/2025.acl-long.866,Inferring Functionality of Attention Heads from their Parameters,"Amit Elhelo, Mor Geva",(missing journal),2025,(missing abstract),289490689,0,0,,
10.18653/v1/2025.acl-long.833,Mis-prompt: Benchmarking Large Language Models for Proactive Error Handling,"Jie Zeng, Yan‐Quan Feng, Mengliang He, Wenhui Lei, Wei Zhang, Zeming Liu, Xiaoming Shi, Aimin Zhou",(missing journal),2025,(missing abstract),289490690,0,0,,
10.18653/v1/2025.acl-long.831,Analyzing the Rapid Generalization of SFT via the Perspective of Attention Head Activation Patterns,"Yang Zhao, Li Du, Xiao Ding, Kai Xiong, Ting Liu, Bing Qin",(missing journal),2025,(missing abstract),289490691,0,0,,
10.18653/v1/2025.acl-long.832,Can’t See the Forest for the Trees: Benchmarking Multimodal Safety Awareness for Multimodal LLMs,"Wenxuan Wang, Xiaoyuan Liu, Kun Gao, Jin Huang, Youliang Yuan, Pinjia He, Shuai Wang, Zhaopeng Tu",(missing journal),2025,(missing abstract),289490692,1,0,,
10.18653/v1/2025.acl-long.808,CalibraEval: Calibrating Prediction Distribution to Mitigate Selection Bias in LLMs-as-Judges,"Haitao Li, Junjie Chen, Qingyao Ai, Zhumin Chu, Yujia Zhou, Dong Qian, Yiqun Liu",(missing journal),2025,(missing abstract),289490693,1,0,,
10.18653/v1/2025.acl-long.1199,Alleviating Hallucinations from Knowledge Misalignment in Large Language Models via Selective Abstention Learning,"Lei Huang, Xiaocheng Feng, Weitao Ma, Yong Fan, Xiachong Feng, Yuxuan Gu, Yangfan Ye, Liang Zhao, Weihong Zhong, Baoxin Wang, Dayong Wu, Guoping Hu, Lingpeng Kong, Tong Xiao, Zhiyuan Liu, Bing Qin",(missing journal),2025,(missing abstract),289490694,0,0,,
10.18653/v1/2025.acl-long.775,Agentic Reward Modeling: Integrating Human Preferences with Verifiable Correctness Signals for Reliable Reward Systems,"Hao Peng, Yunjia Qi, Xiaozhi Wang, Zijun Yao, Bingang Xu, Lei Hou, Juanzi Li",(missing journal),2025,(missing abstract),289490695,0,0,,
10.18653/v1/2025.acl-long.689,MM-Verify: Enhancing Multimodal Reasoning with Chain-of-Thought Verification,"Linzhuang Sun, Hao Liang, Jingxuan Wei, Bihui Yu, Tianpeng Li, Fan Yang, Zenan Zhou, Wentao Zhang",(missing journal),2025,(missing abstract),289490696,0,0,,
10.18653/v1/2025.acl-long.707,Stealing Training Data from Large Language Models in Decentralized Training through Activation Inversion Attack,"Chenxi Dai, Lin Lü, Pan Zhou",(missing journal),2025,(missing abstract),289490697,0,0,,
10.18653/v1/2025.acl-long.771,CodeDPO: Aligning Code Models with Self Generated and Verified Source Code,"Kechi Zhang, Ge Li, Yihong Dong, Jingjing Xu, Jun Zhang, Jing Su, Yongfei Liu, Zhi Jin",(missing journal),2025,(missing abstract),289490698,0,0,,
10.18653/v1/2025.acl-long.715,RSVP: Reasoning Segmentation via Visual Prompting and Multi-modal Chain-of-Thought,"Yi Lu, Jiawang Cao, Yongliang Wu, Bozheng Li, Li Tang, Yangguang Ji, Wu Chong, Jay Wu, Wenbo Zhu",(missing journal),2025,(missing abstract),289490699,1,0,,
10.18653/v1/2025.acl-long.690,Graph-Structured Trajectory Extraction from Travelogues,"Aitaro Yamamoto, Hiroyuki Otomo, Hiroki Ouchi, Shohei Higashiyama, Hiroki Teranishi, Hiroyuki Shindo, Taro Watanabe",(missing journal),2025,(missing abstract),289490700,0,0,,
10.18653/v1/2025.acl-long.759,Beyond One-Size-Fits-All: Tailored Benchmarks for Efficient Evaluation,"Peiwen Yuan, Yueqi Zhang, Shaoxiong Feng, Yiwei Li, Xinglin Wang, Jiayi Shi, Chuyi Tan, Boyuan Pan, Yao Hu, K. Li",(missing journal),2025,(missing abstract),289490701,0,0,,
10.18653/v1/2025.acl-long.642,Qwen2.5-xCoder: Multi-Agent Collaboration for Multilingual Code Instruction Tuning,"Jian Yang, Wei Zhang, Yibo Miao, S. Quan, Z. D. Wu, Qiyao Peng, Liqun Yang, Tianyu Liu, Zeyu Cui, Binyuan Hui, Junyang Lin",(missing journal),2025,(missing abstract),289490702,1,0,,
10.18653/v1/2025.acl-long.589,DebateCoder: Towards Collective Intelligence of LLMs via Test Case Driven LLM Debate for Code Generation,"Jizheng Chen, Kounianhua Du, Xinyi Dai, Weiming Zhang, Xihuai Wang, Yasheng Wang, Ruiming Tang, Weinan Zhang, Yong Yu",(missing journal),2025,(missing abstract),289490703,0,0,,
10.18653/v1/2025.acl-long.508,WebWalker: Benchmarking LLMs in Web Traversal,"Jing Wu, Weihua Yin, Yong Jiang, Zhenglin Wang, Zekun Xi, Runnan Fang, Linhai Zhang, Ying He, Deyu Zhou, Pengjun Xie, Fei Huang",(missing journal),2025,(missing abstract),289490704,1,0,,
10.18653/v1/2025.acl-long.518,PrivaCI-Bench: Evaluating Privacy with Contextual Integrity and Legal Compliance,"Haoran Li, Wenbiao Hu, H.B. Wang T. Jing, Yulin Chen, Qi Hu, Sirui Han, Tianshu Chu, Peizhao Hu, Yangqiu Song",(missing journal),2025,(missing abstract),289490705,0,0,,
10.18653/v1/2025.acl-long.557,GuideBench: Benchmarking Domain-Oriented Guideline Following for LLM Agents,"Lan Diao, X. X. Xu, Wei Sun, Cheng Yang, Zhuosheng Zhang",(missing journal),2025,(missing abstract),289490706,0,0,,
10.18653/v1/2025.acl-long.439,Empathy Prediction from Diverse Perspectives,"Francine Chen, Scott L. Carter, Tatiana Lau, Nayeli Suseth Bravo, Sumanta Bhattacharyya, Kate Sieck, Charlene C. Wu",(missing journal),2025,(missing abstract),289490707,0,0,,
10.18653/v1/2025.acl-long.467,AdaDHP: Fine-Grained Fine-Tuning via Dual Hadamard Product and Adaptive Parameter Selection,"Han Liu, Changya Li, Xiaotong Zhang, Feng Zhang, Fenglong Ma, Wei Wang, Hong Liang Yu",(missing journal),2025,(missing abstract),289490708,0,0,,
10.18653/v1/2025.acl-long.420,SciVer: Evaluating Foundation Models for Multimodal Scientific Claim Verification,"Chengye Wang, Yifei Shen, Zexi Kuang, Arman Cohan, Yilun Zhao",(missing journal),2025,(missing abstract),289490709,0,0,,
10.18653/v1/2025.acl-long.469,Curriculum Debiasing: Toward Robust Parameter-Efficient Fine-Tuning Against Dataset Biases,"M. F. Lee, Yeachan Kim, Wing-Lam Mok, SangKeun Lee",(missing journal),2025,(missing abstract),289490710,0,0,,
10.18653/v1/2025.acl-long.366,How to Train Long-Context Language Models (Effectively),"Tianyu Gao, Alexander Wettig, H. W. Yen, Danqi Chen",(missing journal),2025,(missing abstract),289490711,1,0,,
10.18653/v1/2025.acl-long.341,Fairness through Difference Awareness: Measuring Desired Group Discrimination in LLMs,"Angelina Wang, Michelle Phan, Daniel E. Ho, Sanmi Koyejo",(missing journal),2025,(missing abstract),289490712,0,0,,
10.18653/v1/2025.acl-long.427,COSMMIC: Comment-Sensitive Multimodal Multilingual Indian Corpus for Summarization and Headline Generation,"Raghvendra Kumar, M.H.A. Munas, A. Sahu, T. Nandi, Y. P. Pragathi, Sriparna Saha, José G. Moreno",(missing journal),2025,(missing abstract),289490713,0,0,,
10.18653/v1/2025.acl-long.426,LocAgent: Graph-Guided LLM Agents for Code Localization,"Zhaoling Chen, Robert L. Tang, Gangda Deng, Fang Wu, Jialong Wu, Zhiwei Jiang, Viktor Prasanna, Arman Cohan, Xingyao Wang",(missing journal),2025,(missing abstract),289490714,0,0,,
10.18653/v1/2025.acl-long.402,R2-MultiOmnia: Leading Multilingual Multimodal Reasoning via Self-Training,"Leonardo Ranaldi, Federico Ranaldi, Giulia Pucci",(missing journal),2025,(missing abstract),289490715,0,0,,
10.18653/v1/2025.acl-long.391,Watermarking Large Language Models: An Unbiased and Low-risk Method,"Minjia Mao, Dongjun Wei, Zeyu Chen, Fang Xu, Michael Chau",(missing journal),2025,(missing abstract),289490716,0,0,,
10.18653/v1/2025.acl-long.418,RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework,"Kai Zhu, Yaping Luo, Dongsheng Xu, Yu Yan, Zhenghao Liu, Yu Shi, Ruying Wang, Shuo Wang, Yishan Li, Nan Zhang, Xu Han, Zhiyuan Liu, Maosong Sun",Annual Meeting of the Association for Computational Linguistics,2025,"Retrieval-Augmented Generation (RAG) is a powerful approach that enables large language models (LLMs) to incorporate external knowledge. However, evaluating the effectiveness of RAG systems in specialized scenarios remains challenging due to the high costs of data construction and the lack of suitable evaluation metrics. This paper introduces RAGEval, a framework designed to assess RAG systems across diverse scenarios by generating high-quality documents, questions, answers, and references through a schema-based pipeline. With a focus on factual accuracy, we propose three novel metrics: Completeness, Hallucination, and Irrelevance to evaluate LLM generated responses rigorously. Experimental results show that RAGEval outperforms zero-shot and one-shot methods in terms of clarity, safety, conformity, and richness of generated samples. Furthermore, the use of LLMs for scoring the proposed metrics demonstrates a high level of consistency with human evaluations. RAGEval establishes a new paradigm for evaluating RAG systems in real-world applications. The code and dataset are released at https://github.com/OpenBMB/RAGEval.",289490717,35,17,,
10.18653/v1/2025.acl-long.376,ActiView: Evaluating Active Perception Ability for Multimodal Large Language Models,"Ziyue Wang, Chi Chen, Fuwen Luo, Yurui Dong, Yuanchi Zhang, Yuzhuang Xu, Xiaolong Wang, Peng Li, Yang Liu",(missing journal),2025,(missing abstract),289490718,0,0,,
10.18653/v1/2025.acl-long.465,Boosting Long-Context Information Seeking via Query-Guided Activation Refilling,"Hongjin Qian, Zheng Liu, Peitian Zhang, Zhicheng Dou, Defu Lian",(missing journal),2025,(missing abstract),289490719,0,0,,
10.18653/v1/2025.acl-long.269,"Your Model is Overconfident, and Other Lies We Tell Ourselves","Timothee Mickus, Aman Sinha, Raúl Vázquez",(missing journal),2025,(missing abstract),289490720,0,0,,
10.18653/v1/2025.acl-long.275,Self-Taught Agentic Long Context Understanding,"Yufan Zhuang, Xiaodong Yu, Jialian Wu, Ximeng Sun, Ze Wang, Jiang Liu, Yu-Sheng Su, Jingbo Shang, Zicheng Liu, Emad Barsoum",(missing journal),2025,(missing abstract),289490722,0,0,,
10.18653/v1/2025.acl-long.193,Do Large Language Models have an English Accent? Evaluating and Improving the Naturalness of Multilingual LLMs,"Yanzhu Guo, Simone Conia, Zelin Zhou, Min Li, Saloni Potdar, Henry Xiao",(missing journal),2025,(missing abstract),289496566,0,0,,
10.18653/v1/2025.acl-long.240,MorphMark: Flexible Adaptive Watermarking for Large Language Models,"Zongqi Wang, Teng Gu, Baoyuan Wu, Yujiu Yang",(missing journal),2025,(missing abstract),289496567,0,0,,
10.18653/v1/2025.acl-long.84,Disentangling Memory and Reasoning Ability in Large Language Models,"Mingyu Jin, Weidi Luo, Sitao Cheng, Xinyi Wang, Wenyue Hua, Ruixiang Tang, William Yang Wang, Yongfeng Zhang",(missing journal),2025,(missing abstract),289496568,0,0,,
10.18653/v1/2025.acl-long.88,LangSAMP: Language-Script Aware Multilingual Pretraining,"Yihong Liu, Haotian Ye, Chunlan Ma, Mingyang Wang, Hinrich Schuetze",(missing journal),2025,(missing abstract),289496569,0,0,,
10.18653/v1/2025.acl-long.96,"AfriMed-QA: A Pan-African, Multi-Specialty, Medical Question-Answering Benchmark Dataset","Charles Nimo, Tobi Olatunji, Abraham Toluwase Owodunni, Tassallah Abdullahi, Emmanuel Ayodele, Mardhiyah Sanni, E. Z. Aka, Folafunmi Omofoye, Foutse Yuehgoh, Timothy Faniran, Bonaventure F. P. Dossou, Moshood Yekini, Jonas Kemp, Katherine Heller, Jude Chidubem Omeke, Chidi Asuzu, Naome A. Etori, Amadou Ndiaye, Ifeoma Okoh, Evans Doe Ocansey, Wendy Kinara, Michael L. Best, Irfan Essa, Stephen E. Moore, Chris Fourie, Mercy Asiedu",Annual Meeting of the Association for Computational Linguistics,2025,"Recent advancements in large language model(LLM) performance on medical multiple choice question (MCQ) benchmarks have stimulated interest from healthcare providers and patients globally. Particularly in low-and middle-income countries (LMICs) facing acute physician shortages and lack of specialists, LLMs offer a potentially scalable pathway to enhance healthcare access and reduce costs. However, their effectiveness in the Global South, especially across the African continent, remains to be established. In this work, we introduce AfriMed-QA, the first large scale Pan-African English multi-specialty medical Question-Answering (QA) dataset, 15,000 questions (open and closed-ended) sourced from over 60 medical schools across 16 countries, covering 32 medical specialties. We further evaluate 30 LLMs across multiple axes including correctness and demographic bias. Our findings show significant performance variation across specialties and geographies, MCQ performance clearly lags USMLE (MedQA). We find that biomedical LLMs underperform general models and smaller edge-friendly LLMs struggle to achieve a passing score. Interestingly, human evaluations show a consistent consumer preference for LLM answers and explanations when compared with clinician answers.",289496570,14,23,,
10.18653/v1/2025.acl-long.117,Inference Compute-Optimal Video Vision Language Models,"Peiqi Wang, Shengyun Peng, Xuewen Zhang, Hanchao Yu, Yibo Yang, Lifu Huang, Fujun Liu, Qifan Wang",(missing journal),2025,(missing abstract),289496571,0,0,,
10.18653/v1/2025.acl-long.54,Personality-Guided Code Generation Using Large Language Models,"Yin Biao Guo, Zhenpeng Chen, Jie M. Zhang, Yang Liu, Yun Ma",(missing journal),2025,(missing abstract),289496572,0,0,,
10.18653/v1/2025.acl-long.14,Tree-of-Evolution: Tree-Structured Instruction Evolution for Code Generation in Large Language Models,"Ziyang Luo, Kaixin Li, Hongzhan Lin, Yuchen Tian, Mohan Kankanhalli, Jing Ma",(missing journal),2025,(missing abstract),289496574,0,0,,
10.18653/v1/2025.acl-long.7,Bias in Language Models: Beyond Trick Tests and Towards RUTEd Evaluation,"Kristian Lum, Jacy Reese Anthis, Kevin Robinson, Chirag Nagpal, Alexander D’Amour",(missing journal),2025,(missing abstract),289496575,0,0,,
10.18653/v1/2025.acl-long.16,ReSCORE: Label-free Iterative Retriever Training for Multi-hop Question Answering with Relevance-Consistency Supervision,"D.J. Lee, Wonjun Oh, Boyoung Kim, Min-Young Kim, Joonsuk Park, Paul Hongsuck Seo",Annual Meeting of the Association for Computational Linguistics,2025,"Multi-hop question answering (MHQA) involves reasoning across multiple documents to answer complex questions. Dense retrievers typically outperform sparse methods like BM25 by leveraging semantic embeddings; however, they require labeled query-document pairs for fine-tuning. This poses a significant challenge in MHQA due to the high variability of queries (reformulated) questions throughout the reasoning steps. To overcome this limitation, we introduce Retriever Supervision with Consistency and Relevance (ReSCORE), a novel method for training dense retrievers for MHQA without labeled documents. ReSCORE leverages large language models to capture each documents relevance to the question and consistency with the correct answer and use them to train a retriever within an iterative question-answering framework. Experiments on three MHQA benchmarks demonstrate the effectiveness of ReSCORE, with significant improvements in retrieval, and in turn, the state-of-the-art MHQA performance. Our implementation is available at: https://leeds1219.github.io/ReSCORE.",289496576,1,24,,
10.18653/v1/2025.acl-long.1578,Efficient Domain Continual pretraining by Mitigating the Stability Gap,"Yiduo Guo, Jie Fu, Huishuai Zhang, Dongyan Zhao",(missing journal),2025,(missing abstract),289496693,0,0,,
10.18653/v1/2025.acl-long.1571,Merge Hijacking: Backdoor Attacks to Model Merging of Large Language Models,"Zenghui Yuan, Y. P. Xu, Jiawen Shi, Pan Zhou, Lichao Sun",(missing journal),2025,(missing abstract),289496695,0,0,,
10.18653/v1/2025.acl-long.1543,ScaleBiO: Scalable Bilevel Optimization for LLM Data Reweighting,"Rui Pan, Dylan Zhang, Hanning Zhang, Xingyuan Pan, Minrui Xu, Jipeng Zhang, Renjie Pi, Xiaoyu Wang, Tong Zhang",(missing journal),2025,(missing abstract),289496696,0,0,,
10.18653/v1/2025.acl-long.1593,AmbiK: Dataset of Ambiguous Tasks in Kitchen Environment,"Anastasia Ivanova, Bakaeva Eva, Zoya Volovikova, Alexey K. Kovalev, Aleksandr I. Panov",(missing journal),2025,(missing abstract),289496697,0,0,,
10.18653/v1/2025.acl-long.1492,Serial Lifelong Editing via Mixture of Knowledge Experts,"Yanxiang Cheng, Yu-Chu Yu, Kai-Po Chang, Yu-Chiang Frank Wang",(missing journal),2025,(missing abstract),289496698,0,0,,
10.18653/v1/2025.acl-long.1495,DDxTutor: Clinical Reasoning Tutoring System with Differential Diagnosis-Based Structured Reasoning,"Qian Wu, Zheyao Gao, Longfei Gou, Qi Dou",(missing journal),2025,(missing abstract),289496699,0,0,,
10.18653/v1/2025.acl-long.1443,An Empirical Study of Iterative Refinements for Non-autoregressive Translation,"Yisheng Xiao, Pei Guo, Zechen Sun, Juntao Li, Kai Song, Min Zhang",(missing journal),2025,(missing abstract),289496700,0,0,,
10.18653/v1/2025.acl-long.1419,Cross-Lingual Auto Evaluation for Assessing Multilingual LLMs,"Sumanth Doddapaneni, Mohammed Safi Ur Rahman Khan, Dilip Venkatesh, Raj Dabre, Anoop Kunchukuttan, Mitesh M. Khapra",(missing journal),2025,(missing abstract),289496701,0,0,,
10.18653/v1/2025.acl-long.1444,Retrofitting Large Language Models with Dynamic Tokenization,"Darius Feher, Ivan Vulić, Benjamin Minixhofer",(missing journal),2025,(missing abstract),289496702,0,0,,
10.18653/v1/2025.acl-long.1412,SDD: Self-Degraded Defense against Malicious Fine-tuning,"Zixuan Chen, W.W. Lu, Xin Lin, Ziqian Zeng",Annual Meeting of the Association for Computational Linguistics,2025,"Open-source Large Language Models (LLMs) often employ safety alignment methods to resist harmful instructions. However, recent research shows that maliciously fine-tuning these LLMs on harmful data can easily bypass these safeguards. To counter this, we theoretically uncover why malicious fine-tuning succeeds and identify potential defense strategies. Building on the theoretical analysis, we introduce the Self-Degraded Defense (SDD) framework. SDD encourages LLMs to produce high-quality but irrelevant responses to harmful prompts. When attackers attempt malicious fine-tuning, the general capability of the LLM aligned by SDD will significantly decrease, rendering it incapable of following harmful instructions. Our experimental results confirm SDD's effectiveness against such attacks.",289496703,0,44,,
10.18653/v1/2025.acl-long.1387,Speed Up Your Code: Progressive Code Acceleration Through Bidirectional Tree Editing,"Longhui Zhang, Jiahao Wang, Meishan Zhang, Guohua Cao, Ensheng Shi, Mayuchi Mayuchi, Jun Yu, Honghai Liu, Jing Li, Min Zhang",(missing journal),2025,(missing abstract),289496704,0,0,,
10.18653/v1/2025.acl-long.1356,Rethinking the Role of Prompting Strategies in LLM Test-Time Scaling: A Perspective of Probability Theory,"Yuzheng Liu, Zekun Li, Zhi Fang, Nan Xu, Ran He, Ying Tan",Annual Meeting of the Association for Computational Linguistics,2025,"Recently, scaling test-time compute on Large Language Models (LLM) has garnered wide attention. However, there has been limited investigation of how various reasoning prompting strategies perform as scaling. In this paper, we focus on a standard and realistic scaling setting: majority voting. We systematically conduct experiments on 6 LLMs $\times$ 8 prompting strategies $\times$ 6 benchmarks. Experiment results consistently show that as the sampling time and computational overhead increase, complicated prompting strategies with superior initial performance gradually fall behind simple Chain-of-Thought. We analyze this phenomenon and provide theoretical proofs. Additionally, we propose a probabilistic method to efficiently predict scaling performance and identify the best prompting strategy under large sampling times, eliminating the need for resource-intensive inference processes in practical applications. Furthermore, we introduce two ways derived from our theoretical analysis to significantly improve the scaling performance. We hope that our research can promote to re-examine the role of complicated prompting, unleash the potential of simple prompting strategies, and provide new insights for enhancing test-time scaling performance. Code is available at https://github.com/MraDonkey/rethinking_prompting.",289496705,6,53,,
10.18653/v1/2025.acl-long.1331,Contrastive Learning on LLM Back Generation Treebank for Cross-domain Constituency Parsing,"Peiming Guo, Meishan Zhang, Jianling Li, Min Zhang, Yue Zhang",(missing journal),2025,(missing abstract),289496706,0,0,,
10.18653/v1/2025.acl-long.1327,A Dual-Perspective NLG Meta-Evaluation Framework with Automatic Benchmark and Better Interpretability,"Xinyu Hu, Mingqi Gao, Lin Li, Zhengtao Yu, Xiaojun Wan",(missing journal),2025,(missing abstract),289496707,0,0,,
10.18653/v1/2025.acl-long.1413,CoachMe: Decoding Sport Elements with a Reference-Based Coaching Instruction Generation Model,"Wei-Hsin Yeh, Yu-An Su, C.Y.R. Chen, Yi Lin, Calvin Ku, Wen‐Hsin Chiu, Min‐Chun Hu, Lun‐Wei Ku",Annual Meeting of the Association for Computational Linguistics,2025,"Motion instruction is a crucial task that helps athletes refine their technique by analyzing movements and providing corrective guidance. Although recent advances in multimodal models have improved motion understanding, generating precise and sport-specific instruction remains challenging due to the highly domain-specific nature of sports and the need for informative guidance. We propose CoachMe, a reference-based model that analyzes the differences between a learner's motion and a reference under temporal and physical aspects. This approach enables both domain-knowledge learning and the acquisition of a coach-like thinking process that identifies movement errors effectively and provides feedback to explain how to improve. In this paper, we illustrate how CoachMe adapts well to specific sports such as skating and boxing by learning from general movements and then leveraging limited data. Experiments show that CoachMe provides high-quality instructions instead of directions merely in the tone of a coach but without critical information. CoachMe outperforms GPT-4o by 31.6% in G-Eval on figure skating and by 58.3% on boxing. Analysis further confirms that it elaborates on errors and their corresponding improvement methods in the generated instructions. You can find CoachMe here: https://motionxperts.github.io/",289496708,0,41,,
10.18653/v1/2025.acl-long.1300,QuASAR: A Question-Driven Structure-Aware Approach for Table-to-Text Generation,"Weijie Liu, Yibin Zheng, Fang Kong",(missing journal),2025,(missing abstract),289496709,0,0,,
10.18653/v1/2025.acl-long.1317,Knowledge Graph Retrieval-Augmented Generation for LLM-based Recommendation,"Shijie Wang, Wenqi Fan, Yue Feng, Lin Shanru, Xinyu Ma, Shuaiqiang Wang, Dawei Yin",(missing journal),2025,(missing abstract),289496710,3,0,,
10.18653/v1/2025.acl-long.1289,Make Imagination Clearer! Stable Diffusion-based Visual Imagination for Multimodal Machine Translation,"Andong Chen, Yuchen Song, Kehai Chen, Xuefeng Bai, Muyun Yang, Liqiang Nie, Jie Liu, Tiejun Zhao, Min Zhang",(missing journal),2025,(missing abstract),289496711,1,0,,
10.18653/v1/2025.acl-long.1284,Unraveling LoRA Interference: Orthogonal Subspaces for Robust Model Merging,"Haobo Zhang, Jiayu Zhou",(missing journal),2025,(missing abstract),289496712,0,0,,
10.18653/v1/2025.acl-long.1276,OmniCharacter: Towards Immersive Role-Playing Agents with Seamless Speech-Language Personality Interaction,"Haonan Zhang, Run Luo, Xiong Liu, Yuchuan Wu, Ting-En Lin, Pengpeng Zeng, Qiang Qu, Feng Fang, Min Yang, Lianli Gao, Jingkuan Song, Fei Huang, Yongbin Li",(missing journal),2025,(missing abstract),289496713,0,0,,
10.18653/v1/2025.acl-long.1239,Answering Complex Geographic Questions by Adaptive Reasoning with Visual Context and External Commonsense Knowledge,"Fan Li, Jianxing Yu, Jielong Tang, Wenqing Chen, Hanjiang Lai, Yanghui Rao, Jian Yin",(missing journal),2025,(missing abstract),289496714,0,0,,
10.18653/v1/2025.acl-long.1227,Unveiling Privacy Risks in LLM Agent Memory,"Bo Wang, Weiyi He, Shenglai Zeng, Zhen Xiang, Yue Xing, Jiliang Tang, Pengfei He",Annual Meeting of the Association for Computational Linguistics,2025,"Large Language Model (LLM) agents have become increasingly prevalent across various real-world applications. They enhance decision-making by storing private user-agent interactions in the memory module for demonstrations, introducing new privacy risks for LLM agents. In this work, we systematically investigate the vulnerability of LLM agents to our proposed Memory EXTRaction Attack (MEXTRA) under a black-box setting. To extract private information from memory, we propose an effective attacking prompt design and an automated prompt generation method based on different levels of knowledge about the LLM agent. Experiments on two representative agents demonstrate the effectiveness of MEXTRA. Moreover, we explore key factors influencing memory leakage from both the agent designer's and the attacker's perspectives. Our findings highlight the urgent need for effective memory safeguards in LLM agent design and deployment.",289496715,28,41,,
10.18653/v1/2025.acl-long.1260,Evaluating Multimodal Language Models as Visual Assistants for Visually Impaired Users,"Antonia Karamolegkou, Malvina Nikandrou, Γεώργιος Πανταζόπουλος, Danae Sánchez Villegas, Phillip Rust, Ruchira Dhar, Daniel Hershcovich, Anders Søgaard",(missing journal),2025,(missing abstract),289496716,0,0,,
10.18653/v1/2025.acl-long.1148,CoE: A Clue of Emotion Framework for Emotion Recognition in Conversations,"Zhiyu Shen, Yunhe Pang, Yanghui Rao, Jianxing Yu",(missing journal),2025,(missing abstract),289498547,0,0,,
10.18653/v1/2025.acl-long.1164,"Limited Generalizability in Argument Mining: State-Of-The-Art Models Learn Datasets, Not Arguments","Marc Feger, Katarina Boland, Stefan Dietze",(missing journal),2025,(missing abstract),289498548,0,0,,
10.18653/v1/2025.acl-long.1102,The Role of Visual Modality in Multimodal Mathematical Reasoning: Challenges and Insights,"Yufang Liu, Yao Du, Tao Ji, Jianing Wang, Yang Liu, Yuanbin Wu, Aimin Zhou, Mengdi Zhang, Xunliang Cai",(missing journal),2025,(missing abstract),289498549,0,0,,
10.18653/v1/2025.acl-long.1133,Tracing and Dissecting How LLMs Recall Factual Knowledge for Real World Questions,"Yiqun Wang, Chaoqun Wan, Shengshou Hu, Yonggang Zhang, Xiang Tian, Yaowu Chen, Shen Xu, Jieping Ye",(missing journal),2025,(missing abstract),289498550,0,0,,
10.18653/v1/2025.acl-long.1100,Boosting LLM’s Molecular Structure Elucidation with Knowledge Enhanced Tree Search Reasoning,"Xiang Zhuang, Bin Wu, Jiyu Cui, Kehua Feng, Xiaotong Li, Huabin Xing, Keyan Ding, Qiang Zhang, Huajun Chen",(missing journal),2025,(missing abstract),289498551,0,0,,
10.18653/v1/2025.acl-long.1117,“What do you call a dog that is incontrovertibly true? Dogma”: Testing LLM Generalization through Humor,"Alessio Cocchieri, Luca Ragazzi, Paolo Italiani, Giuseppe Tagliavini, Gianluca Moro",(missing journal),2025,(missing abstract),289498552,0,0,,
10.18653/v1/2025.acl-long.1071,Reinforced IR: A Self-Boosting Framework For Domain-Adapted Information Retrieval,"Chaofan Li, Jianlyu Chen, Yingxia Shao, Chaozhuo Li, Quanqing Xu, Defu Lian, Zheng Liu",(missing journal),2025,(missing abstract),289498553,0,0,,
10.18653/v1/2025.acl-long.955,Reversal of Thought: Enhancing Large Language Models with Preference-Guided Reverse Reasoning Warm-up,"Jiahao Yuan, Danxu Du, Hao Zhang, Zixiang Di, Usman Naseem",(missing journal),2025,(missing abstract),289498554,0,0,,
10.18653/v1/2025.acl-long.966,Multilingual Text-to-Image Generation Magnifies Gender Stereotypes,"Felix Friedrich, Katharina Hämmerl, Patrick Schramowski, Manuel Brack, Jindřich Libovický, Alexander Fraser, Kristian Kersting",(missing journal),2025,(missing abstract),289498555,0,0,,
10.18653/v1/2025.acl-long.1014,ConceptCarve: Dynamic Realization of Evidence,"Eylon Caplan, Dan Goldwasser",(missing journal),2025,(missing abstract),289498556,0,0,,
10.18653/v1/2025.acl-long.970,Safer or Luckier? LLMs as Safety Evaluators Are Not Robust to Artifacts,"Hongyu Chen, Seraphina Goldfarb-Tarrant",(missing journal),2025,(missing abstract),289498557,0,0,,
10.18653/v1/2025.acl-long.1052,Registering Source Tokens to Target Language Spaces in Multilingual Neural Machine Translation,"Zhi Qu, Yiran Wang, Jiannan Mao, Chenchen Ding, Hideki Tanaka, Masao Utiyama, Taro Watanabe",(missing journal),2025,(missing abstract),289498558,1,0,,
10.18653/v1/2025.acl-long.939,Multilingual Arbitration: Optimizing Data Pools to Accelerate Multilingual Progress,"Ayomide Odumakinde, Daniel D’souza, Pat Verga, Beyza Ermiş, Sara Hooker",(missing journal),2025,(missing abstract),289498559,0,0,,
10.18653/v1/2025.acl-long.919,Global MMLU: Understanding and Addressing Cultural and Linguistic Biases in Multilingual Evaluation,"Shivalika Singh, Angelika Romanou, Clémentine Fourrier, David Ifeoluwa Adelani, Jian Gang Ngui, Daniel Vila-Suero, Peerat Limkonchotiwat, Kelly Marchisio, Wei Qi Leong, Yosephine Susanto, Raymond T. Ng, Shayne Longpre, Sebastian Ruder, Wei-Yin Ko, Antoine Bosselut, Alice Oh, André L. Martins, Leshem Choshen, Daphne Ippolito, Enzo Ferrante, Marzieh Fadaee, Beyza Ermiş, Sara Hooker",(missing journal),2025,(missing abstract),289498560,1,0,,
10.18653/v1/2025.acl-long.1056,"Dolphin: Moving Towards Closed-loop Auto-research through Thinking, Practice, and Feedback","Jiakang Yuan, Xiangchao Yan, Bo Zhang, Tao Chen, Botian Shi, Wanli Ouyang, Yu Qiao, Lei Bai, B. Zhou",Annual Meeting of the Association for Computational Linguistics,2025,"The scientific research paradigm is undergoing a profound transformation owing to the development of Artificial Intelligence (AI). Recent works demonstrate that various AI-assisted research methods can largely improve research efficiency by improving data analysis, accelerating computation, and fostering novel idea generation. To further move towards the ultimate goal (i.e., automatic scientific research), in this paper, we introduce Dolphin, a closed-loop LLM-driven framework to enhance the automation level of scientific research. Dolphin first generates novel ideas based on feedback from previous experiments and relevant papers ranked by the topic and task attributes. Then, the generated ideas can be implemented using a code template refined and debugged with the designed exception-traceback-guided local code structure. Finally, Dolphin automatically analyzes the results of each idea and feeds the results back to the next round of idea generation. Experiments are conducted on the benchmark datasets of different topics and a subset of MLE-bench. Results show that Dolphin can continuously improve the performance of the input topic in a loop. We highlight that Dolphin can automatically propose methods that are comparable to the state-of-the-art in some tasks such as 3D point classification.",289498561,4,0,,
10.18653/v1/2025.acl-long.904,OASIS: Order-Augmented Strategy for Improved Code Search,"Gao Zuchen, Zizheng Zhan, Xianming Li, Erxin Yu, Haotian Zhang, Chenbin Chenbin, Yuqun Zhang, Jing Li",(missing journal),2025,(missing abstract),289498562,0,0,,
10.18653/v1/2025.acl-long.856,Hierarchical Attention Generates Better Proofs,"Jianlong Chen, Chao Li, Yang Yuan, Andrew Chi-Chih Yao",(missing journal),2025,(missing abstract),289498563,0,0,,
10.18653/v1/2025.acl-long.834,TripCraft: A Benchmark for Spatio-Temporally Fine Grained Travel Planning,"Soumyabrata Roy Chaudhuri, Pranav Purkar, R. B. Raghav, S.S. Mallick, Manish Gupta, Abhik Jana, Shreya Ghosh",(missing journal),2025,(missing abstract),289498564,1,0,,
10.18653/v1/2025.acl-long.816,Automatic Expert Discovery in LLM Upcycling via Sparse Interpolated Mixture-of-Experts,"Shengzhuang Chen, Ying Wei, Jonathan Richard Schwarz",(missing journal),2025,(missing abstract),289498565,0,0,,
10.18653/v1/2025.acl-long.800,PROPER: A Progressive Learning Framework for Personalized Large Language Models with Group-Level Adaptation,"Linhai Zhang, Jialong Wu, Deyu Zhou, Yulan He",(missing journal),2025,(missing abstract),289498567,0,0,,
10.18653/v1/2025.acl-long.840,Do not Abstain! Identify and Solve the Uncertainty,"J. Y. Liu, JingquanPeng JingquanPeng, Xingming Wu, X.Q. Li, Tiezheng Ge, Bo Zheng, Yong Liu",(missing journal),2025,(missing abstract),289498568,0,0,,
10.18653/v1/2025.acl-long.817,SimulS2S-LLM: Unlocking Simultaneous Inference of Speech LLMs for Speech-to-Speech Translation,"Keqi Deng, Wenxi Chen, Xie Chen, Philip C. Woodland",(missing journal),2025,(missing abstract),289498569,0,0,,
10.18653/v1/2025.acl-long.795,Enhancing Cross-Lingual Transfer through Reversible Transliteration: A Huffman-Based Approach for Low-Resource Languages,"Wenhao Zhuang, Yuan Sun, Xiaobing Zhao",Annual Meeting of the Association for Computational Linguistics,2025,"As large language models (LLMs) are trained on increasingly diverse and extensive multilingual corpora, they demonstrate cross-lingual transfer capabilities. However, these capabilities often fail to effectively extend to low-resource languages, particularly those utilizing non-Latin scripts. While transliterating low-resource languages into Latin script presents a natural solution, there currently lacks a comprehensive framework for integrating transliteration into LLMs training and deployment. Taking a pragmatic approach, this paper innovatively combines character transliteration with Huffman coding to design a complete transliteration framework. Our proposed framework offers the following advantages: 1) Compression: Reduces storage requirements for low-resource language content, achieving up to 50% reduction in file size and 50-80% reduction in token count. 2) Accuracy: Guarantees 100% lossless conversion from transliterated text back to the source language. 3) Efficiency: Eliminates the need for vocabulary expansion for low-resource languages, improving training and inference efficiency. 4) Scalability: The framework can be extended to other low-resource languages. We validate the effectiveness of our framework across multiple downstream tasks, including text classification, machine reading comprehension, and machine translation. Experimental results demonstrate that our method significantly enhances the model's capability to process low-resource languages while maintaining performance on high-resource languages. Our data and code are publicly available at https://github.com/CMLI-NLP/HuffmanTranslit.",289498570,0,31,,
10.18653/v1/2025.acl-long.814,"Sheep’s Skin, Wolf’s Deeds: Are LLMs Ready for Metaphorical Implicit Hate Speech?","Jingjie Zeng, Liang Yang, Zekun Wang, Yuanyuan Sun, Hongfei Lin",(missing journal),2025,(missing abstract),289498571,0,0,,
10.18653/v1/2025.acl-long.1194,LaTIM: Measuring Latent Token-to-Token Interactions in Mamba Models,"Hugo Pitorro, Marcos Treviso",(missing journal),2025,(missing abstract),289498572,0,0,,
10.18653/v1/2025.acl-long.1193,Evaluating LLMs for Portuguese Sentence Simplification with Linguistic Insights,"Arthur Scalercio, Elvis Alves de Souza, María José Bocorny Finatto, Aline Paes",(missing journal),2025,(missing abstract),289498573,0,0,,
10.18653/v1/2025.acl-long.719,"Adapt Once, Thrive with Updates: Transferable Parameter-Efficient Fine-Tuning on Evolving Base Models","Naibin Gu, Peng Fu, Xiyu Liu, Ke Ma, Zheng Lin, Weiping Wang",(missing journal),2025,(missing abstract),289498574,0,0,,
10.18653/v1/2025.acl-long.603,RolePlot: A Systematic Framework for Evaluating and Enhancing the Plot-Progression Capabilities of Role-Playing Agents,"Pinyi Zhang, So-Mi An, Liang Qiao, Yiqing Yu, Jingyang Chen, Jie Wang, Dong-min Yin, Xing Sun, Kai Zhang",(missing journal),2025,(missing abstract),289498575,0,0,,
10.18653/v1/2025.acl-long.649,Rethinking Reward Model Evaluation Through the Lens of Reward Overoptimization,"Sung-Hwan Kim, Dongjin Kang, Taeyoon Kwon, Hyungjoo Chae, Dongha Lee, Jinyoung Yeo",(missing journal),2025,(missing abstract),289498576,0,0,,
10.18653/v1/2025.acl-long.740,Efficient Long Context Language Model Retrieval with Compression,"Minju Seo, Jinheon Baek, Seongyun Lee, Sung Ju Hwang",(missing journal),2025,(missing abstract),289498577,0,0,,
10.18653/v1/2025.acl-long.618,Outlier-Safe Pre-Training for Robust 4-Bit Quantization of Large Language Models,"Jung‐Woo Park, Taewhoo Lee, Chanwoong Yoon, Hyeon Seok Hwang, Jaewoo Kang",(missing journal),2025,(missing abstract),289498578,0,0,,
10.18653/v1/2025.acl-long.632,Can Large Language Models Understand Internet Buzzwords Through User-Generated Content,"Chen Huang, Jie Luo, Xingjun WANG, Wenqiang Lei, Jiancheng Lv",(missing journal),2025,(missing abstract),289498579,0,0,,
10.18653/v1/2025.acl-long.577,TROVE: A Challenge for Fine-Grained Text Provenance via Source Sentence Tracing and Relationship Classification,"Junnan Zhu, Min Xiao, Yining Wang, Feifei Zhai, Zhou Yu, Chengqing Zong",(missing journal),2025,(missing abstract),289498580,1,0,,
10.18653/v1/2025.acl-long.563,VMLU Benchmarks: A comprehensive benchmark toolkit for Vietnamese LLMs,"Cuc Thi Bui, Nguyễn Trường Sơn, T. Trang, Lam Viet Phung, Phạm Thành Huy, Hoang Anh Le, Quoc Huu Van, Phong Nguyen-Thuan, Van Le Tran Truc, Duc Thanh Chau, Le-Minh Nguyen",(missing journal),2025,(missing abstract),289498581,0,0,,
10.18653/v1/2025.acl-long.587,ACECODER: Acing Coder RL via Automated Test-Case Synthesis,"H. Zeng, Dongfu Jiang, Haozhe Wang, Ping Nie, Xiaotong Chen, Wenhu Chen",(missing journal),2025,(missing abstract),289498582,2,0,,
10.18653/v1/2025.acl-long.562,PwnGPT: Automatic Exploit Generation Based on Large Language Models,"Wei Peng, Lin Ye, Xuetao Du, Hongli Zhang, Dongyang Zhan, Yunting Zhang, Yi-Qing Guo, Chen Zhang",(missing journal),2025,(missing abstract),289498583,0,0,,
10.18653/v1/2025.acl-long.507,On Support Samples of Next Word Prediction,"Yuqian Li, Yupei Du, Yufang Liu, Feifei Feng, M.-W. Feng, Yuanbin Wu",(missing journal),2025,(missing abstract),289498584,0,0,,
10.18653/v1/2025.acl-long.586,Beyond Dialogue: A Profile-Dialogue Alignment Framework Towards General Role-Playing Language Model,"Yeyong Yu, Runsheng Yu, Haojie Wei, Zhanqiu Zhang, Quan Qian",(missing journal),2025,(missing abstract),289498585,1,0,,
10.18653/v1/2025.acl-long.451,Toward Automatic Discovery of a Canine Phonetic Alphabet,"Tao Wang, Xingyuan Li, Hridayesh Lekhak, Tuan Minh Dang, Mengyue Wu, Kenny Q. Zhu",(missing journal),2025,(missing abstract),289498586,3,0,,
10.18653/v1/2025.acl-long.455,Identifying Cellular Niches in Spatial Transcriptomics: An Investigation into the Capabilities of Large Language Models,"Huanhuan Wei, Xiao Luo, Hongliang Yu, Jinping Liang, Luning Yang, Lin Li, Alexandra Popa, Xiting Yan",(missing journal),2025,(missing abstract),289498587,0,0,,
10.18653/v1/2025.acl-long.487,Selecting and Merging: Towards Adaptable and Scalable Named Entity Recognition with Large Language Models,"Zhuojun Ding, Wei Wei, Chenghao Fan",(missing journal),2025,(missing abstract),289498588,0,0,,
10.18653/v1/2025.acl-long.485,Attention Entropy is a Key Factor: An Analysis of Parallel Context Encoding with Full-attention-based Pre-trained Language Models,"Zhisong Zhang, Yan Wang, Xinting Huang, Tianqing Fang, Hongming Zhang, Chenlong Deng, Shuaiyi Li, Dong Yu",(missing journal),2025,(missing abstract),289498589,0,0,,
10.18653/v1/2025.acl-long.494,ReflectionCoder: Learning from Reflection Sequence for Enhanced One-off Code Generation,"Houxing Ren, Mingjie Zhan, Zhongyuan Wu, Aojun Zhou, Junting Pan, Hongsheng Li",(missing journal),2025,(missing abstract),289498590,1,0,,
10.18653/v1/2025.acl-long.329,LexTempus: Enhancing Temporal Generalizability of Legal Language Models Through Dynamic Mixture of Experts,"Santosh T.y.s.s, Tuan-Quang Vuong",(missing journal),2025,(missing abstract),289498591,2,0,,
10.18653/v1/2025.acl-long.379,A Text is Worth Several Tokens: Text Embedding from LLMs Secretly Aligns Well with The Key Tokens,"Zhijie Nie, Richong Zhang, Zhanyu Wu",(missing journal),2025,(missing abstract),289498592,0,0,,
10.18653/v1/2025.acl-long.436,BRIGHTER: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages,"Shamsuddeen Hassan Muhammad, Nedjma Ousidhoum, Idris Abdulmumin, Jan Philip Wahle, Terry Ruas, Meriem Beloucif, Christine de Kock, Nirmal Surange, Daniela Teodorescu, Ibrahim Said Ahmad, David Ifeoluwa Adelani, Alham Fikri Aji, Felermino D. M. A. Ali, Ilseyar Alimova, Vladimir Araujo, Nikolay Babakov, Naomi Baes, Ana-Maria Bucur, Andiswa Bukula, Guanqun Cao, Rodrigo Tufiño, Rendi Chevi, Chiamaka Ijeoma Chukwuneke, Alexandra Ciobotaru, Daryna Dementieva, Murja Sani Gadanya, Robert Geislinger, Béla Gipp, Oumaima Hourrane, Oana Ignat, Falalu Ibrahim Lawan, Rooweither Mabuya, Rahmad Mahendra, Vukosi Marivate, Alexander Panchenko, Andrew Piper, Charles Henrique Porto Ferreira, Vitaly Protasov, Samuel Rutunda, Manish Shrivastava, Andreea Udrea, Lilian Wanzare, Sophie Wu, Florian Valentin Wunderlich, Hanif Muhammad Zhafran, Tianhui Zhang, Yi Zhou, Saif M. Mohammad",(missing journal),2025,(missing abstract),289498593,0,0,,
10.18653/v1/2025.acl-long.409,Growing Through Experience: Scaling Episodic Grounding in Language Models,"Chunhui Zhang, Shanshan Wang, Zhongyu Ouyang, Xiangchi Yuan, Soroush Vosoughi",(missing journal),2025,(missing abstract),289498594,0,0,,
10.18653/v1/2025.acl-long.461,LLMs + Persona-Plug = Personalized LLMs,"Jiongnan Liu, Yutao Zhu, Shuting Wang, Xiaochi Wei, Erxue Min, Yu Lu, Shuaiqiang Wang, Dawei Yin, Zhicheng Dou",(missing journal),2025,(missing abstract),289498595,1,0,,
10.18653/v1/2025.acl-long.347,PIC: Unlocking Long-Form Text Generation Capabilities of Large Language Models via Position ID Compression,"Haoran Que, Wenge Rong",(missing journal),2025,(missing abstract),289498596,0,0,,
10.18653/v1/2025.acl-long.355,Hybrid Preferences: Learning to Route Instances for Human vs. AI Feedback,"Lester James V. Miranda, Yizhong Wang, Yanai Elazar, Sachin Kumar, Valentina Pyatkin, Faeze Brahman, Noah A. Smith, Hannaneh Hajishirzi, Pradeep Dasigi",(missing journal),2025,(missing abstract),289498597,0,0,,
10.18653/v1/2025.acl-long.435,Building Better: Avoiding Pitfalls in Developing Language Resources when Data is Scarce,"Nedjma Ousidhoum, Meriem Beloucif, Saif M. Mohammad",(missing journal),2025,(missing abstract),289498598,0,0,,
10.18653/v1/2025.acl-long.360,Deontological Keyword Bias: The Impact of Modal Expressions on Normative Judgments of Language Models,"Bumjin Park, Leejinsil Leejinsil, Jaesik Choi",(missing journal),2025,(missing abstract),289498599,0,0,,
10.18653/v1/2025.acl-long.441,"INTERACT: Enabling Interactive, Question-Driven Learning in Large Language Models","Aum Kendapadi, Kerem Zaman, Rakesh R. Menon, Shashank Srivastava",(missing journal),2025,(missing abstract),289498600,0,0,,
10.18653/v1/2025.acl-long.264,SECRET: Semi-supervised Clinical Trial Document Similarity Search,"Trisha Das, Afrah Shafquat, Mandis Beigi, Jacob Aptekar, Jimeng Sun",(missing journal),2025,(missing abstract),289498602,0,0,,
10.18653/v1/2025.acl-long.194,Enhancing Character-Level Understanding in LLMs through Token Internal Structure Learning,"Xu Zhu, Zhao Zhi, Zihan Zhang, Yuchi Liu, Quanwei Shen, Fei Liu, Yu Kuang, Jian He, Conglin Liu",(missing journal),2025,(missing abstract),289504469,2,0,,
10.18653/v1/2025.acl-long.168,Whose Boat Does it Float? Improving Personalization in Preference Tuning via Inferred User Personas,"Nishant Balepur, Vishakh Padmakumar, Fumeng Yang, Feng Shi, Rachel Rudinger, Jordan Lee Boyd-Graber",(missing journal),2025,(missing abstract),289504470,0,0,,
10.18653/v1/2025.acl-long.133,Direct Prompt Optimization with Continuous Representations,"Yangkun Wang, Zihan Wang, Jingbo Shang",(missing journal),2025,(missing abstract),289504471,0,0,,
10.18653/v1/2025.acl-long.135,"GigaSpeech 2: An Evolving, Large-Scale and Multi-domain ASR Corpus for Low-Resource Languages with Automated Crawling, Transcription and Refinement","Yifan Yang, Zheshu Song, Jianheng Zhuo, Mingyu Cui, Jinpeng Li, Bo Yang, Yexing Du, Ziyang Ma, Xunying Liu, Ziyuan Wang, Ke Li, Shuai Fan, Kai Yu, Wei-Qiang Zhang, Guoguo Chen, Xie Chen",(missing journal),2025,(missing abstract),289504472,1,0,,
10.18653/v1/2025.acl-long.129,D.Va: Validate Your Demonstration First Before You Use It,"Qi Zhang, Zhiqing Xiao, R. Xiao, Lirong Gao, Junbo Zhao",(missing journal),2025,(missing abstract),289504473,0,0,,
10.18653/v1/2025.acl-long.76,The Hidden Attention of Mamba Models,"Ameen Ali, Itamar Zimerman, Lior Wolf",(missing journal),2025,(missing abstract),289504474,2,0,,
10.18653/v1/2025.acl-long.70,Neural Topic Modeling with Large Language Models in the Loop,"Xiaohao Yang, He Zhao, Weijie Xu, Yuanyuan Qi, Jueqing Lu, Dinh Phung, Lan Du",(missing journal),2025,(missing abstract),289504475,1,0,,
10.18653/v1/2025.acl-long.18,Statistical Deficiency for Task Inclusion Estimation,"Loïc Fosse, Frédéric Béchet, Benoît Favre, Géraldine Damnati, Gwénolé Lecorvé, Maxime Darrin, Philippe Formont, Pablo Piantanida",(missing journal),2025,(missing abstract),289504476,0,0,,
10.18653/v1/2025.acl-long.34,JuStRank: Benchmarking LLM Judges for System Ranking,"Ariel Gera, Odellia Boni, Yotam Perlitz, Roy Bar-Haim, Lilach Eden, Asaf Yehudai",(missing journal),2025,(missing abstract),289504479,0,0,,
10.18653/v1/2025.acl-long.6,Intuitive Fine-Tuning: Towards Simplifying Alignment into a Single Process,"Ermo Hua, Biqing Qi, Kaiyan Zhang, Kai Tian, Xingtai Lv, Ning Ding, Bowen Zhou",(missing journal),2025,(missing abstract),289504482,0,0,,
10.18653/v1/2025.acl-long.47,EvoWiki: Evaluating LLMs on Evolving Knowledge,"Wei Tang, Yuguang Cao, Yang Deng, Jiahao Ying, Bo Wang, Yizhe Yang, Yuyue Zhao, Qi Zhang, Xuanjing Huang, Yu‐Gang Jiang, Yong Liao",(missing journal),2025,(missing abstract),289504487,0,0,,
10.18653/v1/2025.acl-long.1542,Efficient Many-Shot In-Context Learning with Dynamic Block-Sparse Attention,"Emily Xiao, C. H. Li, Yilin Zhang, Graham Neubig, Amanda Bertsch",(missing journal),2025,(missing abstract),289504614,2,0,,
10.18653/v1/2025.acl-long.1515,Persona Dynamics: Unveiling the Impact of Persona Traits on Agents in Text-Based Games,"Seungwon Lim, Seungbeen Lee, D. K. Min, Youngjae Yu",(missing journal),2025,(missing abstract),289504615,0,0,,
10.18653/v1/2025.acl-long.1565,BFS-Prover: Scalable Best-First Tree Search for LLM-based Automatic Theorem Proving,"Ran Xin, Chenguang Xi, Jie Yang, Feng Chen, Hang Wu, Xia Xiao, Yifan Sun, Shen Zheng, Ming Ding",(missing journal),2025,(missing abstract),289504616,0,0,,
10.18653/v1/2025.acl-long.1573,Beyond Output Matching: Bidirectional Alignment for Enhanced In-Context Learning,"Chengwei Qin, Wenhan Xia, Fangkai Jiao, Chen Chen, Yuchen Hu, Bosheng Ding, Ruirui Chen, Shafiq Joty",Annual Meeting of the Association for Computational Linguistics,2025,"Large language models (LLMs) have shown impressive few-shot generalization on many tasks via in-context learning (ICL). Despite their success in showing such emergent abilities, the scale and complexity of larger models also lead to unprecedentedly high computational demands and deployment challenges. In reaction, researchers explore transferring the powerful capabilities of larger models to more efficient and compact models by typically aligning the output of smaller (student) models with that of larger (teacher) models. Existing methods either train student models on the generated outputs of teacher models or imitate their token-level probability distributions. However, these distillation methods pay little to no attention to the input, which also plays a crucial role in ICL. Based on the finding that the performance of ICL is highly sensitive to the selection of demonstration examples, we propose Bidirectional Alignment (BiAlign) to fully leverage the models' preferences for ICL examples to improve the ICL abilities of student models. Specifically, we introduce the alignment of input preferences between student and teacher models by incorporating a novel ranking loss, in addition to aligning the token-level output distribution. With extensive experiments and analysis, we demonstrate that BiAlign can consistently outperform existing baselines on a variety of tasks involving language understanding, reasoning, and coding.",289504617,9,198,,
10.18653/v1/2025.acl-long.1584,"Mapping 1,000+ Language Models via the Log-Likelihood Vector","Momose Oyama, Hiroaki Yamagiwa, Y. Takase, Hidetoshi Shimodaira",(missing journal),2025,(missing abstract),289504618,0,0,,
10.18653/v1/2025.acl-long.1517,𝛿-Stance: A Large-Scale Real World Dataset of Stances in Legal Argumentation,"Ankita Gupta, Douglas Rice, Brendon O’Connor",(missing journal),2025,(missing abstract),289504619,0,0,,
10.18653/v1/2025.acl-long.1599,Introducing Verification Task of Set Consistency with Set-Consistency Energy Networks,"Moon-Sang Song, Hyojoo Son, Jay Yoon Lee",(missing journal),2025,(missing abstract),289504620,0,0,,
10.18653/v1/2025.acl-long.1551,TiC-LM: A Web-Scale Benchmark for Time-Continual LLM Pretraining,"Jeffrey Li, Mohammadreza Armandpour, Seyed Iman Mirzadeh, Sachin Mehta, Vaishaal Shankar, Raviteja Vemulapalli, Samy Bengio, Oncel Tuzel, Mehrdad Farajtabar, Hadi Pouransari, Fartash Faghri",(missing journal),2025,(missing abstract),289504621,0,0,,
10.18653/v1/2025.acl-long.1417,Language Model Probabilities are Not Calibrated in Numeric Contexts,"Charles Lovering, Michael Krumdick, Viet Dac Lai, Varshini Reddy, Seth Ebner, Nilesh Kumar, Rik Koncel-Kedziorski, Chris C. Tanner",(missing journal),2025,(missing abstract),289504622,0,0,,
10.18653/v1/2025.acl-long.1393,Improving Dialogue State Tracking through Combinatorial Search for In-Context Examples,"Haesung Pyun, Yoonah Park, Yohan Jo",(missing journal),2025,(missing abstract),289504623,0,0,,
10.18653/v1/2025.acl-long.1347,Weaving Context Across Images: Improving Vision-Language Models through Focus-Centric Visual Chains,"Juntian Zhang, Chuanqi Cheng, Yuhan Liu, Wei Liu, Jing Luan, Rui Yan",(missing journal),2025,(missing abstract),289504624,0,0,,
10.18653/v1/2025.acl-long.1335,InspireDebate: Multi-Dimensional Subjective-Objective Evaluation-Guided Reasoning and Optimization for Debating,"Fuyu Wang, Jiangtong Li, Kun Zhu, Chao Jiang",(missing journal),2025,(missing abstract),289504625,0,0,,
10.18653/v1/2025.acl-long.1313,Exposing the Achilles’ Heel: Evaluating LLMs Ability to Handle Mistakes in Mathematical Reasoning,"Joykirat Singh, Akshay Nambi, Vibhav Vineet",(missing journal),2025,(missing abstract),289504626,0,0,,
10.18653/v1/2025.acl-long.1297,Generative Reward Modeling via Synthetic Criteria Preference Learning,"Xiaobo Liang, Haoke Zhang, Juntao Li, Kehai Chen, Qiaoming Zhu, M. Zhang",(missing journal),2025,(missing abstract),289504627,0,0,,
10.18653/v1/2025.acl-long.1306,Walk in Others’ Shoes with a Single Glance: Human-Centric Visual Grounding with Top-View Perspective Transformation,"Yuqi Bu, Xin Wu, Zirui Zhao, Yi Cai, David Hsu, Qiong Liu",(missing journal),2025,(missing abstract),289504628,0,0,,
10.18653/v1/2025.acl-long.1215,PCoT: Persuasion-Augmented Chain of Thought for Detecting Fake News and Social Media Disinformation,"Arkadiusz Modzelewski, Witold Sosnowski, Tiziano Labruna, Adam Wierzbicki, Giovanni Da San Martino",(missing journal),2025,(missing abstract),289504629,0,0,,
10.18653/v1/2025.acl-long.1273,CEAES: Bidirectional Reinforcement Learning Optimization for Consistent and Explainable Essay Assessment,"Xia Li, Wenjing Pan",(missing journal),2025,(missing abstract),289504630,0,0,,
10.18653/v1/2025.acl-long.1218,Mind the Gesture: Evaluating AI Sensitivity to Culturally Offensive Non-Verbal Gestures,"Akhila Yerukola, Saadia Gabriel, Ning Peng, Maarten Sap",(missing journal),2025,(missing abstract),289504631,0,0,,
10.18653/v1/2025.acl-long.1253,Delta-KNN: Improving Demonstration Selection in In-Context Learning for Alzheimer’s Disease Detection,"Chuyuan Li, Raymond Li, Thalia S. Field, Giuseppe Carenini",(missing journal),2025,(missing abstract),289504632,0,0,,
10.18653/v1/2025.acl-long.1142,Beyond the Answer: Advancing Multi-Hop QA with Fine-Grained Graph Reasoning and Evaluation,"Qichuan Liu, Chentao Zhang, Chenfeng Zheng, Guosheng Hu, Xiaodong Li, Zhihong Zhang",(missing journal),2025,(missing abstract),289506452,0,0,,
10.18653/v1/2025.acl-long.1108,XDAC: XAI-Driven Detection and Attribution of LLM-Generated News Comments in Korean,"Wooyoung Go, Hyoungshick Kim, Alice Oh, Yongdae Kim",(missing journal),2025,(missing abstract),289506453,0,0,,
10.18653/v1/2025.acl-long.1086,RiOT: Efficient Prompt Refinement with Residual Optimization Tree,"Chunze Zhou, Zhengyan Shi, Yuan Yao, Lei Liang, Huajun Chen, Qiang Zhang",(missing journal),2025,(missing abstract),289506454,0,0,,
10.18653/v1/2025.acl-long.1118,Towards Harmonized Uncertainty Estimation for Large Language Models,"Rui Li, Jing Long, Manzhi Qi, H. Xia, Sha Lei, Peiyi Wang, Zhifang Sui",(missing journal),2025,(missing abstract),289506455,0,0,,
10.18653/v1/2025.acl-long.1146,Curiosity-Driven Reinforcement Learning from Human Feedback,"Haoran Sun, Yekun Chai, Shuohuan Wang, Yu Sun, Hua Wu, Haifeng Wang",(missing journal),2025,(missing abstract),289506456,1,0,,
10.18653/v1/2025.acl-long.996,Understanding Silent Data Corruption in LLM Training,"Jeffrey Jian, Hengzhi Pei, Leonard Lausen, George Karypis",(missing journal),2025,(missing abstract),289506457,1,0,,
10.18653/v1/2025.acl-long.1031,Uncovering the Impact of Chain-of-Thought Reasoning for Direct Preference Optimization: Lessons from Text-to-SQL,"Hanbing Liu, Haoyang Li, Xiaokang Zhang, Ruotong Chen, Haiyong Xu, Tian Tian, Qi Qi, Jing Zhang",(missing journal),2025,(missing abstract),289506458,0,0,,
10.18653/v1/2025.acl-long.965,Guiding not Forcing: Enhancing the Transferability of Jailbreaking Attacks on LLMs via Removing Superfluous Constraints,"Junxiao Yang, Zhexin Zhang, Shiyao Cui, Hongning Wang, Minlie Huang",arXiv (Cornell University),2025,"Jailbreaking attacks can effectively induce unsafe behaviors in Large Language Models (LLMs); however, the transferability of these attacks across different models remains limited. This study aims to understand and enhance the transferability of gradient-based jailbreaking methods, which are among the standard approaches for attacking white-box models. Through a detailed analysis of the optimization process, we introduce a novel conceptual framework to elucidate transferability and identify superfluous constraints-specifically, the response pattern constraint and the token tail constraint-as significant barriers to improved transferability. Removing these unnecessary constraints substantially enhances the transferability and controllability of gradient-based attacks. Evaluated on Llama-3-8B-Instruct as the source model, our method increases the overall Transfer Attack Success Rate (T-ASR) across a set of target models with varying safety levels from 18.4% to 50.3%, while also improving the stability and controllability of jailbreak behaviors on both source and target models.",289506459,0,0,,
10.18653/v1/2025.acl-long.1067,Maximizing the Effectiveness of Larger BERT Models for Compression,"Wen-Shu Fan, Shao-Wei Lu, Shangyu Xing, Xin-Chun Li, De-Chuan Zhan",(missing journal),2025,(missing abstract),289506460,0,0,,
10.18653/v1/2025.acl-long.1049,PsyDial: A Large-scale Long-term Conversational Dataset for Mental Health Support,"Huachuan Qiu, Zhenzhong Lan",(missing journal),2025,(missing abstract),289506461,0,0,,
10.18653/v1/2025.acl-long.957,LLMs can be easily Confused by Instructional Distractions,"Yerin Hwang, Yongil Kim, Jahyun Koo, Taegwan Kang, Hyunkyung Bae, Kyomin Jung",Annual Meeting of the Association for Computational Linguistics,2025,"Despite the fact that large language models (LLMs) show exceptional skill in instruction following tasks, this strength can turn into a vulnerability when the models are required to disregard certain instructions. Instruction-following tasks typically involve a clear task description and input text containing the target data to be processed. However, when the input itself resembles an instruction, confusion may arise, even if there is explicit prompting to distinguish between the task instruction and the input. We refer to this phenomenon as instructional distraction. In this paper, we introduce a novel benchmark, named DIM-Bench, specifically designed to assess LLMs'performance under instructional distraction. The benchmark categorizes real-world instances of instructional distraction and evaluates LLMs across four instruction tasks: rewriting, proofreading, translation, and style transfer -- alongside five input tasks: reasoning, code generation, mathematical reasoning, bias detection, and question answering. Our experimental results reveal that even the most advanced LLMs are susceptible to instructional distraction, often failing to accurately follow user intent in such cases.",289506462,9,39,,
10.18653/v1/2025.acl-long.894,Graphically Speaking: Unmasking Abuse in Social Media with Conversation Insights,"Célia Nouri, Chloé Clavel, Jean‐Philippe Cointet",(missing journal),2025,(missing abstract),289506463,0,0,,
10.18653/v1/2025.acl-long.886,Enhancing Spoken Discourse Modeling in Language Models Using Gestural Cues,"Varsha Suresh, Muhammad Hamza Mughal, Christian Theobalt, Vera Demberg",(missing journal),2025,(missing abstract),289506464,0,0,,
10.18653/v1/2025.acl-long.875,Enhancing Text Editing for Grammatical Error Correction: Arabic as a Case Study,"Bashar Alhafni, Nizar Habash",(missing journal),2025,(missing abstract),289506465,0,0,,
10.18653/v1/2025.acl-long.1041,Neuron Empirical Gradient: Discovering and Quantifying Neurons’ Global Linear Controllability,"Wayne Xin Zhao, Zehui Jiang, Naoki Yoshinaga",(missing journal),2025,(missing abstract),289506466,0,0,,
10.18653/v1/2025.acl-long.1058,Prompt-Guided Internal States for Hallucination Detection of Large Language Models,"Fujie Zhang, Peng Yu, Biao Yi, Baolei Zhang, Tong Li, Zheli Liu",(missing journal),2025,(missing abstract),289506467,0,0,,
10.18653/v1/2025.acl-long.911,"DNASpeech: A Contextualized and Situated Text-to-Speech Dataset with Dialogues, Narratives and Actions","Chuanqi Cheng, Hongda Sun, Bo Du, Shuo Shang, Xinrong Hu, Rui Yan",(missing journal),2025,(missing abstract),289506468,0,0,,
10.18653/v1/2025.acl-long.959,IAM: Efficient Inference through Attention Mapping between Different-scale LLMs,"Yiyi Zhao, Zuchao Li, H. Vicky Zhao",Annual Meeting of the Association for Computational Linguistics,2025,"LLMs encounter significant challenges in resource consumption nowadays, especially with long contexts. Despite extensive efforts dedicate to enhancing inference efficiency, these methods primarily exploit internal sparsity within the models, without leveraging external information for optimization. We identify the high similarity of attention matrices across different-scale LLMs, which offers a novel perspective for optimization. We first conduct a comprehensive analysis of how to measure similarity, how to select mapping Layers and whether mapping is consistency. Based on these insights, we introduce the IAM framework, which achieves dual benefits of accelerated attention computation and reduced KV cache usage by performing attention mapping between small and large LLMs. Our experimental results demonstrate that IAM can accelerate prefill by 15% and reduce KV cache usage by 22.1% without appreciably sacrificing performance. Experiments on different series of models show the generalizability of IAM. Importantly, it is also orthogonal to many existing KV cache optimization methods, making it a versatile addition to the current toolkit for enhancing LLM efficiency.",289506469,3,21,,
10.18653/v1/2025.acl-long.1002,Enhancing Human Evaluation in Machine Translation with Comparative Judgement,"Yixiao Song, Parker Riley, Daniel Deutsch, Markus Freitag",(missing journal),2025,(missing abstract),289506470,0,0,,
10.18653/v1/2025.acl-long.918,RoToR: Towards More Reliable Responses for Order-Invariant Inputs,"So-Young Yoon, Doyeol Ahn, Youngwon Lee, Minkyu Jung, Hye Sook Jang, Seon-Hwan Hwang",(missing journal),2025,(missing abstract),289506471,0,0,,
10.18653/v1/2025.acl-long.987,Unveiling Cultural Blind Spots: Analyzing the Limitations of mLLMs in Procedural Text Comprehension,"Amir Yari, Fajri Koto",(missing journal),2025,(missing abstract),289506472,0,0,,
10.18653/v1/2025.acl-long.924,HAF-RM: A Hybrid Alignment Framework for Reward Model Training,"Shujun Liu, Xiaoyu Shen, Yuhang Lai, Siyuan Wang, Shengbin Yue, Zengfeng Huang, Xuanjing Huang, Zhongyu Wei",(missing journal),2025,(missing abstract),289506473,0,0,,
10.18653/v1/2025.acl-long.941,Chinese SimpleQA: A Chinese Factuality Evaluation for Large Language Models,"Yancheng He, Shilong Li, Jiaheng Liu, Yingshui Tan, Weixun Wang, Hui Huang, Xingyuan Bu, Hangyu Guo, Chengwei Hu, Boren Zheng, Zhuoran Lin, Dekai Sun, Zhicheng Zheng, Wenbo Su, B. Zheng",(missing journal),2025,(missing abstract),289506474,2,0,,
10.18653/v1/2025.acl-long.991,Modeling Complex Semantics Relation with Contrastively Fine-Tuned Relational Encoders,"Naïm Es-Sebbani, Esteban Marquer, Zied Bouraoui",(missing journal),2025,(missing abstract),289506475,0,0,,
10.18653/v1/2025.acl-long.921,ImPart: Importance-Aware Delta-Sparsification for Improved Model Compression and Merging in LLMs,"Yan Yang, Youtang Li, Hongru Wang, X.X. Wei, Jiaao Yu, Yun Chen, G. Q. Chen",(missing journal),2025,(missing abstract),289506476,0,0,,
10.18653/v1/2025.acl-long.802,MMBoundary: Advancing MLLM Knowledge Boundary Awareness through Reasoning Step Confidence Calibration,"Zhitao He, Sandeep Polisetty, Zheng Fan, Yudong Huang, Shujin Wu, Yi R. Fung",(missing journal),2025,(missing abstract),289506477,0,0,,
10.18653/v1/2025.acl-long.823,ACT: Knowledgeable Agents to Design and Perform Complex Tasks,"Makoto Nakatsuji, Shuhei Tateishi, Yasuhiro Fujiwara, Ayaka Matsumoto, Narichika Nomoto, Yukio Sato",(missing journal),2025,(missing abstract),289506478,0,0,,
10.18653/v1/2025.acl-long.793,Theoretical Guarantees for Minimum Bayes Risk Decoding,"Yumiko Ichihara, Yuu Jinnai, Kaito Ariu, Tetsuro Morimura, Eiji Uchibe",(missing journal),2025,(missing abstract),289506479,0,0,,
10.18653/v1/2025.acl-long.794,Mutual-Taught for Co-adapting Policy and Reward Models,"Tianyuan Shi, Congcong Huang, Fanqi Wan, Li Zhong, Ziyi Yang, Weizhou Shen, Xiaojun Quan, Ming Yan",(missing journal),2025,(missing abstract),289506480,0,0,,
10.18653/v1/2025.acl-long.1185,ALGEN: Few-shot Inversion Attacks on Textual Embeddings via Cross-Model Alignment and Generation,"Yiyi Chen, Qiongkai Xu, Johannes Bjerva",(missing journal),2025,(missing abstract),289506481,0,0,,
10.18653/v1/2025.acl-long.592,"Phonotomizer: A Compact, Unsupervised, Online Training Approach to Real-Time, Multilingual Phonetic Segmentation","Michael S. Yantosca, Albert M. K. Cheng",(missing journal),2025,(missing abstract),289506482,0,0,,
10.18653/v1/2025.acl-long.697,Browsing Like Human: A Multimodal Web Agent with Experiential Fast-and-Slow Thinking,"Haohao Luo, Jiayi Kuang, Wei Liu, Ying Shen, Jian Luan, Yang Deng",(missing journal),2025,(missing abstract),289506483,0,0,,
10.18653/v1/2025.acl-long.683,LexCLiPR: Cross-Lingual Paragraph Retrieval from Legal Judgments,"Rohit Upadhya, Santosh T.y.s.s",(missing journal),2025,(missing abstract),289506484,2,0,,
10.18653/v1/2025.acl-long.674,How does Misinformation Affect Large Language Model Behaviors and Preferences?,"Peng Miao, Nuo Chen, Jianheng Tang, Jia Li",(missing journal),2025,(missing abstract),289506485,0,0,,
10.18653/v1/2025.acl-long.773,BOOKWORLD: From Novels to Interactive Agent Societies for Story Creation,"Yiting Ran, Xintao Wang, Tian Qiu, Jiaqing Liang, Yanghua Xiao, Deqing Yang",(missing journal),2025,(missing abstract),289506486,2,0,,
10.18653/v1/2025.acl-long.613,WavRAG: Audio-Integrated Retrieval Augmented Generation for Spoken Dialogue Models,"Y.W. Chen, Shengpeng Ji, Haoxiao Wang, Ziqing Wang, Siyu Chen, Jinzheng He, Jin Xu, Zhou Zhao",(missing journal),2025,(missing abstract),289506487,1,0,,
10.18653/v1/2025.acl-long.738,Why Safeguarded Ships Run Aground? Aligned Large Language Models’ Safety Mechanisms Tend to Be Anchored in The Template Region,"Chak Tou Leong, Qingyu Yin, Jian Wang, Wenjie Li",(missing journal),2025,(missing abstract),289506488,0,0,,
10.18653/v1/2025.acl-long.686,Multi-level Association Refinement Network for Dialogue Aspect-based Sentiment Quadruple Analysis,"Zeliang Tong, Wei Wei, Xiaoye Qu, Rikui Huang, Zhixin Chen, Xingyu Yan",(missing journal),2025,(missing abstract),289506489,0,0,,ACL
10.18653/v1/2025.acl-long.594,Safe: Enhancing Mathematical Reasoning in Large Language Models via Retrospective Step-aware Formal Verification,"Chengwu Liu, Ye Yuan, Yichun Yin, Yan Xu, Xin Xu, Zaoyu Chen, Yasheng Wang, Lifeng Shang, Qun Liu, Ming Zhang",(missing journal),2025,(missing abstract),289506490,0,0,,
10.18653/v1/2025.acl-long.605,Can a Single Model Master Both Multi-turn Conversations and Tool Use? CoALM: A Unified Conversational Agentic Language Model,"Emre Can Acikgoz, Jeremiah Greer, Avijit Datta, Ze Yang, William Zeng, Oussama Elachqar, Emmanouil Koukoumidis, Dilek Hakkani-Tür, Gökhan Tür",(missing journal),2025,(missing abstract),289506491,0,0,,
10.18653/v1/2025.acl-long.656,MMLU-CF: A Contamination-free Multi-task Language Understanding Benchmark,"Qihao Zhao, Yangyu Huang, Tengchao Lv, Lei Cui, Qi Sun, Shaoguang Mao, Xin Zhang, Ying Xin, Qiufeng Yin, Shan Li, Furu Wei",(missing journal),2025,(missing abstract),289506492,2,0,,
10.18653/v1/2025.acl-long.495,InvestAlign: Overcoming Data Scarcity in Aligning Large Language Models with Investor Decision-Making Processes Under Herd Behavior,"Huisheng Wang, Zhuoshi Pan, H. Zhang, Mingxiao Liu, Hanqing Gao, Huaici Zhao",Annual Meeting of the Association for Computational Linguistics,2025,"Aligning Large Language Models (LLMs) with investor decision-making processes under herd behavior is a critical challenge in behavioral finance, which grapples with a fundamental limitation: the scarcity of real-user data needed for Supervised Fine-Tuning (SFT). While SFT can bridge the gap between LLM outputs and human behavioral patterns, its reliance on massive authentic data imposes substantial collection costs and privacy risks. We propose InvestAlign, a novel framework that constructs high-quality SFT datasets by leveraging theoretical solutions to similar and simple optimal investment problems rather than complex scenarios. Our theoretical analysis demonstrates that training LLMs with InvestAlign-generated data achieves faster parameter convergence than using real-user data, suggesting superior learning efficiency. Furthermore, we develop InvestAgent, an LLM agent fine-tuned with InvestAlign, which demonstrates significantly closer alignment to real-user data than pre-SFT models in both simple and complex investment problems. This highlights our proposed InvestAlign as a promising approach with the potential to address complex optimal investment problems and align LLMs with investor decision-making processes under herd behavior. Our code is publicly available at https://github.com/thu-social-network-research-group/InvestAlign.",289506493,1,50,,
10.18653/v1/2025.acl-long.454,DiffuseDef: Improved Robustness to Adversarial Attacks via Iterative Denoising,"Zhenhao Li, Huichi Zhou, Marek Rei, Lucia Specia",(missing journal),2025,(missing abstract),289506494,0,0,,
10.18653/v1/2025.acl-long.489,CADReview: Automatically Reviewing CAD Programs with Error Detection and Correction,"J. G. Chen, Xiaoguang Hei, Hongfei Liu, Yuancheng Wei, Zhidong Deng, Jiayuan Xie, Yi Cai, Qing Li",Annual Meeting of the Association for Computational Linguistics,2025,"Computer-aided design (CAD) is crucial in prototyping 3D objects through geometric instructions (i.e., CAD programs). In practical design workflows, designers often engage in time-consuming reviews and refinements of these prototypes by comparing them with reference images. To bridge this gap, we introduce the CAD review task to automatically detect and correct potential errors, ensuring consistency between the constructed 3D objects and reference images. However, recent advanced multimodal large language models (MLLMs) struggle to recognize multiple geometric components and perform spatial geometric operations within the CAD program, leading to inaccurate reviews. In this paper, we propose the CAD program repairer (ReCAD) framework to effectively detect program errors and provide helpful feedback on error correction. Additionally, we create a dataset, CADReview, consisting of over 20K program-image pairs, with diverse errors for the CAD review task. Extensive experiments demonstrate that our ReCAD significantly outperforms existing MLLMs, which shows great potential in design applications.",289506495,0,25,,
10.18653/v1/2025.acl-long.477,Semantic-Eval : A Semantic Comprehension Evaluation Framework for Large Language Models Generation without Training,"Shusheng Li, Jiale Li, Yuan Qu, Xinwei Shi, Yanliang Guo, Zhimin He, Yubo Wang, Wenjun Tan",(missing journal),2025,(missing abstract),289506496,0,0,,
10.18653/v1/2025.acl-long.395,Evaluating Theory of (an uncertain) Mind: Predicting the Uncertain Beliefs of Others from Conversational Cues,"Anthony Sicilia, Malihe Alikhani",(missing journal),2025,(missing abstract),289506497,0,0,,
10.18653/v1/2025.acl-long.410,Exploiting the Shadows: Unveiling Privacy Leaks through Lower-Ranked Tokens in Large Language Models,"Yuan Zhou, Zhuo Zhang, Xiangyu Zhang",(missing journal),2025,(missing abstract),289506498,0,0,,
10.18653/v1/2025.acl-long.373,Alleviating Distribution Shift in Synthetic Data for Machine Translation Quality Estimation,"Xiang Geng, Zhejian Lai, Jiajun Chen, Hao Yang, Shujian Huang",(missing journal),2025,(missing abstract),289506499,0,0,,
10.18653/v1/2025.acl-long.471,On the Reliability of Large Language Models for Causal Discovery,"Tao Feng, Lizhen Qu, Niket Tandon, Zhuang Li, Xiaoxi Kang, Gholamreza Haffari",Annual Meeting of the Association for Computational Linguistics,2025,"This study investigates the efficacy of Large Language Models (LLMs) in causal discovery. Using newly available open-source LLMs, OLMo and BLOOM, which provide access to their pre-training corpora, we investigate how LLMs address causal discovery through three research questions. We examine: (i) the impact of memorization for accurate causal relation prediction, (ii) the influence of incorrect causal relations in pre-training data, and (iii) the contextual nuances that influence LLMs'understanding of causal relations. Our findings indicate that while LLMs are effective in recognizing causal relations that occur frequently in pre-training data, their ability to generalize to new or rare causal relations is limited. Moreover, the presence of incorrect causal relations significantly undermines the confidence of LLMs in corresponding correct causal relations, and the contextual information critically affects the outcomes of LLMs to discern causal connections between random variables.",289506500,12,41,,
10.18653/v1/2025.acl-long.343,Dynamic Scaling of Unit Tests for Code Reward Modeling,"Zeyao Ma, Xiaokang Zhang, Jing Zhang, Jifan Yu, Sijia Luo, Jie Tang",(missing journal),2025,(missing abstract),289506501,0,0,,
10.18653/v1/2025.acl-long.357,The UD-NewsCrawl Treebank: Reflections and Challenges from a Large-scale Tagalog Syntactic Annotation Project,"Angelina Aquino, Lester James V. Miranda, Elsie Marie T. Or",(missing journal),2025,(missing abstract),289506502,0,0,,
10.18653/v1/2025.acl-long.442,Circuit Stability Characterizes Language Model Generalization,A.P. Sun,(missing journal),2025,(missing abstract),289506503,0,0,,
10.18653/v1/2025.acl-long.277,OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis,"Qiushi Sun, Kanzhi Cheng, Zichen Ding, Chuanyang Jin, Yian Wang, Fangzhi Xu, Zhenyu Wu, Chengyou Jia, L. Chen, Zhoumianze Liu, Ben Kao, Guohao Li, Junxian He, Yu Qiao, Zhiyong Wu",(missing journal),2025,(missing abstract),289506504,0,0,,
10.18653/v1/2025.acl-long.299,UAlign: Leveraging Uncertainty Estimations for Factuality Alignment on Large Language Models,"Boyang Xue, Fei Mi, Qi Zhu, Hongru Wang, Rui Wang, Sheng Wang, Erxin Yu, Xuming Hu, Kam‐Fai Wong",(missing journal),2025,(missing abstract),289506505,0,0,,
10.18653/v1/2025.acl-long.273,ATRI: Mitigating Multilingual Audio Text Retrieval Inconsistencies by Reducing Data Distribution Errors,"Yuguo Yin, Yuxin Xie, Wenyuan Yang, Dongchao Yang, Jinghan Ru, Xianwei Zhuang, Liming Liang, Yuexian Zou",(missing journal),2025,(missing abstract),289506507,0,0,,
10.18653/v1/2025.acl-long.257,Mitigating Visual Forgetting via Take-along Visual Conditioning for Multi-modal Long CoT Reasoning,"Hailong Sun, Zhun Sun, Houwen Peng, Han-Jia Ye",(missing journal),2025,(missing abstract),289506508,0,0,,
10.18653/v1/2025.acl-long.225,PTQ1.61: Push the Real Limit of Extremely Low-Bit Post-Training Quantization Methods for Large Language Models,"Jiaqi Zhao, Miao Zhang, Ming Wang, Yuzhang Shang, Kaihao Zhang, Weili Guan, Yaowei Wang, Danshi Wang",(missing journal),2025,(missing abstract),289512509,1,0,,
10.18653/v1/2025.acl-long.178,TEACH: A Contrastive Knowledge Adaptive Distillation Framework for Classical Chinese Understanding,"Yuting Wei, Meng Qi, Yuanxing Xu, Bin Wu",(missing journal),2025,(missing abstract),289512510,0,0,,
10.18653/v1/2025.acl-long.247,A Triple-View Framework for Fine-Grained Emotion Classification with Clustering-Guided Contrastive Learning,"Jing Gong, Binhan Yang, Wei Shen",(missing journal),2025,(missing abstract),289512511,0,0,,
10.18653/v1/2025.acl-long.189,UTBoost: Rigorous Evaluation of Coding Agents on SWE-Bench,"Bin Yu, Y. Zhu, Pinjia He, Daniel Kang",(missing journal),2025,(missing abstract),289512512,0,0,,
10.18653/v1/2025.acl-long.162,Addressing Blind Guessing: Calibration of Selection Bias in Multiple-Choice Question Answering by Video Language Models,"Olga Loginova, Oleksandr Bezrukov, Ravi Shekhar, Alexey Kravets",(missing journal),2025,(missing abstract),289512513,0,0,,
10.18653/v1/2025.acl-long.137,TARGA: Targeted Synthetic Data Generation for Practical Reasoning over Structured Data,"Xiang Huang, Jiayu Shen, Shanshan Huang, Sitao Cheng, Xiaxia Wang, Yuzhong Qu",(missing journal),2025,(missing abstract),289512514,0,0,,
10.18653/v1/2025.acl-long.140,A Survey of Post-Training Scaling in Large Language Models,"Hanyu Lai, Xiao Liu, Jun Gao, Jiale Cheng, Zehan Qi, Yifan Xu, Shuntian Yao, Dan Zhang, Jinhua Du, Zhenyu Hou, Xin Lv, Minlie Huang, Yuxiao Dong, Jie Tang",(missing journal),2025,(missing abstract),289512515,0,0,,
10.18653/v1/2025.acl-long.149,Unveiling the Power of Source: Source-based Minimum Bayes Risk Decoding for Neural Machine Translation,"Boxuan Lyu, Hidetaka Kamigaito, Kotaro Funakoshi, Manabu Okumura",(missing journal),2025,(missing abstract),289512516,0,0,,
10.18653/v1/2025.acl-long.103,CompileAgent: Automated Real-World Repo-Level Compilation with Tool-Integrated LLM-based Agent System,"Hu Li, Guoqiang Chen, Xiuwei Shang, Shaoyin Cheng, Benlong Wu, LiGangyang LiGangyang, Xu Zhu, Weiming Zhang, Nenghai Yu",(missing journal),2025,(missing abstract),289512517,0,0,,
10.18653/v1/2025.acl-long.85,Open-World Attribute Mining for E-Commerce Products with Multimodal Self-Correction Instruction Tuning,"Jiaqi Li, Yanming Li, Xiaoli Shen, Chuanyi Zhang, Guilin Qi, Shengli Bi",(missing journal),2025,(missing abstract),289512518,0,0,,
10.18653/v1/2025.acl-long.69,Capturing Author Self Beliefs in Social Media Language,"Siddharth Mangalik, Adithya V Ganesan, Ahlborn Wheeler, Nicholas Kerry, Jeremy D. W. Clifton, H. Schwartz, Ryan L. Boyd",(missing journal),2025,(missing abstract),289512520,1,0,,
10.18653/v1/2025.acl-long.52,ATLANTIS: Weak-to-Strong Learning via Importance Sampling,"Yi Liu, Guoyin Wang, Shicheng Li, Feifan Song, Xu Sun",(missing journal),2025,(missing abstract),289512524,0,0,,
10.18653/v1/2025.acl-long.63,APPL: A Prompt Programming Language for Harmonious Integration of Programs and Large Language Model Prompts,"Honghua Dong, Qidong Su, Yubo Gao, Zhaoyu Li, Yangjun Ruan, Gennady Pekhimenko, Chris J. Maddison, Xujie Si",(missing journal),2025,(missing abstract),289512525,0,0,,
10.18653/v1/2025.acl-long.41,LACA: Improving Cross-lingual Aspect-Based Sentiment Analysis with LLM Data Augmentation,"Jakub Šmíd, Pavel Přibáň, Pavel Kral",Annual Meeting of the Association for Computational Linguistics,2025,"Cross-lingual aspect-based sentiment analysis (ABSA) involves detailed sentiment analysis in a target language by transferring knowledge from a source language with available annotated data. Most existing methods depend heavily on often unreliable translation tools to bridge the language gap. In this paper, we propose a new approach that leverages a large language model (LLM) to generate high-quality pseudo-labelled data in the target language without the need for translation tools. First, the framework trains an ABSA model to obtain predictions for unlabelled target language data. Next, LLM is prompted to generate natural sentences that better represent these noisy predictions than the original text. The ABSA model is then further fine-tuned on the resulting pseudo-labelled dataset. We demonstrate the effectiveness of this method across six languages and five backbone models, surpassing previous state-of-the-art translation-based approaches. The proposed framework also supports generative models, and we show that fine-tuned LLMs outperform smaller multilingual models.",289512527,0,26,,
10.18653/v1/2025.acl-long.1587,FactBench: A Dynamic Benchmark for In-the-Wild Language Model Factuality Evaluation,"Farima Fatahi Bayat, Lechen Zhang, Sheza Munir, Lu Wang",(missing journal),2025,(missing abstract),289512654,0,0,,
10.18653/v1/2025.acl-long.1547,Emergent Abilities of Large Language Models under Continued Pre-training for Language Adaptation,"A. Abd El-Hady, Eneko Agirre, Mikel Artetxe",(missing journal),2025,(missing abstract),289512655,0,0,,
10.18653/v1/2025.acl-long.1524,CMHKF: Cross-Modality Heterogeneous Knowledge Fusion for Weakly Supervised Video Anomaly Detection,"Guohua Wang, Shengping Song, Wenyin He, Yongsen Zheng",(missing journal),2025,(missing abstract),289512656,0,0,,
10.18653/v1/2025.acl-long.1558,UrbanVideo-Bench: Benchmarking Vision-Language Models on Embodied Intelligence with Video Data in Urban Spaces,"Baining Zhao, Jing Fang, Zichao Dai, Ziyou Wang, Jirong Zha, Weichen Zhang, Chen Gao, Yue Wang, Jinqiang Cui, Xinlei Chen, Yong Li",(missing journal),2025,(missing abstract),289512657,2,0,,
10.18653/v1/2025.acl-long.1484,Activating Distributed Visual Region within LLMs for Efficient and Effective Vision-Language Training and Inference,"Siyuan Wang, Dong Wang, Chengxing Zhou, Zejun Li, Zhihao Fan, Xuanjing Huang, Zhongyu Wei",(missing journal),2025,(missing abstract),289512658,0,0,,
10.18653/v1/2025.acl-long.1491,Multi-Modality Expansion and Retention for LLMs through Parameter Merging and Decoupling,"Jianming Li, Guodong Du, Jing Li, Sim Kuan Goh, Wenya Wang, Yequan Wang, Fangming Liu, Ho-Kin Tang, Saleh Alharbi, Daojing He, Min Zhang",(missing journal),2025,(missing abstract),289512659,1,0,,
10.18653/v1/2025.acl-long.1482,Benchmarking and Improving Large Vision-Language Models for Fundamental Visual Graph Understanding and Reasoning,"Yuemin Zhu, Xuefeng Bai, Kehai Chen, Yang Xiang, Jun Yu, Min Zhang",(missing journal),2025,(missing abstract),289512660,0,0,,
10.18653/v1/2025.acl-long.1466,SpeechIQ: Speech-Agentic Intelligence Quotient Across Cognitive Levels in Voice Understanding by Large Language Models,"Zhen Wan, Chao-Han Huck Yang, Yahan Yu, Jinchuan Tian, Sheng Li, Ke Hu, Zhehuai Chen, Shinji Watanabe, Fei Cheng, Chenhui Chu, Sadao Kurohashi",Annual Meeting of the Association for Computational Linguistics,2025,"We introduce Speech-based Intelligence Quotient (SIQ) as a new form of human cognition-inspired evaluation pipeline for voice understanding large language models, LLM Voice, designed to assess their voice understanding ability. Moving beyond popular voice understanding metrics such as word error rate (WER), SIQ examines LLM Voice across three cognitive levels motivated by Bloom's Taxonomy: (1) Remembering (i.e., WER for verbatim accuracy); (2) Understanding (i.e., similarity of LLM's interpretations); and (3) Application (i.e., QA accuracy for simulating downstream tasks). We demonstrate that SIQ not only quantifies voice understanding abilities but also provides unified comparisons between cascaded methods (e.g., ASR LLM) and end-to-end models, identifies annotation errors in existing benchmarks, and detects hallucinations in LLM Voice. Our framework represents a first-of-its-kind intelligence examination that bridges cognitive principles with voice-oriented benchmarks, while exposing overlooked challenges in multi-modal training. Our code and data will be open source to encourage future studies.",289512661,1,67,,
10.18653/v1/2025.acl-long.1479,LSSF: Safety Alignment for Large Language Models through Low-Rank Safety Subspace Fusion,"Guanghao Zhou, Panjia Qiu, Cen Chen, Hongyu Li, Jason S. Chu, Xin Zhang, Jun Zhou",(missing journal),2025,(missing abstract),289512662,0,0,,
10.18653/v1/2025.acl-long.1351,Evaluating Sequence Labeling on the basis of Information Theory,"Enrique Amigó, Elena Álvarez Mellado, Julio Gonzalo, Jorge Carrillo‐de‐Albornoz",(missing journal),2025,(missing abstract),289512663,0,0,,
10.18653/v1/2025.acl-long.1350,LLMs Caught in the Crossfire: Malware Requests and Jailbreak Challenges,"Haoyang Li, Huan Gao, Zhiyuan Zhao, Zhiyu Lin, Jing Gao, Shichao Zhang",(missing journal),2025,(missing abstract),289512664,2,0,,
10.18653/v1/2025.acl-long.1257,AAD-LLM: Neural Attention-Driven Auditory Scene Understanding,"Xilin Jiang, Sukru Samet Dindar, Vishal Choudhari, Stephan Bickel, Ashesh D. Mehta, Guy M. McKhann, Daniel Friedman, Adeen Flinker, Nima Mesgarani",(missing journal),2025,(missing abstract),289512665,2,0,,
10.18653/v1/2025.acl-long.1261,HumT DumT: Measuring and controlling human-like language in LLMs,"Myra Cheng, Shucong Yu, Dan Jurafsky",(missing journal),2025,(missing abstract),289512666,0,0,,
10.18653/v1/2025.acl-long.1264,Anything Goes? A Crosslinguistic Study of (Im)possible Language Learning in LMs,"Xiulin Yang, Tatsuya Aoyama, Yuekun Yao, Ethan Wilcox",(missing journal),2025,(missing abstract),289512667,0,0,,
10.18653/v1/2025.acl-long.1307,Is linguistically-motivated data augmentation worth it?,"Ray Groshan, Michael Ginn, Alexis Palmer",(missing journal),2025,(missing abstract),289512668,0,0,,
10.18653/v1/2025.acl-long.1291,Multi-document Summarization through Multi-document Event Relation Graph Reasoning in LLMs: a case study in Framing Bias Mitigation,"Yuanyuan Lei, Ruihong Huang",(missing journal),2025,(missing abstract),289512669,0,0,,
10.18653/v1/2025.acl-long.1293,RoCoFT: Efficient Finetuning of Large Language Models with Row-Column Updates,"Md. Kowsher, Tara Esmaeilbeig, Chun-Nam Yu, Chen Chen, Mojtaba Soltanalian, Niloofar Yousefi",(missing journal),2025,(missing abstract),289512670,0,0,,
10.18653/v1/2025.acl-long.1265,Ranking Unraveled: Recipes for LLM Rankings in Head-to-Head AI Combat,"Roland Daynauth, Christopher Clarke, Krisztián Flautner, Lingjia Tang, Jason Mars",(missing journal),2025,(missing abstract),289512671,0,0,,
10.18653/v1/2025.acl-long.1084,Diversity-oriented Data Augmentation with Large Language Models,"Z. Wang, Jinghan Zhang, Xinhao Zhang, Kunpeng Liu, Pengfei Wang, Yuanchun Zhou",Annual Meeting of the Association for Computational Linguistics,2025,"Data augmentation is an essential technique in natural language processing (NLP) for enriching training datasets by generating diverse samples. This process is crucial for improving the robustness and generalization capabilities of NLP models. However, a significant challenge remains: \textit{Insufficient Attention to Sample Distribution Diversity}. Most existing methods focus on increasing the sample numbers while neglecting the sample distribution diversity, which can lead to model overfitting. In response, we explore data augmentation's impact on dataset diversity and propose a \textbf{\underline{D}}iversity-\textbf{\underline{o}}riented data \textbf{\underline{Aug}}mentation framework (\textbf{DoAug}). % \(\mathscr{DoAug}\) Specifically, we utilize a diversity-oriented fine-tuning approach to train an LLM as a diverse paraphraser, which is capable of augmenting textual datasets by generating diversified paraphrases. Then, we apply the LLM paraphraser to a selected coreset of highly informative samples and integrate the paraphrases with the original data to create a more diverse augmented dataset. Finally, we conduct extensive experiments on 12 real-world textual datasets. The results show that our fine-tuned LLM augmenter improves diversity while preserving label consistency, thereby enhancing the robustness and performance of downstream tasks. Specifically, it achieves an average performance gain of \(10.52\%\), surpassing the runner-up baseline with more than three percentage points.",289514479,5,48,,
10.18653/v1/2025.acl-long.1157,Capability Salience Vector: Fine-grained Alignment of Loss and Capabilities for Downstream Task Scaling Law,"Qiming Ge, Guozhong Xing, S. Gao, Yunhua Zhou, Yicheng Zou, Songyang Zhang, Zhi Chen, Hang Yan, Qi Zhang, Qipeng Guo, Kai Chen",(missing journal),2025,(missing abstract),289514480,0,0,,
10.18653/v1/2025.acl-long.1138,FCMR: Robust Evaluation of Financial Cross-Modal Multi-Hop Reasoning,"Seunghee Kim, Changhyeon Kim, Taehyoun Kim",(missing journal),2025,(missing abstract),289514481,0,0,,
10.18653/v1/2025.acl-long.1132,Learning to Look at the Other Side: A Semantic Probing Study of Word Embeddings in LLMs with Enabled Bidirectional Attention,"Z. Feng, Jianfei Ma, Emmanuele Chersoni, Xiaojing Zhao, Xiaoyi Bao",Annual Meeting of the Association for Computational Linguistics,2025,"Autoregressive Large Language Models (LLMs) demonstrate exceptional performance in language understanding and generation. However, their application in text embedding tasks has been relatively slow, along with the analysis of their semantic representation in probing tasks, due to the constraints of the unidirectional attention mechanism. This paper aims to explore whether such constraints can be overcome by enabling bidirectional attention in LLMs. We tested different variants of the Llama architecture through additional training steps, progressively enabling bidirectional attention and unsupervised/supervised contrastive learning.",289514482,2,50,,
10.18653/v1/2025.acl-long.1113,Look Both Ways and No Sink: Converting LLMs into Text Encoders without Training,"Ziyong Lin, Hao‐Yi Wu, S.Z. Wang, Kewei Tu, Zilong Zheng, Zixia Jia",(missing journal),2025,(missing abstract),289514483,0,0,,
10.18653/v1/2025.acl-long.1019,(RSA)²: A Rhetorical-Strategy-Aware Rational Speech Act Framework for Figurative Language Understanding,"Cesare Spinoso-Di Piano, David Eric Austin, Pablo Piantanida, Jackie CK Cheung",(missing journal),2025,(missing abstract),289514484,0,0,,
10.18653/v1/2025.acl-long.979,AutoMixer: Checkpoint Artifacts as Automatic Data Mixers,"Ernie Chang, Yang Li, Patrick Huber, Vish Vogeti, David Kant, Yangyang Shi, Vikas Chandra",(missing journal),2025,(missing abstract),289514485,0,0,,
10.18653/v1/2025.acl-long.951,DIVE into MoE: Diversity-Enhanced Reconstruction of Large Language Models from Dense into Mixture-of-Experts,"Yuchen Feng, B. C. Shen, Nannan Gu, Jiaxuan Zhao, Peng Fu, Zheng Lin, Weiping Wang",(missing journal),2025,(missing abstract),289514486,0,0,,
10.18653/v1/2025.acl-long.947,Segment-Based Attention Masking for GPTs,"Shahar Katz, Liran Ringel, Yaniv Romano, Lior Wolf",(missing journal),2025,(missing abstract),289514487,0,0,,
10.18653/v1/2025.acl-long.888,Segment First or Comprehend First? Explore the Limit of Unsupervised Word Segmentation with Large Language Models,"Zihong Zhang, Lin He, Zuchao Li, Lefei Zhang, Hai Zhao, Bo Du",(missing journal),2025,(missing abstract),289514488,0,0,,
10.18653/v1/2025.acl-long.1026,Targeted Syntactic Evaluation for Grammatical Error Correction,"Aomi Koyama, Masato Mita, Su-Youn Yoon, Yasufumi Takama, Mamoru Komachi",(missing journal),2025,(missing abstract),289514489,0,0,,
10.18653/v1/2025.acl-long.926,DiffPO: Diffusion-styled Preference Optimization for Inference Time Alignment of Large Language Models,"Ruizhe Chen, Wenhao Chai, Zhifei Yang, Xiaotian Zhang, Ziyang Wang, Tony Q. S. Quek, Joey Tianyi Zhou, Soujanya Poria, Zuozhu Liu",(missing journal),2025,(missing abstract),289514490,2,0,,
10.18653/v1/2025.acl-long.945,AgentRM: Enhancing Agent Generalization with Reward Modeling,"Yu Xia, J. D. Fan, Weize Chen, Siyu Yan, Xin Cong, Zhong Zhang, Yue Lu, Yankai Lin, Zhiyuan Liu, Maosong Sun",(missing journal),2025,(missing abstract),289514491,1,0,,
10.18653/v1/2025.acl-long.909,Micro-Act: Mitigate Knowledge Conflict in Question Answering via Actionable Self-Reasoning,"Nan Huo, Jinyang Li, Bowen Qin, Ge Qu, Xiaolong Li, Xiaodong Li, Chenhao Ma, Reynold Cheng",(missing journal),2025,(missing abstract),289514492,0,0,,
10.18653/v1/2025.acl-long.887,ExploraCoder: Advancing Code Generation for Multiple Unseen APIs via Planning and Chained Exploration,"Yunkun Wang, Yue Zhang, Zhentao Qin, Zhi Chen, Binhua Li, Fei Huang, Yongbin Li, Shuiguang Deng",(missing journal),2025,(missing abstract),289514493,0,0,,
10.18653/v1/2025.acl-long.994,Interactive and Expressive Code-Augmented Planning with Large Language Models,"Anthony Z. Liu, Xinhe Wang, Jacob Sansom, Yao Fu, Jongwook Choi, Sungryull Sohn, Jaekyeom Kim, Honglak Lee",(missing journal),2025,(missing abstract),289514494,0,0,,
10.18653/v1/2025.acl-long.822,FRACTAL: Fine-Grained Scoring from Aggregate Text Labels,"Yukti Makhija, Priyanka Agrawal, Rishi Saket, Aravindan Raghuveer",(missing journal),2025,(missing abstract),289514495,0,0,,
10.18653/v1/2025.acl-long.839,FEA-Bench: A Benchmark for Evaluating Repository-Level Code Generation for Feature Implementation,"Wei Li, Xin Zhang, Zhongxin Guo, Shaoguang Mao, Wen Luo, Guangyue Peng, Yangyu Huang, Houfeng Wang, Shan Li",(missing journal),2025,(missing abstract),289514496,1,0,,
10.18653/v1/2025.acl-long.813,Velocitune: A Velocity-based Dynamic Domain Reweighting Method for Continual Pre-training,"Zheheng Luo, Xin Zhang, Xiao Liu, Haoling Li, Yeyun Gong, Qi Chen, Peng Cheng",(missing journal),2025,(missing abstract),289514497,0,0,,
10.18653/v1/2025.acl-long.803,LIFBench: Evaluating the Instruction Following Performance and Stability of Large Language Models in Long-Context Scenarios,"Xiaodong Wu, Minhao Wang, Yichen Liu, Xiaoming Shi, Yan He, Lu Xiangju, Xiashi Zhu, Wei Zhang",(missing journal),2025,(missing abstract),289514498,0,0,,
10.18653/v1/2025.acl-long.1173,Representation Bending for Large Language Model Safety,"Ashkan Yousefpour, Taeheon Kim, Ryan Sungmo Kwon, Seungbeen Lee, Wonje Jeung, Seungju Han, Alvin Wan, H.W. Ngan, Youngjae Yu, Jonghyun Choi",(missing journal),2025,(missing abstract),289514499,2,0,,
10.18653/v1/2025.acl-long.716,QAEval: Mixture of Evaluators for Question-Answering Task Evaluation,"Tan Yue, Rui Mao, Xuzhao Shi, Shuo Zhan, Zuhao Yang, Dongyan Zhao",(missing journal),2025,(missing abstract),289514500,0,0,,
10.18653/v1/2025.acl-long.724,HiddenDetect: Detecting Jailbreak Attacks against Multimodal Large Language Models via Monitoring Hidden States,"Yilei Jiang, Xinyan Gao, Tianshuo Peng, Y. H. Tan, Xiaoyong Zhu, Bo Zheng, Xiangyu Yue",(missing journal),2025,(missing abstract),289514501,1,0,,
10.18653/v1/2025.acl-long.753,MISP-Meeting: A Real-World Dataset with Multimodal Cues for Long-form Meeting Transcription and Summarization,"HangChen HangChen, Chao-Han Huck Yang, Jia-Chen Gu, Sabato Marco Siniscalchi, Jun Du",(missing journal),2025,(missing abstract),289514502,0,0,,
10.18653/v1/2025.acl-long.688,Cooperative or Competitive? Understanding the Interaction between Attention Heads From A Game Theory Perspective,"Xiaoye Qu, Zhe Yu, Dongrui Liu, Wei Wei, Daizong Liu, Jianfeng Dong, Yu Cheng",(missing journal),2025,(missing abstract),289514503,0,0,,
10.18653/v1/2025.acl-long.626,HFT: Half Fine-Tuning for Large Language Models,"Tingfeng Hui, Zhenyu Zhang, Shuohuan Wang, Weiran Xu, Yu Sun, Hua Wu",(missing journal),2025,(missing abstract),289514504,0,0,,
10.18653/v1/2025.acl-long.634,Activation Steering Decoding: Mitigating Hallucination in Large Vision-Language Models through Bidirectional Hidden State Intervention,"Jingran Su, Jingfan Chen, Hongxin Li, Yuntao Chen, Qing Li, Zhaoxiang Zhang",(missing journal),2025,(missing abstract),289514505,2,0,,
10.18653/v1/2025.acl-long.630,Lost in Literalism: How Supervised Training Shapes Translationese in LLMs,"Yafu Li, Ronghao Zhang, Zhilin Wang, Huajian Zhang, Leyang Cui, Yongjing Yin, Tong Xiao, Yanlong Zhang",(missing journal),2025,(missing abstract),289514506,1,0,,
10.18653/v1/2025.acl-long.669,TeamLoRA: Boosting Low-Rank Adaptation with Expert Collaboration and Competition,"Wan‐Wan Lin, Jiang Liu, Wenqiao Zhang, Yang Dai, Haoyuan Li, Zhelun Yu, Wanggui He, Juncheng Li, Jiannan Guo, Hao Jiang, Siliang Tang, Yueting Zhuang",(missing journal),2025,(missing abstract),289514507,0,0,,
10.18653/v1/2025.acl-long.621,Planning-Driven Programming: A Large Language Model Programming Workflow,"Chao Lei, Yanchuan Chang, Nir Lipovetzky, Krista A. Ehinger",(missing journal),2025,(missing abstract),289514508,1,0,,
10.18653/v1/2025.acl-long.646,Knowledge Decoupling via Orthogonal Projection for Lifelong Editing of Large Language Models,"Haoyu Xu, Pengxiang Lan, Enneng Yang, Guibing Guo, Jianzhe Zhao, Linying Jiang, Xingwei Wang",(missing journal),2025,(missing abstract),289514509,0,0,,
10.18653/v1/2025.acl-long.701,"KazMMLU: Evaluating Language Models on Kazakh, Russian, and Regional Knowledge of Kazakhstan","Mukhammed Togmanov, Nurdaulet Mukhituly, Diana Turmakhan, Jonibek Mansurov, Maiya Goloburda, Akhmed Sakip, Zhuohan Xie, Yuxia Wang, Bekassyl Syzdykov, Nurkhan Laiyk, Alham Fikri Aji, Ekaterina Kochmar, Preslav Nakov, Fajri Koto",(missing journal),2025,(missing abstract),289514510,3,0,,
10.18653/v1/2025.acl-long.525,APB: Accelerating Distributed Long-Context Inference by Passing Compressed Context Blocks across GPUs,"Yuxiang Huang, Mingye Li, Xu Han, Chaojun Xiao, Weilin Zhao, Ao Sun, N. Zhou, Jie Zhou, Zhiyuan Liu, Maosong Sun",(missing journal),2025,(missing abstract),289514511,0,0,,
10.18653/v1/2025.acl-long.519,Unveiling Environmental Impacts of Large Language Model Serving: A Functional Unit View,"Yanran Wu, Inez Hua, Yi Ding",(missing journal),2025,(missing abstract),289514512,2,0,,
10.18653/v1/2025.acl-long.575,UORA: Uniform Orthogonal Reinitialization Adaptation in Parameter Efficient Fine-Tuning of Large Models,"Xueyan Zhang, Jie Zhao, Zhifei Yang, Yimin Zhong, Shuhao Guan, Linbo Cao, Y. F. Wang",(missing journal),2025,(missing abstract),289514513,0,0,,
10.18653/v1/2025.acl-long.578,CaLMQA: Exploring culturally specific long-form question answering across 23 languages,"Shane Arora, Marzena Karpinska, Hung-Ting Chen, Ipsita Bhattacharjee, Mohit Iyyer, Eunsol Choi",(missing journal),2025,(missing abstract),289514514,0,0,,
10.18653/v1/2025.acl-long.570,Jailbreaking? One Step Is Enough!,"Weixiong Zheng, Peijian Zeng, Y. Li, Hongyan Wu, Nankai Lin, Junhao Chen, Aimin Yang, Yiling Zhou",(missing journal),2025,(missing abstract),289514515,0,0,,
10.18653/v1/2025.acl-long.550,Dynamic Parallel Tree Search for Efficient LLM Reasoning,"Yifu Ding, Wentao Jiang, Shunyu Liu, Yongcheng Jing, Jinyang Guo, Yingjie Wang, Jing Zhang, Zengmao Wang, Ziwei Liu, Bo Du, Xianglong Liu, Dacheng Tao",(missing journal),2025,(missing abstract),289514516,2,0,,
10.18653/v1/2025.acl-long.503,DenseLoRA: Dense Low-Rank Adaptation of Large Language Models,"Lin Mu, Xiaoyu Wang, Ni Li, Yang Li, Zhize Wu, Peiquan Jin, Yiwen Zhang",(missing journal),2025,(missing abstract),289514517,0,0,,
10.18653/v1/2025.acl-long.538,ARise: Towards Knowledge-Augmented Reasoning via Risk-Adaptive Search,"Yize Zhang, Tianshu Wang, Sirui Chen, Kun Wang, Xiangyao Zeng, Hongyu Lin, Xianpei Han, Le Sun, Chaochao Lu",(missing journal),2025,(missing abstract),289514518,0,0,,
10.18653/v1/2025.acl-long.536,DTCRS: Dynamic Tree Construction for Recursive Summarization,"Guangzhao Luo, Zhi-Wei Jian, W. Qiu, Meihong Wang, Qingqiang Wu",(missing journal),2025,(missing abstract),289514519,0,0,,
10.18653/v1/2025.acl-long.572,PaSa: An LLM Agent for Comprehensive Academic Paper Search,"Yichen He, Guanhua Huang, Peiyuan Feng, Yuan Lin, Yuchen Zhang, Jinmei Li, E Weinan",(missing journal),2025,(missing abstract),289514521,0,0,,
10.18653/v1/2025.acl-long.422,Sinhala Encoder-only Language Models and Evaluation,"Tharindu Ranasinghe, Hansi Hettiarachchi, Nadeesha Pathirana, Damith Premasiri, Lasitha Uyangodage, Isuri Nanomi Arachchige, Alistair Plum, Paul Rayson, Ruslan Mitkov",(missing journal),2025,(missing abstract),289514522,0,0,,
10.18653/v1/2025.acl-long.334,The TIP of the Iceberg: Revealing a Hidden Class of Task-in-Prompt Adversarial Attacks on LLMs,"Sergey Berezin, Reza Farahbakhsh, Noël Crespi",(missing journal),2025,(missing abstract),289514523,0,0,,
10.18653/v1/2025.acl-long.358,DRAG: Distilling RAG for SLMs from LLMs to Transfer Knowledge and Mitigate Hallucination via Evidence and Graph-based Distillation,"J. Chen, Aidar Myrzakhan, Yue Luo, Hamaid Mahmood Khan, Sondos Mahmoud Bsharat, Zhiqiang Shen",(missing journal),2025,(missing abstract),289514524,0,0,,
10.18653/v1/2025.acl-long.393,LLM Braces: Straightening Out LLM Predictions with Relevant Sub-Updates,"Ying Shen, Lifu Huang",(missing journal),2025,(missing abstract),289514525,0,0,,
10.18653/v1/2025.acl-long.323,Evaluating Multimodal Large Language Models on Video Captioning via Monte Carlo Tree Search,"Linhao Yu, Xingguang Ji, Yahui Liu, Fanyu Kong, Chenxi Sun, Jìngyuàn Zhāng, Hongzhi Zhang, V. W., Fuzheng Zhang, Deyi Xiong",(missing journal),2025,(missing abstract),289514526,0,0,,
10.18653/v1/2025.acl-long.289,Towards Effective and Efficient Continual Pre-training of Large Language Models,"Jie Chen, Zhipeng Chen, Jiapeng Wang, Kun Zhou, Yutao Zhu, Jinhao Jiang, Yingqian Min, Xin Zhao, Zhicheng Dou, Jiaxin Mao, Yankai Lin, Ruihua Song, Jun Xu, Xu Chen, Rui Yan, Zhewei Wei, Di Hu, Wenbing Huang, Ji-Rong Wen",(missing journal),2025,(missing abstract),289514527,0,0,,
10.18653/v1/2025.acl-long.286,Entailment-Preserving First-order Logic Representations in Natural Language Entailment,"Jinu Lee, Qi Liu, R. Ma, Vincent Han, Ziqi Wang, Heng Ji, Julia Hockenmaier",(missing journal),2025,(missing abstract),289514528,0,0,,
10.18653/v1/2025.acl-long.292,What Makes a Good Natural Language Prompt?,"Do Xuan Long, Duy Dinh, Ngoc-Hai Nguyen, Kenji Kawaguchi, Nancy F. Chen, Shafiq Joty, Min‐Yen Kan",(missing journal),2025,(missing abstract),289514529,0,0,,
10.18653/v1/2025.acl-long.230,SafeRAG: Benchmarking Security in Retrieval-Augmented Generation of Large Language Model,"Xun Liang, Simin Niu, Zhiyu Li, Sensen Zhang, Hanyu Wang, Feiyu Xiong, Zhaoxin Fan, Bo Tang, J. Zhao, Jiawei Yang, Shichao Song, Mengwei Wang",(missing journal),2025,(missing abstract),289520488,1,0,,
10.18653/v1/2025.acl-long.180,Progressive Multimodal Reasoning via Active Retrieval,"Guanting Dong, Chenghao Zhang, Mengjie Deng, Yutao Zhu, Zhicheng Dou, Ji-Rong Wen",(missing journal),2025,(missing abstract),289520489,0,0,,
10.18653/v1/2025.acl-long.226,ProtoLens: Advancing Prototype Learning for Fine-Grained Interpretability in Text Classification,"Bowen Wei, Ziwei Zhu",(missing journal),2025,(missing abstract),289520490,0,0,,
10.18653/v1/2025.acl-long.190,Towards Better Evaluation for Generated Patent Claims,"Lekang Jiang, Pascal A. Scherz, Stefan M. Goetz",(missing journal),2025,(missing abstract),289520491,1,0,,
10.18653/v1/2025.acl-long.72,Synergizing LLMs with Global Label Propagation for Multimodal Fake News Detection,"Shaojun Hu, Junhui Hu, Huaiwen Zhang",(missing journal),2025,(missing abstract),289520492,1,0,,
10.18653/v1/2025.acl-long.105,Exploring Forgetting in Large Language Model Pre-Training,"Chengde Liao, Ruobing Xie, Xingwu Sun, Haowen Sun, Zhanhui Kang",(missing journal),2025,(missing abstract),289520493,1,0,,
10.18653/v1/2025.acl-long.118,Steering into New Embedding Spaces: Analyzing Cross-Lingual Alignment Induced by Model Interventions in Multilingual Language Models,"Anirudh Sundar, Sinead A. Williamson, Katherine Metcalf, Barry-John Theobald, Skyler Seto, Masha Fedzechkina",(missing journal),2025,(missing abstract),289520494,3,0,,
10.18653/v1/2025.acl-long.75,"Wait, that’s not an option: LLMs Robustness with Incorrect Multiple-Choice Options","Gracjan Góral, Emilia Wiśnios, Piotr Sankowski, Paweł Budzianowski",(missing journal),2025,(missing abstract),289520495,0,0,,
10.18653/v1/2025.acl-long.1600,Language Models can Subtly Deceive Without Lying: A Case Study on Strategic Phrasing in Legislation,"Atharvan Dogra, Krishna Pillutla, Ameet Deshpande, Ananya B. Sai, John J. Nay, Tanmay Rajpurohit, Ashwin Kalyan, Balaraman Ravindran",Annual Meeting of the Association for Computational Linguistics,2025,"We explore the ability of large language models (LLMs) to engage in subtle deception through strategically phrasing and intentionally manipulating information. This harmful behavior can be hard to detect, unlike blatant lying or unintentional hallucination. We build a simple testbed mimicking a legislative environment where a corporate \textit{lobbyist} module is proposing amendments to bills that benefit a specific company while evading identification of this benefactor. We use real-world legislative bills matched with potentially affected companies to ground these interactions. Our results show that LLM lobbyists can draft subtle phrasing to avoid such identification by strong LLM-based detectors. Further optimization of the phrasing using LLM-based re-planning and re-sampling increases deception rates by up to 40 percentage points. Our human evaluations to verify the quality of deceptive generations and their retention of self-serving intent show significant coherence with our automated metrics and also help in identifying certain strategies of deceptive phrasing. This study highlights the risk of LLMs'capabilities for strategic phrasing through seemingly neutral language to attain self-serving goals. This calls for future research to uncover and protect against such subtle deception.",289520612,6,44,,
10.18653/v1/2025.acl-long.1595,Scalable Vision Language Model Training via High Quality Data Curation,"Hongyuan Dong, Zhan Kang, Weijie Yin, LiangXiao LiangXiao, ChaoFeng ChaoFeng, Ran Jiao",(missing journal),2025,(missing abstract),289520613,1,0,,
10.18653/v1/2025.acl-long.1553,Multi-Level Explanations for Generative Language Models,"Lucas Monteiro Paes, Dennis Wei, Hyo Jin, Hendrik Strobelt, Ronny Luss, Amit Dhurandhar, Manish Nagireddy, Karthikeyan Natesan Ramamurthy, Prasanna Sattigeri, Werner Geyer, Soumya Sankar Ghosh",(missing journal),2025,(missing abstract),289520614,0,0,,
10.18653/v1/2025.acl-long.1523,Completing A Systematic Review in Hours instead of Months with Interactive AI Agents,"Rui Qiu, Shijie Chen, Yu Su, Po-Yin Yen, Han Shen",(missing journal),2025,(missing abstract),289520615,0,0,,
10.18653/v1/2025.acl-long.1447,GrammaMT: Improving Machine Translation with Grammar-Informed In-Context Learning,"Rita Ramos, Everlyn Asiko Chimoto, Maartje ter Hoeve, Natalie Schluter",(missing journal),2025,(missing abstract),289520616,0,0,,
10.18653/v1/2025.acl-long.1414,DRPruning: Efficient Large Language Model Pruning through Distributionally Robust Optimization,"Hexuan Deng, Wenxiang Jiao, Xuebo Liu, Jing Li, Min Zhang, Zhaopeng Tu",(missing journal),2025,(missing abstract),289520617,0,0,,
10.18653/v1/2025.acl-long.1428,EditInspector: A Benchmark for Evaluation of Text-Guided Image Edits,"Ron Yosef, Yonatan Bitton, Dani Lischinski, Moran Yanuka",(missing journal),2025,(missing abstract),289520618,0,0,,
10.18653/v1/2025.acl-long.1427,Dialectal Coverage And Generalization in Arabic Speech Recognition,"Amirbek Djanibekov, Hawau Olamide Toyin, Raghad Alshalan, Abdullah Alatir, Hanan Aldarmaki",(missing journal),2025,(missing abstract),289520619,0,0,,
10.18653/v1/2025.acl-long.1463,Can we Retrieve Everything All at Once? ARM: An Alignment-Oriented LLM-based Retrieval Method,"Peter Baile Chen, Yi Zhang, Mike Cafarella, Dan Roth",(missing journal),2025,(missing abstract),289520620,1,0,,
10.18653/v1/2025.acl-long.1429,Reconsidering LLM Uncertainty Estimation Methods in the Wild,"Yavuz Faruk Bakman, Duygu Nur Yaldiz, Shichang Kang, Tuo Zhang, Baturalp Buyukates, Salman Avestimehr, Sai Praneeth Karimireddy",(missing journal),2025,(missing abstract),289520621,0,0,,
10.18653/v1/2025.acl-long.1478,M³GQA: A Multi-Entity Multi-Hop Multi-Setting Graph Question Answering Benchmark,"Boci Peng, Yongchao Liu, Xiaohe Bo, Jiaxin Guo, Yun Zhu, Xuanbo Fan, Chuntao Hong, Yan Zhang",(missing journal),2025,(missing abstract),289520622,0,0,,
10.18653/v1/2025.acl-long.1480,ETF: An Entity Tracing Framework for Hallucination Detection in Code Summaries,"Kishan Maharaj, Vitobha Munigala, Srikanth Tamilselvam, Prince Kumar, Sayandeep Sen, Palani Kodeswaran, Abhijit Mishra, Pushpak Bhattacharyya",(missing journal),2025,(missing abstract),289520623,0,0,,
10.18653/v1/2025.acl-long.1401,Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel Tool Invocation,"Dongsheng Zhu, Weiping Shi, Zhiao Shi, Zhaochun Ren, Shuaiqiang Wang, Lisong Yan, Dawei Yin",(missing journal),2025,(missing abstract),289520624,0,0,,
10.18653/v1/2025.acl-long.1409,"Language Models, Graph Searching, and Supervision Adulteration: When More Supervision is Less and How to Make More More",Arvid Frydenlund,(missing journal),2025,(missing abstract),289520625,0,0,,
10.18653/v1/2025.acl-long.1361,Multi-perspective Alignment for Increasing Naturalness in Neural Machine Translation,"Huiyuan Lai, Esther Ploeger, Rik van Noord, Antonio Toral",(missing journal),2025,(missing abstract),289520626,0,0,,
10.18653/v1/2025.acl-long.1324,Benchmarking Long-Context Language Models on Long Code Understanding,"Jia Li, Xin Guo, Lei Li, Kechi Zhang, Ge Li, Jia Li, Zhengwei Tao, Fang Liu, Chongyang Tao, Yuqi Zhu, Zhi Jin",(missing journal),2025,(missing abstract),289520627,0,0,,
10.18653/v1/2025.acl-long.1345,"Representations of Fact, Fiction and Forecast in Large Language Models: Epistemics and Attitudes","Meng Li, Michael Vrazitulis, David Schlangen",(missing journal),2025,(missing abstract),289520628,0,0,,
10.18653/v1/2025.acl-long.1322,Bone Soups: A Seek-and-Soup Model Merging Approach for Controllable Multi-Objective Generation,"Guofu Xie, Xiao Zhang, Ting Yao, Shi Yunsheng",(missing journal),2025,(missing abstract),289520629,0,0,,
10.18653/v1/2025.acl-long.1357,Information Locality as an Inductive Bias for Neural Language Models,"Taiga Someya, Anej Svete, Brian DuSell, Timothy J. O’Donnell, Mario Giulianelli, Ryan Cotterell",(missing journal),2025,(missing abstract),289520630,2,0,,
10.18653/v1/2025.acl-long.1248,Balancing the Budget: Understanding Trade-offs Between Supervised and Preference-Based Finetuning,"Mohit Raghavendra, Junmo Kang, Alan Ritter",(missing journal),2025,(missing abstract),289520631,0,0,,
10.18653/v1/2025.acl-long.1280,Can LLMs Deceive CLIP? Benchmarking Adversarial Compositionality of Pre-trained Multimodal Representation via Text Updates,"Jaewoo Ahn, Heeseung Yun, Dayoon Ko, Gunhee Kim",(missing journal),2025,(missing abstract),289520632,0,0,,
10.18653/v1/2025.acl-long.1224,The Nature of NLP: Analyzing Contributions in NLP Papers,"Aniket Pramanick, Yufang Hou, Saif M. Mohammad, Iryna Gurevych",(missing journal),2025,(missing abstract),289520633,0,0,,
10.18653/v1/2025.acl-long.1214,Language Models Grow Less Humanlike beyond Phase Transition,"Tatsuya Aoyama, Ethan Wilcox",(missing journal),2025,(missing abstract),289520634,0,0,,
10.18653/v1/2025.acl-long.1137,SoftCoT: Soft Chain-of-Thought for Efficient Reasoning with LLMs,"Yaogeng Xu, Xu Guo, Zhiwei Zeng, Chunyan Miao",(missing journal),2025,(missing abstract),289522455,3,0,,
10.18653/v1/2025.acl-long.1076,Not All Terms Matter: Recall-Oriented Adaptive Learning for PLM-aided Query Expansion in Open-Domain Question Answering,"Xinran Chen, Ben He, Xuanang Chen, Le Sun",(missing journal),2025,(missing abstract),289522456,0,0,,
10.18653/v1/2025.acl-long.1161,A Dual-Mind Framework for Strategic and Expressive Negotiation Agent,"Yutong Liu, Lei Shi, Rui Song, Hao Xu",(missing journal),2025,(missing abstract),289522457,1,0,,
10.18653/v1/2025.acl-long.1135,Data Whisperer: Efficient Data Selection for Task-Specific LLM Fine-Tuning via Few-Shot In-Context Learning,"Shaobo Wang, Xiaopeng Jin, Ziming Wang, Wang Jie, Jiajun Zhang, Kaixin Li, Zichen Wen, Zhong Li, Conghui He, Xuming Hu, Linfeng Zhang",(missing journal),2025,(missing abstract),289522458,1,0,,
10.18653/v1/2025.acl-long.1153,Don’t Half-listen: Capturing Key-part Information in Continual Instruction Tuning,"Yongquan He, Wenyuan Zhang, Xuancheng Huang, Peng Zhang, Lingxun Meng, Xiang Zhou, Ke Zeng, Xunliang Cai",(missing journal),2025,(missing abstract),289522459,0,0,,
10.18653/v1/2025.acl-long.1114,A Statistical and Multi-Perspective Revisiting of the Membership Inference Attack in Large Language Models,"Bowen Chen, Namgi Han, Yusuke Miyao",(missing journal),2025,(missing abstract),289522460,0,0,,
10.18653/v1/2025.acl-long.1106,Retrieval-Augmented Fine-Tuning With Preference Optimization For Visual Program Generation,"Deokhyung Kang, Jeonghun Cho, Yejin Jeon, Se Hyun Jang, Minsub Lee, Jae-Kwang Cho, Gary Lee",(missing journal),2025,(missing abstract),289522461,1,0,,
10.18653/v1/2025.acl-long.958,PlanGenLLMs: A Modern Survey of LLM Planning Capabilities,"Hui Wei, Zihao Zhang, Shenghua He, Tian Xia, Shijia Pan, Fei Liu",(missing journal),2025,(missing abstract),289522462,6,0,,
10.18653/v1/2025.acl-long.1036,LLM Meets Scene Graph: Can Large Language Models Understand and Generate Scene Graphs? A Benchmark and Empirical Study,"Dongil Yang, Minjin Kim, Sunghwan Kim, Beong-woo Kwak, Minjun Park, Jinseok Hong, Woontack Woo, Jinyoung Yeo",(missing journal),2025,(missing abstract),289522463,2,0,,
10.18653/v1/2025.acl-long.1037,Beyond Frameworks: Unpacking Collaboration Strategies in Multi-Agent Systems,"Haochun Wang, Sendong Zhao, Jingbo Wang, Zewen Qiang, Bing Qin, Ting Liu",(missing journal),2025,(missing abstract),289522464,0,0,,
10.18653/v1/2025.acl-long.995,Synergistic Weak-Strong Collaboration by Aligning Preferences,"Yizhu Jiao, Xuchao Zhang, Zhaoyang Wang, Yizhou Ma, Zhihui Deng, Rujia Wang, Chetan Bansal, Saravan Rajmohan, Jiawei Han, Huaxiu Yao",(missing journal),2025,(missing abstract),289522465,0,0,,
10.18653/v1/2025.acl-long.967,Adversarial Alignment with Anchor Dragging Drift (A3D2): Multimodal Domain Adaptation with Partially Shifted Modalities,"Jun Sun, Xinxin Zhang, Simin Hong, Jian Zhu, Lingfang Zeng",(missing journal),2025,(missing abstract),289522466,0,0,,
10.18653/v1/2025.acl-long.1064,Evaluating Personalized Tool-Augmented LLMs from the Perspectives of Personalization and Proactivity,"Yimeng Hao, Cao Peng-fei, Zhuoran Jin, Huanxuan Liao, Yubo Chen, Kang Liu, Jun Zhao",(missing journal),2025,(missing abstract),289522467,1,0,,
10.18653/v1/2025.acl-long.917,Soundwave: Less is More for Speech-Text Alignment in LLMs,"Yuhao Zhang, Zhi‐Heng Liu, Fan Bu, Ruiyu Zhang, Benyou Wang, Haizhou Li",(missing journal),2025,(missing abstract),289522468,0,0,,
10.18653/v1/2025.acl-long.1007,Multi-Attribute Steering of Language Models via Targeted Intervention,"Duy Lap Nguyen, Archiki Prasad, Elias Stengel-Eskin, Mohit Bansal",(missing journal),2025,(missing abstract),289522469,2,0,,
10.18653/v1/2025.acl-long.968,A Reality Check on Context Utilisation for Retrieval-Augmented Generation,"Lovisa Hagström, Sara Vera Marjanović, Haeun Yu, Arnav Arora, Christina Lioma, Maria Maistro, Pepa Atanasova, Isabelle Augenstein",(missing journal),2025,(missing abstract),289522470,0,0,,
10.18653/v1/2025.acl-long.812,Does Time Have Its Place? Temporal Heads: Where Language Models Recall Time-specific Information,"Y.K. Park, Chanwoong Yoon, Jungwoo Park, Minbyul Jeong, Jaewoo Kang",(missing journal),2025,(missing abstract),289522471,0,0,,
10.18653/v1/2025.acl-long.829,TST: A Schema-Based Top-Down and Dynamic-Aware Agent of Text-to-Table Tasks,"Peiwen Jiang, H. B. Jiang, Ruichen Ma, Yvonne Jie Chen, Jinhua Cheng",(missing journal),2025,(missing abstract),289522472,0,0,,
10.18653/v1/2025.acl-long.838,Value Portrait: Assessing Language Models’ Values through Psychometrically and Ecologically Valid Items,"Jongwook Han, Dongmin Choi, Wei Song, Eun‐Ju Lee, You Hwan Jo",(missing journal),2025,(missing abstract),289522473,0,0,,
10.18653/v1/2025.acl-long.801,Enhancing Event-centric News Cluster Summarization via Data Sharpening and Localization Insights,"Longyin Zhang, Bowei Zou, AiTi Aw",(missing journal),2025,(missing abstract),289522474,0,0,,
10.18653/v1/2025.acl-long.1178,Asclepius: A Spectrum Evaluation Benchmark for Medical Multi-Modal Large Language Models,"Jie Liu, Wenxuan Wang, Su Yihang, Jingyuan Huang, Yudi Zhang, Chengyi Li, Wenting Chen, Xiaohan Xing, Kao-Jung Chang, Linlin Shen, Michael R. Lyu",(missing journal),2025,(missing abstract),289522475,4,0,,
10.18653/v1/2025.acl-long.619,Agentic Knowledgeable Self-awareness,"Shuofei Qiao, Zhisong Qiu, Baolong Ren, Xiaobin Wang, Xiangyuan Ru, Ningyu Zhang, Xiang Chen, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen",(missing journal),2025,(missing abstract),289522476,1,0,,
10.18653/v1/2025.acl-long.709,OmniFlatten: An End-to-end GPT Model for Seamless Voice Conversation,"Qinglin Zhang, Luyao Cheng, Chong Deng, Chen Qian, Wen Wang, Siqi Zheng, Jiaqing Liu, Hai Yu, Chao-Hong Tan, Zhihao Du, Shiliang Zhang",(missing journal),2025,(missing abstract),289522477,2,0,,
10.18653/v1/2025.acl-long.747,EPO: Explicit Policy Optimization for Strategic Reasoning in LLMs via Reinforcement Learning,"Xiaoqian Liu, Ke Wang, Yongbin Li, Yuchuan Wu, Wentao Ma, Aobo Kong, Fei Huang, Jianbin Jiao, Junge Zhang",(missing journal),2025,(missing abstract),289522478,0,0,,
10.18653/v1/2025.acl-long.768,Masks Can be Learned as an Alternative to Experts,"Peiyu Liu, Tianwen Wei, Bo Zhu, Xin Zhao, Shuicheng Yan",(missing journal),2025,(missing abstract),289522479,0,0,,
10.18653/v1/2025.acl-long.668,Finite State Automata Inside Transformers with Chain-of-Thought: A Mechanistic Study on State Tracking,"Yifan Zhang, Wei Du, Dan Jin, Jie Fu, Zhi-jiang Jin",(missing journal),2025,(missing abstract),289522480,0,0,,
10.18653/v1/2025.acl-long.664,Lexical Recall or Logical Reasoning: Probing the Limits of Reasoning Abilities in Large Language Models,"Horst A. Beyer, Chris Reed",(missing journal),2025,(missing abstract),289522481,0,0,,
10.18653/v1/2025.acl-long.720,Can Vision-Language Models Evaluate Handwritten Math?,"Oikantik Nath, Hanani Bathina, Mohammed Safi Ur Rahman Khan, Mitesh M. Khapra",(missing journal),2025,(missing abstract),289522482,0,0,,
10.18653/v1/2025.acl-long.695,Emma-X: An Embodied Multimodal Action Model with Grounded Chain of Thought and Look-ahead Spatial Reasoning,"Qi Sun, Pengfei Hong, Tej Deep Pala, Vernon Toh, U-Xuan Tan, Deepanway Ghosal, Soujanya Poria",(missing journal),2025,(missing abstract),289522483,0,0,,
10.18653/v1/2025.acl-long.732,Chinese SafetyQA: A Safety Short-form Factuality Benchmark for Large Language Models,"Yingshui Tan, Boren Zheng, Boyang Zheng, Kankan Cao, He Jing, Jibo Wei, Jiaheng Liu, Yancheng He, Wenbo Su, Xiaoyong Zhu, B. Zheng, Kaifu Zhang",(missing journal),2025,(missing abstract),289522484,0,0,,
10.18653/v1/2025.acl-long.582,BeamLoRA: Beam-Constraint Low-Rank Adaptation,"Nannan Gu, Zhenyu Zhang, Xiyu Liu, Peng Fu, Zheng Lin, Shuohuan Wang, Yuzhou Sun, Hua Wu, Weiping Wang, Haifeng Wang",(missing journal),2025,(missing abstract),289522485,0,0,,
10.18653/v1/2025.acl-long.552,SHARE: An SLM-based Hierarchical Action CorREction Assistant for Text-to-SQL,"Ge Qu, Jinyang Li, Bowen Qin, Xiaolong Li, Nan Huo, Chenhao Ma, Reynold Cheng",(missing journal),2025,(missing abstract),289522486,0,0,,
10.18653/v1/2025.acl-long.506,Towards Context-Robust LLMs: A Gated Representation Fine-tuning Approach,"Shenglai Zeng, Pengfei He, Kai Guo, Tianqi Zheng, Hanqing Lu, Yue Xing, Hui Liu",(missing journal),2025,(missing abstract),289522487,0,0,,
10.18653/v1/2025.acl-long.521,Cool-Fusion: Fuse Large Language Models without Training,"Cong Liu, Xiaojun Quan, Yan Pan, Weigang Wu, Cheng Xu, Liang Lin",(missing journal),2025,(missing abstract),289522488,0,0,,
10.18653/v1/2025.acl-long.537,A Generative Adaptive Replay Continual Learning Model for Temporal Knowledge Graph Reasoning,"Zhiyu Zhang, Wei Chen, Youfang Lin, Huaiyu Wan",(missing journal),2025,(missing abstract),289522489,0,0,,
10.18653/v1/2025.acl-long.398,When People are Floods: Analyzing Dehumanizing Metaphors in Immigration Discourse with Large Language Models,"Julia Mendelsohn, Ceren Budak",(missing journal),2025,(missing abstract),289522490,0,0,,
10.18653/v1/2025.acl-long.462,Developmentally-plausible Working Memory Shapes a Critical Period for Language Acquisition,"Masato Mita, Ryo Yoshida, Yohei Oseki",(missing journal),2025,(missing abstract),289522491,0,0,,
10.18653/v1/2025.acl-long.491,The Lawyer That Never Thinks: Consistency and Fairness as Keys to Reliable AI,"Dana Alsagheer, A. S. M. Maksud Kamal, Mohammad Kamal, Chengjun Wu, Weidong Shi",(missing journal),2025,(missing abstract),289522492,0,0,,
10.18653/v1/2025.acl-long.484,Aligning VLM Assistants with Personalized Situated Cognition,"Yongqi Li, Shen Zhou, Xiaohu Li, Xin Miao, Jintao Wen, M. Xu, Jianhao Chen, Bo Pan, Hee-Jung Kang, Yuanyuan Zhu, Ming Zhong, Tieyun Qian",(missing journal),2025,(missing abstract),289522493,0,0,,
10.18653/v1/2025.acl-long.486,Faster Speculative Decoding via Effective Draft Decoder with Pruned Candidate Tree,"Hao Zheng, Xiaoling Wang",(missing journal),2025,(missing abstract),289522494,0,0,,
10.18653/v1/2025.acl-long.474,Incorporating Domain Knowledge into Materials Tokenization,"Yerim Oh, Jun-Hyung Park, Junho Kim, Sungho Kim, SangKeun Lee",(missing journal),2025,(missing abstract),289522495,0,0,,
10.18653/v1/2025.acl-long.349,Beyond Facts: Evaluating Intent Hallucination in Large Language Models,"Yijie Hao, Hao-Fei Yu, Jiaxuan You",(missing journal),2025,(missing abstract),289522496,1,0,,
10.18653/v1/2025.acl-long.460,Focus on What Matters: Enhancing Medical Vision-Language Models with Automatic Attention Alignment Tuning,"Aofei Chang, Longjun Huang, A. J. Boyd, Parminder Bhatia, Taha Kass‐Hout, Cao Xiao, Fenglong Ma",(missing journal),2025,(missing abstract),289522497,1,0,,
10.18653/v1/2025.acl-long.472,Value-Spectrum: Quantifying Preferences of Vision-Language Models via Value Decomposition in Social Media Contexts,"Jingxuan Li, Yuning Yang, Shengqi Yang, Linfan Zhang, Ying Wu",Annual Meeting of the Association for Computational Linguistics,2025,"The recent progress in Vision-Language Models (VLMs) has broadened the scope of multimodal applications. However, evaluations often remain limited to functional tasks, neglecting abstract dimensions such as personality traits and human values. To address this gap, we introduce Value-Spectrum, a novel Visual Question Answering (VQA) benchmark aimed at assessing VLMs based on Schwartz's value dimensions that capture core human values guiding people's preferences and actions. We design a VLM agent pipeline to simulate video browsing and construct a vector database comprising over 50,000 short videos from TikTok, YouTube Shorts, and Instagram Reels. These videos span multiple months and cover diverse topics, including family, health, hobbies, society, technology, etc. Benchmarking on Value-Spectrum highlights notable variations in how VLMs handle value-oriented content. Beyond identifying VLMs' intrinsic preferences, we also explore the ability of VLM agents to adopt specific personas when explicitly prompted, revealing insights into the adaptability of the model in role-playing scenarios. These findings highlight the potential of Value-Spectrum as a comprehensive evaluation set for tracking VLM preferences in value-based tasks and abilities to simulate diverse personas. The complete code and data are available at: https://github.com/Jeremyyny/Value-Spectrum.",289522498,0,31,,
10.18653/v1/2025.acl-long.374,Evaluation Agent: Efficient and Promptable Evaluation Framework for Visual Generative Models,"Fan Zhang, Shulin Tian, Ziqi Huang, Yu Qiao, Ziwei Liu",(missing journal),2025,(missing abstract),289522499,0,0,,
10.18653/v1/2025.acl-long.301,HoH: A Dynamic Benchmark for Evaluating the Impact of Outdated Information on Retrieval-Augmented Generation,"Jie Ouyang, Tingyue Pan, Mingyue Cheng, Rui Yan, Yucong Luo, Jiaying Lin, Qi Liu",(missing journal),2025,(missing abstract),289522500,0,0,,
10.18653/v1/2025.acl-long.294,Are Rules Meant to be Broken? Understanding Multilingual Moral Reasoning as a Computational Pipeline with UniMoral,"Shivani Kumar, David Jurgens",(missing journal),2025,(missing abstract),289522501,0,0,,
10.18653/v1/2025.acl-long.291,mPLUG-DocOwl2: High-resolution Compressing for OCR-free Multi-page Document Understanding,"Anwen Hu, Haiyang Xu, Liang Zhang, Jiabo Ye, Ming Yan, Ji Zhang, Jin Qin, Fei Huang, Jingren Zhou",(missing journal),2025,(missing abstract),289522502,3,0,,
10.18653/v1/2025.acl-long.270,Bridging the Language Gaps in Large Language Models with Inference-Time Cross-Lingual Intervention,"Weixuan Wang, Minghao Wu, Barry Haddow, Alexandra Birch",(missing journal),2025,(missing abstract),289522503,1,0,,
10.18653/v1/2025.acl-long.171,An Efficient Task-Oriented Dialogue Policy: Evolutionary Reinforcement Learning Injected by Elite Individuals,"Yangyang Zhao, Ben Niu, L. Q. Qin, Shihan Wang",(missing journal),2025,(missing abstract),289528468,0,0,,
10.18653/v1/2025.acl-long.166,Revisiting Common Assumptions about Arabic Dialects in NLP,"Amr Keleg, Sharon Goldwater, Walid Magdy",(missing journal),2025,(missing abstract),289528469,1,0,,
10.18653/v1/2025.acl-long.165,LazyReview: A Dataset for Uncovering Lazy Thinking in NLP Peer Reviews,"Sukannya Purkayastha, Zhuang Li, Anne Lauscher, Lizhen Qu, Iryna Gurevych",(missing journal),2025,(missing abstract),289528470,0,0,,
10.18653/v1/2025.acl-long.227,Fine-grained Video Dubbing Duration Alignment with Segment Supervised Preference Optimization,"Chaoqun Cui, L. Q. Huang, Shijing Wang, Zhe Tong, Zhaolong Huang, Xiao Zeng, Xiaofeng Liu",Annual Meeting of the Association for Computational Linguistics,2025,"Video dubbing aims to translate original speech in visual media programs from the source language to the target language, relying on neural machine translation and text-to-speech technologies. Due to varying information densities across languages, target speech often mismatches the source speech duration, causing audio-video synchronization issues that significantly impact viewer experience. In this study, we approach duration alignment in LLM-based video dubbing machine translation as a preference optimization problem. We propose the Segment Supervised Preference Optimization (SSPO) method, which employs a segment-wise sampling strategy and fine-grained loss to mitigate duration mismatches between source and target lines. Experimental results demonstrate that SSPO achieves superior performance in duration alignment tasks.",289528471,4,52,,
10.18653/v1/2025.acl-long.89,RelationalCoder: Rethinking Complex Tables via Programmatic Relational Transformation,"Haoyu Dong, Yue Hu, Huailiang Peng, Yanan Cao",(missing journal),2025,(missing abstract),289528472,0,0,,
10.18653/v1/2025.acl-long.136,Context-Aware Sentiment Forecasting via LLM-based Multi-Perspective Role-Playing Agents,"Fanhang Man, Huandong Wang, Jing Fang, Zhaoyi Deng, Bin Zhao, Xinlei Chen, Yijia Cao",(missing journal),2025,(missing abstract),289528473,1,0,,
10.18653/v1/2025.acl-long.128,Gender Inclusivity Fairness Index (GIFI): A Multilevel Framework for Evaluating Gender Diversity in Large Language Models,"Zhihong Shan, E. Diana, Jiawei Zhou",(missing journal),2025,(missing abstract),289528474,0,0,,
10.18653/v1/2025.acl-long.113,How Much Do Encoder Models Know About Word Senses?,"Simone Teglia, Simone Tedeschi, Roberto Navigli",(missing journal),2025,(missing abstract),289528475,0,0,,
10.18653/v1/2025.acl-long.98,In-the-wild Audio Spatialization with Flexible Text-guided Localization,"Tianrui Pan, Jishan Liu, Zhenyang Huang, Jie Tang, Gangshan Wu",(missing journal),2025,(missing abstract),289528476,0,0,,
10.18653/v1/2025.acl-long.1574,CiteEval: Principle-Driven Citation Evaluation for Source Attribution,"Yumo Xu, Peng Qi, Jianjun Chen, Kunlun Liu, Rujun Han, Lan Liu, Bonan Min, Vittorio Castelli, A. K. Gupta, Zhiguo Wang",(missing journal),2025,(missing abstract),289528604,0,0,,
10.18653/v1/2025.acl-long.1564,Optimizing Pre-Training Data Mixtures with Mixtures of Data Expert Models,"Liudmila Belenki, Alekh Agarwal, Tianze Shi, Kristina Toutanova",(missing journal),2025,(missing abstract),289528605,0,0,,
10.18653/v1/2025.acl-long.1501,Negative Matters: Multi-Granularity Hard-Negative Synthesis and Anchor-Token-Aware Pooling for Enhanced Text Embeddings,"Tony Pan, Zhichao Duan, Zhenyu Li, Bowen Dong, Ning Liu, Xiuxing Li, Jianyong Wang",Annual Meeting of the Association for Computational Linguistics,2025,"Text embedding models are essential for various natural language processing tasks, enabling the effective encoding of semantic information into dense vector representations. These models are typically optimized using triplets of (query, positive, negative) data pairs for contrastive learning, where the negative samples play a critical role in enhancing the model's ability to discern subtle semantic distinctions. In this work, we introduce a Multi-Granularity Hard-negative (MGH) synthesis framework that leverages large language models (LLMs) to generate diverse negative samples with varying levels of similarity with the query. This approach facilitates a coarse-to-fine curriculum learning strategy during supervised training, allowing the embedding model to progressively learn more nuanced semantic representations. Meanwhile, we propose an Anchor Token Aware (ATA) pooling method that assigns higher weights to anchor tokens based on aggregation patterns observed in LLMs, improving text embedding accuracy without increasing model complexity. Comprehensive experiments on the MTEB benchmark demonstrate that our methods achieve state-of-the-art performance, surpassing existing synthesis strategies both with synthetic data and when combined with public retrieval datasets.",289528606,1,24,,
10.18653/v1/2025.acl-long.1512,It’s Not a Walk in the Park! Challenges of Idiom Translation in Speech-to-text Systems,"Iuliia Zaitova, Badr M. Abdullah, Wei Xue, Dietrich Klakow, Bernd Möbius, Tania Avgustinova",(missing journal),2025,(missing abstract),289528607,0,0,,
10.18653/v1/2025.acl-long.1457,DRAMA: Diverse Augmentation from Large Language Models to Smaller Dense Retrievers,"Xueguang Ma, Xi Victoria Lin, Barlas Oǧuz, Jimmy Lin, Wen-tau Yih, Xilun Chen",(missing journal),2025,(missing abstract),289528608,0,0,,
10.18653/v1/2025.acl-long.1424,Class Distillation with Mahalanobis Contrast: An Efficient Training Paradigm for Pragmatic Language Understanding Tasks,"Chenlu Wang, Weimin Lyu, Ritwik Banerjee",(missing journal),2025,(missing abstract),289528609,0,0,,
10.18653/v1/2025.acl-long.1403,PopAlign: Diversifying Contrasting Patterns for a More Comprehensive Alignment,"Zekun Moore Wang, Shenzhi Wang, Keying Zhu, Jiaheng Liu, Ke Xu, Jie Fu, Wangchunshu Zhou, Wenhao Huang",(missing journal),2025,(missing abstract),289528610,0,0,,
10.18653/v1/2025.acl-long.1321,Better Embeddings with Coupled Adam,"Felix Stollenwerk, Tobias Stollenwerk",(missing journal),2025,(missing abstract),289528611,0,0,,
10.18653/v1/2025.acl-long.1381,Medical Graph RAG: Evidence-based Medical Large Language Model via Graph Retrieval-Augmented Generation,"Junde Wu, Jiayuan Zhu, Qi Yang, Jiefu Chen, Min Xu, Filippo Menolascina, Yueming Jin, Vicente Grau",(missing journal),2025,(missing abstract),289528612,13,0,,
10.18653/v1/2025.acl-long.1399,Know Your Mistakes: Towards Preventing Overreliance on Task-Oriented Conversational AI Through Accountability Modeling,"Suvodip Dey, Y. Sun, Gökhan Tür, Dilek Hakkani-Tür",Annual Meeting of the Association for Computational Linguistics,2025,"Recent LLMs have enabled significant advancements for conversational agents. However, they are also well known to hallucinate, producing responses that seem plausible but are factually incorrect. On the other hand, users tend to over-rely on LLM-based AI agents, accepting AI's suggestion even when it is wrong. Adding positive friction, such as explanations or getting user confirmations, has been proposed as a mitigation in AI-supported decision-making systems. In this paper, we propose an accountability model for LLM-based task-oriented dialogue agents to address user overreliance via friction turns in cases of model uncertainty and errors associated with dialogue state tracking (DST). The accountability model is an augmented LLM with an additional accountability head that functions as a binary classifier to predict the relevant slots of the dialogue state mentioned in the conversation. We perform our experiments with multiple backbone LLMs on two established benchmarks (MultiWOZ and Snips). Our empirical findings demonstrate that the proposed approach not only enables reliable estimation of AI agent errors but also guides the decoder in generating more accurate actions. We observe around 3% absolute improvement in joint goal accuracy (JGA) of DST output by incorporating accountability heads into modern LLMs. Self-correcting the detected errors further increases the JGA from 67.13 to 70.51, achieving state-of-the-art DST performance. Finally, we show that error correction through user confirmations (friction turn) achieves a similar performance gain, highlighting its potential to reduce user overreliance.",289528613,0,38,,
10.18653/v1/2025.acl-long.1405,SEAL: Scaling to Emphasize Attention for Long-Context Retrieval,"Changhun Lee, Minsang Seok, Jie Jin, Yuichiro Cho, Eunhyeok Park",(missing journal),2025,(missing abstract),289528614,0,0,,
10.18653/v1/2025.acl-long.1237,Embedding-Converter: A Unified Framework for Cross-Model Embedding Transformation,"Jinsung Yoon, Sercan Ö. Arık",(missing journal),2025,(missing abstract),289528615,0,0,,
10.18653/v1/2025.acl-long.1301,Automated Structured Radiology Report Generation,"Jean-Benoit Delbrouck, Justin Xu, J Moll, Anugrah Thomas, Zhihong Chen, Sophie Ostmeier, Abdul Rahman Azhar, Kelvin Z. Li, Andrew Johnston, Christian Blüthgen, Eduardo Pontes Reis, Mohamed S. Muneer, Maya Varma, Curtis P. Langlotz",(missing journal),2025,(missing abstract),289528616,0,0,,
10.18653/v1/2025.acl-long.1299,A Self-Denoising Model for Robust Few-Shot Relation Extraction,"Liang Zhang, Yang Zhang, Ziyao Lu, Fandong Meng, Jie Zhou, Jinsong Su",(missing journal),2025,(missing abstract),289528617,0,0,,
10.18653/v1/2025.acl-long.1242,EffiVLM-BENCH: A Comprehensive Benchmark for Evaluating Training-Free Acceleration in Large Vision-Language Models,"Zekun Wang, Minghua Ma, Zexin Wang, Rong Mu, Libo Shan, Ming Liu, Bing Qin",(missing journal),2025,(missing abstract),289528618,2,0,,
10.18653/v1/2025.acl-long.1286,CSTree-SRI: Introspection-Driven Cognitive Semantic Tree for Multi-Turn Question Answering over Extra-Long Contexts,"Zhaowen Wang, Wei Xiang, Kun Du, Yiting Zhang, Libo Qin, Yingjie Xia, Li Kuang",(missing journal),2025,(missing abstract),289528619,0,0,,
10.18653/v1/2025.acl-long.1232,Library-Like Behavior In Language Models is Enhanced by Self-Referencing Causal Cycles,"Munachiso Nwadike, Zangir Iklassov, Toluwani Aremu, Takaharu Hiraoka, Benjamin Heinzerling, Velibor Bojković, Hilal AlQuabeh, Martin Takáč, Kentaro Inui",(missing journal),2025,(missing abstract),289528620,0,0,,
10.18653/v1/2025.acl-long.1285,BIG-Bench Extra Hard,"Mehran Kazemi, Bahare Fatemi, Hritik Bansal, John Palowitch, Chrysovalantis Anastasiou, Sanket Vaibhav Mehta, Lalit K Jain, Virginia Aglietti, Disha Jindal, Peter Chen, Nishanth Dikkala, Gladys Tyen, Xin Liu, Uri Shalit, Silvia Chiappa, Kate Olszewska, Yi Tay, Vinh Q. Tran, Quoc V. Le, Orhan Fırat",(missing journal),2025,(missing abstract),289528621,1,0,,
10.18653/v1/2025.acl-long.1221,Document-Level Event-Argument Data Augmentation for Challenging Role Types,"Joseph Gatto, Omar Sharif, Parker Seegmiller, Sarah Masud Preum",(missing journal),2025,(missing abstract),289528622,0,0,,
10.18653/v1/2025.acl-long.1319,I0T: Embedding Standardization Method Towards Zero Modality Gap,"Na An, Eunki Kim, James H. Thorne, Hyunjung Shim",(missing journal),2025,(missing abstract),289528623,0,0,,
10.18653/v1/2025.acl-long.1103,The Essence of Contextual Understanding in Theory of Mind: A Study on Question Answering with Story Characters,"Chuande Zhou, Qiujing Wang, Mo Yu, Xin Yue, Rui Lu, Jiangnan Li, Yifan Zhou, Shuaidi Zhang, Jie Zhou, Wai Ching Lam",(missing journal),2025,(missing abstract),289530347,1,0,,
10.18653/v1/2025.acl-long.1091,Condor: Enhance LLM Alignment with Knowledge-Driven Data Synthesis and Refinement,"Maosongcao Maosongcao, Taolin Zhang, Mengran Li, Chuyu Zhang, Yunxin Liu, Cong He, Haodong Duan, Songyang Zhang, Kai Chen",(missing journal),2025,(missing abstract),289530348,0,0,,
10.18653/v1/2025.acl-long.1134,Employing Discourse Coherence Enhancement to Improve Cross-Document Event and Entity Coreference Resolution,"Xinyu Chen, Peifeng Li, Qiaoming Zhu",(missing journal),2025,(missing abstract),289530349,1,0,,
10.18653/v1/2025.acl-long.1099,Keys to Robust Edits: From Theoretical Insights to Practical Advances,"Jianhao Yan, Futing Wang, Yun Jun Luo, Yafu Li, Yue Zhang",(missing journal),2025,(missing abstract),289530350,0,0,,
10.18653/v1/2025.acl-long.1096,MMRC: A Large-Scale Benchmark for Understanding Multimodal Large Language Model in Real-World Conversation,"Haochen Xue, Feilong Tang, Ming-Che Hu, Yexin Liu, Qidong Huang, Yulong Li, Chengzhi Liu, Zhongxing Xu, Chong Zhang, Chun-Mei Feng, Yutong Xie, Imran Razzak, Zongyuan Ge, Jionglong Su, Junjun He, Yu Qiao",(missing journal),2025,(missing abstract),289530351,1,0,,
10.18653/v1/2025.acl-long.1092,CulFiT: A Fine-grained Cultural-aware LLM Training Paradigm via Multilingual Critique Data Synthesis,"Ren Feng, Shen Gao, Xiuying Chen, Lisi Chen, Shuo Shang",(missing journal),2025,(missing abstract),289530352,0,0,,
10.18653/v1/2025.acl-long.1046,CogniBench: A Legal-inspired Framework and Dataset for Assessing Cognitive Faithfulness of Large Language Models,"Xiaqiang Tang, Jian Li, Kaijin Hu, Nan Du, Xiaolong Li, Xi Zhang, Weigao Sun, Sihong Xie",(missing journal),2025,(missing abstract),289530353,2,0,,
10.18653/v1/2025.acl-long.929,KiRAG: Knowledge-Driven Iterative Retriever for Enhancing Retrieval-Augmented Generation,"Jinyuan Fang, Zaiqiao Meng, Craig M. MacDonald",(missing journal),2025,(missing abstract),289530354,2,0,,
10.18653/v1/2025.acl-long.914,The AI Gap: How Socioeconomic Status Affects Language Technology Interactions,"Elisa Bassignana, Amanda Cercas Curry, Dirk Hovy",(missing journal),2025,(missing abstract),289530355,2,0,,
10.18653/v1/2025.acl-long.1006,MaCP: Minimal yet Mighty Adaptation via Hierarchical Cosine Projection,"Yixian Shen, Qi Bi, Jia‐Hong Huang, Hongyi Zhu, Andy D. Pimentel, Anuj Pathania",Annual Meeting of the Association for Computational Linguistics,2025,"We present a new adaptation method MaCP, Minimal yet Mighty adaptive Cosine Projection, that achieves exceptional performance while requiring minimal parameters and memory for fine-tuning large foundation models. Its general idea is to exploit the superior energy compaction and decorrelation properties of cosine projection to improve both model efficiency and accuracy. Specifically, it projects the weight change from the low-rank adaptation into the discrete cosine space. Then, the weight change is partitioned over different levels of the discrete cosine spectrum, and each partition's most critical frequency components are selected. Extensive experiments demonstrate the effectiveness of MaCP across a wide range of single-modality tasks, including natural language understanding, natural language generation, text summarization, as well as multi-modality tasks such as image classification and video understanding. MaCP consistently delivers superior accuracy, significantly reduced computational complexity, and lower memory requirements compared to existing alternatives.",289530356,2,50,,
10.18653/v1/2025.acl-long.986,V-Oracle: Making Progressive Reasoning in Deciphering Oracle Bones for You and Me,"Runqi Qiao, Qiuna Tan, Guanting Dong, MinhuiWu MinhuiWu, Jiapeng Wang, Yifan Zhang, Zhuoma GongQue, Chong Sun, Yejun Xu, Yadong Xue, Ye Tian, Zhimin Bao, Lan Yang, Li‐Qun Chen, Honggang Zhang",(missing journal),2025,(missing abstract),289530357,0,0,,
10.18653/v1/2025.acl-long.899,DNCASR: End-to-End Training for Speaker-Attributed ASR,"Xianrui Zheng, Chao Zhang, Philip C. Woodland",Annual Meeting of the Association for Computational Linguistics,2025,"This paper introduces DNCASR, a novel end-to-end trainable system designed for joint neural speaker clustering and automatic speech recognition (ASR), enabling speaker-attributed transcription of long multi-party meetings. DNCASR uses two separate encoders to independently encode global speaker characteristics and local waveform information, along with two linked decoders to generate speaker-attributed transcriptions. The use of linked decoders allows the entire system to be jointly trained under a unified loss function. By employing a serialised training approach, DNCASR effectively addresses overlapping speech in real-world meetings, where the link improves the prediction of speaker indices in overlapping segments. Experiments on the AMI-MDM meeting corpus demonstrate that the jointly trained DNCASR outperforms a parallel system that does not have links between the speaker and ASR decoders. Using cpWER to measure the speaker-attributed word error rate, DNCASR achieves a 9.0% relative reduction on the AMI-MDM Eval set.",289530358,0,42,,
10.18653/v1/2025.acl-long.930,Enhancing Lexicon-Based Text Embeddings with Large Language Models,"Yibin Lei, Tao Shen, Yu Cao, Andrew Yates",(missing journal),2025,(missing abstract),289530359,0,0,,
10.18653/v1/2025.acl-long.906,OmniAlign-V: Towards Enhanced Alignment of MLLMs with Human Preference,"Xiangyu Zhao, Steven X. Ding, Zicheng Zhang, Haian Huang, Maosongcao Maosongcao, Jiaqi Wang, Wei‐Yun Wang, Xinyu Fang, Wenhai Wang, Guangtao Zhai, Hua Yang, Haodong Duan, Kai Chen",(missing journal),2025,(missing abstract),289530360,0,0,,
10.18653/v1/2025.acl-long.1040,THOR-MoE: Hierarchical Task-Guided and Context-Responsive Routing for Neural Machine Translation,"Yunlong Liang, Fandong Meng, Jie Zhou",(missing journal),2025,(missing abstract),289530361,0,0,,
10.18653/v1/2025.acl-long.944,Tunable LLM-based Proactive Recommendation Agent,"Mingze Wang, Chongming Gao, Wenjie Wang, Yangyang Li, Fuli Feng",(missing journal),2025,(missing abstract),289530362,0,0,,
10.18653/v1/2025.acl-long.935,MegaPairs: Massive Data Synthesis for Universal Multimodal Retrieval,"Junjie Zhou, Yongping Xiong, Zheng Liu, Zehuan Liu, Shitao Xiao, Yujin Wang, Bo Zhao, Chen Zhang, Defu Lian",(missing journal),2025,(missing abstract),289530363,0,0,,
10.18653/v1/2025.acl-long.836,Movie101v2: Improved Movie Narration Benchmark,"Zihao Yue, Zhang Yepeng, Ziheng Wang, Qin Jin",(missing journal),2025,(missing abstract),289530364,0,0,,
10.18653/v1/2025.acl-long.843,Improving Chain-of-Thought Reasoning via Quasi-Symbolic Abstractions,"Leonardo Ranaldi, Marco Valentino, André Freitas",Annual Meeting of the Association for Computational Linguistics,2025,"Chain-of-Though (CoT) represents a common strategy for reasoning in Large Language Models (LLMs) by decomposing complex tasks into intermediate inference steps. However, explanations generated via CoT are susceptible to content biases that negatively affect their robustness and faithfulness. To mitigate existing limitations, recent work has proposed using logical formalisms coupled with external symbolic solvers. However, fully symbolic approaches possess the bottleneck of requiring a complete translation from natural language to formal languages, a process that affects efficiency and flexibility. To achieve a trade-off, this paper investigates methods to disentangle content from logical reasoning without a complete formalisation. In particular, we present QuaSAR (for Quasi-Symbolic Abstract Reasoning), a variation of CoT that guides LLMs to operate at a higher level of abstraction via quasi-symbolic explanations. Our framework leverages the capability of LLMs to formalise only relevant variables and predicates, enabling the coexistence of symbolic elements with natural language. We show the impact of QuaSAR for in-context learning and for constructing demonstrations to improve the reasoning capabilities of smaller models. Our experiments show that quasi-symbolic abstractions can improve CoT-based methods by up to 8% accuracy, enhancing robustness and consistency on challenging adversarial variations on both natural language (i.e. MMLU-Redux) and symbolic reasoning tasks (i.e., GSM-Symbolic).",289530365,12,42,,
10.18653/v1/2025.acl-long.851,AGD: Adversarial Game Defense Against Jailbreak Attacks in Large Language Models,"Sheng-Li Pan, Zhiliang Tian, Zhen Huang, Wen-Zhe Yu, Zhihua Wen, Xinwang Liu, Kai Lü, Minlie Huang, Dongsheng Li",(missing journal),2025,(missing abstract),289530366,0,0,,
10.18653/v1/2025.acl-long.849,Can You Really Trust Code Copilot? Evaluating Large Language Models from a Code Security Perspective,"Yutao Mou, Xiao Deng, Yuxiao Luo, Shikun Zhang, Wei Ye",(missing journal),2025,(missing abstract),289530367,0,0,,
10.18653/v1/2025.acl-long.781,VLMInferSlow: Evaluating the Efficiency Robustness of Large Vision-Language Models as a Service,"Xiasi Wang, Tianliang Yao, Simin Chen, Runqi Wang, Lei Ye, Kuofeng Gao, Yi Huang, Yuan Yao",(missing journal),2025,(missing abstract),289530368,1,0,,
10.18653/v1/2025.acl-long.796,Unmasking Style Sensitivity: A Causal Analysis of Bias Evaluation Instability in Large Language Models,"Jiaxu Zhao, Meng Fang, Kun Zhang, Mykola Pechenizkiy",(missing journal),2025,(missing abstract),289530369,0,0,,
10.18653/v1/2025.acl-long.1195,Improving Low-Resource Morphological Inflection via Self-Supervised Objectives,"Adam Wiemerslage, Katharina von der Wense",(missing journal),2025,(missing abstract),289530370,1,0,,
10.18653/v1/2025.acl-long.1209,Math Neurosurgery: Isolating Language Models’ Math Reasoning Abilities Using Only Forward Passes,"Bryan R. Christ, Zachary Gottesman, Jonathan Kropko, Thomas Hartvigsen",(missing journal),2025,(missing abstract),289530371,0,0,,
10.18653/v1/2025.acl-long.1189,Beyond Similarity: A Gradient-based Graph Method for Instruction Tuning Data Selection,"Zhao Yang, Li Du, Xiao Ding, Yunwei Ouyang, Hepeng Wang, Kai Xiong, Jinglong Gao, Zhouhao Sun, Dongliang Xu, Qing Yang, Dongchen Li, Bing Qin, Ting Liu",(missing journal),2025,(missing abstract),289530372,0,0,,
10.18653/v1/2025.acl-long.1171,Towards Dynamic Theory of Mind: Evaluating LLM Adaptation to Temporal Evolution of Human States,"Xiao Yang, Jiashuo Wang, Qiancheng Xu, Changhe Song, Chunpu Xu, Yi Cheng, Wenjie Li, Pengfei Liu",(missing journal),2025,(missing abstract),289530373,0,0,,
10.18653/v1/2025.acl-long.758,Beyond Single Labels: Improving Conversational Recommendation through LLM-Powered Data Augmentation,"Haozhe Xu, Xiaohua Wang, Changze Lv, Xiaoqing Zheng",Annual Meeting of the Association for Computational Linguistics,2025,"Conversational recommender systems (CRSs) enhance recommendation quality by engaging users in multi-turn dialogues, capturing nuanced preferences through natural language interactions. However, these systems often face the false negative issue, where items that a user might like are incorrectly labeled as negative during training, leading to suboptimal recommendations.Expanding the label set through data augmentation presents an intuitive solution but faces the challenge of balancing two key aspects: ensuring semantic relevance and preserving the collaborative information inherent in CRS datasets. To address these issues, we propose a novel data augmentation framework that first leverages an LLM-based semantic retriever to identify diverse and semantically relevant items, which are then filtered by a relevance scorer to remove noisy candidates. Building on this, we introduce a two-stage training strategy balancing semantic relevance and collaborative information. Extensive experiments on two benchmark datasets and user simulators demonstrate significant and consistent performance improvements across various recommenders, highlighting the effectiveness of our approach in advancing CRS performance.",289530374,1,41,,
10.18653/v1/2025.acl-long.777,SAKE: Steering Activations for Knowledge Editing,"Marco Scialanga, Thibault Laugel, Vincent Grari, Marcin Detyniecki",(missing journal),2025,(missing abstract),289530375,0,0,,
10.18653/v1/2025.acl-long.708,From Selection to Generation: A Survey of LLM-based Active Learning,"Yu Xia, Subhojyoti Mukherjee, Zhouhang Xie, Junda Wu, Xintong Li, Ryan Aponte, Hanjia Lyu, Joe Barrow, Hongjie Chen, Franck Dernoncourt, Branislav Kveton, Tong Yu, Ruiyi Zhang, Jiuxiang Gu, Nesreen K. Ahmed, Yu Wang, Xiang Chen, Hanieh Deilamsalehy, Sungchul Kim, Zhengmian Hu, Yue Zhao, Nedim Lipka, Seunghyun Yoon, Ting-Hao Huang, Zichao Wang, Puneet Mathur, Saheb Pal, Koyel Mukherjee, Zhehao Zhang, Namyong Park, Thien Huu Nguyen, Jiebo Luo, Ryan A. Rossi, Julian McAuley",(missing journal),2025,(missing abstract),289530376,0,0,,
10.18653/v1/2025.acl-long.598,Advancing Zero-shot Text-to-Speech Intelligibility across Diverse Domains via Preference Alignment,"Xueyao Zhang, Yuancheng Wang, Chaoren Wang, Ziniu Li, Zhuo Chen, Zhizheng Wu",(missing journal),2025,(missing abstract),289530377,0,0,,
10.18653/v1/2025.acl-long.652,MadaKV: Adaptive Modality-Perception KV Cache Eviction for Efficient Multimodal Long-Context Inference,"Kanglong Li, Zhonghua Jiang, Zelin Shen, ZhaodeWang ZhaodeWang, Chen Lv, Shengyu Zhang, Fan Wu, Fei Wu",(missing journal),2025,(missing abstract),289530378,0,0,,
10.18653/v1/2025.acl-long.666,HiDe-LLaVA: Hierarchical Decoupling for Continual Instruction Tuning of Multimodal Large Language Model,"Haiyang Guo, Fanhu Zeng, Ziwei Xiang, Fei Zhu, Da‐Han Wang, Xu-Yao Zhang, Cheng‐Lin Liu",(missing journal),2025,(missing abstract),289530379,0,0,,
10.18653/v1/2025.acl-long.659,DREsS: Dataset for Rubric-based Essay Scoring on EFL Writing,"Haneul Yoo, Jieun Han, So-Yeon Ahn, Alice Oh",(missing journal),2025,(missing abstract),289530380,0,0,,
10.18653/v1/2025.acl-long.717,Debiasing the Fine-Grained Classification Task in LLMs with Bias-Aware PEFT,"Daiying Zhao, Xinyu Yang, Hang Chen",(missing journal),2025,(missing abstract),289530381,0,0,,
10.18653/v1/2025.acl-long.678,A Training-free LLM-based Approach to General Chinese Character Error Correction,"Houquan Zhou, Bo Zhang, Zhenghua Li, Ming Yan, Min Zhang",(missing journal),2025,(missing abstract),289530383,2,0,,
10.18653/v1/2025.acl-long.580,HyKGE: A Hypothesis Knowledge Graph Enhanced RAG Framework for Accurate and Reliable Medical LLMs Responses,"Xinke Jiang, Ruizhe Zhang, Yongxin Xu, Rihong Qiu, Yue Fang, Zhiyuan Wang, Jinyi Tang, Hongxin Ding, Xu Chu, Junfeng Zhao, Yasha Wang",(missing journal),2025,(missing abstract),289530384,1,0,,
10.18653/v1/2025.acl-long.567,Defining and Evaluating Visual Language Models’ Basic Spatial Abilities: A Perspective from Psychometrics,"Weidong Xu, Dalin Lyu, Weihang Wang, Jie Feng, Chen Gao, Yong Li",(missing journal),2025,(missing abstract),289530385,1,0,,
10.18653/v1/2025.acl-long.523,MuSC: Improving Complex Instruction Following with Multi-granularity Self-Contrastive Training,"Hui Huang, Jiaheng Liu, Yancheng He, Shilong Li, Bing Xu, Conghui Zhu, Muyun Yang, Tiejun Zhao",(missing journal),2025,(missing abstract),289530386,0,0,,
10.18653/v1/2025.acl-long.509,From Trade-off to Synergy: A Versatile Symbiotic Watermarking Framework for Large Language Models,"Yidan Wang, Yubing Ren, Yanan Cao, Binxing Fang",(missing journal),2025,(missing abstract),289530387,0,0,,
10.18653/v1/2025.acl-long.513,Praetor: A Fine-Grained Generative LLM Evaluator with Instance-Level Customizable Evaluation Criteria,"Yongqi Leng, Renren Jin, Yue Chen, Zhuowen Han, Ling Shi, Jianxiang Peng, Yang Lei, Juesi Xiao, Deyi Xiong",(missing journal),2025,(missing abstract),289530388,0,0,,
10.18653/v1/2025.acl-long.568,SPHERE: Unveiling Spatial Blind Spots in Vision-Language Models Through Hierarchical Evaluation,"Wenyu Zhang, Wei‐Ren Ng, Lixin Ma, Yuwen Wang, Junqi Zhao, Allison Koenecke, Boyang Li, Wanglu Wanglu",Annual Meeting of the Association for Computational Linguistics,2025,"Current vision-language models may grasp basic spatial cues and simple directions (e.g. left, right, front, back), but struggle with the multi-dimensional spatial reasoning necessary for human-like understanding and real-world applications. To address this gap, we develop SPHERE (Spatial Perception and Hierarchical Evaluation of REasoning), a hierarchical evaluation framework supported by a new human-annotated dataset. SPHERE systematically probes models across increasing levels of complexity, from fundamental skills to multi-skill integration and high-level reasoning that combines spatial, visual, and logical understanding. Benchmark evaluation of state-of-the-art models reveals significant deficiencies, especially in reasoning about distance and proximity, understanding both egocentric and allocentric perspectives, and applying spatial logic in physical contexts. These findings expose critical blind spots in existing models and underscore the need for more advanced spatial reasoning techniques, driving the development of vision-language models that align more closely with human spatial cognition. The SPHERE benchmark is available at https://github.com/zwenyu/SPHERE-VLM.",289530389,9,11,,
10.18653/v1/2025.acl-long.565,Unifying Continuous and Discrete Text Diffusion with Non-simultaneous Diffusion Processes,"Bocheng Li, Zhujin Gao, Linli Xu",(missing journal),2025,(missing abstract),289530390,0,0,,
10.18653/v1/2025.acl-long.512,S-RAG: A Novel Audit Framework for Detecting Unauthorized Use of Personal Data in RAG Systems,"Zhirui Zeng, Jiamou Liu, Meng-Fen Chiang, Jialing He, Zijian Zhang",(missing journal),2025,(missing abstract),289530391,0,0,,
10.18653/v1/2025.acl-long.488,Embracing Imperfection: Simulating Students with Diverse Cognitive Levels Using LLM-based Agents,"Tao Wu, Jingyuan Chen, Lin Wang, Mengze Li, Yumeng Zhu, Ang Li, Kun Kuang, Fei Wu",(missing journal),2025,(missing abstract),289530392,0,0,,
10.18653/v1/2025.acl-long.458,Instance-Selection-Inspired Undersampling Strategies for Bias Reduction in Small and Large Language Models for Binary Text Classification,"Guilherme Fonseca, Washington Cunha, Gabriel Prenassi, Marcos André Gonçalves, Leonardo Rocha",(missing journal),2025,(missing abstract),289530393,3,0,,
10.18653/v1/2025.acl-long.308,Beyond Sequences: Two-dimensional Representation and Dependency Encoding for Code Generation,"Xiangyu Zhang, Yu Zhou, Guang Yang, Wei Cheng, Taolue Chen",(missing journal),2025,(missing abstract),289530394,0,0,,
10.18653/v1/2025.acl-long.400,Improving Model Factuality with Fine-grained Critique-based Evaluator,"Yiqing Xie, Wenxuan Zhou, Pradyot Prakash, Di Jin, Yuning Mao, Quintin Fettes, Arya Talebzadeh, Sinong Wang, Fang Han, Carolyn Penstein Rosé, Daniel Fried, Hejia Zhang",(missing journal),2025,(missing abstract),289530395,0,0,,
10.18653/v1/2025.acl-long.361,LegalReasoner: Step-wised Verification-Correction for Legal Judgment Reasoning,"Weijie Shi, Zhu Han, Jiaming Ji, M. Li, Jipeng Zhang, Ruiyuan Zhang, Jia Zhu, Jiajie Xu, Sirui Han, Yemin Guo",(missing journal),2025,(missing abstract),289530396,2,0,,
10.18653/v1/2025.acl-long.404,Cross-Lingual Pitfalls: Automatic Probing Cross-Lingual Weakness of Multilingual Large Language Models,"Xu Zhang, Yanbo Wang, Yue Huang, Xiuying Chen, Jieyu Zhao, Meng Jiang, Xiangliang Zhang",(missing journal),2025,(missing abstract),289530397,0,0,,
10.18653/v1/2025.acl-long.342,MergePrint: Merge-Resistant Fingerprints for Robust Black-box Ownership Verification of Large Language Models,"Shojiro Yamabe, Futa Kai Waseda, Tsubasa Takahashi, Koki Wataoka",Annual Meeting of the Association for Computational Linguistics,2025,"Protecting the intellectual property of Large Language Models (LLMs) has become increasingly critical due to the high cost of training. Model merging, which integrates multiple expert models into a single multi-task model, introduces a novel risk of unauthorized use of LLMs due to its efficient merging process. While fingerprinting techniques have been proposed for verifying model ownership, their resistance to model merging remains unexplored. To address this gap, we propose a novel fingerprinting method, MergePrint, which embeds robust fingerprints capable of surviving model merging. MergePrint enables black-box ownership verification, where owners only need to check if a model produces target outputs for specific fingerprint inputs, without accessing model weights or intermediate outputs. By optimizing against a pseudo-merged model that simulates merged behavior, MergePrint ensures fingerprints that remain detectable after merging. Additionally, to minimize performance degradation, we pre-optimize the fingerprint inputs. MergePrint pioneers a practical solution for black-box ownership verification, protecting LLMs from misappropriation via merging, while also excelling in resistance to broader model theft threats.",289530398,3,32,,
10.18653/v1/2025.acl-long.434,Warmup Generations: A Task-Agnostic Approach for Guiding Sequence-to-Sequence Learning with Unsupervised Initial State Generation,"Senyu Li, Zipeng Sun, Jiayi Wang, Xue Liu, Pontus Stenetorp, Siva Reddy, David Ifeoluwa Adelani",(missing journal),2025,(missing abstract),289530399,0,0,,
10.18653/v1/2025.acl-long.386,Large Language Models are Good Relational Learners,"Wu Fang, Vijay Prakash Dwivedi, Jure Leskovec",(missing journal),2025,(missing abstract),289530400,0,0,,
10.18653/v1/2025.acl-long.428,Mind the Gap: Static and Interactive Evaluations of Large Audio Models,"Minzhi Li, William A. Held, Michael J. Ryan, Kunat Pipatanakul, Potsawee Manakul, Zhigang Zhu, Diyi Yang",(missing journal),2025,(missing abstract),289530401,0,0,,
10.18653/v1/2025.acl-long.388,Distilling an End-to-End Voice Assistant Without Instruction Training Data,"William A. Held, Yanzhe Zhang, Minzhi Li, Weiyan Shi, Michael J. Ryan, Diyi Yang",(missing journal),2025,(missing abstract),289530402,3,0,,
10.18653/v1/2025.acl-long.285,Lost in the Context: Insufficient and Distracted Attention to Contexts in Preference Modeling,"Shihan Dou, Junyang Chen, Chao‐Yuan Huang, Chen Feng, Wei Chengzhi, Huiyuan Zheng, Shichun Liu, Yan Liu, Chenxiao Liu, Chenguang Xin, Lin Yan, Zongzhang Zhang, Tao Gui, Qi Zhang, Jimmy Xiangji Huang",(missing journal),2025,(missing abstract),289530403,0,0,,
10.18653/v1/2025.acl-long.300,CoT-Valve: Length-Compressible Chain-of-Thought Tuning,"Xiaolong Ma, Guangnian Wan, Kintak Raymond Yu, Guohong Fang, Xinchao Wang",(missing journal),2025,(missing abstract),289530404,0,0,,
10.18653/v1/2025.acl-long.290,Efficient Universal Goal Hijacking with Semantics-guided Prompt Organization,"Yihao Huang, Chong Wang, Xiaojun Jia, Qing Guo, Felix Juefei-Xu, Jian Zhang, Liu Yang, Geguang Pu",Annual Meeting of the Association for Computational Linguistics,2025,"Universal goal hijacking is a kind of prompt injection attack that forces LLMs to return a target malicious response for arbitrary normal user prompts. The previous methods achieve high attack performance while being too cumbersome and time-consuming. Also, they have concentrated solely on optimization algorithms, overlooking the crucial role of the prompt. To this end, we propose a method called POUGH that incorporates an efficient optimization algorithm and two semantics-guided prompt organization strategies. Specifically, our method starts with a sampling strategy to select representative prompts from a candidate pool, followed by a ranking strategy that prioritizes them. Given the sequentially ranked prompts, our method employs an iterative optimization algorithm to generate a fixed suffix that can concatenate to arbitrary user prompts for universal goal hijacking. Experiments conducted on four popular LLMs and ten types of target responses verified the effectiveness.",289530405,10,56,,
10.18653/v1/2025.acl-long.256,Knowledge Boundary of Large Language Models: A Survey,"Moxin Li, Yong Zhao, Wenxuan Zhang, Shuaiyi Li, Wenya Xie, See-Kiong Ng, Tat‐Seng Chua, Yang Deng",(missing journal),2025,(missing abstract),289530408,1,0,,
10.18653/v1/2025.acl-long.187,LongReward: Improving Long-context Large Language Models with AI Feedback,"Jiajie Zhang, Zhongni Hou, Xin Lv, Shulin Cao, Zhenyu Hou, Yilin Niu, Lei Hou, Yuxiao Dong, Ling Feng, Juanzi Li",(missing journal),2025,(missing abstract),289536356,0,0,,
10.18653/v1/2025.acl-long.221,SurveyPilot: an Agentic Framework for Automated Human Opinion Collection from Social Media,"Viet Thanh Pham, Lizhen Qu, Zhuang Li, Suraj Sharma, Gholamreza Haffari",(missing journal),2025,(missing abstract),289536357,0,0,,
10.18653/v1/2025.acl-long.245,Improve Safety Training of Large Language Models with Safety-Critical Singular Vectors Localization,"Peijian Gu, Quan Wang, Zhendong Mao",(missing journal),2025,(missing abstract),289536358,0,0,,
10.18653/v1/2025.acl-long.172,SR-LLM: Rethinking the Structured Representation in Large Language Model,"Jiahuan Zhang, Tianheng Wang, Ziyi Huang, Yulong Wu, Han-Qing Wu, DongbaiChen DongbaiChen, Linfeng Song, Yue Zhang, Guozheng Rao, Kaicheng Yu",(missing journal),2025,(missing abstract),289536359,1,0,,
10.18653/v1/2025.acl-long.254,Optimizing Decomposition for Optimal Claim Verification,"Yining Lu, Noah Ziems, Hy Dang, Meng Jiang",(missing journal),2025,(missing abstract),289536360,0,0,,
10.18653/v1/2025.acl-long.179,RAG-Critic: Leveraging Automated Critic-Guided Agentic Workflow for Retrieval Augmented Generation,"Guanting Dong, Jiajie Jin, Xiaoxi Li, Yutao Zhu, Zhicheng Dou, Ji–Rong Wen",(missing journal),2025,(missing abstract),289536361,0,0,,
10.18653/v1/2025.acl-long.234,Multimodal Pragmatic Jailbreak on Text-to-image Models,"Tong Liu, Zhixin Lai, Jiawen Wang, Gengyuan Zhang, Shuo Chen, Philip Torr, Vera Demberg, Volker Tresp, Jindong Gu",(missing journal),2025,(missing abstract),289536362,0,0,,
10.18653/v1/2025.acl-long.81,Real-time Factuality Assessment from Adversarial Feedback,"Sanxing Chen, Yukun Huang, Bhuwan Dhingra",Annual Meeting of the Association for Computational Linguistics,2025,"We show that existing evaluations for assessing the factuality of news from conventional sources, such as claims on fact-checking websites, result in high accuracies over time for LLM-based detectors-even after their knowledge cutoffs. This suggests that recent popular false information from such sources can be easily identified due to its likely presence in pre-training/retrieval corpora or the emergence of salient, yet shallow, patterns in these datasets. Instead, we argue that a proper factuality evaluation dataset should test a model's ability to reason about current events by retrieving and reading related evidence. To this end, we develop a novel pipeline that leverages natural language feedback from a RAG-based detector to iteratively modify real-time news into deceptive variants that challenge LLMs. Our iterative rewrite decreases the binary classification ROC-AUC by an absolute 17.5 percent for a strong RAG-based GPT-4o detector. Our experiments reveal the important role of RAG in both evaluating and generating challenging news examples, as retrieval-free LLM detectors are vulnerable to unseen events and adversarial attacks, while feedback from RAG-based evaluation helps discover more deceitful patterns.",289536363,0,33,,
10.18653/v1/2025.acl-long.150,ToolHop: A Query-Driven Benchmark for Evaluating Large Language Models in Multi-Hop Tool Use,"Junjie Ye, Zhengyin Du, Xiaoli Yao, Weijian Lin, Yufei Xu, Zehui Chen, Z. Wang, Siyu Zhu, Zhiheng Xi, Siyu Yuan, Tao Gui, Qi Zhang, Xuanjing Huang, Jiecao Chen",(missing journal),2025,(missing abstract),289536364,0,0,,
10.18653/v1/2025.acl-long.159,Token Prepending: A Training-Free Approach for Eliciting Better Sentence Embeddings from LLMs,"Yuchen Fu, Zifeng Cheng, Zhiwei Jiang, Zhonghui Wang, Yafeng Yin, Zhengliang Li, Qing Gu",(missing journal),2025,(missing abstract),289536365,0,0,,
10.18653/v1/2025.acl-long.139,"Prompt Candidates, then Distill: A Teacher-Student Framework for LLM-driven Data Annotation","Menghang Xia, Haobo Wang, Yixuan Li, Zewei Yu, Jindong Wang, Junbo Zhao, Runze Wu",(missing journal),2025,(missing abstract),289536366,0,0,,
10.18653/v1/2025.acl-long.78,LEANCODE: Understanding Models Better for Code Simplification of Pre-trained Large Language Models,"Yan Wang, Ling Ding, Thi Thu Huong Nguyen, Shaohua Wang, Yanan Zheng",(missing journal),2025,(missing abstract),289536367,0,0,,
10.18653/v1/2025.acl-long.127,"Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference","Benjamin C. Warner, Antoine Chaffin, Benjamin Clavié, Orion Weller, Oskar Hallström, Said Taghadouini, Alexis Gallagher, R. Biswas, Faisal Ladhak, Tom Aarsen, Griffin Adams, Jeremy Howard, Iacopo Poli",(missing journal),2025,(missing abstract),289536368,41,0,,
10.18653/v1/2025.acl-long.106,Bias in the Mirror : Are LLMs opinions robust to their own adversarial attacks,"Virgile Rennard, Christos Xypolopoulos, Michalis Vazirgiannis",(missing journal),2025,(missing abstract),289536369,2,0,,
10.18653/v1/2025.acl-long.42,Fusing Highly Specialized Language Models for Comprehensive Expertise,"Ning Ding, Yulin Chen, Ganqu Cui, Xingtai Lv, Weilin Zhao, Kaiyan Zhang, Ruobing Xie, Bowen Zhou, Zhiyuan Liu, Maosong Sun",(missing journal),2025,(missing abstract),289536372,0,0,,
10.18653/v1/2025.acl-long.66,Cuckoo: An IE Free Rider Hatched by Massive Nutrition in LLM’s Nest,"Letian Peng, Zilong Wang, Feng Yao, Jingbo Shang",(missing journal),2025,(missing abstract),289536375,0,0,,
10.18653/v1/2025.acl-long.1567,Logic-Regularized Verifier Elicits Reasoning from LLMs,"Xin Yu Wang, Changzhi Sun, Lijun Cheng, Yuanbin Wu, Dell Zhang, Xiaoling Wang, Xuelong Li",(missing journal),2025,(missing abstract),289536500,0,0,,
10.18653/v1/2025.acl-long.1603,Design Choices for Extending the Context Length of Visual Language Models,"Mukai Li, Lei Li, Shansan Gong, Qi Liu",(missing journal),2025,(missing abstract),289536501,0,0,,
10.18653/v1/2025.acl-long.1537,Behavioural vs. Representational Systematicity in End-to-End Models: An Opinionated Survey,"Ivan Vegner, Sydelle De Souza, Valentin Forch, Martha Lewis, Leonidas A. A. Doumas",(missing journal),2025,(missing abstract),289536502,0,0,,
10.18653/v1/2025.acl-long.1563,Energy Considerations of Large Language Model Inference and Efficiency Optimizations,"Jared Fernandez, Clara Na, V. Tiwari, Yonatan Bisk, Sasha Luccioni, Emma Strubell",(missing journal),2025,(missing abstract),289536503,0,0,,
10.18653/v1/2025.acl-long.1528,REAL-MM-RAG: A Real-World Multi-Modal Retrieval Benchmark,"Navve Wasserman, Roi Pony, Oshri Naparstek, Adi Raz Goldfarb, Eli Schwartz, Udi Barzelay, Leonid Karlinsky",(missing journal),2025,(missing abstract),289536504,0,0,,
10.18653/v1/2025.acl-long.1530,LongSafety: Evaluating Long-Context Safety of Large Language Models,"Yida Lu, Jiale Cheng, Zhexin Zhang, Shiyao Cui, Cunxiang Wang, Xiaotao Gu, Yuxiao Dong, Junwang Tang, Hongning Wang, Minlie Huang",(missing journal),2025,(missing abstract),289536505,0,0,,
10.18653/v1/2025.acl-long.1525,CLaSp: In-Context Layer Skip for Self-Speculative Decoding,"Longze Chen, R. Shan, Hui‐Ming Wang, Lu Wang, Ziqiang Liu, Run Luo, Jiawei Wang, Hamid Alinejad‐Rokny, Min Yang",(missing journal),2025,(missing abstract),289536506,0,0,,
10.18653/v1/2025.acl-long.1589,Inferring from Logits: Exploring Best Practices for Decoding-Free Generative Candidate Selection,"Mingyu Derek, Yanna Ding, Zijie Huang, Jianxi Gao, Yizhou Sun, W. Wang",(missing journal),2025,(missing abstract),289536507,0,0,,
10.18653/v1/2025.acl-long.1550,Towards Style Alignment in Cross-Cultural Translation,"Shreya Havaldar, Adam Stein, Eric Wong, Lyle Ungar",(missing journal),2025,(missing abstract),289536508,0,0,,
10.18653/v1/2025.acl-long.1548,R-Fairness: Assessing Fairness of Ranking in Subjective Data,"Lorenzo Balzotti, Donatella Firmani, Jerin George Mathew, Riccardo Torlone, Sihem Amer-Yahia",(missing journal),2025,(missing abstract),289536509,0,0,,
10.18653/v1/2025.acl-long.1535,MAPLE: Enhancing Review Generation with Multi-Aspect Prompt LEarning in Explainable Recommendation,"Ching-Wen Yang, Zhiquan Feng, Ying-Jia Lin, Che Wei Chen, Kun-da Wu, Hao Xu, Yao Jui-Feng, Hung-Yu Kao",(missing journal),2025,(missing abstract),289536510,0,0,,
10.18653/v1/2025.acl-long.1583,CoRe-MMRAG: Cross-Source Knowledge Reconciliation for Multimodal RAG,"Yang Tian, F Liu, Jingyuan Zhang, V. W., Yupeng Hu, Liqiang Nie",(missing journal),2025,(missing abstract),289536511,0,0,,
10.18653/v1/2025.acl-long.1498,Analyzing and Mitigating Inconsistency in Discrete Speech Tokens for Neural Codec Language Models,"Wenrui Liu, Zhifang Guo, Jin Xu, Yuanjun Lv, Yunfei Chu, Zemin Liu, Chun-Yang Lin",(missing journal),2025,(missing abstract),289536512,0,0,,
10.18653/v1/2025.acl-long.1489,Less is More: Explainable and Efficient ICD Code Prediction with Clinical Entities,"James W. Douglas, Yidong Gan, Ben Hachey, Jonathan K. Kummerfeld",(missing journal),2025,(missing abstract),289536513,0,0,,
10.18653/v1/2025.acl-long.1430,Bregman Conditional Random Fields: Sequence Labeling with Parallelizable Inference Algorithms,"Caio Corro, Mathieu Lacroix, Joseph Le Roux",(missing journal),2025,(missing abstract),289536514,0,0,,
10.18653/v1/2025.acl-long.1485,CCHall: A Novel Benchmark for Joint Cross-Lingual and Cross-Modal Hallucinations Detection in Large Language Models,"Yongheng Zhang, Xu Liu, Ruoxi Zhou, Qiguang Chen, Hao Fei, Wenpeng Lü, Libo Qin",(missing journal),2025,(missing abstract),289536515,0,0,,
10.18653/v1/2025.acl-long.1431,SEE: Strategic Exploration and Exploitation for Cohesive In-Context Prompt Optimization,"Wendi Cui, Jiaxin Zhang, Zhuohang Li, Hao Sun, Damien Lopez, Kamalika Das, Bradley Malin, Sricharan Kumar",(missing journal),2025,(missing abstract),289536516,0,0,,
10.18653/v1/2025.acl-long.1462,Symmetrical Visual Contrastive Optimization: Aligning Vision-Language Models with Minimal Contrastive Images,"Shengguang Wu, Fan-Yun Sun, Kaiyue Wen, Nick Haber",(missing journal),2025,(missing abstract),289536517,2,0,,
10.18653/v1/2025.acl-long.1425,Structure-aware Domain Knowledge Injection for Large Language Models,"Kai Liu, Ze Chen, Zhihang Fu, Wei Zhang, Rongxin Jiang, Fan Zhou, Yaowu Chen, Yue Wu, Jieping Ye",Annual Meeting of the Association for Computational Linguistics,2025,"This paper introduces a pioneering methodology, termed StructTuning, to efficiently transform foundation Large Language Models (LLMs) into domain specialists. It significantly reduces the training corpus needs to a mere 5% while achieving an impressive 100% of traditional knowledge injection performance. Motivated by structured human education, we propose a novel two-stage strategy for knowledge injection and alignment: Structure-aware Continual Pre-Training (SCPT) and Structure-aware Supervised Fine-Tuning (SSFT). In the SCPT phase, we automatically extract the domain knowledge taxonomy and reorganize the training corpora, enabling LLMs to effectively link textual segments to targeted knowledge points within the taxonomy. In the SSFT phase, we explicitly prompt models to elucidate the underlying knowledge structure in their outputs, leveraging the structured domain insight to address practical problems. Our ultimate method was extensively evaluated across model architectures and scales on LongBench and MMedBench datasets, demonstrating superior performance against other knowledge injection methods. We also explored our method's scalability across different training corpus sizes, laying the foundation to enhance domain-specific LLMs with better data utilization.",289536518,3,64,,
10.18653/v1/2025.acl-long.1332,MMDEND: Dendrite-Inspired Multi-Branch Multi-Compartment Parallel Spiking Neuron for Sequence Modeling,"Kexin Wang, Yuhong Chou, Di Shang, Shijie Mei, Jiahong Zhang, Yanbin Huang, Man Yao, Bo Xu, Guoqi Li",(missing journal),2025,(missing abstract),289536519,0,0,,
10.18653/v1/2025.acl-long.1340,Counterspeech the ultimate shield! Multi-Conditioned Counterspeech Generation through Attributed Prefix Learning,"Aswini Kumar Padhi, Anil Bandhakavi, Tanmoy Chakraborty",(missing journal),2025,(missing abstract),289536520,0,0,,
10.18653/v1/2025.acl-long.1353,T-REG: Preference Optimization with Token-Level Reward Regularization,"Wenxuan Zhou, Shujian Zhang, Lingxiao Zhao, Tao Meng",(missing journal),2025,(missing abstract),289536521,0,0,,
10.18653/v1/2025.acl-long.1362,Temporal reasoning for timeline summarisation in social media,"Jiayu Song, Mahmud Elahi Akhter, Dana Atzil‐Slonim, Maria Liakata",(missing journal),2025,(missing abstract),289536522,1,0,,
10.18653/v1/2025.acl-long.1363,Beyond Negative Stereotypes – Non-Negative Abusive Utterances about Identity Groups and Their Semantic Variants,"Tina Lommel, Elisabeth Eder, Josef Ruppenhofer, Michael Wiegand",(missing journal),2025,(missing abstract),289536523,0,0,,
10.18653/v1/2025.acl-long.1386,"Adverse Event Extraction from Discharge Summaries: A New Dataset, Annotation Scheme, and Initial Findings","Imane Guellil, Salomé Andres, Atul Anand, Bruce Guthrie, Huayu Zhang, Abul Hasan, Honghan Wu, Beatrice Alex",(missing journal),2025,(missing abstract),289536524,0,0,,
10.18653/v1/2025.acl-long.1369,Inner Thinking Transformer: Leveraging Dynamic Depth Scaling to Foster Adaptive Internal Thinking,"Yilong Chen, Junyuan Shang, Zhenyu Zhang, Yanxi Xie, Jiawei Sheng, Tingwen Liu, Shuohuan Wang, Yu Sun, Hua Wu, Haifeng Wang",(missing journal),2025,(missing abstract),289536525,0,0,,
10.18653/v1/2025.acl-long.1385,Learn to Memorize: Scalable Continual Learning in Semiparametric Models with Mixture-of-Neighbors Induction Memory,"Guangyue Peng, Tao Ge, Wen Luo, Wei Li, Houfeng Wang",(missing journal),2025,(missing abstract),289536526,0,0,,
10.18653/v1/2025.acl-long.1336,"OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization","Hongliang He, Wenlin Yao, Kaixin Ma, Wenhao Yu, Hongming Zhang, Tianqing Fang, Zhenzhong Lan, Dong Yu",(missing journal),2025,(missing abstract),289536527,0,0,,
10.18653/v1/2025.acl-long.1303,Predicting Through Generation: Why Generation Is Better for Prediction,"Md. Kowsher, Nusrat Jahan Prottasha, Prakash Bhat, Chun-Nam Yu, Mojtaba Soltanalian, Iván Garibay, Özlem Özmen Garibay, Chen Chen, Niloofar Yousefi",(missing journal),2025,(missing abstract),289536528,0,0,,
10.18653/v1/2025.acl-long.1308,From Lists to Emojis: How Format Bias Affects Model Alignment,"Xuanchang Zhang, Wei Xiong, Lichang Chen, Tianyi Zhou, Heng Huang, Tong Zhang",(missing journal),2025,(missing abstract),289536529,0,0,,
10.18653/v1/2025.acl-long.1269,Causal Graph based Event Reasoning using Semantic Relation Experts,"Mahnaz Koupaee, Xueying Bai, Ming-Syan Chen⋆, Greg Durrett, Nathanael Chambers, Niranjan Balasubramanian",(missing journal),2025,(missing abstract),289536530,0,0,,
10.18653/v1/2025.acl-long.1219,500xCompressor: Generalized Prompt Compression for Large Language Models,"Zongqian Li, Yixuan Su, Nigel Collier",(missing journal),2025,(missing abstract),289536531,0,0,,
10.18653/v1/2025.acl-long.1283,The Efficiency vs. Accuracy Trade-off: Optimizing RAG-Enhanced LLM Recommender Systems Using Multi-Head Early Exit,"Huixue Zhou, Hengrui Gu, Zaifu Zhan, Xi Liu, Kaixiong Zhou, Yongkang Xiao, Mingli Liang, Srinivas Prasad Govindan, Piyush Chawla, Jiyan Yang, X. C. Meng, Hao Li, Buyun Zhang, Liang Luo, Wen-Yen Chen, Yiping Han, Bo Long, Rui Zhang, Tianlong Chen",(missing journal),2025,(missing abstract),289536532,1,0,,
10.18653/v1/2025.acl-long.1163,Revisiting Scaling Laws for Language Models: The Role of Data Quality and Training Strategies,"Zhengyu Chen, Siqi Wang, Teng Xiao, Yudong Wang, Shen‐Hsing Annabel Chen, Xunliang Cai, Junxian He, Jingang Wang",(missing journal),2025,(missing abstract),289538286,3,0,,
10.18653/v1/2025.acl-long.1085,CoreEval: Automatically Building Contamination-Resilient Datasets with Real-World Knowledge toward Reliable LLM Evaluation,"Jingqian Zhao, Bingbing Wang, Geng Tu, Yice Zhang, Qianlong Wang, Bin Liang, Jing Li, Ruifeng Xu",Annual Meeting of the Association for Computational Linguistics,2025,"Data contamination poses a significant challenge to the fairness of LLM evaluations in natural language processing tasks by inadvertently exposing models to test data during training. Current studies attempt to mitigate this issue by modifying existing datasets or generating new ones from freshly collected information. However, these methods fall short of ensuring contamination-resilient evaluation, as they fail to fully eliminate pre-existing knowledge from models or preserve the semantic complexity of the original datasets. To address these limitations, we propose \textbf{CoreEval}, a \textbf{Co}ntamination-\textbf{re}silient \textbf{Eval}uation strategy for automatically updating data with real-world knowledge. This approach begins by extracting entity relationships from the original data and leveraging the GDELT database to retrieve relevant, up-to-date knowledge. The retrieved knowledge is then recontextualized and integrated with the original data, which is refined and restructured to ensure semantic coherence and enhanced task relevance. Ultimately, a robust data reflection mechanism is employed to iteratively verify and refine labels, ensuring consistency between the updated and original datasets. Extensive experiments on updated datasets validate the robustness of CoreEval, demonstrating its effectiveness in mitigating performance overestimation caused by data contamination.",289538287,0,27,,
10.18653/v1/2025.acl-long.1082,Disentangling Language and Culture for Evaluating Multilingual Large Language Models,"Jiahao Ying, Wei Tang, Yiran Zhao, Yixin Cao, Yu Rong, Wenxuan Zhang",(missing journal),2025,(missing abstract),289538288,0,0,,
10.18653/v1/2025.acl-long.1122,WET: Overcoming Paraphrasing Vulnerabilities in Embeddings-as-a-Service with Linear Transformation Watermarks,"Anudeex Shetty, Qiongkai Xu, Jey Han Lau",(missing journal),2025,(missing abstract),289538289,0,0,,
10.18653/v1/2025.acl-long.1074,JoPA: Explaining Large Language Model’s Generation via Joint Prompt Attribution,"Yurui Chang, Bochuan Cao, Yujia Wang, Jinghui Chen, Lu Lin",(missing journal),2025,(missing abstract),289538290,0,0,,
10.18653/v1/2025.acl-long.1166,Unveil: Unified Visual-Textual Integration and Distillation for Multi-modal Document Retrieval,"Hao Sun, Yingyan Hou, Jiayan Guo, Bo Wang, Chunyu Yang, Jinsong Ni, Zhang Yan",(missing journal),2025,(missing abstract),289538291,0,0,,
10.18653/v1/2025.acl-long.1001,Amplifying Trans and Nonbinary Voices: A Community-Centred Harm Taxonomy for LLMs,"Eddie L. Ungless, Sunipa Dev, Cynthia L. Bennett, Rebecca Gulotta, Jasmijn Bastings, Emily Denton",(missing journal),2025,(missing abstract),289538292,0,0,,
10.18653/v1/2025.acl-long.1021,Consistent Client Simulation for Motivational Interviewing-based Counseling,"Yizhe Yang, Palakorn Achananuparp, Heyan Huang, Jing Jiang, Nicholas K. Lim, Cameron Tan Shi Ern, Phey Ling Kit, Jenny Giam Xiuhui, Janaina Antonino Pinto, Ee‐Peng Lim",(missing journal),2025,(missing abstract),289538293,0,0,,
10.18653/v1/2025.acl-long.908,Measuring Data Diversity for Instruction Tuning: A Systematic Analysis and A Reliable Metric,"Yuming Yang, Nan Yang, Junjie Ye, Shihan Dou, Xiao Wang, Shuo Li, H.K Lv, Tao Gui, Qi Zhang, Jimmy Xiangji Huang",(missing journal),2025,(missing abstract),289538294,0,0,,
10.18653/v1/2025.acl-long.1050,Enhancing Goal-oriented Proactive Dialogue Systems via Consistency Reflection and Correction,"Daniel Zhang, Yaxin Fan, Peifeng Li, Qiaoming Zhu",(missing journal),2025,(missing abstract),289538295,0,0,,
10.18653/v1/2025.acl-long.874,ToolCoder: A Systematic Code-Empowered Tool Learning Framework for Large Language Models,"Hanxing Ding, Shuchang Tao, Liang Pang, Zihao Wei, Jinyang Gao, Bolin Ding, Huawei Shen, Xueqi Cheng",(missing journal),2025,(missing abstract),289538296,0,0,,
10.18653/v1/2025.acl-long.850,From Sub-Ability Diagnosis to Human-Aligned Generation: Bridging the Gap for Text Length Control via MarkerGen,"Peiwen Yuan, Chuyi Tan, Shaoxiong Feng, Yiwei Li, Xinglin Wang, Yueqi Zhang, Jiayi Shi, Boyuan Pan, Yao Hu, Kan Li",(missing journal),2025,(missing abstract),289538297,0,0,,
10.18653/v1/2025.acl-long.853,Table-Critic: A Multi-Agent Framework for Collaborative Criticism and Refinement in Table Reasoning,"Philip S. Yu, Guoxin Chen, Jingjing Wang",(missing journal),2025,(missing abstract),289538298,0,0,,
10.18653/v1/2025.acl-long.826,Improving Contextual Faithfulness of Large Language Models via Retrieval Heads-Induced Optimization,"Lei Huang, Xiaocheng Feng, Weitao Ma, Yong Fan, Xiachong Feng, Yangfan Ye, Weihong Zhong, Yuxuan Gu, Baoxin Wang, Dayong Wu, Guoping Hu, Bing Qin",(missing journal),2025,(missing abstract),289538299,0,0,,
10.18653/v1/2025.acl-long.825,Length Controlled Generation for Black-box LLMs,"Yuxuan Gu, Wenjie Wang, Xiaocheng Feng, Weihong Zhong, Kun Zhu, Lei Huang, Ting Liu, Bing Qin, Tat‐Seng Chua",(missing journal),2025,(missing abstract),289538300,2,0,,
10.18653/v1/2025.acl-long.1174,Analyzing LLMs’ Knowledge Boundary Cognition Across Languages Through the Lens of Internal Representations,"Chenghao Xiao, Hou Pong Chan, Hao Zhang, Mahani Aljunied, Lidong Bing, Noura Al Moubayed, Yu Rong",(missing journal),2025,(missing abstract),289538301,0,0,,
10.18653/v1/2025.acl-long.1187,STaR-SQL: Self-Taught Reasoner for Text-to-SQL,"Mingqian He, Yongliang Shen, Wenqi Zhang, Qiuying Peng, Jun Wang, Weiming Lü",(missing journal),2025,(missing abstract),289538302,0,0,,
10.18653/v1/2025.acl-long.1205,Leveraging In-Context Learning for Political Bias Testing of LLMs,"Patrick Haller, Jannis Vamvas, Rico Sennrich, Lena A. Jäger",(missing journal),2025,(missing abstract),289538303,0,0,,
10.18653/v1/2025.acl-long.750,Digest the Knowledge: Large Language Models empowered Message Passing for Knowledge Graph Question Answering,"Junhong Wan, T.L. Yu, Kunyu Jiang, Yao Fu, Weihao Jiang, Jiang Zhu",(missing journal),2025,(missing abstract),289538304,0,0,,
10.18653/v1/2025.acl-long.653,Efficient OpAmp Adaptation for Zoom Attention to Golden Contexts,"Haoyuan Wu, Rui Ming, Zheng He, Zhuolun He, Bei Yu",(missing journal),2025,(missing abstract),289538305,0,0,,
10.18653/v1/2025.acl-long.700,Can MLLMs Understand the Deep Implication Behind Chinese Images?,"Chenhao Zhang, Feng Xi, Yuelin Bai, Xeron Du, Jinchang Hou, Kaixin Deng, Guangzeng Han, Qinrui Li, Bingli Wang, Jiaheng Liu, Xingwei Qu, Yifei Zhang, Qixuan Zhao, Yiming Liang, Ziqiang Liu, Feiteng Fang, Min Yang, Wenhao Huang, Chenghua Lin, Ge ZHANG, Shiwen Ni",(missing journal),2025,(missing abstract),289538306,0,0,,
10.18653/v1/2025.acl-long.641,Wizard of Shopping: Target-Oriented E-commerce Dialogue Generation with Decision Tree Branching,"Xiangci Li, Zhiyu Chen, Jason Ingyu Choi, Nikhita Vedula, Besnik Fetahu, Oleg Rokhlenko, Shervin Malmasi",(missing journal),2025,(missing abstract),289538307,0,0,,
10.18653/v1/2025.acl-long.629,RankCoT: Refining Knowledge for Retrieval-Augmented Generation through Ranking Chain-of-Thoughts,"M. Wu, Zhenghao Liu, Yukun Yan, Xinze Li, Shiqiang Yu, Zheni Zeng, Yu‐Cheng Gu, Yu Ge",(missing journal),2025,(missing abstract),289538308,2,0,,
10.18653/v1/2025.acl-long.705,Incongruity-aware Tension Field Network for Multi-modal Sarcasm Detection,"Jiecheng Zhang, C. L. Philip Chen, Shuzhen Li, Tong Zhang",(missing journal),2025,(missing abstract),289538309,0,0,,
10.18653/v1/2025.acl-long.722,Towards Objective Fine-tuning: How LLMs’ Prior Knowledge Causes Potential Poor Calibration?,"Z. Wang, Z.H. Shi, Han Zhou, Shiqi Gao, Qingyun Sun, Jianxin Li",(missing journal),2025,(missing abstract),289538310,0,0,,
10.18653/v1/2025.acl-long.774,Quantifying Lexical Semantic Shift via Unbalanced Optimal Transport,"Ryo Kishino, Hiroaki Yamagiwa, Ryo Nagata, Sho Yokoi, Hidetoshi Shimodaira",(missing journal),2025,(missing abstract),289538311,0,0,,
10.18653/v1/2025.acl-long.620,A Unified Agentic Framework for Evaluating Conditional Image Generation,"Jifang Wang, Yangxue Yangxue, Longyue Wang, Zhenran Xu, Yiyu Wang, Yaowei Wang, Weihua Luo, Kaifu Zhang, Baotian Hu, Zhang Min",(missing journal),2025,(missing abstract),289538312,0,0,,
10.18653/v1/2025.acl-long.549,Gradient-Adaptive Policy Optimization: Towards Multi-Objective Alignment of Large Language Models,"Chengao Li, Hanyu Zhang, Yunkun Xu, Hongyan Xue, Xiang Ao, Q. He",(missing journal),2025,(missing abstract),289538313,0,0,,
10.18653/v1/2025.acl-long.543,Powerformer: Efficient and High-Accuracy Privacy-Preserving Language Model with Homomorphic Encryption,"Dong-Jin Park, Eunsang Lee, Joon-Woo Lee",(missing journal),2025,(missing abstract),289538314,0,0,,
10.18653/v1/2025.acl-long.561,Divide-Then-Align: Honest Alignment based on the Knowledge Boundary of RAG,"Xin Sun, Juanying Xie, Zhongqi Chen, Qiang Liu, Shiyu Wu, Yunmin Chen, Bowen Song, Zilei Wang, Weiqiang Wang, Liang Wang",(missing journal),2025,(missing abstract),289538315,0,0,,
10.18653/v1/2025.acl-long.498,EfficientQAT: Efficient Quantization-Aware Training for Large Language Models,"Mengzhao Chen, Wenqi Shao, Peng Xu, Jiahao Wang, Peng Gao, Kaipeng Zhang, Ping Luo",(missing journal),2025,(missing abstract),289538316,4,0,,
10.18653/v1/2025.acl-long.438,CypherBench: Towards Precise Retrieval over Full-scale Modern Knowledge Graphs in the LLM Era,"Yanlin Feng, Simone Papicchio, Sajjadur Rahman",(missing journal),2025,(missing abstract),289538317,0,0,,
10.18653/v1/2025.acl-long.443,Comparing LLM-generated and human-authored news text using formal syntactic theory,"Olga Zamaraeva, Dan Flickinger, Francis Bond, Carlos Gómez‐Rodríguez",(missing journal),2025,(missing abstract),289538318,0,0,,
10.18653/v1/2025.acl-long.384,Aligning Large Language Models with Implicit Preferences from User-Generated Content,"Zhaoxuan Tan, Zheng Li, Tianyi Liu, Haodong Wang, Hyokun Yun, Ming Zeng, Chen Pei, Zhihan Zhang, Yifan Gao, Ruijie Wang, Priyanka Nigam, Bing Yin, Meng Jiang",(missing journal),2025,(missing abstract),289538319,0,0,,
10.18653/v1/2025.acl-long.320,Evaluating Language Models as Synthetic Data Generators,"Seungone Kim, Juyoung Suk, Xiang Yue, Vijay Viswanathan, Seongyun Lee, Yizhong Wang, Kiril Gashteovski, Carolin Lawrence, Sean Welleck, Graham Neubig",(missing journal),2025,(missing abstract),289538320,0,0,,
10.18653/v1/2025.acl-long.394,CONFETTI: Conversational Function-Calling Evaluation Through Turn-Level Interactions,"Tamer Alkhouli, Katerina Margatina, James Gung, Raphael Shu, Claudia Zaghi, Mahendra K. Sunkara, Yi Zhang",(missing journal),2025,(missing abstract),289538321,0,0,,
10.18653/v1/2025.acl-long.446,AIMSCheck: Leveraging LLMs for AI-Assisted Review of Modern Slavery Statements Across Jurisdictions,"Alfons Bora, Akshatha Arodi, Duoyi Zhang, Jordan Bannister, Mirko Bronzi, Arsène Fansi Tchango, Md Abul Bashar, Richi Nayak, Kerrie Mengersen",(missing journal),2025,(missing abstract),289538322,0,0,,
10.18653/v1/2025.acl-long.314,AutoMedEval: Harnessing Language Models for Automatic Medical Capability Evaluation,"Xinhua Zhang, Zetian Ouyang, Linlin Wang, Gerard de Melo, Z J Cao, Xiaoling Wang, Ya Zhang, Yanfeng Wang, Liang He",(missing journal),2025,(missing abstract),289538323,0,0,,
10.18653/v1/2025.acl-long.403,When the LM misunderstood the human chuckled: Analyzing garden path effects in humans and language models,"Samuel Joseph Amouyal, Aya Meltzer‐Asscher, Jonathan Berant",(missing journal),2025,(missing abstract),289538324,0,0,,
10.18653/v1/2025.acl-long.396,Uncertainty in Causality: A New Frontier,"Shaobo Cui, Luca Mouchel, Boi Faltings",(missing journal),2025,(missing abstract),289538325,0,0,,
10.18653/v1/2025.acl-long.318,Towards a More Generalized Approach in Open Relation Extraction,"Qing Wang, Yuepei Li, Qiao Qiao, Kang Zhou, Qi Li",(missing journal),2025,(missing abstract),289538326,0,0,,
10.18653/v1/2025.acl-long.389,CoMet: Metaphor-Driven Covert Communication for Multi-Agent Language Games,"Shuxiang Xu, Fangwei Zhong",(missing journal),2025,(missing abstract),289538327,0,0,,
10.18653/v1/2025.acl-long.278,CORAL: Learning Consistent Representations across Multi-step Training with Lighter Speculative Drafter,"Yepeng Weng, Dianwen Mei, Huishi Qiu, Xujie Chen, Li Liu, Jiang Tian, Zhongchao Shi",(missing journal),2025,(missing abstract),289538328,0,0,,
10.18653/v1/2025.acl-long.260,Dually Self-Improved Counterfactual Data Augmentation Using Large Language Model,"Luhao Zhang, Xinyu Zhang, Linmei Hu, Dandan Song, Liqiang Nie",(missing journal),2025,(missing abstract),289538330,0,0,,
10.18653/v1/2025.acl-long.304,Are the Hidden States Hiding Something? Testing the Limits of Factuality-Encoding Capabilities in LLMs,"Giovanni Servedio, Alessandro Bellis, Dario Di Palma, Vito Walter Anelli, Tommaso Di Noia",(missing journal),2025,(missing abstract),289538331,0,0,,
10.18653/v1/2025.acl-long.205,Visual Evidence Prompting Mitigates Hallucinations in Large Vision-Language Models,"Wei Li, Zhen Huang, Houqiang Li, Le Lu, Lu Yang, Xinmei Tian, Shen Xu, Jieping Ye",(missing journal),2025,(missing abstract),289544177,0,0,,
10.18653/v1/2025.acl-long.197,Positional Overload: Positional Debiasing and Context Window Extension for Large Language Models using Set Encoding,"Lukas Kinder, Lukas Edman, Alexander Fraser, Tobias Käfer",(missing journal),2025,(missing abstract),289544178,0,0,,
10.18653/v1/2025.acl-long.67,FedEx-LoRA: Exact Aggregation for Federated and Efficient Fine-Tuning of Large Language Models,"Raghav Singhal, Kaustubh Ponkshe, Praneeth Vepakomma",(missing journal),2025,(missing abstract),289544179,0,0,,
10.18653/v1/2025.acl-long.145,Ensemble Watermarks for Large Language Models,"Georg Niess, Roman Kern",(missing journal),2025,(missing abstract),289544180,0,0,,
10.18653/v1/2025.acl-long.92,Self-Instructed Derived Prompt Generation Meets In-Context Learning: Unlocking New Potential of Black-Box LLMs,"Zhuo Li, Yuhao Du, Jinpeng Hu, Xiang Wan, Anningzhe Gao",(missing journal),2025,(missing abstract),289544181,0,0,,
10.18653/v1/2025.acl-long.77,KV-Latent: Dimensional-level KV Cache Reduction with Frequency-aware Rotary Positional Embedding,"Shi Luohe, Zuchao Li, Lefei Zhang, Baoyuan Qi, Guoming Liu, H. Vicky Zhao",Annual Meeting of the Association for Computational Linguistics,2025,"Large language models (LLMs) based on Transformer Decoders have become the preferred choice for conversational generative AI. Despite the overall superiority of the Decoder architecture, the gradually increasing Key-Value (KV) cache during inference has emerged as a primary efficiency bottleneck, both in aspects of memory consumption and data transfer bandwidth limitations. To address these challenges, we propose a paradigm called KV-Latent. By down-sampling the Key-Value vector dimensions into a latent space, we can significantly reduce the KV Cache footprint and improve inference speed, only with a small amount of extra training, less than 1\% of pre-training takes. Besides, we enhanced the stability of Rotary Positional Embedding applied on lower-dimensional vectors by modifying its frequency sampling mechanism, avoiding noise introduced by higher frequencies while retaining position attenuation. Our experiments, including both models with Grouped Query Attention and those without, have yielded satisfactory results. Finally, we conducted comparative experiments to study the impact of separately reducing Key and Value components on model's performance. Our approach allows for the construction of more efficient language model systems, and opens the new possibility on KV Cache saving and efficient LLMs. Our code is available at https://github.com/ShiLuohe/KV-Latent.",289544182,3,28,,
10.18653/v1/2025.acl-long.83,On the Mutual Influence of Gender and Occupation in LLM Representations,"Haozhe An, Connor Baumler, Abhilasha Sancheti, Rachel Rudinger",(missing journal),2025,(missing abstract),289544183,0,0,,
10.18653/v1/2025.acl-long.146,Con Instruction: Universal Jailbreaking of Multimodal Large Language Models via Non-Textual Modalities,"Jiahui Geng, Thy Thy Tran, Preslav Nakov, Iryna Gurevych",(missing journal),2025,(missing abstract),289544184,0,0,,
10.18653/v1/2025.acl-long.15,Delving into Multilingual Ethical Bias: The MSQAD with Statistical Hypothesis Tests for Large Language Models,"Seunguk Yu, Juhwan Choi, Youngbin Kim",(missing journal),2025,(missing abstract),289544185,0,0,,
10.18653/v1/2025.acl-long.24,"UniICL: An Efficient ICL Framework Unifying Compression, Selection, and Generation","Jun Gao, Qi Lv, Zili Wang, Tsung-Ching Wu, Ziqiang Cao, Wenjie Li",(missing journal),2025,(missing abstract),289544186,0,0,,
10.18653/v1/2025.acl-long.26,A Survey on Foundation Language Models for Single-cell Biology,"Fan Zhang, Hao Chen, Zhihong Zhu, Ziheng Zhang, Zhenxi Lin, Ziyue Qiao, Yefeng Zheng, Xian Wu",(missing journal),2025,(missing abstract),289544188,1,0,,
10.18653/v1/2025.acl-long.1545,What Happened in LLMs Layers when Trained for Fast vs. Slow Thinking: A Gradient Perspective,"Ming Li, Yanhong Li, Tianyi Zhou",(missing journal),2025,(missing abstract),289544306,1,0,,
10.18653/v1/2025.acl-long.1527,The Harmonic Structure of Information Contours,"Eleftheria Tsipidi, Samuel Kiegeland, Franz Nowak, Tianyang Xu, Ethan Wilcox, Alex Warstadt, Ryan Cotterell, Mario Giulianelli",(missing journal),2025,(missing abstract),289544307,0,0,,
10.18653/v1/2025.acl-long.1435,The Task Shield: Enforcing Task Alignment to Defend Against Indirect Prompt Injection in LLM Agents,"Feiran Jia, Tong Wu, Qin Xin, Anna Squicciarini",(missing journal),2025,(missing abstract),289544308,1,0,,
10.18653/v1/2025.acl-long.1486,TestNUC: Enhancing Test-Time Computing Approaches and Scaling through Neighboring Unlabeled Data Consistency,"Henry Peng Zou, Zheng‐Bing Gu, Yue Zhou, Yankai Chen, Wei Zhang, Liancheng Fang, Yibo Wang, Yangning Li, Kay Liu, Philip S. Yu",Annual Meeting of the Association for Computational Linguistics,2025,"Test-time computing approaches, which leverage additional computational resources during inference, have been proven effective in enhancing large language model performance. This work introduces a novel, linearly scaling approach, TestNUC, that improves test-time predictions by leveraging the local consistency of neighboring unlabeled data-it classifies an input instance by considering not only the model's prediction on that instance but also on neighboring unlabeled instances. We evaluate TestNUC across eight diverse datasets, spanning intent classification, topic mining, domain discovery, and emotion detection, demonstrating its consistent superiority over baseline methods such as standard prompting and self-consistency. Furthermore, TestNUC can be seamlessly integrated with existing test-time computing approaches, substantially boosting their performance. Our analysis reveals that TestNUC scales effectively with increasing amounts of unlabeled data and performs robustly across different embedding models, making it practical for real-world applications. Our code is available at https://github.com/HenryPengZou/TestNUC.",289544309,3,34,,
10.18653/v1/2025.acl-long.1477,SubLIME: Subset Selection via Rank Correlation Prediction for Data-Efficient LLM Evaluation,"Gayathri Saranathan, Cong Xu, Mahammad Parwez Alam, Tarun Kumar, Martin Foltín, Soon Yee Wong, Suparna Bhattacharya",(missing journal),2025,(missing abstract),289544310,0,0,,
10.18653/v1/2025.acl-long.1436,Sandcastles in the Storm: Revisiting the (Im)possibility of Strong Watermarking,"Fabrice Harel-Canada, Boran Erol, Cheong‐Rim Choi, Jason Liu, Gary Jiarui Song, Nanyun Peng, Amit Sahai",(missing journal),2025,(missing abstract),289544311,0,0,,
10.18653/v1/2025.acl-long.1418,MDCure: A Scalable Pipeline for Multi-Document Instruction-Following,"G. Liu, Bowen Shi, Avi Caciularu, Idan Szpektor, Arman Cohan",(missing journal),2025,(missing abstract),289544312,0,0,,
10.18653/v1/2025.acl-long.1366,Training Dynamics Underlying Language Model Scaling Laws: Loss Deceleration and Zero-Sum Learning,"Andrei Mircea, Sanjoy Chakraborty, Nima Chitsazan, Irina Rish, Ekaterina Lobacheva",(missing journal),2025,(missing abstract),289544313,0,0,,
10.18653/v1/2025.acl-long.1372,Mixture of Small and Large Models for Chinese Spelling Check,"Zhijiao Qiao, Houquan Zhou, Zhenghua Li",(missing journal),2025,(missing abstract),289544315,0,0,,
10.18653/v1/2025.acl-long.1390,MIR: Methodology Inspiration Retrieval for Scientific Research Problems,"Aniketh Garikaparthi, Manasi Patwardhan, Aditya Kanade, Ahmed E. Hassan, Lovekesh Vig, Arman Cohan",(missing journal),2025,(missing abstract),289544316,0,0,,
10.18653/v1/2025.acl-long.1407,𝒜3: Automatic Alignment Framework for Attributed Text Generation,"Yue Wang, Haoke Zhang, Juntao Li, Jinxiong Chang, Min Zhang",(missing journal),2025,(missing abstract),289544317,0,0,,
10.18653/v1/2025.acl-long.1274,DeAL: Decoding-time Alignment for Large Language Models,"James Y. Huang, Sailik Sengupta, Daniele Bonadiman, Yi-An Lai, Arshit Gupta, Νικόλαος Παππάς, Saab Mansour, Katrin Kirchhoff, Dan Roth",(missing journal),2025,(missing abstract),289544318,1,0,,
10.18653/v1/2025.acl-long.1271,Do LLMs Understand Dialogues? A Case Study on Dialogue Acts,"Ayesha Qamar, Jonathan Tong, Ruihong Huang",(missing journal),2025,(missing abstract),289544319,0,0,,
10.18653/v1/2025.acl-long.1267,CrafText Benchmark: Advancing Instruction Following in Complex Multimodal Open-Ended World,"Zoya Volovikova, Gregory Gorbov, Petr Kuderov, Aleksandr I. Panov, Alexey Skrynnik",(missing journal),2025,(missing abstract),289544320,0,0,,
10.18653/v1/2025.acl-long.1263,Teaching an Old LLM Secure Coding: Localized Preference Optimization on Distilled Preferences,"Mohd. Hasan, Saikat Chakraborty, Santu Karmaker, Niranjan Balasubramanian",(missing journal),2025,(missing abstract),289544321,0,0,,
10.18653/v1/2025.acl-long.1098,WhiSPA: Semantically and Psychologically Aligned Whisper with Self-Supervised Contrastive and Student-Teacher Learning,"R. Rajeswara Rao, Adithya V Ganesan, Oscar Kjell, Jonah Luby, Akshay Raghavan, Scott Feltman, Whitney R. Ringwald, Ryan L. Boyd, Benjamin J. Luft, Camilo J. Ruggero, Neville Ryant, Roman Kotov, H. Schwartz",(missing journal),2025,(missing abstract),289546143,0,0,,
10.18653/v1/2025.acl-long.1112,TUMLU: A Unified and Native Language Understanding Benchmark for Turkic Languages,"Jafar Isbarov, Arofat Akhundjanova, Mammad Hajili, Kavsar Huseynova, Dmitry Gaynullin, Anar Rzayev, Osman Tursun, Aizirek Turdubaeva, Ilshat Saetov, Rinat Kharisov, Saule Belginova, Ariana Kenbayeva, Amina Alisheva, Abdullatif Köksal, Samir Rustamov, Duygu Ataman",(missing journal),2025,(missing abstract),289546144,1,0,,
10.18653/v1/2025.acl-long.1083,Detecting Sockpuppetry on Wikipedia Using Meta-Learning,"Luc Raszewski, Christine de Kock",Annual Meeting of the Association for Computational Linguistics,2025,"Malicious sockpuppet detection on Wikipedia is critical to preserving access to reliable information on the internet and preventing the spread of disinformation. Prior machine learning approaches rely on stylistic and meta-data features, but do not prioritise adaptability to author-specific behaviours. As a result, they struggle to effectively model the behaviour of specific sockpuppet-groups, especially when text data is limited. To address this, we propose the application of meta-learning, a machine learning technique designed to improve performance in data-scarce settings by training models across multiple tasks. Meta-learning optimises a model for rapid adaptation to the writing style of a new sockpuppet-group. Our results show that meta-learning significantly enhances the precision of predictions compared to pre-trained models, marking an advancement in combating sockpuppetry on open editing platforms. We release a new dataset of sockpuppet investigations to foster future research in both sockpuppetry and meta-learning fields.",289546145,1,45,,
10.18653/v1/2025.acl-long.1130,Does the Emotional Understanding of LVLMs Vary Under High-Stress Environments and Across Different Demographic Attributes?,"Jaewook Lee, Yuri Jang, Oh Geon Kwon, Hyejin Kim",(missing journal),2025,(missing abstract),289546146,0,0,,
10.18653/v1/2025.acl-long.1158,"CRUXEVAL-X: A Benchmark for Multilingual Code Reasoning, Understanding and Execution","Ruiyang Xu, Jialun Cao, Yaojie Lu, Ming Wen, Hongyu Lin, Xianpei Han, Ben He, Shing-Chi Cheung, Le Sun",(missing journal),2025,(missing abstract),289546147,0,0,,
10.18653/v1/2025.acl-long.1143,Mamba Knockout for Unraveling Factual Information Flow,"Nir Endy, Idan Daniel Grosbard, Yuval Ran-Milo, Yonatan Slutzky, Itay Tshuva, Raja Giryes",(missing journal),2025,(missing abstract),289546148,0,0,,
10.18653/v1/2025.acl-long.882,InSerter: Speech Instruction Following with Unsupervised Interleaved Pre-training,"Dingdong Wang, Jin Xu, Ruihang Chu, Zhifang Guo, Xiong Wang, Jincenzi Wu, Dongchao Yang, Shengpeng Ji, Chun-Yang Lin",(missing journal),2025,(missing abstract),289546149,0,0,,
10.18653/v1/2025.acl-long.903,Hierarchical Bracketing Encodings for Dependency Parsing as Tagging,"Ana Ezquerro, David Vilares, Anssi Yli-Jyrä, Carlos Gómez‐Rodríguez",(missing journal),2025,(missing abstract),289546150,0,0,,
10.18653/v1/2025.acl-long.922,Words of Warmth: Trust and Sociability Norms for over 26k English Words,Saif M. Mohammad,(missing journal),2025,(missing abstract),289546151,1,0,,
10.18653/v1/2025.acl-long.1055,LED-Merging: Mitigating Safety-Utility Conflicts in Model Merging with Location-Election-Disjoint,"Qianli Ma, Dongrui Liu, Qian Chen, Linfeng Zhang, Shao Jing",Annual Meeting of the Association for Computational Linguistics,2025,"Fine-tuning pre-trained Large Language Models (LLMs) for specialized tasks incurs substantial computational and data costs. While model merging offers a training-free solution to integrate multiple task-specific models, existing methods suffer from safety-utility conflicts where enhanced general capabilities degrade safety safeguards. We identify two root causes: $\textbf{neuron misidentification}$ due to simplistic parameter magnitude-based selection, and $\textbf{cross-task neuron interference}$ during merging. To address these challenges, we propose $\textbf{LED-Merging}$, a three-stage framework that $\textbf{L}$ocates task-specific neurons via gradient-based attribution, dynamically $\textbf{E}$lects critical neurons through multi-model importance fusion, and $\textbf{D}$isjoints conflicting updates through parameter isolation. Extensive experiments on Llama-3-8B, Mistral-7B, and Llama2-13B demonstrate that LED-Merging effectively reduces harmful response rates, showing a 31.4\% decrease on Llama-3-8B-Instruct on HarmBench, while simultaneously preserving 95\% of utility performance, such as achieving 52.39\% accuracy on GSM8K. LED-Merging resolves safety-utility conflicts and provides a lightweight, training-free paradigm for constructing reliable multi-task LLMs. Code is available at $\href{https://github.com/MqLeet/LED-Merging}{GitHub}$.",289546152,3,57,,
10.18653/v1/2025.acl-long.1047,Neural Incompatibility: The Unbridgeable Gap of Cross-Scale Parametric Knowledge Transfer in Large Language Models,"Yuqiao Tan, Shizhu He, K. Liu, Jun Zhao",(missing journal),2025,(missing abstract),289546153,0,0,,
10.18653/v1/2025.acl-long.975,Impartial Multi-task Representation Learning via Variance-invariant Probabilistic Decoding,"Dou Hu, Lingwei Wei, Wei Zhou, Songlin Hu",(missing journal),2025,(missing abstract),289546154,0,0,,
10.18653/v1/2025.acl-long.985,What’s the Difference? Supporting Users in Identifying the Effects of Prompt and Model Changes Through Token Patterns,"Michael A. Hedderich, Anyi Wang, Rongchun Zhao, Florian Eichin, Jonas Fischer, Barbara Plank",(missing journal),2025,(missing abstract),289546155,0,0,,
10.18653/v1/2025.acl-long.910,Minimal Pair-Based Evaluation of Code-Switching,"Igor Sterner, Simone Teufel",(missing journal),2025,(missing abstract),289546156,0,0,,
10.18653/v1/2025.acl-long.1029,TESS 2: A Large-Scale Generalist Diffusion Language Model,"Jaesung Tae, Hamish Ivison, Sachin Kumar, Arman Cohan",(missing journal),2025,(missing abstract),289546157,0,0,,
10.18653/v1/2025.acl-long.1013,Classifying Unreliable Narrators with Large Language Models,"Anneliese Brei, Katharine Henry, A. K. Sharma, Shashank Srivastava, Snigdha Chaturvedi",(missing journal),2025,(missing abstract),289546158,0,0,,
10.18653/v1/2025.acl-long.820,The Role of Deductive and Inductive Reasoning in Large Language Models,"Chengkun Cai, Zhao Xu, Haoliang Liu, Zhongyu Jiang, Tianfang Zhang, Zongkai Wu, Jenq‐Neng Hwang, Lei Li",(missing journal),2025,(missing abstract),289546159,2,0,,
10.18653/v1/2025.acl-long.865,Fixing Distribution Shifts of LLM Self-Critique via On-Policy Self-Play Training,"Bao Rong, Donglin Yu, Kai Fan, Minpeng Liao",(missing journal),2025,(missing abstract),289546160,2,0,,
10.18653/v1/2025.acl-long.846,LLMs Can Simulate Standardized Patients via Agent Coevolution,"Z. Z. Du, LujieZheng LujieZheng, Ruijin Hu, Yan Xu, Xiawei Li, Yingming Sun, Wei Chen, Jian‐Lin Wu, Haolei Cai, Haochao Ying",(missing journal),2025,(missing abstract),289546161,1,0,,
10.18653/v1/2025.acl-long.870,From Human Reading to NLM Understanding: Evaluating the Role of Eye-Tracking Data in Encoder-Based Models,"Luca Dini, Lucia Domenichelli, Dominique Brunato⋄, Felice Dell’Orletta⋄",(missing journal),2025,(missing abstract),289546162,0,0,,
10.18653/v1/2025.acl-long.819,RetroLLM: Empowering Large Language Models to Retrieve Fine-grained Evidence within Generation,"Xiaoxi Li, Jiajie Jin, Yujia Zhou, Yongkang Wu, Zhonghua Li, Qi Ye, Zhicheng Dou",(missing journal),2025,(missing abstract),289546163,1,0,,
10.18653/v1/2025.acl-long.1184,Towards Fully Exploiting LLM Internal States to Enhance Knowledge Boundary Perception,"Shiyu Ni, Keping Bi, Jiafeng Guo, Lulu Yu, Baolong Bi, Xueqi Cheng",(missing journal),2025,(missing abstract),289546164,0,0,,
10.18653/v1/2025.acl-long.737,Cheems: A Practical Guidance for Building and Evaluating Chinese Reward Models from Scratch,"Xueru Wen, Jianying Lou, Zichao Li, Yaojie Lu, XingYu XingYu, Y. Y. Ji, Guoyong Xu, Hongyu Lin, Bin He, Xianpei Han, L. Sun, D. Zhang",(missing journal),2025,(missing abstract),289546165,0,0,,
10.18653/v1/2025.acl-long.731,Crab: A Novel Configurable Role-Playing LLM with Assessing Benchmark,"He Kai, Yucheng Huang, Wenqing Wang, Delong Ran, Dongming Sheng, Jee‐Fu Huang, Qiang Lin, Jiaxing Xu, Wenqiang Liu, Mengling Feng",(missing journal),2025,(missing abstract),289546166,0,0,,
10.18653/v1/2025.acl-long.729,GraphCheck: Breaking Long-Term Text Barriers with Extracted Knowledge Graph-Powered Fact-Checking,"Yingjian Chen, Haoran Liu, Yinhong Liu, Jingyi Xie, Rui Yang, Han Yuan, Ying Fu, Pengyuan Zhou, Qingyu Chen, James Caverlee, Irene Li",Annual Meeting of the Association for Computational Linguistics,2025,"Large language models (LLMs) are widely used, but they often generate subtle factual errors, especially in long-form text. These errors are fatal in some specialized domains such as medicine. Existing fact-checking with grounding documents methods face two main challenges: (1) they struggle to understand complex multihop relations in long documents, often overlooking subtle factual errors; (2) most specialized methods rely on pairwise comparisons, requiring multiple model calls, leading to high resource and computational costs. To address these challenges, we propose GraphCheck , a fact-checking framework that uses extracted knowledge graphs to enhance text representation. Graph Neural Networks further process these graphs as a soft prompt, enabling LLMs to incorporate structured knowledge more effectively. Enhanced with graph-based reasoning, GraphCheck captures multihop reasoning chains that are often overlooked by existing methods, enabling precise and efficient fact-checking in a single inference call. Experimental results on seven benchmarks spanning both general and medical domains demonstrate up to a 7.1% overall improvement over baseline models. Notably, GraphCheck outperforms existing specialized fact-checkers and achieves comparable performance with state-of-the-art LLMs, such as DeepSeek-V3 and OpenAI-o1, with significantly fewer parameters.",289546167,4,39,,
10.18653/v1/2025.acl-long.651,LLaSE-G1: Incentivizing Generalization Capability for LLaMA-based Speech Enhancement,"Bumsoo Kang, Xinfa Zhu, Zihan Zhang, Zhen Ye, Mingshuai Liu, Ziqian Wang, Yike Zhu, Guobin Ma, Jun Chen, Longshuai Xiao, Chao Weng, Weiwei Xue, Lei Xie",(missing journal),2025,(missing abstract),289546168,3,0,,
10.18653/v1/2025.acl-long.730,SCULPT: Systematic Tuning of Long Prompts,"Shanu Kumar, Akhila Yesantarao Venkata, S K Khandelwal, Bishal Santra, Parag Agrawal, Manish Gupta",(missing journal),2025,(missing abstract),289546169,1,0,,
10.18653/v1/2025.acl-long.670,CRiskEval: A Chinese Multi-Level Risk Evaluation Benchmark Dataset for Large Language Models,"Ling Shi, Deyi Xiong",(missing journal),2025,(missing abstract),289546170,0,0,,
10.18653/v1/2025.acl-long.607,SDPO: Segment-Level Direct Preference Optimization for Social Agents,"Aobo Kong, Wentao Ma, Shiwan Zhao, Yongbin Li, Yuchuan Wu, Ke Wang, Xiaoqian Liu, Qiaowei Li, Yong Qin, Fei Huang",(missing journal),2025,(missing abstract),289546171,0,0,,
10.18653/v1/2025.acl-long.667,Self-supervised Quantized Representation for Seamlessly Integrating Knowledge Graphs with Large Language Models,"Qika Lin, Tianzhe Zhao, Kai He, Zhen Peng, Fangzhi Xu, Ling Huang, Jingying Ma, Mengling Feng",(missing journal),2025,(missing abstract),289546172,5,0,,
10.18653/v1/2025.acl-long.510,AutoGUI: Scaling GUI Grounding with Automatic Functionality Annotations from LLMs,"Hongxin Li, Jingfan Chen, Jingran Su, Yuntao Chen, Qing Li, Zhaoxiang Zhang",(missing journal),2025,(missing abstract),289546173,0,0,,
10.18653/v1/2025.acl-long.584,UniLR: Unleashing the Power of LLMs on Multiple Legal Tasks with a Unified Legal Retriever,"Ang Li, Yiquan Wu, Yifei Liu, Ming Cai, Lizhi Qing, Shihang Wang, Yangyang Kang, Chengyuan Liu, Fei Wu, Kun Kuang",(missing journal),2025,(missing abstract),289546174,2,0,,
10.18653/v1/2025.acl-long.535,Sample-Efficient Human Evaluation of Large Language Models via Maximum Discrepancy Competition,"Kehua Feng, Keyan Ding, Tan Hongzhi, Kede Ma, Zhihua Wang, Shuai Guo, Cheng Yuzhou, Ge Sun, Guochen Zheng, Qiang Zhang, Huajun Chen",(missing journal),2025,(missing abstract),289546175,0,0,,
10.18653/v1/2025.acl-long.496,Enhancing Neural Machine Translation Through Target Language Data: A kNN-LM Approach for Domain Adaptation,"Abudurexiti Reheman, Hongyu Liu, Junhao Ruan, Abudukeyumu Abudula, Yingfeng Luo, Tong Xiao, Jingbo Zhu",(missing journal),2025,(missing abstract),289546176,0,0,,
10.18653/v1/2025.acl-long.545,Can Graph Neural Networks Learn Language with Extremely Weak Text Supervision?,"Zihao Li, Lecheng Zheng, Bowen Jin, Dongqi Fu, Baoyu Jing, Yikun Ban, Jingrui He, Jiawei Han",(missing journal),2025,(missing abstract),289546177,0,0,,
10.18653/v1/2025.acl-long.514,Mitigating Confounding in Speech-Based Dementia Detection through Weight Masking,"Zhecheng Sheng, Xiruo Ding, Brian Hur, Changye Li, Trevor Cohen, Serguei Pakhomov",(missing journal),2025,(missing abstract),289546178,0,0,,
10.18653/v1/2025.acl-long.482,A Drop-In Solution for On-the-Fly Adaptation of Speculative Decoding in Large Language Models,"Jiesong Liu, Brian Park, Xipeng Shen",(missing journal),2025,(missing abstract),289546179,0,0,,
10.18653/v1/2025.acl-long.440,Are LLMs effective psychological assessors? Leveraging adaptive RAG for interpretable mental health screening through psychometric practice,"Federico Ravenda, Seyed Ali Bahrainian, Andrea Raballo, Antonietta Mira, Noriko Kando",(missing journal),2025,(missing abstract),289546180,1,0,,
10.18653/v1/2025.acl-long.500,NexusSum: Hierarchical LLM Agents for Long-Form Narrative Summarization,"Hyuntak Kim, Byung‐Hak Kim",(missing journal),2025,(missing abstract),289546181,0,0,,
10.18653/v1/2025.acl-long.406,Browsing Lost Unformed Recollections: A Benchmark for Tip-of-the-Tongue Search and Reasoning,"Sky CH-Wang, Darshan Deshpande, Smaranda Muresan, A. Kannappan, Rebecca Qian",(missing journal),2025,(missing abstract),289546182,0,0,,
10.18653/v1/2025.acl-long.463,IRIS: An Iterative and Integrated Framework for Verifiable Causal Discovery in the Absence of Tabular Data,"Tao Feng, Lizhen Qu, Niket Tandon, Gholamreza Haffari",Annual Meeting of the Association for Computational Linguistics,2025,"Causal discovery is fundamental to scientific research, yet traditional statistical algorithms face significant challenges, including expensive data collection, redundant computation for known relations, and unrealistic assumptions. While recent LLM-based methods excel at identifying commonly known causal relations, they fail to uncover novel relations. We introduce IRIS (Iterative Retrieval and Integrated System for Real-Time Causal Discovery), a novel framework that addresses these limitations. Starting with a set of initial variables, IRIS automatically collects relevant documents, extracts variables, and uncovers causal relations. Our hybrid causal discovery method combines statistical algorithms and LLM-based methods to discover known and novel causal relations. In addition to causal discovery on initial variables, the missing variable proposal component of IRIS identifies and incorporates missing variables to expand the causal graphs. Our approach enables real-time causal discovery from only a set of initial variables without requiring pre-existing datasets.",289546183,0,51,,
10.18653/v1/2025.acl-long.338,Turning Trash into Treasure: Accelerating Inference of Large Language Models with Token Recycling,"Xianzhen Luo, Yixuan Wang, Qingfu Zhu, Zhiming Zhang, Xuanyu Zhang, Qing Yang, Dongliang Xu",(missing journal),2025,(missing abstract),289546184,1,0,,
10.18653/v1/2025.acl-long.380,Commonsense Reasoning in Arab Culture,"Abdelrahman Sadallah, Junior Cedric Tonga, Khalid Almubarak, Saeed Almheiri, Farah Atif, Chatrine Qwaider, Karima Kadaoui, Sara Shatnawi, Yaser Alesh, Fajri Koto",(missing journal),2025,(missing abstract),289546185,0,0,,
10.18653/v1/2025.acl-long.337,BERT-like Models for Slavic Morpheme Segmentation,"Dmitry Morozov, Lizaveta Astapenka, Anna Glazkova, Timur Garipov, Olga Lyashevskaya",(missing journal),2025,(missing abstract),289546186,0,0,,
10.18653/v1/2025.acl-long.335,Identifying Reliable Evaluation Metrics for Scientific Text Revision,"Léane Jourdan, Nicolás Hernández, Florian Boudin, Richard Dufour",(missing journal),2025,(missing abstract),289546187,0,0,,
10.18653/v1/2025.acl-long.331,FloorPlan-LLaMa: Aligning Architects’ Feedback and Domain Knowledge in Architectural Floor Plan Generation,"Jun Yin, Pengyu Zeng, Haoyuan Sun, Yuxing Dai, Han Zheng, Miao Zhang, Yachao Zhang, S. L. Lu",(missing journal),2025,(missing abstract),289546188,0,0,,
10.18653/v1/2025.acl-long.348,Towards Effective Extraction and Evaluation of Factual Claims,"Dasha Metropolitansky, Jonathan Larson",(missing journal),2025,(missing abstract),289546189,1,0,,
10.18653/v1/2025.acl-long.297,ReLearn: Unlearning via Learning for Large Language Models,"Haoming Xu, Ningyuan Zhao, Liming Yang, Sendong Zhao, Shumin Deng, Mengru Wang, Bryan Hooi, Nay Oo, Huajun Chen, Ningyu Zhang",(missing journal),2025,(missing abstract),289546190,1,0,,
10.18653/v1/2025.acl-long.282,GUI-explorer: Autonomous Exploration and Mining of Transition-aware Knowledge for GUI Agent,"Bin Xie, Rui Shao, Gongwei Chen, Kaiwen Zhou, Yinchuan Li, Jie Liu, Min Zhang, Liqiang Nie",(missing journal),2025,(missing abstract),289546191,0,0,,
10.18653/v1/2025.acl-long.258,MoC: Mixtures of Text Chunking Learners for Retrieval-Augmented Generation System,"Jihao Zhao, Zhiyuan Ji, Zhaoxin Fan, Hanyu Wang, Simin Niu, Bo Tang, Feiyu Xiong, Zhiyu Li",(missing journal),2025,(missing abstract),289546192,3,0,,
10.18653/v1/2025.acl-long.198,FR-Spec: Accelerating Large-Vocabulary Language Models via Frequency-Ranked Speculative Sampling,"Weilin Zhao, Tao Pan, Xu Han, Yudi Zhang, Ao Sun, Yuxiang Huang, Kaihuo Zhang, Weilun Zhao, Yuxuan Li, Jie Zhou, Hao Zhou, Jianyong Wang, Maosong Sun, Zhiyuan Liu",(missing journal),2025,(missing abstract),289552058,0,0,,
10.18653/v1/2025.acl-long.185,Cross-model Transferability among Large Language Models on the Platonic Representations of Concepts,"Youcheng Huang, Chen Huang, Duanyu Feng, Wenqiang Lei, Jiancheng Lv",(missing journal),2025,(missing abstract),289552059,0,0,,
10.18653/v1/2025.acl-long.202,Read it in Two Steps: Translating Extremely Low-Resource Languages with Code-Augmented Grammar Books,"Chen Zhang, Jiuheng Lin, Xiao Liu, Zekai Zhang, Yansong Feng",(missing journal),2025,(missing abstract),289552060,0,0,,
10.18653/v1/2025.acl-long.169,Which of These Best Describes Multiple Choice Evaluation with LLMs? A) Forced B) Flawed C) Fixable D) All of the Above,"Nishant Balepur, Rachel Rudinger, Jordan Lee Boyd-Graber",(missing journal),2025,(missing abstract),289552061,0,0,,
10.18653/v1/2025.acl-long.175,Cracking the Code of Hallucination in LVLMs with Vision-aware Head Divergence,"Jinghan He, Kuan Zhu, Haiyun Guo, Junfeng Fang, Zhengli Hua, Yuheng Jia, Ming Tang, Tat‐Seng Chua, Jinqiao Wang",(missing journal),2025,(missing abstract),289552062,1,0,,
10.18653/v1/2025.acl-long.170,Detection of Human and Machine-Authored Fake News in Urdu,"Mohamad Wijayanuddin Ali, Y. Wang, Bernhard Pfahringer, Tony Smith",(missing journal),2025,(missing abstract),289552063,0,0,,
10.18653/v1/2025.acl-long.237,Benchmarking Open-ended Audio Dialogue Understanding for Large Audio-Language Models,"Kuofeng Gao, Shu‐Tao Xia, Ke Xu, Philip H. S. Torr, Jindong Gu",(missing journal),2025,(missing abstract),289552064,0,0,,
10.18653/v1/2025.acl-long.199,VReST: Enhancing Reasoning in Large Vision-Language Models through Tree Search and Self-Reward Mechanism,"Chengfei Zhang, Jiawei Peng, Zhenglin Wang, Yilong Lai, Hong‐Jin Sun, Heng Chang, Fei Ma, Weijiang Yu",(missing journal),2025,(missing abstract),289552065,0,0,,
10.18653/v1/2025.acl-long.142,HyperFM: Fact-Centric Multimodal Fusion for Link Prediction over Hyper-Relational Knowledge Graphs,"Yuhuan Lu, Weijian Yu, Xin Jing, Dingqi Yang",(missing journal),2025,(missing abstract),289552066,0,0,,
10.18653/v1/2025.acl-long.71,HALoGEN: Fantastic LLM Hallucinations and Where to Find Them,"Abhilasha Ravichander, Shrusti Ghela, David Wadden, Yejin Choi",(missing journal),2025,(missing abstract),289552067,2,0,,
10.18653/v1/2025.acl-long.147,TRACT: Regression-Aware Fine-tuning Meets Chain-of-Thought Reasoning for LLM-as-a-Judge,"Cheng-Han Chiang, Hung-yi Lee, Michał Łukasik",(missing journal),2025,(missing abstract),289552068,0,0,,
10.18653/v1/2025.acl-long.112,Speaking Beyond Language: A Large-Scale Multimodal Dataset for Learning Nonverbal Cues from Video-Grounded Dialogues,"Youngmin Kim, Jiwan Chung, Jisoo Kim, Sunghyun Lee, Sangkyu Lee, Junhyeok Kim, Cheoljong Yang, Youngjae Yu",(missing journal),2025,(missing abstract),289552069,0,0,,
10.18653/v1/2025.acl-long.141,Position-aware Automatic Circuit Discovery,"Tal Haklay, Hadas Orgad, David Bau, Aaron Mueller, Yonatan Belinkov",(missing journal),2025,(missing abstract),289552070,0,0,,
10.18653/v1/2025.acl-long.111,"LLäMmlein: Transparent, Compact and Competitive German-Only Language Models from Scratch","Jan Pfister, Julia Wunderle, Andreas Hotho",Annual Meeting of the Association for Computational Linguistics,2025,"We create two German-only decoder models, LL\""aMmlein 120M and 1B, transparently from scratch and publish them, along with the training data, for the German NLP research community to use. The model training involved several key steps, including extensive data preprocessing, the creation of a custom German tokenizer, the training itself, as well as the evaluation of the final models on various benchmarks. Throughout the training process, multiple checkpoints were saved and analyzed using the SuperGLEBer benchmark to monitor the models' learning dynamics. Compared to state-of-the-art models on the SuperGLEBer benchmark, both LL\""aMmlein models performed competitively, consistently matching or surpassing models with similar parameter sizes. The results show that the models' quality scales with size as expected, but performance improvements on some tasks plateaued early, offering valuable insights into resource allocation for future model development.",289552071,1,27,,
10.18653/v1/2025.acl-long.64,Evaluating Lexical Proficiency in Neural Language Models,"Cristiano Ciaccio, Alessio Miaschi, Felice Dell’Orletta⋄",(missing journal),2025,(missing abstract),289552072,0,0,,
10.18653/v1/2025.acl-long.107,AndroidLab: Training and Systematic Benchmarking of Android Autonomous Agents,"Yifan Xu, Xiao Liu, Xueqiao Sun, Siyi Cheng, Hao Yu, Hanyu Lai, Shudan Zhang, Dan Zhang, Jie Tang, Yuxiao Dong",(missing journal),2025,(missing abstract),289552073,0,0,,
10.18653/v1/2025.acl-long.156,Cultural Learning-Based Culture Adaptation of Language Models,"Chen Cecilia Liu, Anna Korhonen, Iryna Gurevych",(missing journal),2025,(missing abstract),289552074,2,0,,
10.18653/v1/2025.acl-long.5,The Impossibility of Fair LLMs,"Jacy Reese Anthis, Kristian Lum, Michael Ekstrand, Avi Feller, Chenhao Tan",(missing journal),2025,(missing abstract),289552075,3,0,,
10.18653/v1/2025.acl-long.45,Aligning AI Research with the Needs of Clinical Coding Workflows: Eight Recommendations Based on US Data Analysis and Critical Review,"Yidong Gan, Maciej Rybiński, Ben Hachey, Jonathan K. Kummerfeld",(missing journal),2025,(missing abstract),289552077,0,0,,
10.18653/v1/2025.acl-long.31,Can Multimodal Large Language Models Understand Spatial Relations?,"Jingping Liu, Zhengliang Liu, Zhedong Cen, Yan Zhou, Yinan Zou, Weiyan Zhang, Haiyun Jiang, Tong Ruan",Annual Meeting of the Association for Computational Linguistics,2025,"Spatial relation reasoning is a crucial task for multimodal large language models (MLLMs) to understand the objective world. However, current benchmarks have issues like relying on bounding boxes, ignoring perspective substitutions, or allowing questions to be answered using only the model's prior knowledge without image understanding. To address these issues, we introduce SpatialMQA, a human-annotated spatial relation reasoning benchmark based on COCO2017, which enables MLLMs to focus more on understanding images in the objective world. To ensure data quality, we design a well-tailored annotation procedure, resulting in SpatialMQA consisting of 5,392 samples. Based on this benchmark, a series of closed- and open-source MLLMs are implemented and the results indicate that the current state-of-the-art MLLM achieves only 48.14% accuracy, far below the human-level accuracy of 98.40%. Extensive experimental analyses are also conducted, suggesting the future research directions. The benchmark and codes are available at https://github.com/ziyan-xiaoyu/SpatialMQA.git.",289552079,5,24,,
10.18653/v1/2025.acl-long.57,"LongDocURL: a Comprehensive Multimodal Long Document Benchmark Integrating Understanding, Reasoning, and Locating","Chao Deng, Jiale Yuan, Pi Bu, Yan Wang, Zhongzhi Li, Jian Xu, Xiao-Hui Li, Yuan Gao, J. J. Song, Bo Zheng, Chenglin Liu",(missing journal),2025,(missing abstract),289552081,1,0,,
10.18653/v1/2025.acl-long.1588,Training-free LLM Merging for Multi-task Learning,"Zichuan Fu, Xian Wu, Yejing Wang, Wanyu Wang, Shanshan Ye, Hongzhi Yin, Yi Chang, Yefeng Zheng, Xiangyu Zhao",(missing journal),2025,(missing abstract),289552194,0,0,,
10.18653/v1/2025.acl-long.1539,DualRAG: A Dual-Process Approach to Integrate Reasoning and Retrieval for Multi-Hop Question Answering,"Cheng Rong, Jinyi Liu, Yan Zheng, Fei Ni, Jia Du, Hangyu Mao, Fuzheng Zhang, Bo Wang, Jianye Hao",(missing journal),2025,(missing abstract),289552195,0,0,,
10.18653/v1/2025.acl-long.1474,A Spatio-Temporal Point Process for Fine-Grained Modeling of Reading Behavior,"Francesco Ignazio Re, Andreas Opedal, Glib Manaiev, Mario Giulianelli, Ryan Cotterell",(missing journal),2025,(missing abstract),289552196,0,0,,
10.18653/v1/2025.acl-long.1459,MAPoRL: Multi-Agent Post-Co-Training for Collaborative Large Language Models with Reinforcement Learning,"Chanwoo Park, Seungju Han, Xingzhi Guo, Asuman Ozdaglar, Kaiqing Zhang, Joo-Kyung Kim",(missing journal),2025,(missing abstract),289552197,2,0,,
10.18653/v1/2025.acl-long.1441,"Unveiling the Potential of BERT-family: A New Recipe for Building Scalable, General and Competitive Large Language Models","Yisheng Xiao, Juntao Li, Wenpeng Hu, Zhunchen Luo, Min Zhang",(missing journal),2025,(missing abstract),289552198,0,0,,
10.18653/v1/2025.acl-long.1511,CityNavAgent: Aerial Vision-and-Language Navigation with Hierarchical Semantic Planning and Global Memory,"Weichen Zhang, Chen Gao, Shiquan Yu, Ru‐Wen Peng, Baining Zhao, Qian Zhang, Jinqiang Cui, Xinlei Chen, Yongping Li",(missing journal),2025,(missing abstract),289552199,1,0,,
10.18653/v1/2025.acl-long.1473,Quantized Can Still Be Calibrated: A Unified Framework to Calibration in Quantized Large Language Models,"M. Zhong, Guanchu Wang, Yu-Neng Chuang, Na Zou",(missing journal),2025,(missing abstract),289552200,0,0,,
10.18653/v1/2025.acl-long.1397,SHuBERT: Self-Supervised Sign Language Representation Learning via Multi-Stream Cluster Prediction,"Shester Gueuwou, Xiaodan Du, Greg Shakhnarovich, Karen Livescu, Alexander H. Liu",(missing journal),2025,(missing abstract),289552201,0,0,,
10.18653/v1/2025.acl-long.1398,ERU-KG: Efficient Reference-aligned Unsupervised Keyphrase Generation,"Lam Thanh, A Bodke, Pritom Saha Akash, Kevin Chen–Chuan Chang",(missing journal),2025,(missing abstract),289552202,0,0,,
10.18653/v1/2025.acl-long.1333,Understanding Impact of Human Feedback via Influence Functions,"Taywon Min, Haeone Lee, Yongchan Kwon, Kimin Lee",Annual Meeting of the Association for Computational Linguistics,2025,"In Reinforcement Learning from Human Feedback (RLHF), it is crucial to learn suitable reward models from human feedback to align large language models (LLMs) with human intentions. However, human feedback can often be noisy, inconsistent, or biased, especially when evaluating complex responses. Such feedback can lead to misaligned reward signals, potentially causing unintended side effects during the RLHF process. To address these challenges, we explore the use of influence functions to measure the impact of human feedback on the performance of reward models. We propose a compute-efficient approximation method that enables the application of influence functions to LLM-based reward models and large-scale preference datasets. Our experiments showcase two key applications of influence functions: (1) detecting common labeler biases in human feedback datasets and (2) guiding labelers in refining their strategies to better align with expert feedback. By quantifying the impact of human feedback, we believe that influence functions can enhance feedback interpretability and contribute to scalable oversight in RLHF, helping labelers provide more accurate and consistent feedback. Source code is available at https://github.com/mintaywon/IF_RLHF",289552203,4,39,,
10.18653/v1/2025.acl-long.1392,Memorizing is Not Enough: Deep Knowledge Injection Through Reasoning,"Ruoxi Xu, Yunjie Ji, Boxi Cao, Yaojie Lu, Hongyu Lin, Xianpei Han, Ben He, Yingfei Sun, Xiangang Li, Le Sun",(missing journal),2025,(missing abstract),289552204,0,0,,
10.18653/v1/2025.acl-long.1346,Lexical Diversity-aware Relevance Assessment for Retrieval-Augmented Generation,"Zhange Zhang, Yuqing Ma, Yulong Wang, Shan He, Tianbo Wang, Siqi He, Jiakai Wang, Xianglong Liu",(missing journal),2025,(missing abstract),289552205,0,0,,
10.18653/v1/2025.acl-long.1312,SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation,"Zijun Yao, Weijian Qi, Liangming Pan, Shulin Cao, Linmei Hu, Weichuan Liu, Lei Hou, Juanzi Li",(missing journal),2025,(missing abstract),289552206,2,0,,
10.18653/v1/2025.acl-long.1217,iNews: A Multimodal Dataset for Modeling Personalized Affective Responses to News,"Tiancheng Hu, Nigel Collier",(missing journal),2025,(missing abstract),289552207,0,0,,
10.18653/v1/2025.acl-long.1288,RATIONALYST: Pre-training Process-Supervision for Improving Reasoning,"Dongwei Jiang, Guoxuan Wang, Yining Lu, Andrew Wang, Jingyu Zhang, Chuyu Liu, Benjamin Van Durme, Daniel Khashabi",(missing journal),2025,(missing abstract),289552208,0,0,,
10.18653/v1/2025.acl-long.1240,Safety Alignment via Constrained Knowledge Unlearning,"Shi Zesheng, Yucheng Zhou, Jing Li, Yuxin Jin, Yu Li, Daojing He, Fangming Liu, Saleh Alharbi, Jun Yu, Min Zhang",(missing journal),2025,(missing abstract),289552209,0,0,,
10.18653/v1/2025.acl-long.1294,Scaling Laws and Efficient Inference for Ternary Language Models,"Tejas Vaidhya, Ayush Kaushal, Vineet Jain, Francis Couture-Harpin, Prashant Shishodia, Majid Behbahani, Yuriy Nevmyvaka, Irina Rish",(missing journal),2025,(missing abstract),289552210,0,0,,
10.18653/v1/2025.acl-long.1314,Understanding the Dark Side of LLMs’ Intrinsic Self-Correction,"Qingjie Zhang, Di Wang, Hui Qian, Yiming Li, Tianwei Zhang, Minlie Huang, Ke Xu, Hewu Li, Yan Liu, Han Qiu",(missing journal),2025,(missing abstract),289552211,0,0,,
10.18653/v1/2025.acl-long.1305,"StitchLLM: Serving LLMs, One Block at a Time","Bodun Hu, Shuozhe Li, Saurabh Agarwal, Myungjin Lee, Akshay Jajoo, Jiamin Li, Le Xu, Geon-Woo Kim, Donghyun Kim, Xu Hong, Amy Zhang, Aditya Akella",(missing journal),2025,(missing abstract),289552212,0,0,,
10.18653/v1/2025.acl-long.1255,Language Fusion for Parameter-Efficient Cross-lingual Transfer,"Philipp Borchert, Ivan Vulić, Marie‐Francine Moens, Jochen De Weerdt",(missing journal),2025,(missing abstract),289552213,0,0,,
10.18653/v1/2025.acl-long.1282,MTSA: Multi-turn Safety Alignment for LLMs through Multi-round Red-teaming,"Wei Guo, Jing Li, Wenya Wang, Yu Li, Daojing He, Jun Yu, Min Zhang",(missing journal),2025,(missing abstract),289552214,0,0,,
10.18653/v1/2025.acl-long.1266,LLM Agents Making Agent Tools,"Georg Wölflein, Dyke Ferber, Daniel Truhn, Ognjen Arandjelović, Jakob Nikolas Kather",(missing journal),2025,(missing abstract),289552215,2,0,,
10.18653/v1/2025.acl-long.1259,Dehumanizing Machines: Mitigating Anthropomorphic Behaviors in Text Generation Systems,"Myra Cheng, Su Lin Blodgett, Alicia DeVrio, Lisa Egede, Alexandra Olteanu",(missing journal),2025,(missing abstract),289552216,2,0,,
10.18653/v1/2025.acl-long.1235,ReflectDiffu: Reflect between Emotion-intent Contagion and Mimicry for Empathetic Response Generation via a RL-Diffusion Framework,"Jiahao Yuan, Zixiang Di, Zhongyu Cui, Gaokhia Yang, Usman Naseem",(missing journal),2025,(missing abstract),289552217,0,0,,
10.18653/v1/2025.acl-long.1147,T2A-Feedback: Improving Basic Capabilities of Text-to-Audio Generation via Fine-grained AI Feedback,"Z.Y. Wang, Lei Ke, Chen Zhu, Jiawei Huang, S. Zhou, Luping Liu, Xize Cheng, Shengpeng Ji, Zhenhui Ye, Tao Jin, Zhou Zhao",(missing journal),2025,(missing abstract),289554015,0,0,,
10.18653/v1/2025.acl-long.1120,Are We in the AI-Generated Text World Already? Quantifying and Monitoring AIGT on Social Media,"Zhen Sun, Zongmin Zhang, Xinyue Shen, Ziyi Zhang, Yule Liu, Michael Backes, Yang Zhang, Xinlei He",(missing journal),2025,(missing abstract),289554016,1,0,,
10.18653/v1/2025.acl-long.1125,Beyond Logits: Aligning Feature Dynamics for Effective Knowledge Distillation,"Guoqiang Gong, Jiaxing Wang, Jin Xu, Deping Xiang, Zicheng Zhang, Leqi Shen, Yifeng Zhang, JunhuaShu JunhuaShu, ZhaolongXing ZhaolongXing, Zhen Chen, Pengzhang Liu, Ke Zhang",(missing journal),2025,(missing abstract),289554017,0,0,,
10.18653/v1/2025.acl-long.1079,IOPO: Empowering LLMs with Complex Instruction Following via Input-Output Preference Optimization,"Xinghua Zhang, Hou‐Yong Yu, Cheng Fu, Fei Huang, Yongbin Li",(missing journal),2025,(missing abstract),289554018,0,0,,
10.18653/v1/2025.acl-long.1154,Generating Plausible Distractors for Multiple-Choice Questions via Student Choice Prediction,"Y. Lee, Suin Kim, Yohan Jo",(missing journal),2025,(missing abstract),289554019,0,0,,
10.18653/v1/2025.acl-long.950,"A Modular Approach for Clinical SLMs Driven by Synthetic Data with Pre-Instruction Tuning, Model Merging, and Clinical-Tasks Alignment","Jean-Philippe Corbeil, Amin Dada, Jean-Michel Attendu, Asma Ben Abacha, Alessandro Sordoni, Lucas Caccia, Francois Beaulieu, Thomas Lin, Jens Kleesiek, Paul Vozila",Annual Meeting of the Association for Computational Linguistics,2025,"High computation costs and latency of large language models such as GPT-4 have limited their deployment in clinical settings. Small language models (SLMs) offer a cost-effective alternative, but their limited capacity requires biomedical domain adaptation, which remains challenging. An additional bottleneck is the unavailability and high sensitivity of clinical data. To address these challenges, we propose a novel framework for adapting SLMs into high-performing clinical models. We introduce the MediPhi collection of 3.8B-parameter SLMs developed with our novel framework: pre-instruction tuning of experts on relevant medical and clinical corpora (PMC, Medical Guideline, MedWiki, etc.), model merging, and clinical-tasks alignment. To cover most clinical tasks, we extended the CLUE benchmark to CLUE+, doubling its size. Our expert models deliver relative improvements on this benchmark over the base model without any task-specific fine-tuning: 64.3% on medical entities, 49.5% on radiology reports, and 44% on ICD-10 coding (outperforming GPT-4-0125 by 14%). We unify the expert models into MediPhi via model merging, preserving gains across benchmarks. Furthermore, we built the MediFlow collection, a synthetic dataset of 2.5 million high-quality instructions on 14 medical NLP tasks, 98 fine-grained document types, and JSON format support. Alignment of MediPhi using supervised fine-tuning and direct preference optimization achieves further gains of 18.9% on average.",289554020,9,63,,
10.18653/v1/2025.acl-long.988,Improving Language and Modality Transfer in Translation by Character-level Modeling,"Ioannis Tsiamas, David Dale, Marta R. Costa‐jussà",(missing journal),2025,(missing abstract),289554021,0,0,,
10.18653/v1/2025.acl-long.1027,VF-Eval: Evaluating Multimodal LLMs for Generating Feedback on AIGC Videos,"Tianyu Song, Tao Hu, Guo Gan, Yilun Zhao",(missing journal),2025,(missing abstract),289554022,0,0,,
10.18653/v1/2025.acl-long.1066,Evaluating Visual and Cultural Interpretation: The K-Viscuit Benchmark with Human-VLM Collaboration,"ChaeHun Park, Yujin Baek, Jaeseok Kim, Yu‐Jung Heo, Du-Seong Chang, Jaegul Choo",(missing journal),2025,(missing abstract),289554023,0,0,,
10.18653/v1/2025.acl-long.997,Align-SLM: Textless Spoken Language Models with Reinforcement Learning from AI Feedback,"Guan-Ting Lin, Prashanth Gurunath Shivakumar, Aditya Gourav, Yile Gu, Ankur Gandhe, Hung-yi Lee, Ivan Bulyko",(missing journal),2025,(missing abstract),289554024,0,0,,
10.18653/v1/2025.acl-long.962,GRACE: A Granular Benchmark for Evaluating Model Calibration against Human Calibration,"Yoo Yeon Sung, Eve Fleisig, Yu Hou, Ishan Upadhyay, Jordan Lee Boyd-Graber",(missing journal),2025,(missing abstract),289554025,0,0,,
10.18653/v1/2025.acl-long.982,AIR-Bench: Automated Heterogeneous Information Retrieval Benchmark,"Jianlyu Chen, Nan Wang, Chaofan Li, Bo Wang, Shitao Xiao, Han Xiao, Hao Liao, Defu Lian, Zheng Liu",(missing journal),2025,(missing abstract),289554026,0,0,,
10.18653/v1/2025.acl-long.989,DialUp! Modeling the Language Continuum by Adapting Models to Dialects and Dialects to Models,"Niyati Bafna, Eun-Young Chang, Nathaniel Romney Robinson, David R. Mortensen, Kenton Murray, David Yarowsky, Hale Sirin",(missing journal),2025,(missing abstract),289554027,0,0,,
10.18653/v1/2025.acl-long.896,RARE: Retrieval-Augmented Reasoning Enhancement for Large Language Models,"Hieu Tran, Zonghai Yao, Zhichao Yang, Junda Wang, Yifan Zhang, Shuo Han, Feiyun Ouyang, Yu Hong",(missing journal),2025,(missing abstract),289554028,0,0,,
10.18653/v1/2025.acl-long.1004,Partial Colexifications Improve Concept Embeddings,"Arne Rubehn, Johann-Mattis List",(missing journal),2025,(missing abstract),289554029,0,0,,
10.18653/v1/2025.acl-long.1057,PerSphere: A Comprehensive Framework for Multi-Faceted Perspective Retrieval and Summarization,"Yun Luo, Yingjie Li, Xiangkun Hu, Qinglin Qi, Fang Guo, Qipeng Guo, Zheng Zhang, Yue Zhang",(missing journal),2025,(missing abstract),289554030,0,0,,
10.18653/v1/2025.acl-long.1005,Improved Unbiased Watermark for Large Language Models,"Ruibo Chen, Yihan Wu, Junfeng Guo, Heng Huang",(missing journal),2025,(missing abstract),289554031,0,0,,
10.18653/v1/2025.acl-long.1028,Language Model Fine-Tuning on Scaled Survey Data for Predicting Distributions of Public Opinions,"Joseph Suh, Erfan Jahanparast, Suhong Moon, M.-S. Kang, Serina Chang",(missing journal),2025,(missing abstract),289554032,1,0,,
10.18653/v1/2025.acl-long.1000,Deep Temporal Reasoning in Video Language Models: A Cross-Linguistic Evaluation of Action Duration and Completion through Perfect Times,"Olga Loginova, Sofía Ortega Loguinova",(missing journal),2025,(missing abstract),289554033,0,0,,
10.18653/v1/2025.acl-long.961,ZIPA: A family of efficient models for multilingual phone recognition,"Jianguo Zhu, Farhan Samir, Eleanor Chodroff, David R. Mortensen",(missing journal),2025,(missing abstract),289554034,0,0,,
10.18653/v1/2025.acl-long.927,MemeQA: Holistic Evaluation for Meme Understanding,"Khoi P. N. Nguyen, Terrence Li, Dong-Jing Zhou, Gabriel Xiong, Pranav Balu, Nandhan Alahari, Alan Huang, Tanush Chauhan, Harshavardhan Bala, Emre Guzelordu, Affan Kashfi, Ao Xu, Suyesh Shrestha, Megan Kim Vu, Chunhui Wang, Vincent Ng",(missing journal),2025,(missing abstract),289554035,0,0,,
10.18653/v1/2025.acl-long.990,AutoMixAlign: Adaptive Data Mixing for Multi-Task Preference Optimization in LLMs,"Nicholas E. Corrado, Julian Katz-Samuels, Adithya M Devraj, Hyokun Yun, Chao Zhang, Yi Xu, Yi Pan, Bing Yin, Trishul Chilimbi",(missing journal),2025,(missing abstract),289554036,0,0,,
10.18653/v1/2025.acl-long.890,Can Indirect Prompt Injection Attacks Be Detected and Removed?,"Yulin Chen, Haoran Li, Yuan Sui, Ying He, Yue Liu, Yangqiu Song, Bryan Hooi",(missing journal),2025,(missing abstract),289554037,0,0,,
10.18653/v1/2025.acl-long.938,KERL: Knowledge-Enhanced Personalized Recipe Recommendation using Large Language Models,"Mohbat Tharani, Mohammed J. Zaki",(missing journal),2025,(missing abstract),289554038,0,0,,
10.18653/v1/2025.acl-long.883,Exploring LLMs’ Ability to Spontaneously and Conditionally Modify Moral Expressions through Text Manipulation,"Candida M. Greco, Lucio La Cava, Lorenzo Zangari, Andrea Tagarelli",(missing journal),2025,(missing abstract),289554039,0,0,,
10.18653/v1/2025.acl-long.789,Enabling LLM Knowledge Analysis via Extensive Materialization,"Yujia Hu, Tuan-Phong Nguyen, Shrestha Ghosh, Simon Razniewski",Annual Meeting of the Association for Computational Linguistics,2025,"Large language models (LLMs) have majorly advanced NLP and AI, and next to their ability to perform a wide range of procedural tasks, a major success factor is their internalized factual knowledge. Since Petroni et al. (2019), analyzing this knowledge has gained attention. However, most approaches investigate one question at a time via modest-sized pre-defined samples, introducing an ``availability bias'' (Tversky&Kahnemann, 1973) that prevents the analysis of knowledge (or beliefs) of LLMs beyond the experimenter's predisposition. To address this challenge, we propose a novel methodology to comprehensively materialize an LLM's factual knowledge through recursive querying and result consolidation. Our approach is a milestone for LLM research, for the first time providing constructive insights into the scope and structure of LLM knowledge (or beliefs). As a prototype, we build GPTKB, a knowledge base (KB) comprising 101 million relational triples for over 2.9 million entities from GPT-4o-mini. We use GPTKB to exemplarily analyze GPT-4o-mini's factual knowledge in terms of scale, accuracy, bias, cutoff and consistency, at the same time. GPTKB is accessible at https://gptkb.org",289554041,7,40,,
10.18653/v1/2025.acl-long.791,"Llama See, Llama Do: A Mechanistic Perspective on Contextual Entrainment and Distraction in LLMs","Jingcheng Niu, Xingdi Yuan, Tong Wang, Hamidreza Saghir, Amir H. Abdi",(missing journal),2025,(missing abstract),289554042,0,0,,
10.18653/v1/2025.acl-long.852,SCOP: Evaluating the Comprehension Process of Large Language Models from a Cognitive View,"Yongjie Xiao, Hongru Liang, Peixin Qin, Yao Zhang, Wenqiang Lei",(missing journal),2025,(missing abstract),289554043,0,0,,
10.18653/v1/2025.acl-long.859,A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns,"Tianyi Men, Pengfei Cao, Zhuoran Jin, Yubo Chen, Kang Liu, Junfeng Zhao",(missing journal),2025,(missing abstract),289554044,0,0,,
10.18653/v1/2025.acl-long.842,ImpliHateVid: A Benchmark Dataset and Two-stage Contrastive Learning Framework for Implicit Hate Speech Detection in Videos,"Mohammad Zia Ur Rehman, Ankita Bhatnagar, Omkar Kabde, Shubhi Bansal, Nagendra Kumar",Annual Meeting of the Association for Computational Linguistics,2025,"The existing research has primarily focused on text and image-based hate speech detection, video-based approaches remain underexplored. In this work, we introduce a novel dataset, ImpliHateVid, specifically curated for implicit hate speech detection in videos. ImpliHateVid consists of 2,009 videos comprising 509 implicit hate videos, 500 explicit hate videos, and 1,000 non-hate videos, making it one of the first large-scale video datasets dedicated to implicit hate detection. We also propose a novel two-stage contrastive learning framework for hate speech detection in videos. In the first stage, we train modality-specific encoders for audio, text, and image using contrastive loss by concatenating features from the three encoders. In the second stage, we train cross-encoders using contrastive learning to refine multimodal representations. Additionally, we incorporate sentiment, emotion, and caption-based features to enhance implicit hate detection. We evaluate our method on two datasets, ImpliHateVid for implicit hate speech detection and another dataset for general hate speech detection in videos, HateMM dataset, demonstrating the effectiveness of the proposed multimodal contrastive learning for hateful content detection in videos and the significance of our dataset.",289554045,6,29,,
10.18653/v1/2025.acl-long.809,Explaining Matters: Leveraging Definitions and Semantic Expansion for Sexism Detection,"Sahrish Khan, Arshad Jhumka, Gabriele Pergola",(missing journal),2025,(missing abstract),289554046,0,0,,
10.18653/v1/2025.acl-long.855,Scaling Text-Rich Image Understanding via Code-Guided Synthetic Multimodal Data Generation,"Yue Yang, Ajay Patel, Matt Deitke, Tanmay Gupta, Luca Weihs, Andrew Head, Mark Yatskar, Chris Callison-Burch, Ranjay Krishna, Aniruddha Kembhavi, Christopher M. Clark",(missing journal),2025,(missing abstract),289554047,3,0,,
10.18653/v1/2025.acl-long.1167,Don’t Get Lost in the Trees: Streamlining LLM Reasoning by Overcoming Tree Search Exploration Pitfalls,"Ante Wang, Linfeng Song, Tian Ye, Dian Yu, Haitao Mi, Xiangyu Duan, Zhaopeng Tu, Jinsong Su, Yu Dong",(missing journal),2025,(missing abstract),289554048,2,0,,
10.18653/v1/2025.acl-long.1191,Dialogue-RAG: Enhancing Retrieval for LLMs via Node-Linking Utterance Rewriting,"Qiwei Li, Teng Xiao, Zuchao Li, Ping Wang, Mengjia Shen, Hai Zhao",(missing journal),2025,(missing abstract),289554049,0,0,,
10.18653/v1/2025.acl-long.1181,Evaluating the Evaluation of Diversity in Commonsense Generation,"Tianhui Zhang, Bei Peng, Danushka Bollegala",(missing journal),2025,(missing abstract),289554050,0,0,,
10.18653/v1/2025.acl-long.1183,ChemActor: Enhancing Automated Extraction of Chemical Synthesis Actions with LLM-Generated Data,"Shengdong Zhang, Ruijie Yu, Jidong Tian, Feng Zhu, Jiapeng Liu, Xiaokang Yang, Yaohui Jin, Yanyan Xu",(missing journal),2025,(missing abstract),289554051,0,0,,
10.18653/v1/2025.acl-long.1175,Enhancing Retrieval-Augmented Generation via Evidence Tree Search,"Hao Sun, Hengyi Cai, Yuchen Li, Xuanbo Fan, Xiaochi Wei, Shuaiqiang Wang, Yan Zhang, Dawei Yin",(missing journal),2025,(missing abstract),289554052,0,0,,
10.18653/v1/2025.acl-long.749,PreP-OCR: A Complete Pipeline for Document Image Restoration and Enhanced OCR Accuracy,"Shuhao Guan, Moule Lin, Cheng-Zhong Xu, Xinyi Liu, Jinman Zhao, Jiacheng Fan, Qi Xu, Derek Greene",Annual Meeting of the Association for Computational Linguistics,2025,"This paper introduces PreP-OCR, a two-stage pipeline that combines document image restoration with semantic-aware post-OCR correction to enhance both visual clarity and textual consistency, thereby improving text extraction from degraded historical documents. First, we synthesize document-image pairs from plaintext, rendering them with diverse fonts and layouts and then applying a randomly ordered set of degradation operations. An image restoration model is trained on this synthetic data, using multi-directional patch extraction and fusion to process large images. Second, a ByT5 post-OCR model, fine-tuned on synthetic historical text pairs, addresses remaining OCR errors. Detailed experiments on 13,831 pages of real historical documents in English, French, and Spanish show that the PreP-OCR pipeline reduces character error rates by 63.9-70.3% compared to OCR on raw images. Our pipeline demonstrates the potential of integrating image restoration with linguistic error correction for digitizing historical archives.",289554053,5,60,,
10.18653/v1/2025.acl-long.744,A New Formulation of Zipf’s Meaning-Frequency Law through Contextual Diversity,"Ryo Nagata, Kumiko Tanaka‐Ishii",(missing journal),2025,(missing abstract),289554054,0,0,,
10.18653/v1/2025.acl-long.766,"FinanceReasoning: Benchmarking Financial Numerical Reasoning More Credible, Comprehensive and Challenging","Ziwei Tang, E Haihong, Z. Ma, Haoyang He, Jiacheng Liu, Zhongjun Yang, Zihua Rong, Rui Li, Kun Ji, Qing Huang, Xinyang Hu, Yang Liu, Zheng Quan",Annual Meeting of the Association for Computational Linguistics,2025,"We introduce FinanceReasoning, a novel benchmark designed to evaluate the reasoning capabilities of large reasoning models (LRMs) in financial numerical reasoning problems. Compared to existing benchmarks, our work provides three key advancements. (1) Credibility: We update 15.6% of the questions from four public datasets, annotating 908 new questions with detailed Python solutions and rigorously refining evaluation standards. This enables an accurate assessment of the reasoning improvements of LRMs. (2) Comprehensiveness: FinanceReasoning covers 67.8% of financial concepts and formulas, significantly surpassing existing datasets. Additionally, we construct 3,133 Python-formatted functions, which enhances LRMs'financial reasoning capabilities through refined knowledge (e.g., 83.2% $\rightarrow$ 91.6% for GPT-4o). (3) Challenge: Models are required to apply multiple financial formulas for precise numerical reasoning on 238 Hard problems. The best-performing model (i.e., OpenAI o1 with PoT) achieves 89.1% accuracy, yet LRMs still face challenges in numerical precision. We demonstrate that combining Reasoner and Programmer models can effectively enhance LRMs'performance (e.g., 83.2% $\rightarrow$ 87.8% for DeepSeek-R1). Our work paves the way for future research on evaluating and improving LRMs in domain-specific complex reasoning tasks.",289554055,3,19,,
10.18653/v1/2025.acl-long.762,MLAS-LoRA: Language-Aware Parameters Detection and LoRA-Based Knowledge Transfer for Multilingual Machine Translation,"Tianyu Dong, Bo Li, Jinsong Liu, Shaolin Zhu, Deyi Xiong",(missing journal),2025,(missing abstract),289554056,1,0,,
10.18653/v1/2025.acl-long.727,Circuit Compositions: Exploring Modular Structures in Transformer-Based Language Models,"Philipp Mondorf, Sondre Wold, Barbara Plank",(missing journal),2025,(missing abstract),289554057,0,0,,
10.18653/v1/2025.acl-long.706,Instruction Tuning on Public Government and Cultural Data for Low-Resource Language: a Case Study in Kazakh,"Nurkhan Laiyk, Daniil Orel, Rituraj Joshi, Maiya Goloburda, Yuxia Wang, Preslav Nakov, Fajri Koto",(missing journal),2025,(missing abstract),289554058,0,0,,
10.18653/v1/2025.acl-long.661,Cross-Lingual Generalization and Compression: From Language-Specific to Shared Neurons,"Frederick Riemenschneider, Anette Frank",(missing journal),2025,(missing abstract),289554059,1,0,,
10.18653/v1/2025.acl-long.723,Towards Robust ESG Analysis Against Greenwashing Risks: Aspect-Action Analysis with Cross-Category Generalization,"Keane Ong, Rui Mao, Deeksha Varshney, Erik Cambria, Gianmarco Mengaldo",(missing journal),2025,(missing abstract),289554060,1,0,,ACL
10.18653/v1/2025.acl-long.702,Towards Multi-dimensional Evaluation of LLM Summarization across Domains and Languages,"Hyangsuk Min, Yuho Lee, Minjeong Ban, Jiaqi Deng, Na-yeong Kim, Taewon Yun, Hang Su, Jason Cai, Hwanjun Song",(missing journal),2025,(missing abstract),289554061,0,0,,
10.18653/v1/2025.acl-long.655,Adaptive Tool Use in Large Language Models with Meta-Cognition Trigger,"Wenjun Li, Dexun Li, Kuicai Dong, Cong Zhang, Hao Zhang, Weiwen Liu, Yasheng Wang, Ruiming Tang, Yong Liu",(missing journal),2025,(missing abstract),289554062,0,0,,
10.18653/v1/2025.acl-long.726,Two Intermediate Translations Are Better Than One: Fine-tuning LLMs for Document-level Translation Refinement,"Yichen Dong, Xinglin Lyu, Junhui Li, Daimeng Wei, Min Zhang, Shimin Tao, Hao Yang",(missing journal),2025,(missing abstract),289554063,0,0,,
10.18653/v1/2025.acl-long.599,GiFT: Gibbs Fine-Tuning for Code Generation,"Haochen Li, Wu-chun Feng, Xin Zhou, Zhiqi Shen",(missing journal),2025,(missing abstract),289554064,0,0,,
10.18653/v1/2025.acl-long.676,GALLa: Graph Aligned Large Language Models for Improved Source Code Understanding,"Ziyin Zhang, Hang Yu, S. Lee, Peng Di, Jianguo Li, Rui Wang",(missing journal),2025,(missing abstract),289554065,0,0,,
10.18653/v1/2025.acl-long.679,HSCR: Hierarchical Self-Contrastive Rewarding for Aligning Medical Vision Language Models,"Songtao Jiang, Yan Zhang, Yeying Jin, Zhihang Tang, Yangyang Wu, Feng Yang, Wu Jian, Zuozhu Liu",(missing journal),2025,(missing abstract),289554066,1,0,,
10.18653/v1/2025.acl-long.745,The Mirage of Model Editing: Revisiting Evaluation in the Wild,"Wanli Yang, Fei Sun, Jane C. Tan, Xinyu Ma, Qi Cao, Dawei Yin, Huawei Shen, Xueqi Cheng",(missing journal),2025,(missing abstract),289554067,0,0,,
10.18653/v1/2025.acl-long.648,Can LLM Watermarks Robustly Prevent Unauthorized Knowledge Distillation?,"Leyi Pan, Aiwei Liu, Shiyu Huang, Yijian Lu, Xuming Hu, Lijie Wen, Irwin King, Philip S. Yu",(missing journal),2025,(missing abstract),289554068,1,0,,
10.18653/v1/2025.acl-long.635,Interactive Evolution: A Neural-Symbolic Self-Training Framework For Large Language Models,"Fangzhi Xu, Qiushi Sun, Kanzhi Cheng, Jun Liu, Yu Qiao, Zhiyong Wu",(missing journal),2025,(missing abstract),289554069,0,0,,
10.18653/v1/2025.acl-long.497,Multi-level Relevance Document Identifier Learning for Generative Retrieval,"Fuwei Zhang, Xiaoyu Liu, Xinyu Jia, Yong Zhang, Shuai Zhang, Xiang Li, Deqing Wang, Wei Lin, Zhao Zhang",(missing journal),2025,(missing abstract),289554070,0,0,,
10.18653/v1/2025.acl-long.515,MCS-Bench: A Comprehensive Benchmark for Evaluating Multimodal Large Language Models in Chinese Classical Studies,"Yang Liu, Jiahuan Cao, Hiuyi Cheng, Yongxin Shi, Kai Ding, Lianwen Jin",(missing journal),2025,(missing abstract),289554071,0,0,,
10.18653/v1/2025.acl-long.581,LongRecipe: Recipe for Efficient Long Context Generalization in Large Language Models,"Zhiyuan Hu, Yuliang Liu, Jinman Zhao, Suyuchen Wang, WangYan WangYan, Wei Shen, Qing Gu, Luu Anh Tuan, See-Kiong Ng, Zhiwei Jiang, Bryan Hooi",(missing journal),2025,(missing abstract),289554072,0,0,,
10.18653/v1/2025.acl-long.527,GainRAG: Preference Alignment in Retrieval-Augmented Generation through Gain Signal Synthesis,"Yi Jiang, Sendong Zhao, Jianbo Li, Haochun Wang, Bing Qin",(missing journal),2025,(missing abstract),289554073,1,0,,
10.18653/v1/2025.acl-long.481,Investigating and Extending Homans’ Social Exchange Theory with Large Language Model based Agents,"Lei Wang, Zhuo Zhang, Cheng Xu",(missing journal),2025,(missing abstract),289554074,0,0,,
10.18653/v1/2025.acl-long.475,PIG: Privacy Jailbreak Attack on LLMs via Gradient-based Iterative In-Context Optimization,"Yidan Wang, Yanan Cao, Yubing Ren, Fang Fang, Zheng Lin, Binxing Fang",(missing journal),2025,(missing abstract),289554075,0,0,,
10.18653/v1/2025.acl-long.437,SkillVerse : Assessing and Enhancing LLMs with Tree Evaluation,"Yufei Tian, Jiao Sun, Nanyun Peng, Z. Zhang",(missing journal),2025,(missing abstract),289554076,0,0,,
10.18653/v1/2025.acl-long.359,G-Safeguard: A Topology-Guided Security Lens and Treatment on LLM-based Multi-agent Systems,"Shilong Wang, Guibin Zhang, Miao Yu, Guancheng Wan, Fanqing Meng, Chunbao Guo, Kun Wang, Yang Wang",(missing journal),2025,(missing abstract),289554077,0,0,,
10.18653/v1/2025.acl-long.322,Learning to Rewrite: Generalized LLM-Generated Text Detection,"Wei Hao, Ran Li, Weiliang Zhao, Junfeng Yang, Chengzhi Mao",(missing journal),2025,(missing abstract),289554078,0,0,,
10.18653/v1/2025.acl-long.431,TripleFact: Defending Data Contamination in the Evaluation of LLM-driven Fake News Detection,"Xu Cheng, Nan Yan",(missing journal),2025,(missing abstract),289554079,0,0,,
10.18653/v1/2025.acl-long.390,CER: Confidence Enhanced Reasoning in LLMs,"Ali Razghandi, Seyed Mohammad Hadi Hosseini, Mahdieh Soleymani Baghshah",(missing journal),2025,(missing abstract),289554080,0,0,,
10.18653/v1/2025.acl-long.417,Self-Error-Instruct: Generalizing from Errors for LLMs Mathematical Reasoning,"Erxin Yu, J. Li, Ming Liao, Qi Zhu, Boyang Xue, M. Xu, Baojun Wang, Lanqing Hong, Fei Mi, Lifeng Shang",(missing journal),2025,(missing abstract),289554081,0,0,,
10.18653/v1/2025.acl-long.421,MultiAgentBench : Evaluating the Collaboration and Competition of LLM agents,"Kaiyi Zhu, Hongyi Du, Zhang Hong, Xiaocheng Yang, Shu Qing Guo, Zhe Wang, Zhihua Wang, Cheng Qian, Robert Tang, Heng Ji, Jiaxuan You",(missing journal),2025,(missing abstract),289554082,2,0,,
10.18653/v1/2025.acl-long.397,SynthesizeMe! Inducing Persona-Guided Prompts for Personalized Reward Models in LLMs,"Michael J. Ryan, Omar Shaikh, Aditri Bhagirath, Daniel Frees, William A. Held, Diyi Yang",(missing journal),2025,(missing abstract),289554083,0,0,,
10.18653/v1/2025.acl-long.284,Making FETCH! Happen: Finding Emergent Dog Whistles Through Common Habitats,"Kuleen Sasse, Carlos Aguirre, Isabel Cachola, Sharon Levy, Mark Dredze",(missing journal),2025,(missing abstract),289554084,0,0,,
10.18653/v1/2025.acl-long.259,Mitigating Selection Bias with Node Pruning and Auxiliary Options,"Hyeong Kyu Choi, Weijie Xu, Xue Chi, Stephanie Eckman, Chandan K. Reddy",(missing journal),2025,(missing abstract),289554087,0,0,,
10.18653/v1/2025.acl-long.183,LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks,"Yushi Bai, Shangqing Tu, Jiajie Zhang, Hao Peng, Xiaozhi Wang, Xin Lv, Shulin Cao, Jiazheng Xu, Lei Hou, Yuxiao Dong, Jie Tang, Juanzi Li",(missing journal),2025,(missing abstract),289559992,3,0,,
10.18653/v1/2025.acl-long.86,Normalized AOPC: Fixing Misleading Faithfulness Metrics for Feature Attributions Explainability,"Joakim Edin, Andreas Geert Motzfeldt, Casper L. Christensen, Tuukka Ruotsalo, Lars Maaløe, Maria Maistro",(missing journal),2025,(missing abstract),289559993,1,0,,
10.18653/v1/2025.acl-long.148,DioR: Adaptive Cognitive Detection and Contextual Retrieval Optimization for Dynamic Retrieval-Augmented Generation,"Hanghui Guo, Jia Xiong Zhu, Shimin Di, Weijie Shi, Zhiping Chen, Jiajie Xu",(missing journal),2025,(missing abstract),289559994,1,0,,
10.18653/v1/2025.acl-long.99,L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models,"Hyesung Jeon, Yulhwa Kim, Jae Joon Kim",Annual Meeting of the Association for Computational Linguistics,2025,"Due to the high memory and computational costs associated with large language models (LLMs), model compression techniques such as quantization, which reduces inference costs, and parameter-efficient fine-tuning (PEFT) methods like Low-Rank Adaptation (LoRA), which reduce training costs, have gained significant popularity. This trend has spurred active research into quantization-aware PEFT techniques, aimed at maintaining model accuracy while minimizing memory overhead during both inference and training. Previous quantization-aware PEFT methods typically apply post-training quantization (PTQ) to pre-trained LLMs, followed by PEFT to recover accuracy loss. Meanwhile, this approach has limitations in recovering the accuracy loss. In this paper, we propose L4Q, a method that integrates Quantization-Aware Training (QAT) with LoRA. By employing a memory-optimized layer design, L4Q significantly reduces QAT's memory overhead, making its training cost comparable to LoRA, while preserving the advantage of QAT in producing fully quantized LLMs with high accuracy. Our experiments demonstrate that this combined approach to quantization and fine-tuning achieves superior accuracy compared to decoupled fine-tuning schemes, particularly in 4-bit and 3-bit quantization, positioning L4Q as an efficient QAT solution. Using the LLaMA and Mistral models with instructional datasets, we showcase L4Q's capabilities in language tasks and few-shot learning.",289559995,6,44,,
10.18653/v1/2025.acl-long.82,Improve Vision Language Model Chain-of-thought Reasoning,"Ruohong Zhang, Bowen Zhang, Yanghao Li, Haotian Zhang, Zhiqing Sun, Zhe Gan, Yinfei Yang, Ruoming Pang, Yiming Yang",(missing journal),2025,(missing abstract),289559996,2,0,,
10.18653/v1/2025.acl-long.158,Refuse Whenever You Feel Unsafe: Improving Safety in LLMs via Decoupled Refusal Training,"Youliang Yuan, Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Jiahao Xu, Liang Tian, Pinjia He, Zhaopeng Tu",(missing journal),2025,(missing abstract),289559997,0,0,,
10.18653/v1/2025.acl-long.90,Algorithmic Fidelity of Large Language Models in Generating Synthetic German Public Opinions: A Case Study,"Bolei Ma, Berk Yoztyurk, Anna‐Carolina Haensch, Xinpeng Wang, Markus Herklotz, Frauke Kreuter, Barbara Plank, Matthias Aßenmacher",(missing journal),2025,(missing abstract),289559998,0,0,,
10.18653/v1/2025.acl-long.49,PunchBench: Benchmarking MLLMs in Multimodal Punchline Comprehension,"Kun Ouyang, Yuanxin Liu, Shicheng Li, Yi Liu, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun",(missing journal),2025,(missing abstract),289560003,0,0,,
10.18653/v1/2025.acl-long.1577,KRISTEVA: Close Reading as a Novel Task for Benchmarking Interpretive Reasoning,"Peiqi Sui, Juan Diego Rodríguez, Philippe Laban, Jennifer Murphy, Joseph P. Dexter, Richard Jean So, Samuel Baker, Pramit Chaudhuri",(missing journal),2025,(missing abstract),289560122,0,0,,
10.18653/v1/2025.acl-long.1519,Enabling Chatbots with Eyes and Ears: An Immersive Multimodal Conversation System for Dynamic Interactions,"Jihyoung Jang, Minwook Bae, Minji Kim, Dilek Hakkani-Tür, Hyounghun Kim",(missing journal),2025,(missing abstract),289560124,0,0,,
10.18653/v1/2025.acl-long.1516,SeedBench: A Multi-task Benchmark for Evaluating Large Language Models in Seed Science,"Jie Ying, Zihong Chen, Zhefan Wang, Wanli Jiang, Chenyang Wang, Zhonghang Yuan, Haoyang Su, Huanjun Kong, Fan Yang, Nanqing Dong",(missing journal),2025,(missing abstract),289560125,0,0,,
10.18653/v1/2025.acl-long.1601,"AfroCS-xs: Creating a Compact, High-Quality, Human-Validated Code-Switched Dataset for African Languages","Kayode Olaleye, Arturo Oncevay, Mathieu Sibue, Nompumelelo Zondi, Michelle Terblanche, Sibongile Mapikitla, Richard Lastrucci, Charese Smiley, Vukosi Marivate",(missing journal),2025,(missing abstract),289560126,0,0,,
10.18653/v1/2025.acl-long.1521,TACLR: A Scalable and Efficient Retrieval-based Method for Industrial Product Attribute Value Identification,"Yun Su, Huitian Zou, Lin Sun, Ting Zhang, Haiyang Yang, Yu Chen, David Lo, Qinghe Zhang, Shuguang Han, Jufeng Chen",(missing journal),2025,(missing abstract),289560127,0,0,,
10.18653/v1/2025.acl-long.1434,Beyond True or False: Retrieval-Augmented Hierarchical Analysis of Nuanced Claims,"Priyanka Kargupta, Runchu Tian, Jiawei Han",(missing journal),2025,(missing abstract),289560128,0,0,,
10.18653/v1/2025.acl-long.1460,Map&amp;Make: Schema Guided Text to Table Generation,"Naman Ahuja, Fenil Denish Bardoliya, Chitta Baral, Vivek Gupta",(missing journal),2025,(missing abstract),289560129,0,0,,
10.18653/v1/2025.acl-long.1426,FinMME: Benchmark Dataset for Financial Multi-Modal Reasoning Evaluation,"Junyu Luo, Zong-Hong Kou, Liming Yang, Xiao Luo, Jinsheng Huang, Zhiping Xiao, Jingshu Peng, Chengzhong Liu, Jiaming Ji, Xuanzhe Liu, Sirui Han, Ming Zhang, Yike Guo",(missing journal),2025,(missing abstract),289560130,2,0,,
10.18653/v1/2025.acl-long.1422,Tree-of-Debate: Multi-Persona Debate Trees Elicit Critical Thinking for Scientific Comparative Analysis,"Priyanka Kargupta, Ishika Agarwal, Tal August, Jiawei Han",(missing journal),2025,(missing abstract),289560131,0,0,,
10.18653/v1/2025.acl-long.1404,Robust Utility-Preserving Text Anonymization Based on Large Language Models,"Tianyu Yang, Xiaodan Zhu, Iryna Gurevych",(missing journal),2025,(missing abstract),289560132,1,0,,
10.18653/v1/2025.acl-long.1337,FOCUS: Evaluating Pre-trained Vision-Language Models on Underspecification Reasoning,"Kankan Zhou, Eason Lai, Kyriakos Mouratidis, Jing Jiang",(missing journal),2025,(missing abstract),289560133,0,0,,
10.18653/v1/2025.acl-long.1334,T2I-FactualBench: Benchmarking the Factuality of Text-to-Image Models with Knowledge-Intensive Concepts,"Ziwei Huang, Wanggui He, Qian Long, Yandi Wang, Haoyuan Li, Zhelun Yu, Fangxun Shu, Weilong Dai, Hao Jiang, Fei Wu, Leilei Gan",(missing journal),2025,(missing abstract),289560134,0,0,,
10.18653/v1/2025.acl-long.1354,Gödel Agent: A Self-Referential Agent Framework for Recursively Self-Improvement,"Yin Xiong, Xinyi Wang, Liangming Pan, Lin Li, Xiaojun Wan, William Yang Wang",(missing journal),2025,(missing abstract),289560135,2,0,,
10.18653/v1/2025.acl-long.1378,LLM-based Rumor Detection via Influence Guided Sample Selection and Game-based Perspective Analysis,"Zhiliang Tian, Jingyuan Huang, Zejiang He, Zhen Huang, Menglong Lu, Linbo Qiao, Songzhu Mei, Yijie Wang, Dongsheng Li",(missing journal),2025,(missing abstract),289560136,0,0,,
10.18653/v1/2025.acl-long.1349,Chinese Inertial GAN for Handwriting Signal Generation and Recognition,"Yifeng Wang, Yi Zhao",(missing journal),2025,(missing abstract),289560137,0,0,,
10.18653/v1/2025.acl-long.1394,Pretraining Context Compressor for Large Language Models with Embedding-Based Memory,"Yu‐Hong Dai, Jianxun Lian, Yitian Huang, Wei Zhang, Mingyang Zhou, Mingqi Wu, Xing Xie, Hao Liao",(missing journal),2025,(missing abstract),289560138,0,0,,
10.18653/v1/2025.acl-long.1359,Query-driven Document-level Scientific Evidence Extraction from Biomedical Studies,"Massimiliano Pronesti, Joao H. Bettencourt‐Silva, Paul Flanagan, Alessandra Pascale, Oisín Redmond, Anja Belz, Yufang Hou",(missing journal),2025,(missing abstract),289560139,0,0,,
10.18653/v1/2025.acl-long.1225,GeLLM³O: Generalizing Large Language Models for Multi-property Molecule Optimization,"Vishal Dey, Xiao Hu, Xia Ning",(missing journal),2025,(missing abstract),289560140,0,0,,
10.18653/v1/2025.acl-long.1268,QG-SMS: Enhancing Test Item Analysis via Student Modeling and Simulation,"Bang H. Nguyen, Tingting Du, Mengxia Yu, Lawrence Angrave, Jiang Meng",(missing journal),2025,(missing abstract),289560141,1,0,,
10.18653/v1/2025.acl-long.1249,All That Glitters is Not Novel: Plagiarism in AI Generated Research,"Tarun Gupta, Danish Pruthi",(missing journal),2025,(missing abstract),289560142,0,0,,
10.18653/v1/2025.acl-long.1119,VITAL: A New Dataset for Benchmarking Pluralistic Alignment in Healthcare,"Ashalatha Shetty, Amin Beheshti, Mark Dras, Usman Naseem",(missing journal),2025,(missing abstract),289561973,0,0,,
10.18653/v1/2025.acl-long.1032,On Generalization across Measurement Systems: LLMs Entail More Test-Time Compute for Underrepresented Cultures,"Minh Duc Bui, K. Park, Goran Glavaš, Fabian David Schmidt, Katharina Von Der Wense",(missing journal),2025,(missing abstract),289561974,0,0,,
10.18653/v1/2025.acl-long.1039,K/DA: Automated Data Generation Pipeline for Detoxifying Implicitly Offensive Language in Korean,"Minkyeong Jeon, H. David Jeong, Y. Kim, Jiyoung Kim, Jae Youl Cho, Byung-Jun Lee",(missing journal),2025,(missing abstract),289561975,0,0,,
10.18653/v1/2025.acl-long.972,AlignDistil: Token-Level Language Model Alignment as Adaptive Policy Distillation,"Songming Zhang, Xue Zhang, Tong Zhang, Bojie Hu, Yufeng Chen, Jinan Xu",(missing journal),2025,(missing abstract),289561976,0,0,,
10.18653/v1/2025.acl-long.1003,Infogen: Generating Complex Statistical Infographics from Documents,"Akash Ghosh, Aparna Garimella, Pritika Ramu, Sambaran Bandyopadhyay, Sriparna Saha",Annual Meeting of the Association for Computational Linguistics,2025,"Statistical infographics are powerful tools that simplify complex data into visually engaging and easy-to-understand formats. Despite advancements in AI, particularly with LLMs, existing efforts have been limited to generating simple charts, with no prior work addressing the creation of complex infographics from text-heavy documents that demand a deep understanding of the content. We address this gap by introducing the task of generating statistical infographics composed of multiple sub-charts (e.g., line, bar, pie) that are contextually accurate, insightful, and visually aligned. To achieve this, we define infographic metadata that includes its title and textual insights, along with sub-chart-specific details such as their corresponding data and alignment. We also present Infodat, the first benchmark dataset for text-to-infographic metadata generation, where each sample links a document to its metadata. We propose Infogen, a two-stage framework where fine-tuned LLMs first generate metadata, which is then converted into infographic code. Extensive evaluations on Infodat demonstrate that Infogen achieves state-of-the-art performance, outperforming both closed and open-source LLMs in text-to-statistical infographic generation.",289561977,1,24,,
10.18653/v1/2025.acl-long.1053,VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search,"Yikun Wang, Siyin Wang, Qinyuan Cheng, Zhaoye Fei, Liang Ding, Qipeng Guo, Dacheng Tao, Xipeng Qiu",(missing journal),2025,(missing abstract),289561978,0,0,,
10.18653/v1/2025.acl-long.815,Neuron-Level Sequential Editing for Large Language Models,"H. B. Jiang, Junfeng Fang, Tianyu Zhang, Baolong Bi, An Zhang, Ruipeng Wang, Liang Tao, Xiang Wang",(missing journal),2025,(missing abstract),289561979,1,0,,
10.18653/v1/2025.acl-long.811,PhysReason: A Comprehensive Benchmark towards Physics-Based Reasoning,"Xinyu Zhang, Yuxuan Dong, Yanrui Wu, Jiaxing Huang, Chengyou Jia, Basura Fernando, Mike Zheng Shou, Lingling Zhang, Jun Liu",(missing journal),2025,(missing abstract),289561980,3,0,,
10.18653/v1/2025.acl-long.873,SceneGenAgent: Precise Industrial Scene Generation with Coding Agent,"Xia Xiao, Dan Zhang, Zibo Liao, Zhenyu Hou, T. R. Sun, Jing Li, Ling Fu, Yuxiao Dong",(missing journal),2025,(missing abstract),289561981,0,0,,
10.18653/v1/2025.acl-long.879,When Harry Meets Superman: The Role of The Interlocutor in Persona-Based Dialogue Generation,"Daniela Occhipinti, Marco Guerini, Malvina Nissim",(missing journal),2025,(missing abstract),289561982,0,0,,
10.18653/v1/2025.acl-long.860,Meta-Learning Neural Mechanisms rather than Bayesian Priors,"Michael Goodale, Salvador Mascarenhas, Yair Lakretz",(missing journal),2025,(missing abstract),289561983,0,0,,
10.18653/v1/2025.acl-long.830,EventRAG: Enhancing LLM Generation with Event Knowledge Graphs,"Zhi-Xue Yang, Yilin Wang, Zhengyan Shi, Yuan Yao, Lei Liang, Keyan Ding, Emine Yılmaz, Huajun Chen, Qiang Zhang",(missing journal),2025,(missing abstract),289561984,0,0,,
10.18653/v1/2025.acl-long.1210,Multiple LLM Agents Debate for Equitable Cultural Alignment,"Dayeon Ki, Rachel Rudinger, Tianyi Zhou, Marine Carpuat",(missing journal),2025,(missing abstract),289561985,0,0,,
10.18653/v1/2025.acl-long.1179,InstructPart: Task-Oriented Part Segmentation with Instruction Reasoning,"Zifu Wan, Yaqi Xie, Ce Zhang, Zhiqiu Lin, Zihan Wang, Simon Stepputtis, Deva Ramanan, Katia Sycara",(missing journal),2025,(missing abstract),289561986,0,0,,
10.18653/v1/2025.acl-long.1196,Don’t Reinvent the Wheel: Efficient Instruction-Following Text Embedding based on Guided Space Transformation,"Yingchaojie Feng, Yiqun Sun, Yandong Sun, Minfeng Zhu, Qiang Huang, Anthony K. H. Tung, Wei Chen",(missing journal),2025,(missing abstract),289561987,0,0,,
10.18653/v1/2025.acl-long.1190,FastMCTS: A Simple Sampling Strategy for Data Synthesis,"Peiji Li, Kai Lv, Yunfan Shao, Ye Ma, Linyang Li, Xuemei Zheng, Xipeng Qiu, Qipeng Guo",(missing journal),2025,(missing abstract),289561988,0,0,,
10.18653/v1/2025.acl-long.1202,Graph Counselor: Adaptive Graph Exploration via Multi-Agent Synergy to Enhance LLM Reasoning,"Junqi Gao, Xiang Zou, Ying Ai, Dong Li, Y. Niu, Biqing Qi, Jianxing Liu",(missing journal),2025,(missing abstract),289561989,0,0,,
10.18653/v1/2025.acl-long.757,MasRouter: Learning to Route LLMs for Multi-Agent Systems,"Yanwei Yue, Guibin Zhang, Boyang Liu, Guancheng Wan, Kun Wang, Dawei Cheng, Qi Yan",(missing journal),2025,(missing abstract),289561990,0,0,,
10.18653/v1/2025.acl-long.687,Innovative Image Fraud Detection with Cross-Sample Anomaly Analysis: The Power of LLMs,"Qiwen Wang, Junqi Yang, Zhimin Lin, Zhiping Ying, Weiqiang Wang, Lin Chen",(missing journal),2025,(missing abstract),289561991,0,0,,
10.18653/v1/2025.acl-long.660,PQR: Improving Dense Retrieval via Potential Query Modeling,"Junfeng Kang, Rui Li, Qi Liu, Yanjiang Chen, Zheng Zhang, Junzhe Jiang, Heng Yu, Yu Su",(missing journal),2025,(missing abstract),289561992,0,0,,
10.18653/v1/2025.acl-long.680,MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale,"Jiawei Guo, Tianyu Zheng, Yi‐Zhi Li, Yuelin Bai, Bo Li, Yubo Wang, K. J. Zhu, Graham Neubig, Wenhu Chen, Yue Xiang",(missing journal),2025,(missing abstract),289561993,0,0,,
10.18653/v1/2025.acl-long.585,Generative Psycho-Lexical Approach for Constructing Value Systems in Large Language Models,"Haoran Ye, Tianze Zhang, Yuhang Xie, Youjun Liu, Yuanyi Ren, Xin Zhang, Guojie Song",(missing journal),2025,(missing abstract),289561994,0,0,,
10.18653/v1/2025.acl-long.504,"Exploring the Potential of LLMs as Personalized Assistants: Dataset, Evaluation, and Analysis","J Mok, I.K. Kim, SangBo Park, Sungroh Yoon",(missing journal),2025,(missing abstract),289561995,0,0,,
10.18653/v1/2025.acl-long.569,User-side Model Consistency Monitoring for Open Source Large Language Models Inference Services,"Qijun Miao, Zhixuan Fang",(missing journal),2025,(missing abstract),289561996,0,0,,
10.18653/v1/2025.acl-long.571,Parenting: Optimizing Knowledge Selection of Retrieval-Augmented Language Models with Parameter Decoupling and Tailored Tuning,"Yongxin Xu, Ruizhe Zhang, Xinke Jiang, Yujie Feng, Yuzhen Xiao, Xinyu Ma, Runchuan Zhu, Xu Chu, Junfeng Zhao, Yasha Wang",(missing journal),2025,(missing abstract),289561997,0,0,,
10.18653/v1/2025.acl-long.522,DAPE V2: Process Attention Score as Feature Map for Length Extrapolation,"Chuanyang Zheng, Yihang Gao, Han Shi, Jing Xiong, Jiankai Sun, Jingyao Li, Minbin Huang, Xiaozhe Ren, Michael K. Ng, Xin Jiang, Zhenguo Li, Yu Li",(missing journal),2025,(missing abstract),289561998,0,0,,
10.18653/v1/2025.acl-long.529,SCOPE: Optimizing Key-Value Cache Compression in Long-context Generation,"Jialong Wu, Zhenglin Wang, Linhai Zhang, Yumian Lai, Yuanyuan He, Deyu Zhou",(missing journal),2025,(missing abstract),289561999,0,0,,
10.18653/v1/2025.acl-long.579,Croppable Knowledge Graph Embedding,"Yushan Zhu, Wen Zhang, Zhi-Qiang Liu, Mingyang Chen, Lei Liang, Huajun Chen",(missing journal),2025,(missing abstract),289562000,0,0,,
10.18653/v1/2025.acl-long.526,PPT: A Minor Language News Recommendation Model via Cross-Lingual Preference Pattern Transfer,"Yiyang Zhang, Nan Chen",(missing journal),2025,(missing abstract),289562001,0,0,,
10.18653/v1/2025.acl-long.502,Uni-Retrieval: A Multi-Style Retrieval Framework for STEM’s Education,"Yanhao Jia, Xinyi Wu, Hao Li, QinglinZhang QinglinZhang, Yuxiao Hu, Shuai Zhao, Wenqi Fan",(missing journal),2025,(missing abstract),289562002,0,0,,
10.18653/v1/2025.acl-long.447,"Collapse of Dense Retrievers: Short, Early, and Literal Biases Outranking Factual Evidence","Mohsen Fayyaz, Ali Modarressi, Hinrich Schuetze, Nanyun Peng",(missing journal),2025,(missing abstract),289562003,1,0,,
10.18653/v1/2025.acl-long.470,Does Context Matter? ContextualJudgeBench for Evaluating LLM-based Judges in Contextual Settings,"Aimin Xu, Srijan Bansal, Yifei Ming, Semih Yavuz, Shafiq Joty",(missing journal),2025,(missing abstract),289562004,1,0,,
10.18653/v1/2025.acl-long.371,LLM as a Broken Telephone: Iterative Generation Distorts Information,"Amr Mohamed, Mingmeng Geng, Michalis Vazirgiannis, Guokan Shang",(missing journal),2025,(missing abstract),289562005,0,0,,
10.18653/v1/2025.acl-long.432,Meaning Beyond Truth Conditions: Evaluating Discourse Level Understanding via Anaphora Accessibility,"Xiaomeng Zhu, Zhenghao Zhou, Simon Charlow, Robert Frank",(missing journal),2025,(missing abstract),289562006,0,0,,
10.18653/v1/2025.acl-long.399,AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection,"Weiping Luo, Shenghong Dai, Xiaogeng Liu, Suman Banerjee, Huan Sun, Muhao Chen, Chaowei Xiao",(missing journal),2025,(missing abstract),289562007,0,0,,
10.18653/v1/2025.acl-long.325,Quaff: Quantized Parameter-Efficient Fine-Tuning under Outlier Spatial Stability Hypothesis,"Hongwei Huang, Dapeng Wu",(missing journal),2025,(missing abstract),289562008,0,0,,
10.18653/v1/2025.acl-long.425,"Pragmatics in the Era of Large Language Models: A Survey on Datasets, Evaluation, Opportunities and Challenges","Bolei Ma, Yuting Li, Wei Zhou, Ziwei Gong, Yang Janet Liu, Katja Jasinskaja, Annemarie Friedrich, Julia Hirschberg, Frauke Kreuter, Barbara Plank",(missing journal),2025,(missing abstract),289562009,3,0,,
10.18653/v1/2025.acl-long.387,SpaRE: Enhancing Spatial Reasoning in Vision-Language Models with Synthetic Data,"Michael Ogezi, Freda Shi",(missing journal),2025,(missing abstract),289562010,0,0,,
10.18653/v1/2025.acl-long.382,Translation and Fusion Improves Cross-lingual Information Extraction,"Yang Chen, Vedaant Shah, Alan Ritter",(missing journal),2025,(missing abstract),289562011,0,0,,
10.18653/v1/2025.acl-long.392,On Synthetic Data Strategies for Domain-Specific Generative Retrieval,"He‐Rui Wen, Jiang Guo, Yi Zhang, Jiarong Jiang, Zhiguo Wang",(missing journal),2025,(missing abstract),289562012,0,0,,
10.18653/v1/2025.acl-long.328,Biased LLMs can Influence Political Decision-Making,"Jillian Fisher, Shangbin Feng, Robert Aron, Thomas Richardson, Yejin Choi, Douglas Fisher, Jennifer Pan, Yulia Tsvetkov, Katharina Reinecke",(missing journal),2025,(missing abstract),289562013,4,0,,
10.18653/v1/2025.acl-long.479,"When to Speak, When to Abstain: Contrastive Decoding with Abstention","Hyuhng Joon Kim, Youna Kim, Sang‐Goo Lee, Taeuk Kim",(missing journal),2025,(missing abstract),289562014,0,0,,
10.18653/v1/2025.acl-long.340,Drift: Enhancing LLM Faithfulness in Rationale Generation via Dual-Reward Probabilistic Inference,"Jiazheng Li, Hanqi Yan, Yulan He",(missing journal),2025,(missing abstract),289562015,0,0,,
10.18653/v1/2025.acl-long.315,CoT-based Synthesizer: Enhancing LLM Performance through Answer Synthesis,"Bohan Zhang, Xiaokang Zhang, Jing Zhang, Jifan Yu, Sijia Luo, Jie Tang",(missing journal),2025,(missing abstract),289562016,1,0,,
10.18653/v1/2025.acl-long.408,Conspiracy Theories and Where to Find Them on TikTok,"F Corso, Francesco Pierri, Gianmarco De Francisci Morales",(missing journal),2025,(missing abstract),289562017,0,0,,
10.18653/v1/2025.acl-long.339,Unlocking General Long Chain-of-Thought Reasoning Capabilities of Large Language Models via Representation Engineering,"Xinyu Tang, Xiaolei Wang, Zhiyuan Lv, Yingqian Min, Xin Zhao, Binbin Hu, Ziqi Liu, Zhiqiang Zhang",(missing journal),2025,(missing abstract),289562018,0,0,,
10.18653/v1/2025.acl-long.480,On the Risk of Evidence Pollution for Malicious Social Text Detection in the Era of LLMs,"Herun Wan, Minnan Luo, Zhonghua Su, Guang Dai, Xiang Zhao",(missing journal),2025,(missing abstract),289562019,0,0,,
10.18653/v1/2025.acl-long.307,CxGGEC: Construction-Guided Grammatical Error Correction,"Yusheng Cao, Tianxiang Wang, Lvxiaowei Xu, Zhenyao Wang, Ming Bo Cai",(missing journal),2025,(missing abstract),289562020,0,0,,
10.18653/v1/2025.acl-long.354,Gumbel Reranking: Differentiable End-to-End Reranker Optimization,"Siyuan Huang, Zhiyuan Ma, Jintao Du, Changhua Meng, Weiqiang Wang, Jingwen Leng, Minyi Guo, Zhouhan Lin",(missing journal),2025,(missing abstract),289562021,1,0,,
10.18653/v1/2025.acl-long.385,VQAGuider: Guiding Multimodal Large Language Models to Answer Complex Video Questions,"Yuyan Chen, Jiyuan Jia, Jiaxin Lu, Siyue Li, Yu Guan, Ming Yang, Qingpei Guo",(missing journal),2025,(missing abstract),289562022,0,0,,
10.18653/v1/2025.acl-long.280,Decoding Reading Goals from Eye Movements,"Omer Shubi, Cfir Avraham Hadar, Yevgeni Berzak",(missing journal),2025,(missing abstract),289562023,0,0,,
10.18653/v1/2025.acl-long.298,Understanding Cross-Domain Adaptation in Low-Resource Topic Modeling,"Pritom Saha Akash, Kevin Chen–Chuan Chang",(missing journal),2025,(missing abstract),289562024,0,0,,
10.18653/v1/2025.acl-long.310,What Is That Talk About? A Video-to-Text Summarization Dataset for Scientific Presentations,"Dikai Liu, Chenxi Whitehouse, Xi Yu, Louis Mahon, Rohit Saxena, Zheng Zhao, Yifu Qiu, Mirella Lapata, Vera Demberg",(missing journal),2025,(missing abstract),289562025,0,0,,
10.18653/v1/2025.acl-long.293,X-TURING: Towards an Enhanced and Efficient Turing Test for Long-Term Dialogue Agents,"Weiqi Wu, Hongqiu Wu, Zhao Hai",Annual Meeting of the Association for Computational Linguistics,2025,"The Turing test examines whether AIs exhibit human-like behaviour in natural language conversations. The traditional setting limits each participant to one message at a time and requires constant human participation. This fails to reflect a natural conversational style and hinders the evaluation of dialogue agents based on Large Language Models (LLMs) in complex and prolonged interactions. This paper proposes \textbf{\textsc{X-Turing}}, which enhances the original test with a \textit{burst dialogue} pattern, allowing more dynamic exchanges using consecutive messages. It further reduces human workload by iteratively generating dialogues that simulate the long-term interaction between the agent and a human to compose the majority of the test process. With the \textit{pseudo-dialogue} history, the agent then engages in a shorter dialogue with a real human, which is paired with a human-human conversation on the same topic to be judged using questionnaires. We introduce the \textit{X-Turn Pass-Rate} metric to assess the human likeness of LLMs across varying durations. While LLMs like GPT-4 initially perform well, achieving pass rates of 51.9\% and 38.9\% during 3 turns and 10 turns of dialogues respectively, their performance drops as the dialogue progresses, which underscores the difficulty in maintaining consistency in the long term.",289562026,3,34,,
10.18653/v1/2025.acl-long.263,L-CiteEval: A Suite for Evaluating Fidelity of Long-context Models,"Zecheng Tang, Keyan Zhou, Juntao Li, Baibei Ji, Jie Hou, Min Zhang",(missing journal),2025,(missing abstract),289562027,0,0,,
10.18653/v1/2025.acl-long.268,YuLan-Mini: Pushing the Limits of Open Data-efficient Language Model,"Yiwen Hu, Hongmei Song, Jie Chen, Jia Deng, Jiapeng Wang, Kun Zhou, Yutao Zhu, Jinhao Jiang, Zican Dong, Yang Lu, Miao Xu, Xin Zhao, Ji-Rong Wen",(missing journal),2025,(missing abstract),289562028,0,0,,
10.18653/v1/2025.acl-long.246,WarriorCoder: Learning from Expert Battles to Augment Code Large Language Models,"Huawen Feng, Pu Zhao, Qing‐Feng Sun, Can Xu, Fangkai Yang, Lu Wang, Qianli Ma, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang",(missing journal),2025,(missing abstract),289567890,0,0,,
10.18653/v1/2025.acl-long.249,Demons in the Detail: On Implementing Load Balancing Loss for Training Specialized Mixture-of-Expert Models,"Zihan Qiu, Zeyu Huang, Bo Zheng, Kaiyue Wen, Z. Y. Wang, Rui Men, Ivan Titov, Dayiheng Liu, Jingren Zhou, Junyang Lin",(missing journal),2025,(missing abstract),289567892,2,0,,
10.18653/v1/2025.acl-long.188,"Influences on LLM Calibration: A Study of Response Agreement, Loss Functions, and Prompt Styles","Ye Xia, Pedro Araujo, Klim Zaporojets, Benjamin Roth",(missing journal),2025,(missing abstract),289567893,0,0,,
10.18653/v1/2025.acl-long.239,ShifCon: Enhancing Non-Dominant Language Capabilities with a Shift-based Multilingual Contrastive Framework,"H. Zhang, Chenming Shang, Sizhe Wang, Dongdong Zhang, Yiyao Yu, Feng Yao, Renliang Sun, Yujiu Yang, Furu Wei",(missing journal),2025,"Although fine-tuning Large Language Models (LLMs) with multilingual data can rapidly enhance the multilingual capabilities of LLMs, they still exhibit a performance gap between the dominant language (e.g., English) and non-dominant ones due to the imbalance of training data across languages. To further enhance the performance of non-dominant languages, we propose ShifCon, a Shift-based multilingual Contrastive framework that aligns the internal forward process of other languages toward that of the dominant one. Specifically, it shifts the representations of non-dominant languages into the dominant language subspace, allowing them to access relatively rich information encoded in the model parameters. The enriched representations are then shifted back into their original language subspace before generation. Moreover, we introduce a subspace distance metric to pinpoint the optimal layer area for shifting representations and employ multilingual contrastive learning to further enhance the alignment of representations within this area. Experiments demonstrate that our ShifCon framework significantly enhances the performance of non-dominant languages, particularly for low-resource ones. Further analysis offers extra insights to verify the effectiveness of ShifCon and propel future research.",289567894,0,0,,
10.18653/v1/2025.acl-long.174,Contrastive Prompting Enhances Sentence Embeddings in LLMs through Inference-Time Steering,"Zifeng Cheng, Zhonghui Wang, Yuchen Fu, Zhiwei Jiang, Yafeng Yin, Cong Wang, Qing Gu",(missing journal),2025,(missing abstract),289567895,0,0,,
10.18653/v1/2025.acl-long.201,Meta-Reflection: A Feedback-Free Reflection Learning Framework,"Yaoke Wang, Yun Zhu, XintongBao XintongBao, Wenqiao Zhang, Shuang-Shuang Dai, Kehan Chen, Wenqiang Li, Gang Huang, Siliang Tang, Yueting Zhuang",(missing journal),2025,(missing abstract),289567896,0,0,,
10.18653/v1/2025.acl-long.243,Learning to Generate Structured Output with Schema Reinforcement Learning,"Yue Lu, H. Li, Xin Cong, Zhong Zhang, Yesai Wu, Yankai Lin, Zhiyuan Liu, Fangming Liu, Maosong Sun",(missing journal),2025,(missing abstract),289567897,0,0,,
10.18653/v1/2025.acl-long.157,A-TASC: Asian TED-Based Automatic Subtitling Corpus,"Yuhan Zhou, Naoki Yoshinaga",(missing journal),2025,(missing abstract),289567898,0,0,,
10.18653/v1/2025.acl-long.155,Iron Sharpens Iron: Defending Against Attacks in Machine-Generated Text Detection with Adversarial Training,"Yuanfan Li, Zhaohan Zhang, Chengzhengxu Li, Chao Shen, Xiaoming Liu",(missing journal),2025,(missing abstract),289567899,0,0,,
10.18653/v1/2025.acl-long.80,Ask-Before-Detection: Identifying and Mitigating Conformity Bias in LLM-Powered Error Detector for Math Word Problem Solutions,"Hang Li, Tingfa Xu, Kaiqi Yang, Y. P. Chu, Yanling Chen, Y. Song, Qingsong Wen, Hui Liu",(missing journal),2025,(missing abstract),289567900,0,0,,
10.18653/v1/2025.acl-long.95,From Information to Insight: Leveraging LLMs for Open Aspect-Based Educational Summarization,"Yang Zhong, Diane Litman",(missing journal),2025,(missing abstract),289567901,0,0,,ACL
10.18653/v1/2025.acl-long.109,Multimodal Transformers are Hierarchical Modal-wise Heterogeneous Graphs,"Yijie Jin, Junjie Peng, Xujie Lin, Haochen Yuan, Lan Wang, Cangzhi Zheng",(missing journal),2025,(missing abstract),289567902,0,0,,
10.18653/v1/2025.acl-long.131,MAIN-RAG: Multi-Agent Filtering Retrieval-Augmented Generation,"Chia-Yuan Chang, Zhimeng Jiang, Vineeth Rakesh, Menghai Pan, Chin‐Chia Michael Yeh, Guanchu Wang, Mingzhi Hu, Zhichao Xu, Yan Zheng, Mahashweta Das, Na Zou",(missing journal),2025,(missing abstract),289567903,2,0,,
10.18653/v1/2025.acl-long.130,Are Any-to-Any Models More Consistent Across Modality Transfers Than Specialists?,"Jiwan Chung, Jung‐Hwan Yoon, J H Park, S K Lee, Jiacai Yang, Sooyeon Park, Youngjae Yu",(missing journal),2025,(missing abstract),289567904,0,0,,
10.18653/v1/2025.acl-long.43,HybGRAG: Hybrid Retrieval-Augmented Generation on Textual and Relational Knowledge Bases,"Meng-Chieh Lee, Qi Zhu, Costas Mavromatis, Zhen Han, Soji Adeshina, Vassilis N. Ioannidis, Huzefa Rangwala, Christos Faloutsos",(missing journal),2025,(missing abstract),289567906,1,0,,
10.18653/v1/2025.acl-long.60,Re-identification of De-identified Documents with Autoregressive Infilling,"Lucas Georges Gabriel Charpentier, Pierre Lison",(missing journal),2025,(missing abstract),289567907,0,0,,
10.18653/v1/2025.acl-long.22,"How to Enable Effective Cooperation Between Humans and NLP Models: A Survey of Principles, Formalizations, and Beyond","Chen Huang, Yang Deng, Wenqiang Lei, Jiancheng Lv, Tat‐Seng Chua, Jimmy Xiangji Huang",(missing journal),2025,(missing abstract),289567908,0,0,,
10.18653/v1/2025.acl-long.25,BelarusianGLUE: Towards a Natural Language Understanding Benchmark for Belarusian,"Maksim Aparovich, Volha Harytskaya, Vladislav Poritski, Oksana Volchek, Pavel Smrž",(missing journal),2025,(missing abstract),289567910,0,0,,
10.18653/v1/2025.acl-long.68,Measuring Social Biases in Masked Language Models by Proxy of Prediction Quality,"Rahul Zalkikar, Kanchan Chandra",Annual Meeting of the Association for Computational Linguistics,2025,"Transformer language models have achieved state-of-the-art performance for a variety of natural language tasks but have been shown to encode unwanted biases. We evaluate the social biases encoded by transformers trained with the masked language modeling objective using proposed proxy functions within an iterative masking experiment to measure the quality of transformer models'predictions and assess the preference of MLMs towards disadvantaged and advantaged groups. We find all models encode concerning social biases. We compare bias estimations with those produced by other evaluation methods using benchmark datasets and assess their alignment with human annotated biases. We extend previous work by evaluating social biases introduced after retraining an MLM under the masked language modeling objective and find proposed measures produce more accurate and sensitive estimations of biases introduced by retraining MLMs based on relative preference for biased sentences between models, while other methods tend to underestimate biases after retraining on sentences biased towards disadvantaged groups.",289567918,2,31,,
10.18653/v1/2025.acl-long.1546,Beyond Text Compression: Evaluating Tokenizers Across Scales,"Jonas F. Lotz, António V. Lopes, Stephan Peitz, Hendra Setiawan, L Emili",(missing journal),2025,(missing abstract),289568044,0,0,,
10.18653/v1/2025.acl-long.1560,ONEBench to Test Them All: Sample-Level Benchmarking Over Open-Ended Capabilities,"Adhiraj Ghosh, Sebastian Dziadzio, Ameya Prabhu, Vishaal Udandarao, Samuel Albanie, Matthias Bethge",(missing journal),2025,(missing abstract),289568045,0,0,,
10.18653/v1/2025.acl-long.1572,Where Are We? Evaluating LLM Performance on African Languages,"Ife Adebara, Hawau Olamide Toyin, Nahom Tesfu Ghebremichael, AbdelRahim Elmadany, Muhammad Abdul-Mageed",(missing journal),2025,(missing abstract),289568046,0,0,,
10.18653/v1/2025.acl-long.1450,Assessing Reliability and Political Bias In LLMs’ Judgements of Formal and Material Inferences With Partisan Conclusions,"Reto Gubelmann, Ghassen Karray",(missing journal),2025,(missing abstract),289568047,0,0,,
10.18653/v1/2025.acl-long.1453,ConLoan: A Contrastive Multilingual Dataset for Evaluating Loanwords,"Sina Ahmadi, M. Heß, Elena Álvarez Mellado, Alessia Battisti, Cui Ding, Anne Göhring, Yingqiang Gao, Zifan Jiang, Andrianos Michail, Peshmerge Morad, Joel Niklaus, Maria Panagiotopoulou, Stefano Perrella, Juri Opitz, Anastassia Shaitarova, Rico Sennrich",(missing journal),2025,(missing abstract),289568048,0,0,,
10.18653/v1/2025.acl-long.1438,From Perceptions to Decisions: Wildfire Evacuation Decision Prediction with Behavioral Theory-informed LLMs,"R.N. Broun Chen, Chenguang Wang, Yuran Sun, Xilei Zhao, Susu Xu",(missing journal),2025,(missing abstract),289568049,0,0,,
10.18653/v1/2025.acl-long.1440,Hanging in the Balance: Pivotal Moments in Crisis Counseling Conversations,"Vivian Nguyen, Lillian Lee, Cristian Danescu-Niculescu-Mizil",(missing journal),2025,(missing abstract),289568050,0,0,,
10.18653/v1/2025.acl-long.1499,PlanningArena: A Modular Benchmark for Multidimensional Evaluation of Planning and Tool Learning,"Zihan Zheng, Taisong Cui, Changsheng Xie, Jiahui Pan, Qianglong Chen, Lewei He",(missing journal),2025,(missing abstract),289568051,0,0,,
10.18653/v1/2025.acl-long.1469,CLIPErase: Efficient Unlearning of Visual-Textual Associations in CLIP,"Tianyu Yang, Lei Dai, Xiangqi Wang, Minhao Cheng, Yapeng Tian, Xiangliang Zhang",(missing journal),2025,(missing abstract),289568052,0,0,,
10.18653/v1/2025.acl-long.1487,The Esethu Framework: Reimagining Sustainable Dataset Governance and Curation for Low-Resource Languages,"Jenalea Rajab, Anuoluwapo Aremu, Everlyn Asiko Chimoto, Dale Dunbar, Graham Morrissey, Fadel Thior, Luke J. Potgieter, Jessica Ojo, Atnafu Lambebo Tonja, Wilhelmina Nekoto, Pelonomi Moiloa, Jade Abbott, Vukosi Marivate, Benjamin Rosman",(missing journal),2025,(missing abstract),289568053,1,0,,
10.18653/v1/2025.acl-long.1376,SGIC: A Self-Guided Iterative Calibration Framework for RAG,"Guanhua Chen, Yukun Yao, Lidia S. Chao, X. Liu, Martin D. F. Wong",(missing journal),2025,(missing abstract),289568054,0,0,,
10.18653/v1/2025.acl-long.1370,Document-Level Text Generation with Minimum Bayes Risk Decoding using Optimal Transport,Yuu Jinnai,(missing journal),2025,(missing abstract),289568055,0,0,,
10.18653/v1/2025.acl-long.1360,"Towards Robust Universal Information Extraction: Dataset, Evaluation, and Solution","Jizhao Zhu, Akang Shi, Zixuan Li, Long Bai, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng",(missing journal),2025,(missing abstract),289568056,0,0,,
10.18653/v1/2025.acl-long.1302,LPOI: Listwise Preference Optimization for Vision Language Models,"Fatemeh Pesaran zadeh, Yoojin Oh, Gunhee Kim",(missing journal),2025,(missing abstract),289568057,0,0,,
10.18653/v1/2025.acl-long.1292,Who Writes What: Unveiling the Impact of Author Roles on AI-generated Text Detection,"Jiatao Li, Xiaojun Wan",(missing journal),2025,(missing abstract),289568058,0,0,,
10.18653/v1/2025.acl-long.1287,InductionBench: LLMs Fail in the Simplest Complexity Class,"Wenyue Hua, Tak-Lam Wong, Fei Sun, Liangming Pan, Adam Jardine, William Yang Wang",(missing journal),2025,(missing abstract),289568059,0,0,,
10.18653/v1/2025.acl-long.1243,Pre-Training Curriculum for Multi-Token Prediction in Language Models,"Ansar Aynetdinov, Alan Akbik",(missing journal),2025,(missing abstract),289568060,0,0,,
10.18653/v1/2025.acl-long.1216,Coordinating Chaos: A Structured Review of Linguistic Coordination Methodologies,"Benjamin Roger Litterer, David Jurgens, Dallas Card",(missing journal),2025,(missing abstract),289568061,0,0,,
10.18653/v1/2025.acl-long.1236,SARA: Salience-Aware Reinforced Adaptive Decoding for Large Language Models in Abstractive Summarization,"Nayu Liu, Junnan Zhu, Yiming Ma, Zhicong Lu, Wei Xu, Yong Yang, Jiang Zhong, Kaiwen Wei",(missing journal),2025,(missing abstract),289568062,0,0,,
10.18653/v1/2025.acl-long.1160,Rubrik’s Cube: Testing a New Rubric for Evaluating Explanations on the CUBE dataset,"Diana Galván-Sosa, Gabrielle Gaudeau, Pride Kavumba, Y. Li, Hongyi Gu, Yuan Zheng, Keisuke Sakaguchi, Paula Buttery",(missing journal),2025,(missing abstract),289569778,0,0,,
10.18653/v1/2025.acl-long.1139,Beyond Prompt Engineering: Robust Behavior Control in LLMs via Steering Target Atoms,"Mengru Wang, Zheng Xu, Shengyu Mao, Shumin Deng, Zhaopeng Tu, Hua‐Jun Chen, Ningyu Zhang",(missing journal),2025,(missing abstract),289569779,2,0,,
10.18653/v1/2025.acl-long.1123,HoPE: A Novel Positional Encoding Without Long-Term Decay for Enhanced Context Awareness and Extrapolation,"Yuhan Chen, Ang Lv, Jian Luan, Bin Wang, Wei Liu",(missing journal),2025,(missing abstract),289569780,0,0,,
10.18653/v1/2025.acl-long.1116,Mining the uncertainty patterns of humans and models in the annotation of moral foundations and human values,"Neele Falk, Gabriella Lapesa",(missing journal),2025,(missing abstract),289569781,0,0,,
10.18653/v1/2025.acl-long.1121,From English to Second Language Mastery: Enhancing LLMs with Cross-Lingual Continued Instruction Tuning,"Linjuan Wu, Haoran Wei, Baosong Yang, Weiming Lü",(missing journal),2025,(missing abstract),289569782,0,0,,
10.18653/v1/2025.acl-long.1155,Exploring Explanations Improves the Robustness of In-Context Learning,"Ukyo Honda, Tatsushi Oka",(missing journal),2025,(missing abstract),289569783,2,0,,
10.18653/v1/2025.acl-long.1087,Caution for the Environment: Multimodal LLM Agents are Susceptible to Environmental Distractions,"Xinbei Ma, Yiting Wang, Yao Yao, Tongxin Yuan, Aston Zhang, Zhuosheng Zhang, Hai Zhao",(missing journal),2025,(missing abstract),289569784,0,0,,
10.18653/v1/2025.acl-long.1077,A Mutual Information Perspective on Knowledge Graph Embedding,"Li Jiang, Xiangdong Su, Zehua Duo, Tian Lan, Xiaotao Guo, Guanglai Gao",(missing journal),2025,(missing abstract),289569785,0,0,,
10.18653/v1/2025.acl-long.1110,"Silencing Empowerment, Allowing Bigotry: Auditing the Moderation of Hate Speech on Twitch","P. K. Shukla, Winston Chong, Yash Patel, Brennan Schaffner, Danish Pruthi, Arjun Nitin Bhagoji",(missing journal),2025,(missing abstract),289569786,2,0,,
10.18653/v1/2025.acl-long.915,Probing LLMs for Multilingual Discourse Generalization Through a Unified Label Set,"Florian Eichin, Yang Janet Liu, Barbara Plank, Michael A. Hedderich",(missing journal),2025,(missing abstract),289569787,0,0,,
10.18653/v1/2025.acl-long.953,Computation Mechanism Behind LLM Position Generalization,"Chi Han, Heng Ji",(missing journal),2025,(missing abstract),289569788,0,0,,
10.18653/v1/2025.acl-long.1068,Can LLMs Reason About Program Semantics? A Comprehensive Evaluation of LLMs on Formal Specification Inference,"Thanh Le-Cong, Xuan-Bach D. Le, Toby Murray",(missing journal),2025,(missing abstract),289569789,2,0,,
10.18653/v1/2025.acl-long.897,Defense Against Prompt Injection Attack by Leveraging Attack Techniques,"Yulin Chen, Haoran Li, Zihao Zheng, Dongya Wu, Yangqiu Song, Bryan Hooi",(missing journal),2025,(missing abstract),289569790,1,0,,
10.18653/v1/2025.acl-long.884,Mixture of Ordered Scoring Experts for Cross-prompt Essay Trait Scoring,"Po-Kai Chen, Bo-Wei Tsai, Wei Shi, Chien-Yao Wang, Jia-Ching Wang, Yi-Ting Huang",(missing journal),2025,(missing abstract),289569791,0,0,,
10.18653/v1/2025.acl-long.878,"Less, but Better: Efficient Multilingual Expansion for LLMs via Layer-wise Mixture-of-Experts","Xue Zhang, Yunlong Liang, Fandong Meng, Songming Zhang, Yufeng Chen, Jinan Xu, Jie Zhou",(missing journal),2025,(missing abstract),289569792,0,0,,
10.18653/v1/2025.acl-long.1018,Open-World Planning via Lifted Regression with LLM-Inferred Affordances for Embodied Agents,"X. Liu, Ali Pesaranghader, Hanze Li, Punyaphat Sukcharoenchaikul, Jaehong Kim, Tanmana Sadhu, Heung Seok Jeon, Scott Sanner",(missing journal),2025,(missing abstract),289569793,0,0,,
10.18653/v1/2025.acl-long.1054,Automated CAD Modeling Sequence Generation from Text Descriptions via Transformer-Based Large Language Models,"Jiahua Liao, Junyan Xu, Yongqi Sun, Matthew F. Tang, Sailing He, Jau‐Chyn Liao, Shui Yu, Yun Li, Xiaohong Guan",(missing journal),2025,(missing abstract),289569794,1,0,,
10.18653/v1/2025.acl-long.877,ELBA-Bench: An Efficient Learning Backdoor Attacks Benchmark for Large Language Models,"Xuxu Liu, Siyuan Liang, Mengya Han, Yong Luo, Aishan Liu, Xiantao Cai, Zheng He, Dacheng Tao",(missing journal),2025,(missing abstract),289569795,0,0,,
10.18653/v1/2025.acl-long.923,BehaviorBox: Automated Discovery of Fine-Grained Performance Differences Between Language Models,"Lindia Tjuatja, Graham Neubig",(missing journal),2025,(missing abstract),289569796,0,0,,
10.18653/v1/2025.acl-long.797,"MockConf: A Student Interpretation Dataset: Analysis, Word- and Span-level Alignment and Baselines","Dávid Javorský, Ondřej Bojar, François Yvon",(missing journal),2025,(missing abstract),289569797,0,0,,
10.18653/v1/2025.acl-long.864,Pixel-Level Reasoning Segmentation via Multi-turn Conversations,"Dunbo Cai, Xiaocui Yang, Yongkang Liu, Daling Wang, Feng Shi, Yifei Zhang, Soujanya Poria",(missing journal),2025,(missing abstract),289569798,0,0,,
10.18653/v1/2025.acl-long.872,Insight Over Sight: Exploring the Vision-Knowledge Conflicts in Multimodal LLMs,"Xiaoyuan Liu, Wenxuan Wang, Youliang Yuan, Jen-tse Huang, Qiancheng Liu, Pinjia He, Zhaopeng Tu",Annual Meeting of the Association for Computational Linguistics,2025,"This paper explores the problem of commonsense level vision-knowledge conflict in Multimodal Large Language Models (MLLMs), where visual information contradicts model's internal commonsense knowledge. To study this issue, we introduce an automated framework, augmented with human-in-the-loop quality control, to generate inputs designed to simulate and evaluate these conflicts in MLLMs. Using this framework, we have crafted a diagnostic benchmark consisting of 374 original images and 1,122 high-quality question-answer (QA) pairs. The benchmark covers two aspects of conflict and three question types, providing a thorough assessment tool. We apply this benchmark to assess the conflict-resolution capabilities of nine representative MLLMs from various model families. Our results indicate an evident over-reliance on parametric knowledge for approximately 20% of all queries, especially among Yes-No and action-related problems. Based on these findings, we evaluate the effectiveness of existing approaches to mitigating the conflicts and compare them to our""Focus-on-Vision""prompting strategy. Despite some improvement, the vision-knowledge conflict remains unresolved and can be further scaled through our data construction framework. Our proposed framework, benchmark, and analysis contribute to the understanding and mitigation of vision-knowledge conflicts in MLLMs.",289569799,10,51,,
10.18653/v1/2025.acl-long.847,Donate or Create? Comparing Data Collection Strategies for Emotion-labeled Multimodal Social Media Posts,"Christopher Bagdon, Aidan Combs, Carina Silberer, Roman Klinger",(missing journal),2025,(missing abstract),289569800,0,0,,
10.18653/v1/2025.acl-long.841,Decoding by Contrasting Knowledge: Enhancing Large Language Model Confidence on Edited Facts,"Baolong Bi, Shenghua Liu, Lingrui Mei, Yiwei Wang, Junfeng Fang, Pengliang Ji, Xueqi Cheng",(missing journal),2025,(missing abstract),289569801,0,0,,
10.18653/v1/2025.acl-long.1206,ACORD: An Expert-Annotated Retrieval Dataset for Legal Contract Drafting,"Shanshan Wang, Maksim Zubkov, Kaiyu Fan, Sarah Harrell, Y. Sun, Wei Chen, Andreas Plesner, Roger Wattenhofer",(missing journal),2025,(missing abstract),289569802,0,0,,
10.18653/v1/2025.acl-long.1182,"Generate First, Then Sample: Enhancing Fake News Detection with LLM-Augmented Reinforced Sampling","Tong Zhao, Yimeng Gu, Huidong Liu, Qiang Liu, Shu Wu, Haichao Shi, Xiao-Yu Zhang",(missing journal),2025,(missing abstract),289569803,0,0,,
10.18653/v1/2025.acl-long.782,The Alternative Annotator Test for LLM-as-a-Judge: How to Statistically Justify Replacing Human Annotators with LLMs,"Nitay Calderon, Roi Reichart, Rotem Dror",(missing journal),2025,(missing abstract),289569804,3,0,,
10.18653/v1/2025.acl-long.710,DoMIX: An Efficient Framework for Exploiting Domain Knowledge in Fine-Tuning,"Dohoon Kim, Dong Hun Kang, Todd K. Moon",(missing journal),2025,(missing abstract),289569805,0,0,,
10.18653/v1/2025.acl-long.761,IRT-Router: Effective and Interpretable Multi-LLM Routing via Item Response Theory,"Wei Song, Zhenya Huang, Cheng Cheng, Weibo Gao, Bihan Xu, GuanHao Zhao, Fei Wang, Runze Wu",(missing journal),2025,(missing abstract),289569806,0,0,,
10.18653/v1/2025.acl-long.776,Adaptive and Robust Translation from Natural Language to Multi-model Query Languages,"Gengyuan Shi, Chaokun Wang, Yabin Liu, Jiawei Ren",(missing journal),2025,(missing abstract),289569807,0,0,,
10.18653/v1/2025.acl-long.746,LAQuer: Localized Attribution Queries in Content-grounded Generation,"Eran Hirsch, Aviv Slobodkin, David Wan, Elias Stengel-Eskin, Mohit Bansal, Ido Dagan",(missing journal),2025,(missing abstract),289569808,2,0,,
10.18653/v1/2025.acl-long.725,SwiLTra-Bench: The Swiss Legal Translation Benchmark,"Joel Niklaus, Jakob Merane, Luka Nenadic, Sina Ahmadi, Yingqiang Gao, Cyrill A. H. Chevalley, Claude Humbel, Christophe Gösken, Leonardo Tanzi, Thomas Lüthi, Stefan Palombo, Spencer Poff, Boling Yang, Nan Wu, Matthew Guillod, Robin Mamié, Daniel Brunner, Julio Pereyra, Niko A. Grupen",(missing journal),2025,(missing abstract),289569809,0,0,,
10.18653/v1/2025.acl-long.728,Can LLMs Ground when they (Don’t) Know: A Study on Direct and Loaded Political Questions,"Clara Lachenmaier, Judith Sieker, Sina Zarrieß",(missing journal),2025,(missing abstract),289569810,0,0,,
10.18653/v1/2025.acl-long.684,Multi-task Adversarial Attacks against Black-box Model with Few-shot Queries,"Wenqiang Wang, Yan Xiao, Hao Lin, Yangshijie Zhang, Xiaochun Cao",Annual Meeting of the Association for Computational Linguistics,2025,"Current multi-task adversarial text attacks rely on abundant access to shared internal features and numerous queries, often limited to a single task type. As a result, these attacks are less effective against practical scenarios involving black-box feedback APIs, limited queries, or multiple task types. To bridge this gap, we propose \textbf{C}luster and \textbf{E}nsemble \textbf{M}ulti-task Text Adversarial \textbf{A}ttack (\textbf{CEMA}), an effective black-box attack that exploits the transferability of adversarial texts across different tasks. CEMA simplifies complex multi-task scenarios by using a \textit{deep-level substitute model} trained in a \textit{plug-and-play} manner for text classification, enabling attacks without mimicking the victim model. This approach requires only a few queries for training, converting multi-task attacks into classification attacks and allowing attacks across various tasks. CEMA generates multiple adversarial candidates using different text classification methods and selects the one that most effectively attacks substitute models. In experiments involving multi-task models with two, three, or six tasks--spanning classification, translation, summarization, and text-to-image generation--CEMA demonstrates significant attack success with as few as 100 queries. Furthermore, CEMA can target commercial APIs (e.g., Baidu and Google Translate), large language models (e.g., ChatGPT 4o), and image-generation models (e.g., Stable Diffusion V2), showcasing its versatility and effectiveness in real-world applications.",289569811,1,72,,
10.18653/v1/2025.acl-long.677,MEDDxAgent: A Unified Modular Agent Framework for Explainable Automatic Differential Diagnosis,"D.K. Rose, Chia-Chien Hung, Marco Lepri, Israa Alqassem, Kiril Gashteovski, Carolin Lawrence",(missing journal),2025,(missing abstract),289569812,0,0,,
10.18653/v1/2025.acl-long.662,SDBench: A Survey-based Domain-specific LLM Benchmarking and Optimization Framework,"Cheng Guo, Kai Hu, Shaoyan Liang, Yiyang Jiang, Yi Gao, Xian‐Sheng Hua, Wei Dong",(missing journal),2025,(missing abstract),289569813,0,0,,
10.18653/v1/2025.acl-long.615,Finding the Sweet Spot: Preference Data Construction for Scaling Preference Optimization,"Yao Xiao, Hai Ye, Lequn Chen, Hwee Tou Ng, Lidong Bing, Xiaoli Li, Ryang Suk Lee",(missing journal),2025,(missing abstract),289569814,0,0,,
10.18653/v1/2025.acl-long.764,Evaluating Design Decisions for Dual Encoder-based Entity Disambiguation,"Susanna Rücker, Alan Akbik",(missing journal),2025,(missing abstract),289569815,0,0,,
10.18653/v1/2025.acl-long.711,EAGLE: Expert-Guided Self-Enhancement for Preference Alignment in Pathology Large Vision-Language Model,"Meidan Ding, Jipeng Zhang, Wenxuan Wang, Haiqin Zhong, Xiaoqin Wang, Xinheng Lyu, Wenting Chen, Linlin Shen",(missing journal),2025,(missing abstract),289569816,0,0,,
10.18653/v1/2025.acl-long.499,Exploring How Generative MLLMs Perceive More Than CLIP with the Same Vision Encoder,"Siting Li, Pang Wei Koh, Simon S. Du",Annual Meeting of the Association for Computational Linguistics,2025,"Recent research has shown that CLIP models struggle with visual reasoning tasks that require grounding compositionality, understanding spatial relationships, or capturing fine-grained details. One natural hypothesis is that the CLIP vision encoder does not embed essential information for these tasks. However, we find that this is not always the case: The encoder gathers query-relevant visual information, while CLIP fails to extract it. In particular, we show that another branch of Vision-Language Models (VLMs), Generative Multimodal Large Language Models (MLLMs), achieve significantly higher accuracy than CLIP in many of these tasks using the same vision encoder and weights, indicating that these Generative MLLMs perceive more -- as they extract and utilize visual information more effectively. We conduct a series of controlled experiments and reveal that their success is attributed to multiple key design choices, including patch tokens, position embeddings, and prompt-based weighting. On the other hand, enhancing the training data alone or applying a stronger text encoder does not suffice to solve the task, and additional text tokens offer little benefit. Interestingly, we find that fine-grained visual reasoning is not exclusive to generative models trained by an autoregressive loss: When converted into CLIP-like encoders by contrastive finetuning, these MLLMs still outperform CLIP under the same cosine similarity-based evaluation protocol. Our study highlights the importance of VLM architectural choices and suggests directions for improving the performance of CLIP-like contrastive VLMs.",289569817,7,41,,
10.18653/v1/2025.acl-long.564,Scaling up the State Size of RNN LLMs for Long-Context Scenarios,"Kai Liu, Jian‐Fei Gao, Kai Chen",(missing journal),2025,(missing abstract),289569818,0,0,,
10.18653/v1/2025.acl-long.501,HAIC: Improving Human Action Understanding and Generation with Better Captions for Multi-modal Large Language Models,"Xiao Wang, Jingyun Hua, Weihong Lin, Yuanxing Zhang, Fuzheng Zhang, Jie Wu, Wang Zhang, Liqiang Nie",(missing journal),2025,(missing abstract),289569819,0,0,,
10.18653/v1/2025.acl-long.555,An Empirical Study of Many-to-Many Summarization with Large Language Models,"Jiaan Wang, Fandong Meng, Zengkui Sun, Yunlong Liang, Yuxuan Cao, Jiarong Xu, Haoxiang Shi, Jie Zhou",(missing journal),2025,(missing abstract),289569820,0,0,,
10.18653/v1/2025.acl-long.546,Towards Enhanced Immersion and Agency for LLM-based Interactive Drama,"Hongqiu Wu, Weiqi Wu, Tianyang Xu, Jie Zhang, Hai Zhao",(missing journal),2025,(missing abstract),289569821,2,0,,
10.18653/v1/2025.acl-long.553,GenderAlign: An Alignment Dataset for Mitigating Gender Bias in Large Language Models,"Tao Zhang, Ziqian Zeng, YuxiangXiao YuxiangXiao, Huiping Zhuang, Cen Chen, James R. Foulds, Shimei Pan",(missing journal),2025,(missing abstract),289569822,0,0,,
10.18653/v1/2025.acl-long.478,Between Circuits and Chomsky: Pre-pretraining on Formal Languages Imparts Linguistic Biases,"Michael Y. Hu, Jackson Petty, Chuan Shi, William Merrill, Tal Linzen",(missing journal),2025,(missing abstract),289569823,0,0,,
10.18653/v1/2025.acl-long.476,Agents Under Siege: Breaking Pragmatic Multi-Agent LLM Systems with Optimized Prompt Attacks,"Rana Shahroz, Zhen Tan, Sang‐Ho Yun, Charles B. Fleming, Tianlong Chen",(missing journal),2025,(missing abstract),289569824,0,0,,
10.18653/v1/2025.acl-long.457,Bitnet.cpp: Efficient Edge Inference for Ternary LLMs,"Jinheng Wang, Hai Zhou, Ting Song, Shijie Cao, Yan Xia, Ting Cao, Jianyu Wei, Shuming Ma, Hongyu Wang, Furu Wei",(missing journal),2025,(missing abstract),289569825,2,0,,
10.18653/v1/2025.acl-long.405,VLSBench: Unveiling Visual Leakage in Multimodal Safety,"Xuan Hu, Dongrui Liu, Zhengwei Li, Xiaoming Huang, Jing Shao",(missing journal),2025,(missing abstract),289569826,1,0,,
10.18653/v1/2025.acl-long.412,Explicit and Implicit Data Augmentation for Social Event Detection,"Congbo Ma, Yuxia Wang, Jia Wu, Jian Yang, Jing Du, Zitai Qiu, Xiu‐Qing Li, Wang Hu, Preslav Nakov",Annual Meeting of the Association for Computational Linguistics,2025,"Social event detection involves identifying and categorizing important events from social media, which relies on labeled data, but annotation is costly and labor-intensive. To address this problem, we propose Augmentation framework for Social Event Detection (SED-Aug), a plug-and-play dual augmentation framework, which combines explicit text-based and implicit feature-space augmentation to enhance data diversity and model robustness. The explicit augmentation utilizes large language models to enhance textual information through five diverse generation strategies. For implicit augmentation, we design five novel perturbation techniques that operate in the feature space on structural fused embeddings. These perturbations are crafted to keep the semantic and relational properties of the embeddings and make them more diverse. Specifically, SED-Aug outperforms the best baseline model by approximately 17.67% on the Twitter2012 dataset and by about 15.57% on the Twitter2018 dataset in terms of the average F1 score. The code is available at GitHub: https://github.com/congboma/SED-Aug.",289569827,0,44,,
10.18653/v1/2025.acl-long.312,ProvBench: A Benchmark of Legal Provision Recommendation for Contract Auto-Reviewing,"Xiuxuan Shen, Zhongyuan Jiang, Junsan Zhang, Junxiao Han, Yao Wan, Chengjie Guo, Bingcheng Liu, Jie Wu, Rong Li, Philip S. Yu",(missing journal),2025,(missing abstract),289569828,0,0,,
10.18653/v1/2025.acl-long.313,F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching,"Yushen Chen, Zhikang Niu, Ziyang Ma, Keqi Deng, Chunhui Wang, JianZhao JianZhao, Kai Yu, Xie Chen",(missing journal),2025,(missing abstract),289569829,18,0,,
10.18653/v1/2025.acl-long.377,Enough Coin Flips Can Make LLMs Act Bayesian,"Ritwik Gupta, Rodolfo Corona, Jiaxin Ge, Eric Wang, Dan Klein, Trevor Darrell, David M. Chan",(missing journal),2025,(missing abstract),289569830,0,0,,
10.18653/v1/2025.acl-long.333,FineReason: Evaluating and Improving LLMs’ Deliberate Reasoning through Reflective Puzzle Solving,"G Chen, Weiwen Xu, Hao Zhang, Hou Pong Chan, Chaoqun Liu, Lidong Bing, Deli Zhao, Anh Tuan Luu, Rong Yu",(missing journal),2025,(missing abstract),289569831,0,0,,
10.18653/v1/2025.acl-long.252,Crowd Comparative Reasoning: Unlocking Comprehensive Evaluations for LLM-as-a-Judge,"Q. Y. Zhang, Yufei Wang, Yuxin Jiang, Liangyou Li, Chuhan Wu, Yasheng Wang, Xin Jiang, Lifeng Shang, Ruiming Tang, Fuyuan Lyu, Chen Ma",(missing journal),2025,(missing abstract),289574372,0,0,,
10.18653/v1/2025.acl-long.233,Text is All You Need: LLM-enhanced Incremental Social Event Detection,"Zitai Qiu, Congbo Ma, Jia Wu, Jian Yang",(missing journal),2025,(missing abstract),289574373,0,0,,
10.18653/v1/2025.acl-long.231,AnRe: Analogical Replay for Temporal Knowledge Graph Forecasting,"Guoan Tang, Zheng Chu, Wenxiang Zheng, Jianbin Xiang, Yizhuo Li, Weihao Zhang, Ming Liu, Bing Qin",(missing journal),2025,(missing abstract),289574374,0,0,,
10.18653/v1/2025.acl-long.176,Hierarchical Document Refinement for Long-context Retrieval-augmented Generation,"Jiajie Jin, Xiaoxi Li, Guanting Dong, Yuyao Zhang, Yutao Zhu, Yongkang Wu, Zhonghua Li, Qi Ye, Zhicheng Dou",(missing journal),2025,(missing abstract),289574376,0,0,,
10.18653/v1/2025.acl-long.144,Less for More: Enhanced Feedback-aligned Mixed LLMs for Molecule Caption Generation and Fine-Grained NLI Evaluation,"Dimitris Gkoumas, Maria Liakata",Annual Meeting of the Association for Computational Linguistics,2025,"Scientific language models drive research innovation but require extensive fine-tuning on large datasets. This work enhances such models by improving their inference and evaluation capabilities with minimal or no additional training. Focusing on molecule caption generation, we explore post-training synergies between alignment fine-tuning and model merging in a cross-modal setup. We reveal intriguing insights into the behaviour and suitability of such methods while significantly surpassing state-of-the-art models. Moreover, we propose a novel atomic-level evaluation method leveraging off-the-shelf Natural Language Inference (NLI) models for use in the unseen chemical domain. Our experiments demonstrate that our evaluation operates at the right level of granularity, effectively handling multiple content units and subsentence reasoning, while widely adopted NLI methods consistently misalign with assessment criteria.",289574377,0,68,,
10.18653/v1/2025.acl-long.153,Aristotle: Mastering Logical Reasoning with A Logic-Complete Decompose-Search-Resolve Framework,"Jundong Xu, Fei Hao, M. X. Luo, Qian Liu, Liangming Pan, William Yang Wang, Preslav Nakov, Mong Li Lee, Wynne Hsu",(missing journal),2025,(missing abstract),289574378,0,0,,
10.18653/v1/2025.acl-long.97,Root Defense Strategies: Ensuring Safety of LLM at the Decoding Level,"Xinyi Zeng, Yuying Shang, Jiawei Chen, Jingyuan Zhang, Yu Tian",(missing journal),2025,(missing abstract),289574379,0,0,,
10.18653/v1/2025.acl-long.73,"“Yes, My LoRD.” Guiding Language Model Extraction with Locality Reinforced Distillation","Zi Liang, Qingqing Ye, Yanyun Wang, Sen Zhang, Yaxin Xiao, Ronghua Li, Jianliang Xu, Haibo Hu",(missing journal),2025,(missing abstract),289574380,2,0,,
10.18653/v1/2025.acl-long.122,Did Translation Models Get More Robust Without Anyone Even Noticing?,"Ben Peters, André F. T. Martins",(missing journal),2025,(missing abstract),289574381,0,0,,
10.18653/v1/2025.acl-long.36,MultiSocial: Multilingual Benchmark of Machine-Generated Text Detection of Social-Media Texts,"Dominik Macko, Jakub Kopál, Róbert Móro, Ivan Srba",(missing journal),2025,(missing abstract),289574383,3,0,,
10.18653/v1/2025.acl-long.1534,The Noisy Path from Source to Citation: Measuring How Scholars Engage with Past Research,"Hong Chen, Misha Teplitskiy, David Jurgens",(missing journal),2025,(missing abstract),289574477,0,0,,
10.18653/v1/2025.acl-long.1461,IRIS: Interpretable Retrieval-Augmented Classification for Long Interspersed Document Sequences,"Fengnan Li, Elliot D. Hill, Jiang Shu, Jiaxin Gao, Matthew Engelhard",Annual Meeting of the Association for Computational Linguistics,2025,"Transformer-based models have achieved state-of-the-art performance in document classification but struggle with long-text processing due to the quadratic computational complexity in the self-attention module. Existing solutions, such as sparse attention, hierarchical models, and key sentence extraction, partially address the issue but still fall short when the input sequence is exceptionally lengthy. To address this challenge, we propose IRIS (Interpretable Retrieval-Augmented Classification for long Interspersed Document Sequences), a novel, lightweight framework that utilizes retrieval to efficiently classify long documents while enhancing interpretability. IRIS segments documents into chunks, stores their embeddings in a vector database, and retrieves those most relevant to a given task using learnable query vectors. A linear attention mechanism then aggregates the retrieved embeddings for classification, allowing the model to process arbitrarily long documents without increasing computational cost and remaining trainable on a single GPU. Our experiments across six datasets show that IRIS achieves comparable performance to baseline models on standard benchmarks, and excels in three clinical note disease risk prediction tasks where documents are extremely long and key information is sparse. Furthermore, IRIS provides global interpretability by revealing a clear summary of key risk factors identified by the model. These findings highlight the potential of IRIS as an efficient and interpretable solution for long-document classification, particularly in healthcare applications where both performance and explainability are crucial.",289574478,0,36,,
10.18653/v1/2025.acl-long.1481,Meta-Tool: Unleash Open-World Function Calling Capabilities of General-Purpose Large Language Models,"Su‐Juan Qin, Yu Zhu, Linjie Mu, Shaoting Zhang, Xiaofan Zhang",(missing journal),2025,(missing abstract),289574479,0,0,,
10.18653/v1/2025.acl-long.1446,Bilingual Zero-Shot Stance Detection,"Chenye Zhao, Cornelia Caragea",(missing journal),2025,(missing abstract),289574480,1,0,,
10.18653/v1/2025.acl-long.1470,ViGiL3D: A Linguistically Diverse Dataset for 3D Visual Grounding,"Austin Wang, ZeMing Gong, Anne Lynn S. Chang",(missing journal),2025,(missing abstract),289574481,0,0,,
10.18653/v1/2025.acl-long.1471,The time scale of redundancy between prosody and linguistic context,"Tamar I. Regev, Chiebuka Ohams, Sihao Xie, Lukas Wolf, Evelina Fedorenko, Alex Warstadt, Ethan Wilcox, Tiago Pimentel",(missing journal),2025,(missing abstract),289574482,1,0,,
10.18653/v1/2025.acl-long.1382,Unifying Uniform and Binary-coding Quantization for Accurate Compression of Large Language Models,"Seungcheol Park, Jeongin Bae, Beomseok Kwon, Min-Jun Kim, Byeongwook Kim, Se Jung Kwon, U Kang, Dongsoo Lee",(missing journal),2025,(missing abstract),289574483,0,0,,
10.18653/v1/2025.acl-long.1367,Parameter-Aware Contrastive Knowledge Editing: Tracing and Rectifying based on Critical Transmission Paths,"Songlin Zhai, Yuan Meng, Yuxin Zhang, Guilin Qi",(missing journal),2025,(missing abstract),289574484,0,0,,
10.18653/v1/2025.acl-long.1355,AgentGym: Evaluating and Training Large Language Model-based Agents across Diverse Environments,"Zhiheng Xi, Yiwen Ding, Wen-Xiang Chen, Boyang Hong, Honglin Guo, Junzhe Wang, Xin Guo, Dingwen Yang, Chenyang Liao, He Wei, Songyang Gao, Lu Chen, Rui Zheng, Yicheng Zou, Tao Gui, Qi Zhang, Xipeng Qiu, Jimmy Xiangji Huang, Zuxuan Wu, Yu‐Gang Jiang",(missing journal),2025,(missing abstract),289574485,0,0,,
10.18653/v1/2025.acl-long.1352,GRAT: Guiding Retrieval-Augmented Reasoning through Process Rewards Tree Search,"Xianshu Peng, Wei Wei",(missing journal),2025,(missing abstract),289574486,0,0,,
10.18653/v1/2025.acl-long.1272,Research Borderlands: Analysing Writing Across Research Cultures,"Shaily Bhatt, Tal August, Maria Antoniak",(missing journal),2025,(missing abstract),289574487,0,0,,
10.18653/v1/2025.acl-long.1281,Attention Speaks Volumes: Localizing and Mitigating Bias in Language Models,"Rishabh Adiga, Besmira Nushi, Varun Chandrasekaran",(missing journal),2025,(missing abstract),289574488,1,0,,
10.18653/v1/2025.acl-long.1233,Shaping the Safety Boundaries: Understanding and Defending Against Jailbreaks in Large Language Models,"Lan Gao, Jiahui Geng, Xiangliang Zhang, Preslav Nakov, Xiuying Chen",(missing journal),2025,(missing abstract),289574489,0,0,,
10.18653/v1/2025.acl-long.1238,Improving Automatic Evaluation of Large Language Models (LLMs) in Biomedical Relation Extraction via LLMs-as-the-Judge,"Md Tahmid Rahman Laskar, Israt Jahan, Elham Dolatabadi, Chun Peng, Enamul Hoque, Jimmy Xiangji Huang",(missing journal),2025,(missing abstract),289574490,0,0,,
10.18653/v1/2025.acl-long.1144,"Small Changes, Big Impact: How Manipulating a Few Neurons Can Drastically Alter LLM Aggression","Jaewook Lee, Junseo Jang, Oh-Woog Kwon, Harksoo Kim",(missing journal),2025,(missing abstract),289575735,0,0,,
10.18653/v1/2025.acl-long.1080,ProMALex: Progressive Modular Adapters for Multi-Jurisdictional Legal Language Modeling,"Santosh T.y.s.s, Mohamed Hesham Elganayni",(missing journal),2025,(missing abstract),289575736,2,0,,
10.18653/v1/2025.acl-long.933,CC-Tuning: A Cross-Lingual Connection Mechanism for Improving Joint Multilingual Supervised Fine-Tuning,"Yangfan Ye, Xiaocheng Feng, Z. Y. Yuan, Xiachong Feng, L. Q. Qin, Lei Huang, Weitao Ma, Yudong Huang, Zhirui Zhang, Yunfei Lu, Xiaohui Yan, Duyu Tang, Dandan Tu, Bing Qin",(missing journal),2025,(missing abstract),289575737,0,0,,
10.18653/v1/2025.acl-long.1034,Veracity Bias and Beyond: Uncovering LLMs’ Hidden Beliefs in Problem-Solving Reasoning,"Yue Zhou, Barbara Di Eugenio",(missing journal),2025,(missing abstract),289575738,0,0,,
10.18653/v1/2025.acl-long.960,nvAgent: Automated Data Visualization from Natural Language via Collaborative Agent Workflow,"Guifang Ouyang, Jingyao Chen, Z. D. Nie, Yu Gui, Yao Wan, Hongyu Zhang, Dong‐Ping Chen",(missing journal),2025,(missing abstract),289575739,1,0,,
10.18653/v1/2025.acl-long.1025,Know You First and Be You Better: Modeling Human-Like User Simulators via Implicit Profiles,"Kuang Wang, Xianfei Li, Shunli Yang, Li Zhou, Feng Jiang, Haizhou Li",(missing journal),2025,(missing abstract),289575740,0,0,,
10.18653/v1/2025.acl-long.1048,Enhancing Mathematical Reasoning in LLMs by Stepwise Correction,"Zhenyu Wu, Qingkai Zeng, Zhihan Zhang, Zhaoxuan Tan, Chao Shen, Meng Jiang",(missing journal),2025,(missing abstract),289575741,0,0,,
10.18653/v1/2025.acl-long.1033,CORDIAL: Can Multimodal Large Language Models Effectively Understand Coherence Relationships?,"Aashish Anantha Ramakrishnan, A. G. Ramakrishnan, Dongwon Lee",(missing journal),2025,(missing abstract),289575742,0,0,,
10.18653/v1/2025.acl-long.974,Steering off Course: Reliability Challenges in Steering Language Models,"Paolo Silva, Hari Sethuraman, Deepak Rajagopal, Hannaneh Hajishirzi, Sachin Kumar",(missing journal),2025,(missing abstract),289575743,1,0,,
10.18653/v1/2025.acl-long.885,Sparse Logit Sampling: Accelerating Knowledge Distillation in LLMs,"Anshumann Anshumann, Mohd Abbas Zaidi, Akhil Kedia, Jin-Woo Ahn, Tae‐Geon Kwon, Kangwook Lee, Haejun Lee, Joo‐Hyung Lee",(missing journal),2025,(missing abstract),289575744,0,0,,
10.18653/v1/2025.acl-long.892,The Distracting Effect: Understanding Irrelevant Passages in RAG,"Chen Amiraz, Florin Cuconasu, Simone Filice, Zohar Karnin",Annual Meeting of the Association for Computational Linguistics,2025,"A well-known issue with Retrieval Augmented Generation (RAG) is that retrieved passages that are irrelevant to the query sometimes distract the answer-generating LLM, causing it to provide an incorrect response. In this paper, we shed light on this core issue and formulate the distracting effect of a passage w.r.t. a query (and an LLM). We provide a quantifiable measure of the distracting effect of a passage and demonstrate its robustness across LLMs. Our research introduces novel methods for identifying and using hard distracting passages to improve RAG systems. By fine-tuning LLMs with these carefully selected distracting passages, we achieve up to a 7.5% increase in answering accuracy compared to counterparts fine-tuned on conventional RAG datasets. Our contribution is two-fold: first, we move beyond the simple binary classification of irrelevant passages as either completely unrelated vs. distracting, and second, we develop and analyze multiple methods for finding hard distracting passages. To our knowledge, no other research has provided such a comprehensive framework for identifying and utilizing hard distracting passages.",289575745,11,23,,
10.18653/v1/2025.acl-long.783,CrisisTS: Coupling Social Media Textual Data and Meteorological Time Series for Urgency Classification,"R. Meunier, Farah Benamara, Véronique Moriceau, Zhongzheng Qiao, Savitha Ramasamy",(missing journal),2025,(missing abstract),289575746,0,0,,
10.18653/v1/2025.acl-long.807,Task-Specific Information Decomposition for End-to-End Dense Video Captioning,"Zhiyue Liu, Xinru Zhang, Jinyuan Liu",(missing journal),2025,(missing abstract),289575747,0,0,,
10.18653/v1/2025.acl-long.1204,Can Language Models Replace Programmers for Coding? REPOCOD Says ‘Not Yet’,"Shanchao Liang, Nan Jiang, Yiran Hu, Lin Tan",(missing journal),2025,(missing abstract),289575748,0,0,,
10.18653/v1/2025.acl-long.760,iQUEST: An Iterative Question-Guided Framework for Knowledge Base Question Answering,"Shuai Wang, Yinan Yu",Annual Meeting of the Association for Computational Linguistics,2025,"Large Language Models (LLMs) excel in many natural language processing tasks but often exhibit factual inconsistencies in knowledge-intensive settings. Integrating external knowledge resources, particularly knowledge graphs (KGs), provides a transparent and updatable foundation for more reliable reasoning. Knowledge Base Question Answering (KBQA), which queries and reasons over KGs, is central to this effort, especially for complex, multi-hop queries. However, multi-hop reasoning poses two key challenges: (1)~maintaining coherent reasoning paths, and (2)~avoiding prematurely discarding critical multi-hop connections. To tackle these challenges, we introduce iQUEST, a question-guided KBQA framework that iteratively decomposes complex queries into simpler sub-questions, ensuring a structured and focused reasoning trajectory. Additionally, we integrate a Graph Neural Network (GNN) to look ahead and incorporate 2-hop neighbor information at each reasoning step. This dual approach strengthens the reasoning process, enabling the model to explore viable paths more effectively. Detailed experiments demonstrate the consistent improvement delivered by iQUEST across four benchmark datasets and four LLMs.",289575749,4,24,,
10.18653/v1/2025.acl-long.754,Learning Together to Perform Better: Teaching Small-Scale LLMs to Collaborate via Preferential Rationale Tuning,"Sohan Patnaik, Milan Aggarwal, Sumit Bhatia, Balaji Krishnamurthy",(missing journal),2025,(missing abstract),289575750,0,0,,
10.18653/v1/2025.acl-long.743,"Predicting Turn-Taking and Backchannel in Human-Machine Conversations Using Linguistic, Acoustic, and Visual Signals","Yuxin Lin, Yinglin Zheng, Ming Zeng, Wangzheng Shi",(missing journal),2025,(missing abstract),289575751,0,0,,
10.18653/v1/2025.acl-long.647,𝜙-Decoding: Adaptive Foresight Sampling for Balanced Inference-Time Exploration and Exploitation,"Fangzhi Xu, Hang Yan, Chang Ma, Haiteng Zhao, Junyan Liu, Qika Lin, Zhiyong Wu",(missing journal),2025,(missing abstract),289575752,0,0,,
10.18653/v1/2025.acl-long.755,MolRAG: Unlocking the Power of Large Language Models for Molecular Property Prediction,"Ziting Xian, Jing Gu, Lingbo Li, Shangsong Liang",(missing journal),2025,(missing abstract),289575753,1,0,,
10.18653/v1/2025.acl-long.704,SHARE: Shared Memory-Aware Open-Domain Long-Term Dialogue Dataset Constructed from Movie Script,"Eunwon Kim, Chanho Park, Buru Chang",(missing journal),2025,(missing abstract),289575754,1,0,,
10.18653/v1/2025.acl-long.644,Genius: A Generalizable and Purely Unsupervised Self-Training Framework For Advanced Reasoning,"Fangzhi Xu, Hang Yan, Chang Ma, Haiteng Zhao, Qiushi Sun, Kanzhi Cheng, Junxian He, Jun Liu, Zhiyong Wu",(missing journal),2025,(missing abstract),289575755,0,0,,
10.18653/v1/2025.acl-long.751,RecLM: Recommendation Instruction Tuning,"Yangqin Jiang, Yuhao Yang, Lianghao Xia, Da Luo, Kangyi Lin, Chao Huang",(missing journal),2025,(missing abstract),289575756,0,0,,
10.18653/v1/2025.acl-long.596,PsyAdvisor: A Plug-and-Play Strategy Advice Planner with Proactive Questioning in Psychological Conversations,"Yuxin Hu, Dongfang Liu, Bo Liu, Yanbing Chen, Jiuxin Cao, Yan Liu",(missing journal),2025,(missing abstract),289575757,0,0,,
10.18653/v1/2025.acl-long.614,ChildMandarin: A Comprehensive Mandarin Speech Dataset for Young Children Aged 3-5,"Jiaming Zhou, Shiyao Wang, Shiwan Zhao, Jie He, Haoqin Sun, Hui Wang, Cheng Liu, Aobo Kong, Yujie Guo, Xi Yang, Yequan Wang, Yonghua Lin, Yong Qin",(missing journal),2025,(missing abstract),289575758,0,0,,
10.18653/v1/2025.acl-long.681,SIFT-50M: A Large-Scale Multilingual Dataset for Speech Instruction Fine-Tuning,"Prabhat Pandey, Rupak Vignesh Swaminathan, K V Vijay Girish, Arunasish Sen, Jian Feng Xie, Grant P. Strimel, Andreas Schwarz",(missing journal),2025,(missing abstract),289575759,0,0,,
10.18653/v1/2025.acl-long.617,SINCon: Mitigate LLM-Generated Malicious Message Injection Attack for Rumor Detection,"Mingqing Zhang, Qiang Liu, Xiang Tao, Shu Wu, Wang Liang",(missing journal),2025,(missing abstract),289575760,0,0,,
10.18653/v1/2025.acl-long.692,Investigating and Enhancing the Robustness of Large Multimodal Models Against Temporal Inconsistency,"Jiafeng Liang, Shixin Jiang, Xuan Dong, Ning Wang, Zheng Chu, Hui Su, Jinlan Fu, Ming Liu, See-Kiong Ng, Bing Qin",(missing journal),2025,(missing abstract),289575761,0,0,,
10.18653/v1/2025.acl-long.531,MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts,"Wei Tao, Haocheng Lu, Xiaoyang Qu, Bin Zhang, Ke Lu, Jiguang Wan, Jianzong Wang",(missing journal),2025,(missing abstract),289575762,0,0,,
10.18653/v1/2025.acl-long.574,EpMAN: Episodic Memory AttentioN for Generalizing to Longer Contexts,"Subhajit Chaudhury, Payel Das, Sarathkrishna Swaminathan, Γεώργιος Κόλλιας, Elliot C. Nelson, Khushbu Pahwa, Tejaswini Pedapati, Igor Melnyk, Matthew Riemer",(missing journal),2025,(missing abstract),289575763,0,0,,
10.18653/v1/2025.acl-long.459,Forward Knows Efficient Backward Path: Saliency-Guided Memory-Efficient Fine-tuning of Large Language Models,"Yong Ho Kim, Sangkeun Lee",(missing journal),2025,(missing abstract),289575764,0,0,,
10.18653/v1/2025.acl-long.356,SEOE: A Scalable and Reliable Semantic Evaluation Framework for Open Domain Event Detection,"Yi-Fan Lu, Xian-Ling Mao, Tian Lan, Tong Zhang, Yutong Zhu, Heyan Huang",(missing journal),2025,(missing abstract),289575765,0,0,,
10.18653/v1/2025.acl-long.567,Defining and Evaluating Visual Language Models' Basic Spatial Abilities: A Perspective from Psychometrics,"Wenrui Xu, Dalin Lyu, Weihang Wang, J. Feng, Chen Gao, Yong Li",Annual Meeting of the Association for Computational Linguistics,2025,"The Theory of Multiple Intelligences underscores the hierarchical nature of cognitive capabilities. To advance Spatial Artificial Intelligence, we pioneer a psychometric framework defining five Basic Spatial Abilities (BSAs) in Visual Language Models (VLMs): Spatial Perception, Spatial Relation, Spatial Orientation, Mental Rotation, and Spatial Visualization. Benchmarking 13 mainstream VLMs through nine validated psychometric experiments reveals significant gaps versus humans (average score 24.95 vs. 68.38), with three key findings: 1) VLMs mirror human hierarchies (strongest in 2D orientation, weakest in 3D rotation) with independent BSAs (Pearson's r<0.4); 2) Smaller models such as Qwen2-VL-7B surpass larger counterparts, with Qwen leading (30.82) and InternVL2 lagging (19.6); 3) Interventions like chain-of-thought (0.100 accuracy gain) and 5-shot training (0.259 improvement) show limits from architectural constraints. Identified barriers include weak geometry encoding and missing dynamic simulation. By linking psychometric BSAs to VLM capabilities, we provide a diagnostic toolkit for spatial intelligence evaluation, methodological foundations for embodied AI development, and a cognitive science-informed roadmap for achieving human-like spatial intelligence.",289791120,16,41,,
10.18653/v1/2025.acl-long.805,M2S: Multi-turn to Single-turn jailbreak in Red Teaming for LLMs,"Junwoo Ha, Hyunjun Kim, Sangyoon Yu, Haon Park, Ashkan Yousefpour, Yuna Park, Suhyun Kim",Volume 1,2025,"We introduce a novel framework for consolidating multi-turn adversarial ``jailbreak''prompts into single-turn queries, significantly reducing the manual overhead required for adversarial testing of large language models (LLMs). While multi-turn human jailbreaks have been shown to yield high attack success rates, they demand considerable human effort and time. Our multi-turn-to-single-turn (M2S) methods -- Hyphenize, Numberize, and Pythonize -- systematically reformat multi-turn dialogues into structured single-turn prompts. Despite removing iterative back-and-forth interactions, these prompts preserve and often enhance adversarial potency: in extensive evaluations on the Multi-turn Human Jailbreak (MHJ) dataset, M2S methods achieve attack success rates from 70.6 percent to 95.9 percent across several state-of-the-art LLMs. Remarkably, the single-turn prompts outperform the original multi-turn attacks by as much as 17.5 percentage points while cutting token usage by more than half on average. Further analysis shows that embedding malicious requests in enumerated or code-like structures exploits ``contextual blindness'', bypassing both native guardrails and external input-output filters. By converting multi-turn conversations into concise single-turn prompts, the M2S framework provides a scalable tool for large-scale red teaming and reveals critical weaknesses in contemporary LLM defenses.",289828494,7,19,,
10.18653/v1/2025.acl-long.1074,XPrompt:Explaining Large Language Model's Generation via Joint Prompt Attribution,"Yurui Chang, Bochuan Cao, Yujia Wang, Jinghui Chen, Lu Lin",Annual Meeting of the Association for Computational Linguistics,2024,"Large Language Models (LLMs) have demonstrated impressive performances in complex text generation tasks. However, the contribution of the input prompt to the generated content still remains obscure to humans, underscoring the necessity of understanding the causality between input and output pairs. Existing works for providing prompt-specific explanation often confine model output to be classification or next-word prediction. Few initial attempts aiming to explain the entire language generation often treat input prompt texts independently, ignoring their combinatorial effects on the follow-up generation. In this study, we introduce a counterfactual explanation framework based on Joint Prompt Attribution, JoPA, which aims to explain how a few prompt texts collaboratively influences the LLM's complete generation. Particularly, we formulate the task of prompt attribution for generation interpretation as a combinatorial optimization problem, and introduce a probabilistic algorithm to search for the casual input combination in the discrete space. We define and utilize multiple metrics to evaluate the produced explanations, demonstrating both the faithfulness and efficiency of our framework.",291141738,6,42,,
10.18653/v1/2025.acl-long.1253,Delta-KNN: Improving Demonstration Selection in In-Context Learning for Alzheimer's Disease Detection,"Chuyuan Li, Raymond Li, T. Field, Giuseppe Carenini",Annual Meeting of the Association for Computational Linguistics,2025,"Alzheimer's Disease (AD) is a progressive neurodegenerative disorder that leads to dementia, and early intervention can greatly benefit from analyzing linguistic abnormalities. In this work, we explore the potential of Large Language Models (LLMs) as health assistants for AD diagnosis from patient-generated text using in-context learning (ICL), where tasks are defined through a few input-output examples. Empirical results reveal that conventional ICL methods, such as similarity-based selection, perform poorly for AD diagnosis, likely due to the inherent complexity of this task. To address this, we introduce Delta-KNN, a novel demonstration selection strategy that enhances ICL performance. Our method leverages a delta score to assess the relative gains of each training example, coupled with a KNN-based retriever that dynamically selects optimal""representatives""for a given input. Experiments on two AD detection datasets across three open-source LLMs demonstrate that Delta-KNN consistently outperforms existing ICL baselines. Notably, when using the Llama-3.1 model, our approach achieves new state-of-the-art results, surpassing even supervised classifiers.",291170256,1,60,,
10.18653/v1/2025.acl-long.1140,MobiLoRA: Accelerating LoRA-based LLM Inference on Mobile Devices via Context-aware KV Cache Optimization,"Borui Li, Yitao Wang, Haoran Ma, Ligeng Chen, Jun Xiao, Shuai Wang",Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),2025,(missing abstract),291694901,0,0,,
10.18653/v1/2025.acl-long.1211,RefreshKV: Updating Small KV Cache During Long-form Generation,"Fangyuan Xu, Tanya Goyal, Eunsol Choi",Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),2025,(missing abstract),291718091,4,0,,
10.18653/v1/2025.acl-long.652,MadaKV: Adaptive Modality-Perception KV Cache Eviction for Efficient Multimodal Long-Context Inference,"Kunxi Li, Zhonghua Jiang, Zhouzhou Shen, ZhaodeWang ZhaodeWang, Chengfei Lv, Shengyu Zhang, Fan Wu, Fei Wu",Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),2025,(missing abstract),291718348,0,0,,
